[{"authors":["D Roy√©","Mar√≠a T Zarrabeitia","Javier Riancho","Ana Santurt√∫n"],"categories":null,"content":"","date":1554076800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1554076800,"objectID":"1bb4954049456a115c245d50b0442dcc","permalink":"/es/publication/ictus_madrid_2019/","publishdate":"2019-04-01T00:00:00Z","relpermalink":"/es/publication/ictus_madrid_2019/","section":"publication","summary":"The understanding of the role of environment on the pathogenesis of stroke is gaining importance in the context of climate change. This study analyzes the temporal pattern of ischemic stroke (IS) in Madrid, Spain, during a 13-year period (2001-2013), and the relationship between ischemic stroke (admissions and deaths) incidence and environmental factors on a daily scale by using a quasi-Poisson regression model. To assess potential delayed and non-linear effects of air pollutants and Apparent Temperature (AT), a biometeorological index which represents human thermal comfort on IS, a lag non-linear model was fitted in a generalized additive model. The mortality rate followed a downward trend over the studied period, however admission rates progressively increased. Our results show that both increases and decreases in AT had a marked relationship with IS deaths, while hospital admissions were only associated with low AT. When analyzing the cumulative effects (for lag 0 to 14 days), with an AT of 1.7¬∞C (percentile 5%) a RR of 1.20 (95% CI, 1.05-1.37) for IS mortality and a RR of 1.09 (95% CI, 0.91-1.29) for morbidity is estimated. Concerning gender differences, men show higher risks of mortality in low temperatures and women in high temperatures. No significant relationship was found between air pollutant concentrations and IS morbi mortality, but this result must be interpreted with caution, since there are strong spatial fluctuations of the former between nearby geographical areas that make it difficult to perform correlation analyses.","tags":["efectos de corto plazo","Espa√±a","Madrid","ambiente t√©rmico","ictus isqu√©mico","contaminaci√≥n atmosferica","temperatura aparente","mortalidad","ingresos hospitalarios"],"title":"A time series analysis of the relationship between Apparent Temperature, Air Pollutants and Ischemic Stroke in Madrid, Spain","type":"publication"},{"authors":null,"categories":["gesti√≥n","R","R:intermedio"],"content":"\rCuando trabajamos con diferentes fuentes de datos, nos podemos encontrar con tablas distrubidas sobre varias hojas de Excel. En este post vamos a importar la temperatura media diaria de Madrid y Berl√≠n que se encuentra en dos archvios de Excel con hojas para cada a√±o entre 2000 y 2005: descarga.\nPaquetes\rEn este post usaremos los siguientes paquetes:\n\r\rPaquete\rDescripci√≥n\r\r\r\rtidyverse\rConjunto de paquetes (visualizaci√≥n y manipulaci√≥n de datos): ggplot2, dplyr, purrr,etc.\r\rfs\rProporciona una interfaz uniforme y multiplataforma para las operaciones del sistema de archivos\r\rreadxl\rImportar archivos Excel\r\r\r\r#instalamos los paquetes si hace falta\rif(!require(\u0026quot;tidyverse\u0026quot;)) install.packages(\u0026quot;tidyverse\u0026quot;)\rif(!require(\u0026quot;fs\u0026quot;)) install.packages(\u0026quot;fs\u0026quot;)\rif(!require(\u0026quot;readxl\u0026quot;)) install.packages(\u0026quot;readxl\u0026quot;)\r#librer√≠as\rlibrary(tidyverse)\rlibrary(fs)\rlibrary(readxl)\rPor defecto, la funci√≥n read_excel() importa la primera hoja. Para importar una hoja diferente es necesario indicarlo con el argumento sheet o bien el n√∫mero o el nombre (segundo argumento).\n#importar primera hoja\rread_excel(\u0026quot;madrid_temp.xlsx\u0026quot;)\r## # A tibble: 366 x 3\r## date ta yr\r## \u0026lt;dttm\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 2000-01-01 00:00:00 5.4 2000\r## 2 2000-01-02 00:00:00 5 2000\r## 3 2000-01-03 00:00:00 3.5 2000\r## 4 2000-01-04 00:00:00 4.3 2000\r## 5 2000-01-05 00:00:00 0.6 2000\r## 6 2000-01-06 00:00:00 3.8 2000\r## 7 2000-01-07 00:00:00 6.2 2000\r## 8 2000-01-08 00:00:00 5.4 2000\r## 9 2000-01-09 00:00:00 5.5 2000\r## 10 2000-01-10 00:00:00 4.8 2000\r## # ... with 356 more rows\r#importar hoja 3\rread_excel(\u0026quot;madrid_temp.xlsx\u0026quot;,3)\r## # A tibble: 365 x 3\r## date ta yr\r## \u0026lt;dttm\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 2002-01-01 00:00:00 8.7 2002\r## 2 2002-01-02 00:00:00 7.4 2002\r## 3 2002-01-03 00:00:00 8.5 2002\r## 4 2002-01-04 00:00:00 9.2 2002\r## 5 2002-01-05 00:00:00 9.3 2002\r## 6 2002-01-06 00:00:00 7.3 2002\r## 7 2002-01-07 00:00:00 5.4 2002\r## 8 2002-01-08 00:00:00 5.6 2002\r## 9 2002-01-09 00:00:00 6.8 2002\r## 10 2002-01-10 00:00:00 6.1 2002\r## # ... with 355 more rows\rLa funci√≥n excel_sheets() permite extraer los nombres de las hojas.\npath \u0026lt;- \u0026quot;madrid_temp.xlsx\u0026quot;\rpath%\u0026gt;%\rexcel_sheets()\r## [1] \u0026quot;2000\u0026quot; \u0026quot;2001\u0026quot; \u0026quot;2002\u0026quot; \u0026quot;2003\u0026quot; \u0026quot;2004\u0026quot; \u0026quot;2005\u0026quot;\rEl resultado nos indica que en cada hoja encontramos un a√±o de los datos desde 2000 a 2005. La funci√≥n m√°s importante para leer m√∫ltiples hojas es map() del paquete {purrr} que forma parte de la colecci√≥n de paquetes {tidyverse}. map() permite aplicar una funci√≥n a cada elemento de un vector o lista.\npath \u0026lt;- \u0026quot;madrid_temp.xlsx\u0026quot;\rmad \u0026lt;- path%\u0026gt;%\rexcel_sheets()%\u0026gt;%\rset_names()%\u0026gt;%\rmap(read_excel,\rpath=path)\rstr(mad)\r## List of 6\r## $ 2000:Classes \u0026#39;tbl_df\u0026#39;, \u0026#39;tbl\u0026#39; and \u0026#39;data.frame\u0026#39;: 366 obs. of 3 variables:\r## ..$ date: POSIXct[1:366], format: \u0026quot;2000-01-01\u0026quot; ...\r## ..$ ta : num [1:366] 5.4 5 3.5 4.3 0.6 3.8 6.2 5.4 5.5 4.8 ...\r## ..$ yr : num [1:366] 2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...\r## $ 2001:Classes \u0026#39;tbl_df\u0026#39;, \u0026#39;tbl\u0026#39; and \u0026#39;data.frame\u0026#39;: 365 obs. of 3 variables:\r## ..$ date: POSIXct[1:365], format: \u0026quot;2001-01-01\u0026quot; ...\r## ..$ ta : num [1:365] 8.2 8.8 7.5 9.2 10 9 5.5 4.6 3 7.9 ...\r## ..$ yr : num [1:365] 2001 2001 2001 2001 2001 ...\r## $ 2002:Classes \u0026#39;tbl_df\u0026#39;, \u0026#39;tbl\u0026#39; and \u0026#39;data.frame\u0026#39;: 365 obs. of 3 variables:\r## ..$ date: POSIXct[1:365], format: \u0026quot;2002-01-01\u0026quot; ...\r## ..$ ta : num [1:365] 8.7 7.4 8.5 9.2 9.3 7.3 5.4 5.6 6.8 6.1 ...\r## ..$ yr : num [1:365] 2002 2002 2002 2002 2002 ...\r## $ 2003:Classes \u0026#39;tbl_df\u0026#39;, \u0026#39;tbl\u0026#39; and \u0026#39;data.frame\u0026#39;: 365 obs. of 3 variables:\r## ..$ date: POSIXct[1:365], format: \u0026quot;2003-01-01\u0026quot; ...\r## ..$ ta : num [1:365] 9.4 10.8 9.7 9.2 6.3 6.6 3.8 6.4 4.3 3.4 ...\r## ..$ yr : num [1:365] 2003 2003 2003 2003 2003 ...\r## $ 2004:Classes \u0026#39;tbl_df\u0026#39;, \u0026#39;tbl\u0026#39; and \u0026#39;data.frame\u0026#39;: 366 obs. of 3 variables:\r## ..$ date: POSIXct[1:366], format: \u0026quot;2004-01-01\u0026quot; ...\r## ..$ ta : num [1:366] 6.6 5.9 7.8 8.1 6.4 5.7 5.2 6.9 11.8 12.2 ...\r## ..$ yr : num [1:366] 2004 2004 2004 2004 2004 ...\r## $ 2005:Classes \u0026#39;tbl_df\u0026#39;, \u0026#39;tbl\u0026#39; and \u0026#39;data.frame\u0026#39;: 365 obs. of 3 variables:\r## ..$ date: POSIXct[1:365], format: \u0026quot;2005-01-01\u0026quot; ...\r## ..$ ta : num [1:365] 7.1 7.8 6.4 5.6 4.4 6.8 7.4 6 5.2 4.2 ...\r## ..$ yr : num [1:365] 2005 2005 2005 2005 2005 ...\rEl resultado es una lista nombrada con el nombre de cada hoja que contiene el data.frame. Dado que se trata de la misma tabla en todas las hojas, podr√≠amos usar la funci√≥n bind_rows(), no obstante, existe una variante de map()que directamente nos une todas las tablas por fila: map_df(). Si fuese necesario unir por columna se deber√≠a usar map_dfc().\npath \u0026lt;- \u0026quot;madrid_temp.xlsx\u0026quot;\rmad \u0026lt;- path%\u0026gt;%\rexcel_sheets()%\u0026gt;%\rset_names()%\u0026gt;%\rmap_df(read_excel,\rpath=path)\rmad\r## # A tibble: 2,192 x 3\r## date ta yr\r## \u0026lt;dttm\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 2000-01-01 00:00:00 5.4 2000\r## 2 2000-01-02 00:00:00 5 2000\r## 3 2000-01-03 00:00:00 3.5 2000\r## 4 2000-01-04 00:00:00 4.3 2000\r## 5 2000-01-05 00:00:00 0.6 2000\r## 6 2000-01-06 00:00:00 3.8 2000\r## 7 2000-01-07 00:00:00 6.2 2000\r## 8 2000-01-08 00:00:00 5.4 2000\r## 9 2000-01-09 00:00:00 5.5 2000\r## 10 2000-01-10 00:00:00 4.8 2000\r## # ... with 2,182 more rows\rEn nuestro caso tenemos una columna en cada hoja (a√±o, pero tambi√©n la fecha) que diferencia cada tabla. Si no fuera el caso, deber√≠amos usar el nombre de las hojas como nueva columna al unir todas. En bind_rows() puede hacerse con el argumento .id asignando un nombre para la columna. Lo mismo valdr√≠a para map_df().\npath \u0026lt;- \u0026quot;madrid_temp.xlsx\u0026quot;\rmad \u0026lt;- path%\u0026gt;%\rexcel_sheets()%\u0026gt;%\rset_names()%\u0026gt;%\rmap_df(read_excel,\rpath=path,\r.id=\u0026quot;yr2\u0026quot;)\rstr(mad)\r## Classes \u0026#39;tbl_df\u0026#39;, \u0026#39;tbl\u0026#39; and \u0026#39;data.frame\u0026#39;: 2192 obs. of 4 variables:\r## $ yr2 : chr \u0026quot;2000\u0026quot; \u0026quot;2000\u0026quot; \u0026quot;2000\u0026quot; \u0026quot;2000\u0026quot; ...\r## $ date: POSIXct, format: \u0026quot;2000-01-01\u0026quot; \u0026quot;2000-01-02\u0026quot; ...\r## $ ta : num 5.4 5 3.5 4.3 0.6 3.8 6.2 5.4 5.5 4.8 ...\r## $ yr : num 2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...\r¬øPero c√≥mo importamos m√∫ltiples archivos de Excel?\nPara ello, primero debemos conocer la funci√≥n dir_ls() del paquete {fs}. Es cierto que existe la funci√≥n dir() de R Base, pero las ventajas del reciente paquete son varias, pero especialmente es la compatibilidad con la colecci√≥n de {tidyverse}.\ndir_ls()\r## berlin_temp.xlsx featured.png index.es.html index.es.Rmd ## madrid_temp.xlsx\r#podemos filtrar los archivos que queremos\rdir_ls(regexp=\u0026quot;xlsx\u0026quot;) \r## berlin_temp.xlsx madrid_temp.xlsx\rImportamos los dos archivos de Excel que tenemos.\n#sin unir\rdir_ls(regexp=\u0026quot;xlsx\u0026quot;)%\u0026gt;%\rmap(read_excel)\r## $berlin_temp.xlsx\r## # A tibble: 366 x 3\r## date ta yr\r## \u0026lt;dttm\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 2000-01-01 00:00:00 1.2 2000\r## 2 2000-01-02 00:00:00 3.6 2000\r## 3 2000-01-03 00:00:00 5.7 2000\r## 4 2000-01-04 00:00:00 5.1 2000\r## 5 2000-01-05 00:00:00 2.2 2000\r## 6 2000-01-06 00:00:00 1.8 2000\r## 7 2000-01-07 00:00:00 4.2 2000\r## 8 2000-01-08 00:00:00 4.2 2000\r## 9 2000-01-09 00:00:00 4.2 2000\r## 10 2000-01-10 00:00:00 1.7 2000\r## # ... with 356 more rows\r## ## $madrid_temp.xlsx\r## # A tibble: 366 x 3\r## date ta yr\r## \u0026lt;dttm\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 2000-01-01 00:00:00 5.4 2000\r## 2 2000-01-02 00:00:00 5 2000\r## 3 2000-01-03 00:00:00 3.5 2000\r## 4 2000-01-04 00:00:00 4.3 2000\r## 5 2000-01-05 00:00:00 0.6 2000\r## 6 2000-01-06 00:00:00 3.8 2000\r## 7 2000-01-07 00:00:00 6.2 2000\r## 8 2000-01-08 00:00:00 5.4 2000\r## 9 2000-01-09 00:00:00 5.5 2000\r## 10 2000-01-10 00:00:00 4.8 2000\r## # ... with 356 more rows\r#uniendo con una nueva columna\rdir_ls(regexp=\u0026quot;xlsx\u0026quot;)%\u0026gt;%\rmap_df(read_excel,.id=\u0026quot;city\u0026quot;)\r## # A tibble: 732 x 4\r## city date ta yr\r## \u0026lt;chr\u0026gt; \u0026lt;dttm\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 berlin_temp.xlsx 2000-01-01 00:00:00 1.2 2000\r## 2 berlin_temp.xlsx 2000-01-02 00:00:00 3.6 2000\r## 3 berlin_temp.xlsx 2000-01-03 00:00:00 5.7 2000\r## 4 berlin_temp.xlsx 2000-01-04 00:00:00 5.1 2000\r## 5 berlin_temp.xlsx 2000-01-05 00:00:00 2.2 2000\r## 6 berlin_temp.xlsx 2000-01-06 00:00:00 1.8 2000\r## 7 berlin_temp.xlsx 2000-01-07 00:00:00 4.2 2000\r## 8 berlin_temp.xlsx 2000-01-08 00:00:00 4.2 2000\r## 9 berlin_temp.xlsx 2000-01-09 00:00:00 4.2 2000\r## 10 berlin_temp.xlsx 2000-01-10 00:00:00 1.7 2000\r## # ... with 722 more rows\rAhora bien, en este caso s√≥lo importamos la primera hoja de cada archivo Excel. Para resolver este problema, debemos crear nuestra propia funci√≥n. En esta funci√≥n hacemos lo que hicimos previamente de forma individual.\nread_multiple_excel \u0026lt;- function(path) {\rpath%\u0026gt;%\rexcel_sheets() %\u0026gt;% set_names() %\u0026gt;% map_df(read_excel, path = path)\r}\rAplicamos nuestra funci√≥n creada para importar m√∫ltiples hojas de varios archivos Excel.\n#por separado\rdata \u0026lt;- dir_ls(regexp=\u0026quot;xlsx\u0026quot;) %\u0026gt;% map(read_multiple_excel)\rstr(data)\r## List of 2\r## $ berlin_temp.xlsx:Classes \u0026#39;tbl_df\u0026#39;, \u0026#39;tbl\u0026#39; and \u0026#39;data.frame\u0026#39;: 2192 obs. of 3 variables:\r## ..$ date: POSIXct[1:2192], format: \u0026quot;2000-01-01\u0026quot; ...\r## ..$ ta : num [1:2192] 1.2 3.6 5.7 5.1 2.2 1.8 4.2 4.2 4.2 1.7 ...\r## ..$ yr : num [1:2192] 2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...\r## $ madrid_temp.xlsx:Classes \u0026#39;tbl_df\u0026#39;, \u0026#39;tbl\u0026#39; and \u0026#39;data.frame\u0026#39;: 2192 obs. of 3 variables:\r## ..$ date: POSIXct[1:2192], format: \u0026quot;2000-01-01\u0026quot; ...\r## ..$ ta : num [1:2192] 5.4 5 3.5 4.3 0.6 3.8 6.2 5.4 5.5 4.8 ...\r## ..$ yr : num [1:2192] 2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...\r#unir todas\rdata_df \u0026lt;- dir_ls(regexp=\u0026quot;xlsx\u0026quot;) %\u0026gt;% map_df(read_multiple_excel,\r.id=\u0026quot;city\u0026quot;)\rstr(data_df)\r## Classes \u0026#39;tbl_df\u0026#39;, \u0026#39;tbl\u0026#39; and \u0026#39;data.frame\u0026#39;: 4384 obs. of 4 variables:\r## $ city: chr \u0026quot;berlin_temp.xlsx\u0026quot; \u0026quot;berlin_temp.xlsx\u0026quot; \u0026quot;berlin_temp.xlsx\u0026quot; \u0026quot;berlin_temp.xlsx\u0026quot; ...\r## $ date: POSIXct, format: \u0026quot;2000-01-01\u0026quot; \u0026quot;2000-01-02\u0026quot; ...\r## $ ta : num 1.2 3.6 5.7 5.1 2.2 1.8 4.2 4.2 4.2 1.7 ...\r## $ yr : num 2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...\r\r","date":1552176000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1552176000,"objectID":"d08ba3e4444285e38a94522cbea8f517","permalink":"/es/2019/importar-varias-hojas-excel-en-r/","publishdate":"2019-03-10T00:00:00Z","relpermalink":"/es/2019/importar-varias-hojas-excel-en-r/","section":"post","summary":"Cuando trabajamos con diferentes fuentes de datos, nos podemos encontrar con tablas distrubidas sobre varias hojas de Excel. En este post vamos a importar la temperatura media diaria de Madrid y Berl√≠n que se encuentran en dos archvios de Excel con hojas para cada a√±o entre 2000 y 2005.","tags":["excel","hojas","importar"],"title":"Importar varias hojas Excel en R","type":"post"},{"authors":null,"categories":["sig","R","R:elemental"],"content":"\rEn geograf√≠a, la distancia al mar es una variable fundamental, especialmente relevante a la hora de modelizar. Por ejemplo, en interpolaciones de la temperatura del aire habitualmente se hace uso de la distancia al mar como variable predictora, ya que existe una relaci√≥n casual entre ambas que explica la variaci√≥n espacial. ¬øC√≥mo podemos estimar la distancia (m√°s corta) a la costa en R?\nPaquetes\rEn este post usaremos los siguientes paquetes:\n\r\rPaquete\rDescripci√≥n\r\r\r\rtidyverse\rConjunto de librer√≠as (visualizaci√≥n y manipulaci√≥n de datos): ggplot2, dplyr, etc.\r\rsf\rSimple Feature: importar, exportar y manipular datos vectoriales\r\rraster\rImportar, exportar y manipular raster\r\rrnaturalearth\rConjunto de mapas vectoriales ‚Äònatural earth‚Äô\r\rRColorBrewer\rPaletas de colores\r\r\r\r#instalamos los paquetes si hace falta\rif(!require(\u0026quot;tidyverse\u0026quot;)) install.packages(\u0026quot;tidyverse\u0026quot;)\rif(!require(\u0026quot;sf\u0026quot;)) install.packages(\u0026quot;sf\u0026quot;)\rif(!require(\u0026quot;raster\u0026quot;)) install.packages(\u0026quot;raster\u0026quot;)\rif(!require(\u0026quot;rnaturalearth\u0026quot;)) install.packages(\u0026quot;rnaturalearth\u0026quot;)\r#librer√≠as\rlibrary(rnaturalearth)\rlibrary(sf)\rlibrary(raster)\rlibrary(tidyverse)\rlibrary(RColorBrewer)\r\rLa costa de Islandia como ejemplo\rNuestro ejemplo en este post ser√° Islandia, como es un territorio insular facilitar√° el ensayo y de este modo es posible mostrar el proceso de forma sencilla. La librer√≠a rnaturalearth permite importar los l√≠mites de pa√≠ses (con diferentes niveles administrativos) de todo el mundo. Los datos vienen de la plataforma naturalearthdata.com. Recomiendo explorar la librer√≠a, m√°s info aqu√≠. La funci√≥n ne_countries( ) importa los l√≠mites de pa√≠ses. En este caso indicamos con el argumento scale la resoluci√≥n (10,50 o 110m), con country indicamos el pa√≠s concreto de inter√©s y con returnclass determinamos que clase queremos (sf o sp), en nuestro caso sf (simple feature).\nworld \u0026lt;- ne_countries(scale=50) #mapamundi con 50m de resoluci√≥n\rplot(world) #tiene clase sp por defecto\r#importamos los l√≠mites de Islandia iceland \u0026lt;- ne_countries(scale=10,country = \u0026quot;Iceland\u0026quot;,returnclass = \u0026quot;sf\u0026quot;)\r#info del objeto vectorial\riceland\r## Simple feature collection with 1 feature and 94 fields\r## geometry type: MULTIPOLYGON\r## dimension: XY\r## bbox: xmin: -24.53991 ymin: 63.39671 xmax: -13.50292 ymax: 66.56415\r## epsg (SRID): 4326\r## proj4string: +proj=longlat +datum=WGS84 +no_defs\r## featurecla scalerank labelrank sovereignt sov_a3 adm0_dif level\r## 188 Admin-0 country 0 3 Iceland ISL 0 2\r## type admin adm0_a3 geou_dif geounit gu_a3 su_dif\r## 188 Sovereign country Iceland ISL 0 Iceland ISL 0\r## subunit su_a3 brk_diff name name_long brk_a3 brk_name brk_group\r## 188 Iceland ISL 0 Iceland Iceland ISL Iceland \u0026lt;NA\u0026gt;\r## abbrev postal formal_en formal_fr name_ciawf note_adm0\r## 188 Iceland IS Republic of Iceland \u0026lt;NA\u0026gt; Iceland \u0026lt;NA\u0026gt;\r## note_brk name_sort name_alt mapcolor7 mapcolor8 mapcolor9 mapcolor13\r## 188 \u0026lt;NA\u0026gt; Iceland \u0026lt;NA\u0026gt; 1 4 4 9\r## pop_est pop_rank gdp_md_est pop_year lastcensus gdp_year\r## 188 339747 10 16150 2017 NA 2016\r## economy income_grp wikipedia fips_10_\r## 188 2. Developed region: nonG7 1. High income: OECD NA IC\r## iso_a2 iso_a3 iso_a3_eh iso_n3 un_a3 wb_a2 wb_a3 woe_id woe_id_eh\r## 188 IS ISL ISL 352 352 IS ISL 23424845 23424845\r## woe_note adm0_a3_is adm0_a3_us adm0_a3_un adm0_a3_wb\r## 188 Exact WOE match as country ISL ISL NA NA\r## continent region_un subregion region_wb name_len\r## 188 Europe Europe Northern Europe Europe \u0026amp; Central Asia 7\r## long_len abbrev_len tiny homepart min_zoom min_label max_label\r## 188 7 7 NA 1 0 2 7\r## ne_id wikidataid name_ar name_bn name_de name_en name_es name_fr\r## 188 1159320917 Q189 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; Island Iceland Islandia Islande\r## name_el name_hi name_hu name_id name_it name_ja name_ko name_nl\r## 188 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; Izland Islandia Islanda \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; IJsland\r## name_pl name_pt name_ru name_sv name_tr name_vi name_zh\r## 188 Islandia Isl√¢ndia \u0026lt;NA\u0026gt; Island Izlanda Iceland \u0026lt;NA\u0026gt;\r## geometry\r## 188 MULTIPOLYGON (((-14.56363 6...\r#aqu√≠ Islandia\rplot(iceland)\rPor defecto, la funci√≥n plot( ) con la clase sf nos crea tantas facetas del mapa como variables tiene. Para limitarlo podemos usar o bien con el nombre de una variable plot(iceland[\u0026quot;admin\u0026quot;]) o el argumento max.plot plot(iceland,max.plot=1). Con el argumento max.plot=1 la funci√≥n usa la primera variable disponible del mapa.\nAdem√°s, vemos en la informaci√≥n del objeto sf que la proyecci√≥n es WGS84 con grados decimales (c√≥digo EPSG:4326). Para el c√°lculo de distancias es m√°s conveniente usar metros en lugar de grados. Debido a ello, lo primero que hacemos es transformar el mapa de Islandia a UTM Zona 27 (c√≥digo EPSG:3055). M√°s informaci√≥n sobre EPSG y proyecciones aqu√≠. Con ese objetivo, usamos la funci√≥n st_transform( ). Simplemente indicamos el mapa y el c√≥digo EPSG.\n#transformamos a UTM\riceland \u0026lt;- st_transform(iceland,3055)\r\rCrear una red de puntos\rTodav√≠a necesitamos los puntos donde queremos conocer la distancia. En nuestro caso ser√° una red regular de puntos en Islandia con una resoluci√≥n de 5km. Esa tarea la hacemos con la funci√≥n st_make_grid( ), indicando con el argumento cellsize la resoluci√≥n en la unidad del sistema de coordenadas (metros en nuestro caso) y qu√© geometr√≠a nos gustar√≠a crear what (poligonos, centros o esquinas).\n#crear red de puntos\rgrid \u0026lt;- st_make_grid(iceland,cellsize = 5000,what = \u0026quot;centers\u0026quot;)\r#nuestra red sobre la extensi√≥n de Islandia\rplot(grid)\r#exraemos s√≥lamente los puntos en los l√≠mites de Islandia\rgrid \u0026lt;- st_intersection(grid,iceland) #nuestra red ahora\rplot(grid)\r\rCalcular la distancia\rPara estimar la distancia usamos la funci√≥n st_distance( ) que nos devuelve un vector de distancias para todos nuestros puntos de la red. Pero antes es necesario transformar el mapa de Islandia de una forma de pol√≠gono (MULTIPOLYGON) a l√≠nea (MULTILINESTRING). M√°s detalles con ?st_cast.\n#convertimos Islandia de geometr√≠a poligono a l√≠nea\riceland \u0026lt;- st_cast(iceland,\u0026quot;MULTILINESTRING\u0026quot;)\r#c√°lculo de la distancia entre la costa y nuestros puntos\rdist \u0026lt;- st_distance(iceland,grid)\r#distancia con unidad en metros\rhead(dist)\r## Units: [m]\r## [1] 790.7906 1151.4360 1270.7603 3128.9057 2428.5677 4197.7472\r\rVisualizar la distancia calculada\rUna vez obtenida la distancia para nuestros puntos, podemos combinarlos con las coordenadas y plotearlos en ggplot2. Para ello, creamos un data.frame. El objeto dist es una matriz de una columna, por eso, tenemos que convertirla a vector con la funci√≥n as.vector( ). Adem√°s, dividimos por 1000 para convertir la distancia en metros a km. La funci√≥n st_coordinates( ) extrae las coordenadas de nuestros puntos. Para la visualizaci√≥n usamos un vector de colores con la gama RdGy (m√°s aqu√≠).\n#creamos un data.frame con la distancia y las coorendas de los puntos\rdf \u0026lt;- data.frame(dist=as.vector(dist)/1000,\rst_coordinates(grid))\r#estructura\rstr(df)\r## \u0026#39;data.frame\u0026#39;: 4104 obs. of 3 variables:\r## $ dist: num 0.791 1.151 1.271 3.129 2.429 ...\r## $ X : num 608796 613796 583796 588796 593796 ...\r## $ Y : num 7033371 7033371 7038371 7038371 7038371 ...\r#colores col_dist \u0026lt;- brewer.pal(11,\u0026quot;RdGy\u0026quot;)\rggplot(df,aes(X,Y,fill=dist))+ #variables\rgeom_tile()+ #geometr√≠a\rscale_fill_gradientn(colours=rev(col_dist))+ #colores para la distancia\rlabs(fill=\u0026quot;Distance (km)\u0026quot;)+ #nombre de la leyenda\rtheme_void()+ #estilo del mapa\rtheme(legend.position = \u0026quot;bottom\u0026quot;) #posici√≥n de la leyenda\r\rExportar la distancia como raster\rPara poder exportar la distancia con respecto al mar de Islandia, debemos usar la funci√≥n rasterize( ) de la librer√≠a raster.\nPrimero, es necesario crear un raster vac√≠o. En este raster debemos indicar la resoluci√≥n, en nuestro caso es de 5000m, la proyecci√≥n y la extensi√≥n del raster.\nLa proyecci√≥n la podemos extraer de la informaci√≥n del mapa de Islandia.\n\rLa extensi√≥n la conseguimos extraer de nuestros puntos grid con la funci√≥n extent( ). No obstante, esta √∫ltima funci√≥n necesita la clase sp, por eso pasamos el objeto grid en formato sf, √∫nicamente para ello, a la clase sp usando la funci√≥n as( ) y el argumento ‚ÄúSpatial‚Äù.\n\r\rAdem√°s de lo anterior, el data.frame df que creamos antes debemos convertir en clase sf. Por eso, aplicamos la funci√≥n st_as_sf( ) con el argumento coords indicando los nombres de las coordenadas. Adicionalmente, tambi√©n definimos el sistema de coordenadas que conocemos.\n\r\r#obtenemos la extensi√≥n\rext \u0026lt;- extent(as(grid,\u0026quot;Spatial\u0026quot;))\r#objeto extent\rext\r## class : Extent ## xmin : 338795.6 ## xmax : 848795.6 ## ymin : 7033371 ## ymax : 7383371\r#raster destino\rr \u0026lt;- raster(resolution=5000,ext=ext,crs=\u0026quot;+proj=utm +zone=27 +ellps=intl +towgs84=-73,47,-83,0,0,0,0 +units=m +no_defs\u0026quot;)\r#convertimos los puntos a un spatial object clase sf\rdist_sf \u0026lt;- st_as_sf(df,coords=c(\u0026quot;X\u0026quot;,\u0026quot;Y\u0026quot;))%\u0026gt;%\rst_set_crs(3055)\r#creamos el raster de la distancia\rdist_raster \u0026lt;- rasterize(dist_sf,r,\u0026quot;dist\u0026quot;,fun=mean)\r#raster\rdist_raster\r## class : RasterLayer ## dimensions : 70, 102, 7140 (nrow, ncol, ncell)\r## resolution : 5000, 5000 (x, y)\r## extent : 338795.6, 848795.6, 7033371, 7383371 (xmin, xmax, ymin, ymax)\r## coord. ref. : +proj=utm +zone=27 +ellps=intl +towgs84=-73,47,-83,0,0,0,0 +units=m +no_defs ## data source : in memory\r## names : layer ## values : 0.006124901, 115.1712 (min, max)\r#plotear el raster\rplot(dist_raster)\r#exportamos el raster\rwriteRaster(dist_raster,file=\u0026quot;dist_islandia.tif\u0026quot;,format=\u0026quot;GTiff\u0026quot;, overwrite=TRUE)\rCon el c√°lculo de la distancia podemos llegar crear arte, como se ve en la cabezera de este post, que incluye un mapamundi √∫nicamente con la distancia al mar de todos los continentes. Una perspectiva diferente a nuestro mundo (aqu√≠ m√°s).\n\r","date":1546905600,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1546905600,"objectID":"f87c54a1462617a9bb20bc83c72f22e4","permalink":"/es/2019/calcular-la-distancia-al-mar-en-r/","publishdate":"2019-01-08T00:00:00Z","relpermalink":"/es/2019/calcular-la-distancia-al-mar-en-r/","section":"post","summary":"En geograf√≠a, la distancia al mar es una variable fundamental, especialmente relevante a la hora de modelizar. Por ejemplo, en interpolaciones de la temperatura del aire habitualmente se hace uso de la distancia al mar como variable predictora, ya que existe una relaci√≥n casual entre ambas que explica la variaci√≥n espacial. ¬øC√≥mo podemos estimar la distancia (m√°s corta) a la costa en R?","tags":["distancia","raster","calculo","variable"],"title":"Calcular la distancia al mar en R","type":"post"},{"authors":["F Mori-Gamarra","L Moure-Rodr√≠guez","X Sureda","C Carbiae","D Roy√©","A Montes-Mart√≠nez","F Cadaveira","F Caama√±o-Isorna"],"categories":null,"content":"","date":1545350400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1545350400,"objectID":"73e424dbc4f01c179ac85fe184da7c84","permalink":"/es/publication/alcohol_galicia2018/","publishdate":"2018-12-21T00:00:00Z","relpermalink":"/es/publication/alcohol_galicia2018/","section":"publication","summary":"Objetivo: Valorar la influencia que la densidad de los puntos de venta y los de venta y consumo de alcohol ejercen sobre los patrones de consumo de los/las j√≥venes preuniversitarios/as de Galicia. M√©todos: Se ha llevado a cabo un an√°lisis transversal de la cohorte de estudiantes de la Universidad de Santiago de Compostela (Cohorte Compostela 2016). Se calcularon las prevalencias de consumo para cada uno de los municipios de procedencia de los/las estudiantes de primer ciclo durante el a√±o anterior al ingreso. Se valor√≥ la asociaci√≥n del consumo de riesgo de alcohol (CRA) y consumo intensivo de alcohol (CIA) con un modelo log√≠stico, considerando como variables independientes la poblaci√≥n del municipio, la densidad de locales de venta, la densidad de locales de venta y consumo de alcohol, y la densidad de ambos tipos de locales en el municipio. Resultados: La prevalencia de CRA fue del 60,5% (interval de confianza del 95% [IC95%]: 58,4-62,5) y la de CIA de 28,5% (IC95%: 26,7-30,2). Se observ√≥ una gran variabilidad seg√∫n el municipio de procedencia. El modelo log√≠stico multivariante mostr√≥ que los municipios con una densidad de 8,42-9,34 de ambos tipos de locales por mil habitantes presentaban mayor riesgo de CRA (odds ratio [OR]:1.39; IC95%: 1,09-1,78) y de CIA (OR= 1,29; IC95%: 1,01-1,66). Conclusi√≥n: Estos datos sugieren la importancia de incluir la informaci√≥n del entorno al estudiar el consumo de alcohol. Conocer mejor el entorno podr√≠a ayudar a plantear pol√≠ticas que fomenten en la poblaci√≥n conductas m√°s saludables.","tags":["Densidad de puntos de venta de alcohol","Alcohol","Consumo de menores de edad","Adolescentes"],"title":"Densidad de los puntos de venta de alcohol y su consumo en j√≥venes de Galicia","type":"publication"},{"authors":[],"categories":null,"content":"   Probability of a frost day (minimum temperature less than 0¬∫C) through the year in Europe. Data: E-OBS 18e.\n   Probability of a frost day (minimum temperature less than 0¬∫C/32¬∫F) through the year in the Contiguous United States. Data: PRISM. Platform: Google Earth Engine.\n\rLas anomal√≠as invernales de temperatura y precipitaci√≥n en Bilbao. Datos: ECA\u0026amp;D.\r\r\rLas anomal√≠as invernales de temperatura y precipitaci√≥n en Zaragoza. Datos: ECA\u0026amp;D.\r\r\rLas anomal√≠as invernales de temperatura y precipitaci√≥n en Santander. Datos: ECA\u0026amp;D.\r\r\rLas anomal√≠as invernales de temperatura y precipitaci√≥n en M√°laga. Datos: ECA\u0026amp;D.\r\r\rLas anomal√≠as invernales de temperatura y precipitaci√≥n en Sevilla. Datos: ECA\u0026amp;D.\r\r\rLas anomal√≠as invernales de temperatura y precipitaci√≥n en Santiago. Datos: ECA\u0026amp;D.\r\r\rLas anomal√≠as invernales de temperatura y precipitaci√≥n en Valencia. Datos: ECA\u0026amp;D.\r\r\rLas anomal√≠as invernales de temperatura y precipitaci√≥n en Vigo. Datos: ECA\u0026amp;D.\r\r\rLas anomal√≠as invernales de temperatura y precipitaci√≥n en A Coru√±a. Datos: ECA\u0026amp;D.\r\r\rAnomal√≠as de la temperatura media diaria en invierno de Madrid. Datos: ECA\u0026amp;D. Las series temporales se homogeneizaron con climatol.\r\r\rAnomal√≠as de la temperatura media diaria en invierno de Santander. Datos: ECA\u0026amp;D. Las series temporales se homogeneizaron con climatol.\r\r\rAnomal√≠as de la temperatura media diaria en invierno de Barcelona. Datos: ECA\u0026amp;D. Las series temporales se homogeneizaron con climatol.\r\r\rAnomal√≠as de la temperatura media diaria en invierno de Santiago. Datos: ECA\u0026amp;D. Las series temporales se homogeneizaron con climatol.\r\r\rAnomal√≠as de la temperatura media diaria en invierno de Bilbao. Datos: ECA\u0026amp;D. Las series temporales se homogeneizaron con climatol.\r\r\rAnomal√≠as de la temperatura media diaria en invierno de Sevilla. Datos: ECA\u0026amp;D. Las series temporales se homogeneizaron con climatol.\r\r\rAnomal√≠as de la temperatura media diaria en invierno de A Coru√±a. Datos: ECA\u0026amp;D. Las series temporales se homogeneizaron con climatol.\r\r\rAnomal√≠as de la temperatura media diaria en invierno de M√°laga. Datos: ECA\u0026amp;D. Las series temporales se homogeneizaron con climatol.\r\r\rPromedio del primer d√≠a de verano en Europa (temperatura m√°xima \u0026gt;25¬∫C). Datos: E-OSB 18e.\r\r\rDistribuci√≥n del promedio del primer d√≠a de verano en Europa (temperatura m√°xima \u0026gt;25¬∫C). Datos: E-OSB 18e.\r\r\rWarming stripes for several Spanish cities. These graphs represent and communicate climate change in a very illustrative and effective way. Data: ECA\u0026amp;D. Time series were homogenized with climatol. More: post.\r\r\r62 years of annual anomalies of precipitation (%) in peninsular Spain in a single graphic. Data: SPREAD.\r\r\rSummer anomaly of temperature and precipitation in Barcelona 1914-2018. Data: ECA\u0026amp;D.\r\r\rSummer anomaly of temperature and precipitation in Madrid 1920-2018. Data: ECA\u0026amp;D.\r\r\rSummer anomaly of temperature and precipitation in Santiago de Compostela 1950-2018. Data: ECA\u0026amp;D.\r\r\rMonthly precipitation anomaly registered in Santiago de Compostela in 2017. Data: ECA\u0026amp;D.\r\r\rMonthly precipitation anomaly registered in Barcelona in 2018. Data: ECA\u0026amp;D, opendata.aemet.es.\r\r\rCloud fraction anomaly for Europe (Summer 2018). Data: NASA/MODIS Platform: Google Earth Engine.\r\r\rTrends of first frost days in Barcelona 1950-2016. 12.1 days later each decade. Data: ECA\u0026amp;D.\r\r\rTrends of last frost days in Madrid 1920-2016. Data: ECA\u0026amp;D.\r\r\rTrends of first tropical nights in Barcelona 1950-2016. Data: ECA\u0026amp;D.\r\r\rTrends of last tropical nights in Barcelona 1950-2016. Data: ECA\u0026amp;D.\r\r\rTrends of first tropical night (minimum temperature \u0026gt; 20¬∫C) in Madrid 1920-2016. -2.3 days earlier each decade. Data: ECA\u0026amp;D.\r\r\rTrends of last tropical night (minimum temperature \u0026gt; 20¬∫C) in Madrid 1920-2016. 1.9 days later each decade. Data: ECA\u0026amp;D.\r\r\rTrends of frist days with more than 30¬∫C in several Spanish cities. Data: ECA\u0026amp;D.\r\r\rTrends of last days with more than 30¬∫C in several Spanish cities. Data: ECA\u0026amp;D.\r\r\rAverage of consecutive days without rainfall 1950-2012. Data: SPREAD.\r\r\rAverage of consecutive days without rainfall by seasons 1950-2012 in the Iberian Peninsula. Data: SPREAD.\r\r\rAnnual precipitation per inhabitant in Europe based on gridded population (1km resolution) and precipitation (0.25¬∫) data. Data: ECA\u0026amp;D, SEDAC.\r\r\rAverage cloud fraction for summer 2018 and normal 2001-2018 in Europe. Data: NASA/MODIS Platform: Google Earth Engine.\r\r\rLand Surface Temperature anomaly for summer 2018 in Europe. Data: NASA/MODIS Platform: Google Earth Engine.\r\r\rAverage Land Surface Temperature for summer 2018 and normal 2001-2018 in Europe. Data: NASA/MODIS Platform: Google Earth Engine.\r\r\rDistribution of temperature anomalies in autumn according to different decades in Barcelona. You can clearly see how the autumn is getting warmer due to global warming. Data: ECA\u0026amp;D.\r\r\rDistribution of temperature anomalies in autumn according to different decades in Santiago de Compostela. You can clearly see how the autumn is getting warmer due to global warming. Data: ECA\u0026amp;D.\r\r\rClimate circles for several Spanish cities. For each day of the year the average of the maximum and minimum (bar length) and the average temperature (color) is indicated. Data: ECA\u0026amp;D.\r\r\rClimate circles for several European cities. For each day of the year the average of the maximum and minimum (bar length) and the average temperature (color) is indicated. Data: ECA\u0026amp;D.\r\r\rGraphic definition of climate and weather. The difference between weather and climate is particularly a scale of time. Single atmospheric conditions over a short period of time is weather, and climate is the statistical description of all these single condicions over a relatively long period of time.\r\r\rClimate circles for several Chilean cities. For each day of the year the average of the maximum and minimum (bar length) and the average temperature (color) is indicated. Data: explorador.cr2.cl.\r\r\rSummer months, mild winters, lot of sun and little wind, the climatic preferences for the Galician population. Map is based on survey results. More: article (galician).\r\r\rWhere is the lightning activity concentrated in a few days in Galicia? Values toward 1 indicate that a few days contribute much of all the lightning; instead, values toward 0 are places where more regularity is observed. More: article.\r\r\rHow is the lightning activity distributed annual and by seasons in Galicia? Data: meteogalicia. More: article.\r\r\rHow is the lightning activity distributed by month and hour in Galicia? Data: meteogalicia. More: article.\r\r\rSeasonal rainfall regime, i.e. ranking seasons according to average precipitation (1950-2017) in descending order in Europe. (P, spring; S, summer; A, autumn; W, winter). Data: ECA\u0026amp;D.\r\r\rSeasonal rainfall regime, i.e. ranking seasons according to average precipitation (1956-2006) in descending order in the contiguous United States. (P, spring; S, summer; A, autumn; W, winter). More: article, dataset.\r\r\rConcentration of Daily Precipitation (1956-2006) in the contiguous United States. (P, spring; S, summer; A, autumn; W, winter). The frequency distribution of daily precipitation amounts almost anywhere conforms to a negative exponential distribution, reflecting the fact that there are many small daily totals and few large ones. More: article, dataset.\r\r\rAverage cloud fraction for summer 2001-2018 in the contiguous United States. Data: NASA/MODIS. Platform: Google Earth Engine.\r\r\rAverage cloud fraction for winter 2001-2018 in the contiguous United States. Data: NASA/MODIS. Platform: Google Earth Engine.\r\r\rSummer day probability (maximum temperature \u0026gt; 25¬∫C) for different dates in Europe. Data: ECA\u0026amp;D.\r\r\rSummer day probability (maximum temperature \u0026gt; 25¬∫C) through the year in Europe. Data: ECA\u0026amp;D.\r\r\rSummer day probability (maximum temperature \u0026gt; 25¬∫C) through the year in the pensinular Spain. Data: STEAD from Research Group climayagua.\r\r\rSummer day probability (maximum temperature \u0026gt; 25¬∫C) for different dates in the pensinular Spain. Data: STEAD from Research Group climayagua.\r\r\rSummer day probability (maximum temperature \u0026gt; 25¬∫C/77¬∫F) through the year in the Contiguous United States. Data: Maurer et al (2002).\r\r\rAnnual sunhours for Germany in 2017. Map is a result of a interpolation process based on sunhour registers and cloudiness from MODIS. Data: ECA\u0026amp;D, NASA/MODIS. Platform for MODIS: Google Earth Engine.\r\r\rWarming stripes for Lisboa. These graphs represent and communicate climate change in a very illustrative and effective way. Data: GISTEMP. More: post.\r\r\rWhere do we observe the trajectories of extratropical cyclones in Europe? Here the frequency for the months October to March between 1979-2010. Data: extra-tropical cyclone tracks.\r\r\rWarming stripes for Madrid. These graphs represent and communicate climate change in a very illustrative and effective way. Data: ECA\u0026amp;D. More: post.\r\r\rAverage cloud fraction for summer 2001-2018 in Germany. Data: NASA/MODIS. Platform: Google Earth Engine.\r\r\rAverage cloud fraction for winter 2001-2018 in Germany. Data: NASA/MODIS. Platform: Google Earth Engine.\r\r\rAnnual sunhours for Galicia (Spain) in 2017. Map is a result of a interpolation process based on sunhour registers and cloudiness from MODIS. Data: Meteogalicia, NASA/MODIS. Platform for MODIS: Google Earth Engine.\r\r\rAnnual sunhours for Spain in 2017. Map is a result of a interpolation process based on sunhour registers and cloudiness from MODIS. Data: ECA\u0026amp;D, NASA/MODIS. Platform for MODIS: Google Earth Engine.\r\r\rPotential insolation (sun hours) in Barcelona\u0026rsquo;s city center for July 21 and December 22. The calculation is based on the Sky View Factor. Estimation made using SAGA-GIS. Data: LiDAR-IGN.\r\r\rAverage Diurnal Land Surface Temperature for July 2017 in Europe. Data: NASA/MODIS Platform: Google Earth Engine.\r\r\rAverage Night Land Surface Temperature for July 2017 in Europe. Data: NASA/MODIS. Platform: Google Earth Engine.\r\r\rNumber of snow days on the ground in the Iberian Peninsula (2002-2017). The daily images with a binary code (condition: Snow_Cover_Daily_Tile == 200, and Fractional_Snow_Cover \u0026gt; 90) have been reclassified and than summed up and divided by the number of years. Data: NASA/MODIS. Platform: Google Earth Engine.\r\r\rClimate circles for several American cities. For each day of the year the average of the maximum and minimum (bar length) and the average temperature (color) is indicated. Data: NCDC-CDO/NOAA.\r\r\rAverage cloud fraction for summer 2018 and normal 2001-2017 in the Iberian Peninsular. Data: NASA/MODIS. Platform: Google Earth Engine.\r\r\rAverage cloud fraction for march 2018 and march 2001-2018 in the Iberian Peninsular. Data: NASA/MODIS. Platform: Google Earth Engine.\r\r\rAccumulated precipitation of 2017 compared to other years in Valladolid. Data: ECA\u0026amp;D.\r\r\rAccumulated precipitation of 2017 compared to other years in Vigo. Data: ECA\u0026amp;D.\r\r ","date":1544832000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1544832000,"objectID":"75473ca83a36f50bff87cff6d89ab60a","permalink":"/es/graphs/climate/","publishdate":"2018-12-15T00:00:00Z","relpermalink":"/es/graphs/climate/","section":"graphs","summary":" ","tags":["clima","tiempo","visualizaci√≥n","atmosfera","temperatura"],"title":"Clima y tiempo","type":"graphs"},{"authors":[],"categories":null,"content":"\r\rInspirado por el gran trabajo de @geo_coe, he creado un mapa de elevaci√≥n para el r√≠o serpenteante Ebro, tramo medio entre Logro√±o y Zaragoza en Espa√±a. Datos: Modelo Digital del Terreno - MDT05.\r\r\rInspirado por el gran trabajo de @geo_coe, he creado un mapa de elevaci√≥n para el r√≠o serpenteante Alag√≥n, afluente m√°s largo del r√≠o Tajo en Espa√±a. Datos: Modelo Digital del Terreno - MDT05.\r\r\rUrban growth of Santiag de Compostela from before 1800 until today. Data: Catastro INSPIRE QGIS-Plugin.\r\r\rFlight routes of the ten busiest airports by passenger traffic in Europe based on 24 hour data for each airport. Data: https://www.flightradar24.com/. More: article (spanish)\r\r\rThe Sky View Factor is very useful urban spatial indicator for radiation and thermal environmental assessment. SVF describes how visible is the sky (0: the entire sky is blocked from view; 1: free view on the whole sky). Estimation made using SAGA-GIS. Data: LiDAR-IGN.\r\r\rEuropean flight density based on 24 hour data for each of the ten busiest airports by passenger. Data: https://www.flightradar24.com/. More: article (spanish)\r\r\rFlight routes of Frankfurt airport based on 24 hour data. Data: https://www.flightradar24.com/. More: article (spanish)\r\r\rFlight routes of the busiest airports in the Iberian Peninsula based on 24 hour data. Data: https://www.flightradar24.com/. More: article (spanish)\r\r\rFlight routes of Paris Charles de Gaulle airport based on 24 hour data. Data: https://www.flightradar24.com/. More: link\r\r\rUrban growth of Madrid from before 1800 until today. Data: Catastro INSPIRE QGIS-Plugin.\r\r\rTotal hours of fishing activity per km2 for the year 2016 in the Iberian Peninsula. Data: https://globalfishingwatch.org/\r\r\rTotal hours of fishing activity per km2 for the year 2016 in the Mediterranean. Data: https://globalfishingwatch.org/\r\r\rDistribution of gas stations (Point Of Interest) in Europe, extracted from the overpass API of OpenStreetMaps (June 2017). Data: OpenStreetMaps. More: script\r\r\rDistribution of drinking water (Point Of Interest) in Europe, extracted from the overpass API of OpenStreetMaps (June 2017). Data: OpenStreetMaps. More: article (spanish),script\r\r\rDistribution of gas and charging stations (Point Of Interest) in Europe, extracted from the overpass API of OpenStreetMaps (June 2017). Data: OpenStreetMaps. More: script\r\r\rDistribution of drinking water (Point Of Interest) in the World, extracted from the overpass API of OpenStreetMaps (June 2017). Data: OpenStreetMaps. More: article (Spanish),script\r\r\rAnother perspective on the world. Distance to the sea (the more black, the further away is the sea). Euclidean distance estimation made with R. More: article (Spanish)\r\r\rNumber of bars per 10,000 inhabitants in Europe, extracted from the overpass API of OpenStreetMaps (June 2017). Data: OpenStreetMaps. More: article (Spanish),script\r\r\rNumber of Cafes per 10,000 inhabitants in Europe, extracted from the overpass API of OpenStreetMaps (June 2017). Data: OpenStreetMaps. More: script\r\r\rDistribution of building heights at 10 meter resolution in European capitals. Data: COPERNICUS\r\r\rDifferences of building heights at 10 meter resolution in European capitals. Data: COPERNICUS\r\r\rUrban growth of Barcelona from before 1800 until today. Data: Catastro INSPIRE QGIS-Plugin.\r\r\rNumber of published articles in ElPa√≠s by year for the term \u0026lsquo;wildfire\u0026rsquo;. Data: elpais\r\r\rDistribution of fastfood restaurants in the contiguous United States, extracted from the overpass API of OpenStreetMaps (June 2017). Data: OpenStreetMaps. More: script\r\r\rNumber of fastfood restaurants per 10,000 inhabitants in Europe, extracted from the overpass API of OpenStreetMaps (June 2017). Data: OpenStreetMaps. More: script\r\r\rNumber of pharmacies per 10,000 inhabitants in Europe, extracted from the overpass API of OpenStreetMaps (June 2017). Data: OpenStreetMaps. More: script\r\r\rSpain leads access to Open Data in the EU. Data: europendataportal\r\r\rNumber of pubs per 10,000 inhabitants in Europe, extracted from the overpass API of OpenStreetMaps (June 2017). Data: OpenStreetMaps. More: script\r\r\rDistribution of fastfood restaurants in Europe., extracted from the overpass API of OpenStreetMaps (June 2017). Data: OpenStreetMaps. More: script\r\r\rNumber of restaurants per 10,000 inhabitants in Europe, extracted from the overpass API of OpenStreetMaps (June 2017). Data: OpenStreetMaps. More: script\r\r\rNumber of Kebab restaurants per 10,000 inhabitants in Europe, extracted from the overpass API of OpenStreetMaps (June 2017). Data: OpenStreetMaps. More: script\r\r ","date":1544832000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1515196800,"objectID":"50475b73777bcefbc7c28a465867fada","permalink":"/es/graphs/geography/","publishdate":"2018-12-15T00:00:00Z","relpermalink":"/es/graphs/geography/","section":"graphs","summary":" ","tags":["visualizaci√≥n","geograf√≠a","distribuci√≥n","humana","f√≠sica"],"title":"Geograf√≠a","type":"graphs"},{"authors":[],"categories":null,"content":"\r\rLight pollution by municipality in 2015. What is the municipality that emits the most artificial light? The map shows the Coefficient of Variation (standard deviation/mean) of each municipalities. Data: VIIRS Nighttime Lights NOAA (2015).\r\r\rWhich coast has more light pollution in Peninsular Spain? The coast margins include a buffer of 5km. Data: VIIRS Nighttime Lights NOAA (2016).\r\r\rLight pollution by municipality in 2015. What is the municipality that emits the most artificial light? The map shows the Coefficient of Variation (standard deviation/mean) of each municipalities. Data: VIIRS Nighttime Lights NOAA (2015).\r\r\rPollution spots from nitrogen dioxide (NO2) in autumn 2018 in the Iberian Peninsula. Clearly stand out Barcelona and Madrid. Data: NASA/MODIS. Platform: Google Earth Engine.\r\r\rPollution spots from nitrogen dioxide (NO2) in autumn 2018 in Germany. Clearly stands out the Rhine-Ruhr metropolitan region. Data: NASA/MODIS. Platform: Google Earth Engine.\r\r\rPollution spots from nitrogen dioxide (NO2) in autumn 2018 in the contiguous United States. Data: NASA/MODIS. Platform: Google Earth Engine.\r\r\rAir pollution in the Iberian Peninsula. Annual average of PM2.5 for 2016 seen by MODIS/MISR/SeaWiFS. Clearly visible are Madrid and Barcelona. Data: SEDAC.\r\r\rOur human footprint in the Iberian Peninsula, or rather, the pressure we exert on the terrestrial ecosystem. Data: Global terrestrial Human Footprint .\r\r ","date":1544832000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1544054400,"objectID":"0a4eb2a3127a9eac4b4ad1d7d8244d3c","permalink":"/es/graphs/environment/","publishdate":"2018-12-15T00:00:00Z","relpermalink":"/es/graphs/environment/","section":"graphs","summary":" ","tags":["visualizaci√≥n","ambiente","natura","contaminaci√≥n","ecosistema"],"title":"Medio ambiente","type":"graphs"},{"authors":[],"categories":null,"content":"\r\rPopulation pyramid of Galicia since 1975. Data: IGE\r\r\rPopulation pyramid of Galician provinces since 1975. Data: IGE\r\r\rPopulation pyramid of Spanish autonomous community since 1998. Data: INE\r\r\rMigration flows between Spanish autonomous communities in 2008. Data: INE\r\r ","date":1544832000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1544054400,"objectID":"3110f041ae5e0db11189de7b98b09047","permalink":"/es/graphs/population/","publishdate":"2018-12-15T00:00:00Z","relpermalink":"/es/graphs/population/","section":"graphs","summary":" ","tags":["visualizaci√≥n","demograf√≠a","humana","envejecimiento"],"title":"Populaci√≥n","type":"graphs"},{"authors":[],"categories":null,"content":"\r\rEvolution of adult obesity in Europe between 1975 and 2016. Data: ourwoldindata, script.\r\r\rNational Overdose Death in the US by different drugs since 1999, showing a horrifying trend. Data: ourwoldindata.\r\r ","date":1544832000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1515196800,"objectID":"311610b04f97c3287614999a5b749d99","permalink":"/es/graphs/health/","publishdate":"2018-12-15T00:00:00Z","relpermalink":"/es/graphs/health/","section":"graphs","summary":" ","tags":["visualizaci√≥n","salud","poblaci√≥n","enfermedad","global"],"title":"Salud","type":"graphs"},{"authors":null,"categories":["visualizaci√≥n","R","R:elemental"],"content":"\rEste a√±o se hicieron muy famosos en todo el mundo los llamados warming stripes, las tiras del calentamiento global, que fueron creadas por el cient√≠fico Ed Hawkins de la Universidad de Reading. Estos gr√°ficos representan y comunican el cambio clim√°tico de una forma muy ilustrativa y eficaz.\nVisualising global temperature change since records began in 1850. Versions for USA, central England \u0026amp; Toronto available too: https://t.co/H5Hv9YgZ7v pic.twitter.com/YMzdySrr3A\n\u0026mdash; Ed Hawkins (@ed_hawkins) May 23, 2018  A partir de su idea, cre√© tiras para ejemplos de Espa√±a, como el siguiente de Madrid.\n#Temperatura anual en #MadridRetiro desde 1920 a 2017. #CambioClimatico #dataviz #ggplot2 (idea de @ed_hawkins üôè) @Divulgameteo @edupenabad @climayagua @ClimaGroupUB @4gotas_com pic.twitter.com/wmLb5uczpT\n\u0026mdash; Dominic Roy√© (@dr_xeo) June 2, 2018  En este post voy a ense√±ar c√≥mo se pueden crear estas tiras en R con el paquete ggplot2. Aunque debo decir que existen muchos caminos en R que nos pueden llevar al mismo resultado o a uno similar, incluso dentro de ggplot2.\nDatos\rEn este caso usaremos las temperaturas anuales de Lisboa del GISS Surface Temperature Analysis que comprenden el periodo 1880-2018. Se trata de series temporales homogeneizadas. Tambi√©n se podr√≠an usar temperaturas mensuales u otras series temporales. El archivo se puede descargar aqu√≠. Lo primero que debemos hacer, siempre y cuando no lo hayamos hecho, es instalar la colecci√≥n de paquetes tidyverse que incluyen tambi√©n ggplot2. Adem√°s, nos har√° falta el paquete lubridate para el tratamiento de fechas. Despu√©s, importamos los datos de Lisboa que est√°n en formato csv.\n#instalamos los paquetes lubridate y tidyverse\rif(!require(\u0026quot;lubridate\u0026quot;)) install.packages(\u0026quot;lubridate\u0026quot;)\rif(!require(\u0026quot;tidyverse\u0026quot;)) install.packages(\u0026quot;tidyverse\u0026quot;)\r#librer√≠as\rlibrary(tidyverse)\rlibrary(lubridate)\rlibrary(RColorBrewer)\r#importar las temperaturas anuales\rtemp_lisboa \u0026lt;- read_csv(\u0026quot;temp_lisboa.csv\u0026quot;)\rstr(temp_lisboa)\r## Classes \u0026#39;spec_tbl_df\u0026#39;, \u0026#39;tbl_df\u0026#39;, \u0026#39;tbl\u0026#39; and \u0026#39;data.frame\u0026#39;: 139 obs. of 18 variables:\r## $ YEAR : num 1880 1881 1882 1883 1884 ...\r## $ JAN : num 9.17 11.37 10.07 10.86 11.16 ...\r## $ FEB : num 12 11.8 11.9 11.5 10.6 ...\r## $ MAR : num 13.6 14.1 13.5 10.5 12.4 ...\r## $ APR : num 13.1 14.4 14 13.8 12.2 ...\r## $ MAY : num 15.7 17.3 15.6 14.6 16.4 ...\r## $ JUN : num 17 19.2 17.9 17.2 19.1 ...\r## $ JUL : num 19.1 21.8 20.3 19.5 21.4 ...\r## $ AUG : num 20.6 23.5 21 21.6 22.4 ...\r## $ SEP : num 20.7 20 18 18.8 19.5 ...\r## $ OCT : num 17.9 16.3 16.4 15.8 16.4 ...\r## $ NOV : num 12.5 14.7 13.7 13.5 12.5 ...\r## $ DEC : num 11.07 9.97 10.66 9.46 10.25 ...\r## $ D-J-F : num 10.7 11.4 10.6 11 10.4 ...\r## $ M-A-M : num 14.1 15.2 14.3 12.9 13.6 ...\r## $ J-J-A : num 18.9 21.5 19.7 19.4 20.9 ...\r## $ S-O-N : num 17 17 16 16 16.1 ...\r## $ metANN: num 15.2 16.3 15.2 14.8 15.3 ...\r## - attr(*, \u0026quot;spec\u0026quot;)=\r## .. cols(\r## .. YEAR = col_double(),\r## .. JAN = col_double(),\r## .. FEB = col_double(),\r## .. MAR = col_double(),\r## .. APR = col_double(),\r## .. MAY = col_double(),\r## .. JUN = col_double(),\r## .. JUL = col_double(),\r## .. AUG = col_double(),\r## .. SEP = col_double(),\r## .. OCT = col_double(),\r## .. NOV = col_double(),\r## .. DEC = col_double(),\r## .. `D-J-F` = col_double(),\r## .. `M-A-M` = col_double(),\r## .. `J-J-A` = col_double(),\r## .. `S-O-N` = col_double(),\r## .. metANN = col_double()\r## .. )\rVemos en las columnas que tenemos valores mensuales y estacionales, y el valor anual. Pero antes de proceder a visualizar la temperatura anual, debemos sustituir los valores ausentes 999.9 por NA, usando la funci√≥n ifelse( ) que lleva una condici√≥n y los argumentos correspondientes a verdadero y falso de la condici√≥n dada.\n#selecionamos la columna del a√±o y la temperatura anual\rtemp_lisboa_yr \u0026lt;- select(temp_lisboa,YEAR,metANN)\r#cambiamos el nombre de la columna temp_lisboa_yr \u0026lt;- rename(temp_lisboa_yr,ta=metANN)\r#valores ausentes 999.9\rsummary(temp_lisboa_yr) \r## YEAR ta ## Min. :1880 Min. : 14.53 ## 1st Qu.:1914 1st Qu.: 15.65 ## Median :1949 Median : 16.11 ## Mean :1949 Mean : 37.38 ## 3rd Qu.:1984 3rd Qu.: 16.70 ## Max. :2018 Max. :999.90\rtemp_lisboa_yr \u0026lt;- mutate(temp_lisboa_yr,ta=ifelse(ta==999.9,NA,ta))\rCuando usamos el a√±o como variable, no solemos convertirlo en un objeto de fecha, no obstante es aconsejable. De este modo nos permite usar las funciones de fechas del paquete lubridate y las funciones de apoyo dentro de ggplot2. La funci√≥n str_c( ) del paquete stringr, forma parte de la colecci√≥n de tidyverse, es similar a paste( ) de R Base que nos permite combinar caracteres especificando un separador (sep=‚Äú-‚Äù). La funci√≥n ymd( ) (year month day) del paquete lubridate convierte una fecha en un objeto Date. Es posible combinar varias funciones haciendo uso del pipe operator %\u0026gt;% que ayuda a encadenar sin asignar el resultado a un nuevo objeto. Su uso es muy extendido especialmente con el paquete tidyverse. Si quieres saber m√°s de su uso, aqu√≠ tienes un tutorial.\ntemp_lisboa_yr \u0026lt;- mutate(temp_lisboa_yr,date=str_c(YEAR,\u0026quot;01-01\u0026quot;,sep=\u0026quot;-\u0026quot;)%\u0026gt;%ymd())\r\rCreando las tiras\rPrimero, creamos el estilo del gr√°fico, especificando todo los argumentos del aspecto que queremos ajustar. Partimos del estilo por defecto de theme_minimal( ). Adem√°s, asignamos los colores procedientes de RColorBrewer a un objeto col_srip. M√°s informaci√≥n sobre los colores usados aqu√≠.\ntheme_strip \u0026lt;- theme_minimal()+\rtheme(axis.text.y = element_blank(),\raxis.line.y = element_blank(),\raxis.title = element_blank(),\rpanel.grid.major=element_blank(),\rlegend.title = element_blank(),\raxis.text.x=element_text(vjust=3),\rpanel.grid.minor=element_blank(),\rplot.title=element_text(size=14,face=\u0026quot;bold\u0026quot;)\r)\rcol_strip \u0026lt;- brewer.pal(11,\u0026quot;RdBu\u0026quot;)\rbrewer.pal.info\r## maxcolors category colorblind\r## BrBG 11 div TRUE\r## PiYG 11 div TRUE\r## PRGn 11 div TRUE\r## PuOr 11 div TRUE\r## RdBu 11 div TRUE\r## RdGy 11 div FALSE\r## RdYlBu 11 div TRUE\r## RdYlGn 11 div FALSE\r## Spectral 11 div FALSE\r## Accent 8 qual FALSE\r## Dark2 8 qual TRUE\r## Paired 12 qual TRUE\r## Pastel1 9 qual FALSE\r## Pastel2 8 qual FALSE\r## Set1 9 qual FALSE\r## Set2 8 qual TRUE\r## Set3 12 qual FALSE\r## Blues 9 seq TRUE\r## BuGn 9 seq TRUE\r## BuPu 9 seq TRUE\r## GnBu 9 seq TRUE\r## Greens 9 seq TRUE\r## Greys 9 seq TRUE\r## Oranges 9 seq TRUE\r## OrRd 9 seq TRUE\r## PuBu 9 seq TRUE\r## PuBuGn 9 seq TRUE\r## PuRd 9 seq TRUE\r## Purples 9 seq TRUE\r## RdPu 9 seq TRUE\r## Reds 9 seq TRUE\r## YlGn 9 seq TRUE\r## YlGnBu 9 seq TRUE\r## YlOrBr 9 seq TRUE\r## YlOrRd 9 seq TRUE\rPara el gr√°fico final usamos la geometr√≠a geom_tile( ). Como los datos no tienen un valor espec√≠fico para el eje Y, usamos un valor dummy, aqu√≠ es 1. Adem√°s, ajusto el ancho de la barra de colores en la leyenda.\n ggplot(temp_lisboa_yr,\raes(x=date,y=1,fill=ta))+\rgeom_tile()+\rscale_x_date(date_breaks = \u0026quot;6 years\u0026quot;,\rdate_labels = \u0026quot;%Y\u0026quot;,\rexpand=c(0,0))+\rscale_y_continuous(expand=c(0,0))+\rscale_fill_gradientn(colors=rev(col_strip))+\rguides(fill=guide_colorbar(barwidth = 1))+\rlabs(title=\u0026quot;LISBOA 1880-2018\u0026quot;,\rcaption=\u0026quot;Datos: GISS Surface Temperature Analysis\u0026quot;)+\rtheme_strip\rEn el caso de que quisieramos obtener √∫nicamente las tiras, podemos usar theme_void( ) y el argumento show.legend=FALSE en geom_tile( ) para eliminar todos los elementos de estilo. Tambi√©n podemos cambiar el color para los valores NA, incluyendo el argumento na.value=‚Äúgrey70‚Äù en la funci√≥n scale_fill_gradientn( ).\n ggplot(temp_lisboa_yr,\raes(x=date,y=1,fill=ta))+\rgeom_tile(show.legend = FALSE)+\rscale_x_date(date_breaks = \u0026quot;6 years\u0026quot;,\rdate_labels = \u0026quot;%Y\u0026quot;,\rexpand=c(0,0))+\rscale_y_discrete(expand=c(0,0))+\rscale_fill_gradientn(colors=rev(col_strip))+\rtheme_void()\r\r","date":1543968000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1543968000,"objectID":"1586fbefaa1189d4ab4003f1df033d79","permalink":"/es/2018/c%C3%B3mo-crear-warming-stripes-in-r/","publishdate":"2018-12-05T00:00:00Z","relpermalink":"/es/2018/c%C3%B3mo-crear-warming-stripes-in-r/","section":"post","summary":"Este a√±o se hicieron muy famosos en todo el mundo los llamados warming stripes, las tiras del calentamiento global, que fueron creados por el cient√≠fico Ed Hawkins de la Universidad de Reading. Estos gr√°ficos representan y comunican el cambio clim√°tico de una forma muy ilustrativa y eficaz.","tags":["ggplot2","warming stripes","calentamiento global"],"title":"C√≥mo crear 'Warming Stripes' in R","type":"post"},{"authors":null,"categories":["visualizaci√≥n","R:elemental","R","mapping"],"content":"\rLa base de datos de Open Street Maps\rRecientemente cre√© un mapa de la distribuci√≥n de gasolineras y estaciones de carga el√©ctrica en Europa.\nPopulation density through the number of gas stations in Europe. #dataviz @AGE_Oficial @mipazos @simongerman600 @openstreetmap pic.twitter.com/eIUx2yn7ej\n\u0026mdash; Dominic Roy√© (@dr_xeo) February 25, 2018  ¬øC√≥mo se puede obtener estos datos?\nPues, en este caso us√© puntos de inter√©s (PDIs) de la base de datos de Open Street Maps (OSM). Obviamente OSM no s√≥lo contiene las carreteras, sino tambi√©n informaci√≥n que nos puede ser √∫til a la hora de usar un mapa, como por ejemplo las ubicaciones de hospitales o gasolineras. Para evitar la descarga de todo el OSM y extraer la informaci√≥n requerida, se puede hacer uso de una overpass API, que nos permite hacer consultas a la base de datos de OSM con nuestros propios criterios.\nUna forma f√°cil de acceder a una overpass API es a trav√©s de overpass-turbo.eu, que incluso incluye un asistente para construir una consulta y muestra los resultados sobre un mapa interactivo. Una explicaci√≥n detallada de la p√°gina anterior la podemos encontrar aqu√≠. Sin embargo, tenemos a nuestra disposic√≥n el paquete osmdata que nos permite crear y hacer las consultas directamente desde el entorno de R. A√∫n as√≠, el uso de la overpass-turbo.eu puede ser √∫til cuando no estamos seguros de lo que buscamos o tenemos alguna dificultad en construir la consulta.\n\rAcceso a la overpass API desde R\rEl primer paso, que debemos seguir, es instalar varios paquetes, en el caso de que no est√©n instaldos. En casi todos mis scripts hago uso de tidyverse que es una colecci√≥n fundamental de distintos paquetes, incluyendo dplyr (manipulaci√≥n de datos), ggplot2 (visualizaci√≥n), etc. El paquete sf es el nuevo est√°ndar para trabajar con datos espaciales y es compatible con ggplot2 y dplyr. Por √∫ltimo, ggmap nos facilita el trabajo para crear mapas.\n#instalamos los paquetes osmdata, sf, tidyverse y ggmap\rif(!require(\u0026quot;osmdata\u0026quot;)) install.packages(\u0026quot;osmdata\u0026quot;)\rif(!require(\u0026quot;tidyverse\u0026quot;)) install.packages(\u0026quot;tidyverse\u0026quot;)\rif(!require(\u0026quot;sf\u0026quot;)) install.packages(\u0026quot;sf\u0026quot;)\rif(!require(\u0026quot;ggmap\u0026quot;)) install.packages(\u0026quot;ggmap\u0026quot;)\r#cargamos las librer√≠as\rlibrary(tidyverse)\rlibrary(osmdata)\rlibrary(sf)\rlibrary(ggmap)\r\rConstruir una consulta\rAntes de crear una consulta, debemos conocer qu√© podemos filtrar. La funci√≥n available_features( ) nos devuelve un listado amplio de las caracter√≠sticas disponibles en OSM que a su vez tienen diferentes categor√≠as (tags). Est√°n disponibles m√°s detalles en la wiki de OSM aqu√≠. Por ejemplo, la caracter√≠stica shop contiene como categor√≠a entre otros supermarket, fishing, books, etc.\n#las primeras cinco caracter√≠sticas head(available_features())\r## [1] \u0026quot;4wd only\u0026quot; \u0026quot;abandoned\u0026quot; \u0026quot;abutters\u0026quot; \u0026quot;access\u0026quot; \u0026quot;addr\u0026quot; \u0026quot;addr:city\u0026quot;\r#instalaciones y establecimientos p√∫blicos\rhead(available_tags(\u0026quot;amenity\u0026quot;))\r## [1] \u0026quot;animal boarding\u0026quot; \u0026quot;animal shelter\u0026quot; \u0026quot;archive\u0026quot; \u0026quot;arts centre\u0026quot; ## [5] \u0026quot;atm\u0026quot; \u0026quot;baby hatch\u0026quot;\r#tiendas\rhead(available_tags(\u0026quot;shop\u0026quot;))\r## [1] \u0026quot;agrarian\u0026quot; \u0026quot;alcohol\u0026quot; \u0026quot;anime\u0026quot; \u0026quot;antiques\u0026quot; \u0026quot;appliance\u0026quot; \u0026quot;art\u0026quot;\rLa primera consulta: ¬øD√≥nde podemos encontrar cines en Madrid?\rPara construir la consulta se hace uso del pipe operator %\u0026gt;% que ayuda a encadenar varias funciones sin asignar el resultado a un nuevo objeto. Su uso es muy extendido especialmente con el paquete tidyverse. Si quieres saber m√°s de su uso, aqu√≠ tienes un tutorial.\nEn la primera parte de la consulta debemos indicar el lugar donde queremos extraer la informaci√≥n. La funci√≥n getbb( ) crea un rect√°ngulo de selecci√≥n para un lugar dado, buscando el nombre. La funci√≥n principal es opq( ) que construye la consulta final. A√±adimos con la funci√≥n add_osm_feature( ) nuestros criterios de filtro. En esta primera consulta buscaremos cines en Madrid. Por eso, usamos como clave amenity y como categor√≠a cinema. Existen varios formatos para obtener el resultado de la consulta. La funci√≥n osmdata_*( ) env√≠a la consulta al servidor y en funci√≥n del sufijo * sf/sp/xml nos devuelve el formato simple feature, spatial o XML.\n#construcci√≥n de la consulta\rq \u0026lt;- getbb(\u0026quot;Madrid\u0026quot;)%\u0026gt;%\ropq()%\u0026gt;%\radd_osm_feature(\u0026quot;amenity\u0026quot;, \u0026quot;cinema\u0026quot;)\rstr(q) #la estructura de la consulta\r## List of 4\r## $ bbox : chr \u0026quot;40.3119774,-3.8889539,40.6437293,-3.5179163\u0026quot;\r## $ prefix : chr \u0026quot;[out:xml][timeout:25];\\n(\\n\u0026quot;\r## $ suffix : chr \u0026quot;);\\n(._;\u0026gt;;);\\nout body;\u0026quot;\r## $ features: chr \u0026quot; [\\\u0026quot;amenity\\\u0026quot;=\\\u0026quot;cinema\\\u0026quot;]\u0026quot;\r## - attr(*, \u0026quot;class\u0026quot;)= chr [1:2] \u0026quot;list\u0026quot; \u0026quot;overpass_query\u0026quot;\rcinema \u0026lt;- osmdata_sf(q)\rcinema\r## Object of class \u0026#39;osmdata\u0026#39; with:\r## $bbox : 40.3119774,-3.8889539,40.6437293,-3.5179163\r## $overpass_call : The call submitted to the overpass API\r## $meta : metadata including timestamp and version numbers\r## $osm_points : \u0026#39;sf\u0026#39; Simple Features Collection with 195 points\r## $osm_lines : NULL\r## $osm_polygons : \u0026#39;sf\u0026#39; Simple Features Collection with 12 polygons\r## $osm_multilines : NULL\r## $osm_multipolygons : NULL\rVemos que el resultado es una lista de distintos objetos espaciales. En nuestro caso √∫nicamente nos interesar√≠a osm_points.\n¬øC√≥mo podemos visulizar estos puntos?\nLa ventaja de objetos sf es que para ggplot2 existe una geometr√≠a propia geom_sf( ). Adem√°s, haciendo uso de ggmap podemos incluir un mapa de fondo. La funci√≥n get_map( ) descarga el mapa para un lugar dado. En lugar puede ser una direcci√≥n, latitud/longitud o un rect√°ngulo de selecci√≥n. El argumento maptype nos permite indicar el estilo o tipo de mapa. Podemos consultar m√°s detalles en la ayuda de la funci√≥n ?get_map.\nCuando construimos un gr√°fico con ggplot habitualmente empezamos con ggplot( ). En este caso, se empieza por ggmap( ) que incluye el objeto con nuestro mapa de fondo. Despu√©s a√±adimos con geom_sf( ) los puntos de los cines en Madrid. Es importante indicar con el argumento inherit.aes=FALSE que debe usar aesthetic mappings del objeto espacial osm_points. Adem√°s, indicamos el color (colour, fill), transparencia (alpha), tipo y tama√±o (size) del c√≠rculo.\n#nuestro mapa de fondo\rmad_map \u0026lt;- get_map(getbb(\u0026quot;Madrid\u0026quot;),maptype = \u0026quot;toner-background\u0026quot;)\r#mapa final\rggmap(mad_map)+\rgeom_sf(data=cinema$osm_points,\rinherit.aes =FALSE,\rcolour=\u0026quot;#238443\u0026quot;,\rfill=\u0026quot;#004529\u0026quot;,\ralpha=.5,\rsize=4,\rshape=21)+\rlabs(x=\u0026quot;\u0026quot;,y=\u0026quot;\u0026quot;)\r\r¬øD√≥nde est√°n los supermercados de Mercadona?\rEn lugar de obtener un rect√°ngulo de selecci√≥n con la funci√≥n getbb( ) podemos construir nuestro propio. Para ello, creamos una matriz de dos columnas, siendo aqu√≠ el orden Este/Oeste/Sur/Norte. En la consulta usamos dos caracter√≠sticas: name y shop para poder filtrar supermercados que sean de esta marca en concreto. En funci√≥n del area o bien del volumen que tenga la consulta, es necesario ampliar el tiempo de espera. Por defecto, son 25 segundo (timeout).\nEl mapa que creamos en este caso se basa √∫nicamente en los puntos de supermercados. Por eso, usamos la gram√°tica habitual a√±adiendo la geometr√≠a geom_sf( ). La funci√≥n theme_void( ) elimina todo con excepci√≥n de los puntos. Por defecto, el objeto sf en ggplot crea ret√≠culas que se pueden quitar usando la funci√≥n coord_sf( ) con el argumento datum=NA.\n#rect√°ngulo de selecci√≥n para la Pen√≠nsula Ib√©rica\rm \u0026lt;- matrix(c(-10,5,30,46),ncol=2,byrow=TRUE)\rrow.names(m) \u0026lt;- c(\u0026quot;x\u0026quot;,\u0026quot;y\u0026quot;)\rnames(m) \u0026lt;- c(\u0026quot;min\u0026quot;,\u0026quot;max\u0026quot;)\r#construcci√≥n de la consulta\rq \u0026lt;- m %\u0026gt;% opq (timeout=25*100) %\u0026gt;%\radd_osm_feature(\u0026quot;name\u0026quot;,\u0026quot;Mercadona\u0026quot;)%\u0026gt;%\radd_osm_feature(\u0026quot;shop\u0026quot;,\u0026quot;supermarket\u0026quot;)\rstr(q) #estructura de la consulta\r## List of 4\r## $ bbox : chr \u0026quot;5,-10,46,30\u0026quot;\r## $ prefix : chr \u0026quot;[out:xml][timeout:2500];\\n(\\n\u0026quot;\r## $ suffix : chr \u0026quot;);\\n(._;\u0026gt;;);\\nout body;\u0026quot;\r## $ features: chr [1:2] \u0026quot; [\\\u0026quot;name\\\u0026quot;=\\\u0026quot;Mercadona\\\u0026quot;]\u0026quot; \u0026quot; [\\\u0026quot;shop\\\u0026quot;=\\\u0026quot;supermarket\\\u0026quot;]\u0026quot;\r## - attr(*, \u0026quot;class\u0026quot;)= chr [1:2] \u0026quot;list\u0026quot; \u0026quot;overpass_query\u0026quot;\r#consulta mercadona \u0026lt;- osmdata_sf(q)\r#mapa final del resultado\rggplot(mercadona$osm_points)+\rgeom_sf(colour=\u0026quot;#08519c\u0026quot;,\rfill=\u0026quot;#08306b\u0026quot;,\ralpha=.5,\rsize=1,\rshape=21)+\rcoord_sf(datum=NA)+\rtheme_void()\r\r\r","date":1541203200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1541203200,"objectID":"ce0faf06485edd221cd537202535fa95","permalink":"/es/2018/acceso-a-la-base-de-datos-de-openstreetmaps-desde-r/","publishdate":"2018-11-03T00:00:00Z","relpermalink":"/es/2018/acceso-a-la-base-de-datos-de-openstreetmaps-desde-r/","section":"post","summary":"Recientemente cre√© un mapa de la distribuci√≥n de las gasolineras y estaciones de carga el√©ctrica en Europa. ¬øC√≥mo se puede obtener estos datos? Pues, en este caso us√© puntos de inter√©s (PDIs) de la base de datos de *Open Street Maps* (OSM). Obviamente OSM no s√≥lo contiene las carreteras sino tambi√©n informaci√≥n que nos puede ser √∫til a la hora de usar un mapa como por ejemplo las ubicaciones de hospitales o gasolineras.","tags":["base de datos","overpass API","OSM","Puntos de inter√©s"],"title":"Acceso a la base de datos de OpenStreetMaps desde R","type":"post"},{"authors":["D Roy√©","N Lorenzo","D Rasilla","A Mart√≠"],"categories":null,"content":"","date":1541030400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1541030400,"objectID":"ae246d77b9b92c3f6254230def92ce47","permalink":"/es/publication/cloudiness_ip_2018/","publishdate":"2018-11-01T00:00:00Z","relpermalink":"/es/publication/cloudiness_ip_2018/","section":"publication","summary":"This paper presents the first systematic study of the relationships between atmospheric circulation types (CT) and cloud fraction (CF) over the whole Iberian Peninsula, using satellite data from the MODIS (MOD09GA and MYD09GA) cloud mask for the period 2001--2017. The high level of detail, in combination with a classification for circulation patterns, provides us with relevant information about the spatio-temporal variability of cloudiness and the main mechanisms affecting the genesis of clouds. The results show that westerly CTs are the most influential, followed by cyclonic types, in cloudiness in the west of the Iberian Peninsula. Westerly flows, however, do not affect the Mediterranean coastline, which is dominated by easterly CTs, suggesting that local factors such as convective processes, orography and proximity to a body of warm water could play a major role in cloudiness processes. The Cantabrian Coast also has a particularly characteristic cloudiness dominated by northerly CTs. In general, the results found in this study are in line with the few studies that exist on cloudiness in the Iberian Peninsula. Furthermore, the results are geographically consistent, showing links to synoptic forcing in terms of atmospheric circulation patterns and the impact of the Iberian Peninsula's complex orography upon this element of the climate system.","tags":["nubosidad","tipos de circulaci√≥n","Pen√≠nsula Ib√©rica","MODIS","tiempo","patrones espacio-temporales"],"title":"Spatio-temporal variations of cloud fraction based on circulation types in the Iberian Peninsula","type":"publication"},{"authors":null,"categories":["R","R:intermedio"],"content":"\r\r1 Introducci√≥n\r2 NCEP\r2.1 Paquetes\r2.2 Descarga de datos\r2.3 Promedio mensual\r2.4 Visualizaci√≥n\r\r3 ERA-Interim\r3.1 Instalaci√≥n\r3.2 Conexi√≥n y descarga con la ECMWF API\r3.3 Procesar ncdf\r\r4 Actualizaci√≥n para acceder ERA-5\r\r\rUn amigo me propuso que presentara los niveles de aprendizaje de R como categor√≠as. Una idea que ahora introduzco para cada entrada del blog. Hay tres niveles: elemental, intermedio y avanzado. Espero que ayude al lector y al usuario R.\n1 Introducci√≥n\rEn este post ense√±ar√© c√≥mo podemos descargar y trabajar directamente con datos provenientes de los rean√°lisis clim√°ticos en R. Se trata de sistemas de asimilaci√≥n de datos que combinan modelos de pron√≥stico meteorol√≥gico y observaciones de distintas fuentes de forma objetiva con el fin de sintetizar el estado actual y la evoluci√≥n de multiples variables de la atm√≥sfera, la superficie de la tierra y los oc√©anos. Los dos rean√°lisis m√°s usados son NCEP-DO (Reanalysis II) de la NOAA/OAR/ESRL, una versi√≥n mejorada de NCEP-NCAR (Reanalysis I), y ERA-Interim del ECMWF. Dado que NCEP-DO es de la primera generaci√≥m, se recomienda usar rean√°lisis de tercera generaci√≥n, especialmente ERA-Interim. Una visi√≥n general de los actuales rean√°lisis atmosf√©ricos la podemos encontrar aqu√≠. Primero vamos a ver c√≥mo acceder a los datos del NCEP a trav√©s de un paquete de R en CRAN que facilita la descarga y el manejo de los datos. Despu√©s haremos lo mismo con ERA-Interim, no obstante, para acceder a este √∫ltimo dataset de rean√°lisis es necesario usar python y la correspondiente API del ECMWF.\n\r2 NCEP\rPara acceder a los rean√°lisis del NCEP es necesario instalar el paquete correspondiente RNCEP. La funci√≥n principal es NCEP.gather( ). La resoluci√≥n del rean√°lisis del NCEP es de 2,5¬∫ X 2,5¬∫.\n2.1 Paquetes\r#instalamos los paquetes RNCEP, lubridate y tidyverse\rif(!require(\u0026quot;RNCEP\u0026quot;)) install.packages(\u0026quot;RNCEP\u0026quot;)\rif(!require(\u0026quot;lubridate\u0026quot;)) install.packages(\u0026quot;lubridate\u0026quot;)\rif(!require(\u0026quot;tidyverse\u0026quot;)) install.packages(\u0026quot;tidyverse\u0026quot;)\rif(!require(\u0026quot;sf\u0026quot;)) install.packages(\u0026quot;sf\u0026quot;)\r#cargamos las librer√≠as\rlibrary(RNCEP)\rlibrary(lubridate) #la necesitamos para manipular fechas\rlibrary(tidyverse) #para visualizar y manipular library(RColorBrewer) #colores para la visualizaci√≥n\rlibrary(sf) #para importar un shapefile y trabajar con geom_sf\r\r2.2 Descarga de datos\rDescargaremos la temperatura del aire a la altura de 850haPa para el a√±o 2016. Las variables y niveles de presi√≥n pueden ser consultados en los detalles de la funci√≥n ?NCEP.gather. El argumento reanalysis2 nos permite descargar tanto la versi√≥n I como la versi√≥n II, siendo por defecto FALSE, o sea, se accede al rean√°lisis I. En todas las consultas obtendremos datos horarios de cada 6 horas (00:00, 06:00, 12:00 y 18:00). Esto supone un total de 1464 valores para el a√±o 2016.\n#definimos los argumentos necesarios\rmonth_range \u0026lt;- c(1,12) #per√≠odo de meses\ryear_range \u0026lt;- c(2016,2016) #per√≠odo de a√±os\rlat_range \u0026lt;- c(30,60) #rango de latitud\rlon_range \u0026lt;- c(-30,50) #rango de longitud\rdata \u0026lt;- NCEP.gather(\u0026quot;air\u0026quot;, #nombre de la variable\r850, #altura 850hPa\rmonth_range,year_range,\rlat_range,lon_range,\rreturn.units = TRUE,\rreanalysis2=TRUE)\r## [1] Units of variable \u0026#39;air\u0026#39; are degK\r## [1] Units of variable \u0026#39;air\u0026#39; are degK\r#dimensiones dim(data) \r## [1] 13 33 1464\r#encontramos en dimnames( ) lon,lat y tiempo\r#fechas y horas date_time \u0026lt;- dimnames(data)[[3]]\rdate_time \u0026lt;- ymd_h(date_time)\rhead(date_time)\r## [1] \u0026quot;2016-01-01 00:00:00 UTC\u0026quot; \u0026quot;2016-01-01 06:00:00 UTC\u0026quot;\r## [3] \u0026quot;2016-01-01 12:00:00 UTC\u0026quot; \u0026quot;2016-01-01 18:00:00 UTC\u0026quot;\r## [5] \u0026quot;2016-01-02 00:00:00 UTC\u0026quot; \u0026quot;2016-01-02 06:00:00 UTC\u0026quot;\r#longitud y latitud\rlat \u0026lt;- dimnames(data)[[1]]\rlon \u0026lt;- dimnames(data)[[2]]\rhead(lon);head(lat)\r## [1] \u0026quot;-30\u0026quot; \u0026quot;-27.5\u0026quot; \u0026quot;-25\u0026quot; \u0026quot;-22.5\u0026quot; \u0026quot;-20\u0026quot; \u0026quot;-17.5\u0026quot;\r## [1] \u0026quot;60\u0026quot; \u0026quot;57.5\u0026quot; \u0026quot;55\u0026quot; \u0026quot;52.5\u0026quot; \u0026quot;50\u0026quot; \u0026quot;47.5\u0026quot;\r\r2.3 Promedio mensual\rVemos que se trata de un array de tres dimensiones con [lat,lon,tiempo]. Adem√°s, extraemos latitud, longitud y el tiempo. La temperatura est√° dada en Kelvin. El objetivo aqu√≠ ser√° mostrar dos mapas comparando enero y julio de 2016.\n#creamos nuestra variable de agrupaci√≥n group \u0026lt;- month(date_time) #estimamos el promedio por mes de la temperatura\rdata_month \u0026lt;- aperm(\rapply(\rdata, #nuestros datos\rc(1,2), #aplicamos a cada serie temporal 1:fila, 2:columna la funci√≥n mean( )\rby, #agrupar por group, #meses como agrupaci√≥n\rfunction(x)ifelse(all(is.na(x)),NA,mean(x))),\rc(2,3,1)) #reordenamos para obtener un array como el original\rdim(data_month) #temperatura 850haP por mes enero a diciembre\r## [1] 13 33 12\r\r2.4 Visualizaci√≥n\rAhora, podemos visualizar con ggplot2 la temperatura de enero y julio. En este ejemplo, uso geom_sf( ) del paquetes sf, que hace el trabajo m√°s f√°cil para visualizar en ggplot objetos espaciales (en el futuro har√© un post sobre sf and ggplot). En la dimensi√≥n de latitud y longitud vemos que √∫nicamente nos indica para cada fila y columna un valor. Pero necesitamos las coordenadas de todas las celdas de la matriz. Para crear todas las combinaciones entre dos variables usamos la funci√≥n expand.grid( ).\n#primero creamos todas las combinaciones de lonlat\rlonlat \u0026lt;- expand.grid(lon=lon,lat=lat)\r#lonlat es car√°cter, ya que fue un nombre, por eso lo convertimos en n√∫merico\rlonlat \u0026lt;- apply(lonlat,2,as.numeric)\r#lon y lat no est√°n en el orden como lo esperamos\r#fila=lon; columna=lat\rdata_month \u0026lt;- aperm(data_month,c(2,1,3))\r#subtraemos 273.15K para convertir K a ¬∫C.\rdf \u0026lt;- data.frame(lonlat,\rTa01=as.vector(data_month[,,1])-273.15,\rTa07=as.vector(data_month[,,7])-273.15)\rAntes de visualizar los datos con ggplot2, tenemos que adpatar la tabla. El shapefile con los limites de los pa√≠ses se puede descargar aqu√≠.\n#convertimos la tabla ancha en una larga\rdf \u0026lt;- gather(df,month,Ta,Ta01:Ta07)%\u0026gt;%\rmutate(month=factor(month,unique(month),c(\u0026quot;Jan\u0026quot;,\u0026quot;Jul\u0026quot;)))\r#importamos el limite de pa√≠ses\rlimit \u0026lt;- st_read(\u0026quot;CNTR_RG_03M_2014.shp\u0026quot;)\r## Reading layer `CNTR_RG_03M_2014\u0026#39; from data source `C:\\Users\\xeo19\\Documents\\GitHub\\blogR_update\\content\\post\\es\\2018-09-15-acceso-a-datos-de-los-reanalisis-desde-r\\CNTR_RG_03M_2014.shp\u0026#39; using driver `ESRI Shapefile\u0026#39;\r## Simple feature collection with 256 features and 3 fields\r## geometry type: MULTIPOLYGON\r## dimension: XY\r## bbox: xmin: -180 ymin: -90 xmax: 180 ymax: 83.66068\r## epsg (SRID): NA\r## proj4string: +proj=longlat +ellps=GRS80 +no_defs\r#gama de colores\rcolbr \u0026lt;- brewer.pal(11,\u0026quot;RdBu\u0026quot;)\rggplot(df)+\rgeom_tile(aes(lon,lat,fill=Ta))+ #temperatura\rgeom_sf(data=limit,fill=NA,size=.5)+ #limite\rscale_fill_gradientn(colours=rev(colbr))+\rcoord_sf(ylim=c(30,60),xlim=c(-30,50))+\rscale_x_continuous(breaks=seq(-30,50,10),expand=c(0,0))+\rscale_y_continuous(breaks=seq(30,60,5),expand=c(0,0))+\rlabs(x=\u0026quot;\u0026quot;,y=\u0026quot;\u0026quot;,fill=\u0026quot;Ta 850hPa (¬∫C)\u0026quot;)+\rfacet_grid(month~.)+ #mapa por mes\rtheme_bw()\r\r\r3 ERA-Interim\rEl ECMWF ofrece acceso a sus bases de datos p√∫blicos a partir de una pyhton-API. Es necesario estar registrado en la web del ECMWF. Se puede darse de alta aqu√≠. Al tratarse de otro lenguaje de programaci√≥n, en R debemos usar un interfaz entre ambos lo que nos permite el paquete reticulate. Tambi√©n debemos que tener instalada una distribuci√≥n de pyhton (versi√≥n 2.x o 3.x). En el caso de Windows podemos usar anaconda.\n3.1 Instalaci√≥n\rif(!require(\u0026quot;reticulate\u0026quot;)) install.packages(\u0026quot;reticulate\u0026quot;)\rif(!require(\u0026quot;ncdf4\u0026quot;)) install.packages(\u0026quot;ncdf4\u0026quot;) #para manejar formato netCDF\r#cargamos las librer√≠as\rlibrary(reticulate)\rlibrary(ncdf4)\rUna vez que tenemos instalado anaconda y el paquete reticulate, podemos instalar el paquete python ecmwfapi. La instalaci√≥n la podemos llevar a cabo, o bien atrav√©s del CMD de Windows usando el comando conda install -c conda-forge ecmwf-api-client, o bien con la funci√≥n py_install( ) del paquete reticulate. La misma funci√≥n permite instalar cualquier librer√≠a python desde R.\n#instalamos la API ECMWF\rpy_install(\u0026quot;ecmwf-api-client\u0026quot;)\r## ## Installation complete.\r\r3.2 Conexi√≥n y descarga con la ECMWF API\rPara poder acceder a la API es requisito crear un archivo con la informaci√≥n del usuario.\nEl archivo ‚Äú.ecmwfapirc‚Äù debe contener la siguiente informaci√≥n:\n{\r\u0026quot;url\u0026quot; : \u0026quot;https://api.ecmwf.int/v1\u0026quot;,\r\u0026quot;key\u0026quot; : \u0026quot;XXXXXXXXXXXXXXXXXXXXXX\u0026quot;,\r\u0026quot;email\u0026quot; : \u0026quot;john.smith@example.com\u0026quot;\r}\rLa clave podemos obtenerla con la cuenta de usuario aqu√≠.\nEl archivo se puede crear con el bloc de notas de Windows.\nCreamos un documento ‚Äúecmwfapirc.txt‚Äù.\rRenombramos este archivo a ‚Äú.ecmwfapirc.‚Äù\r\rEl √∫ltimo punto desaparece de forma autom√°tica. Despu√©s guardamos este archivo en ‚ÄúC:/USERNAME/.ecmwfapirc‚Äù o ‚ÄúC:/USERNAME/Documents/.ecmwfapirc‚Äù.\n#importamos la librer√≠a python ecmwfapi\recmwf \u0026lt;- import(\u0026#39;ecmwfapi\u0026#39;)\r#en este paso debe existir el archivo .ecmwfapirc\rserver = ecmwf$ECMWFDataServer() #iniciamos la conexi√≥n\rLlegados a este punto, ¬øc√≥mo creamos una consulta? Lo m√°s f√°cil es ir a la web del ECMWF d√≥nde elegimos la base de datos, en este caso ERA-Interim en superficie, para crear un script con todos los datos necesarios. M√°s detalles sobre la sintaxis podemos encontrar aqu√≠. Cuando procedemos en la web s√≥lamente tenemos que hacer click en ‚ÄúView MARS Request‚Äù. Este paso nos lleva al script en python.\n\r\rCon la sintaxis del script que nos da la MARS Request podemos crear la consulta en R.\n#creamos la consulta\rquery \u0026lt;-r_to_py(list(\rclass=\u0026#39;ei\u0026#39;,\rdataset= \u0026quot;interim\u0026quot;, #base de datos\rdate= \u0026quot;2017-01-01/to/2017-12-31\u0026quot;, #periodo expver= \u0026quot;1\u0026quot;,\rgrid= \u0026quot;0.125/0.125\u0026quot;, #resoluci√≥n\rlevtype=\u0026quot;sfc\u0026quot;,\rparam= \u0026quot;167.128\u0026quot;, # temperatura del aire (2m)\rarea=\u0026quot;45/-10/30/5\u0026quot;, #N/W/S/E\rstep= \u0026quot;0\u0026quot;,\rstream=\u0026quot;oper\u0026quot;,\rtime=\u0026quot;00:00:00/06:00:00/12:00:00/18:00:00\u0026quot;, #paso de tiempo\rtype=\u0026quot;an\u0026quot;,\rformat= \u0026quot;netcdf\u0026quot;, #formato\rtarget=\u0026#39;ta2017.nc\u0026#39; #nombre del archivo\r))\rserver$retrieve(query)\rEl resultado es un archivo netCDF que podemos processar con el paquete ncdf4.\n\r3.3 Procesar ncdf\rA partir de aqu√≠, el objetivo ser√° la extracci√≥n de una serie temporal de una coordenada m√°s pr√≥xima a una dada. Usaremos las coordenadas de Madrid (40.418889, -3.691944).\n#cargamos las librer√≠as library(sf)\rlibrary(ncdf4)\rlibrary(tidyverse)\r#abrimos la conexi√≥n con el archivo\rnc \u0026lt;- nc_open(\u0026quot;ta2017.nc\u0026quot;)\r#extraemos lon y lat\rlat \u0026lt;- ncvar_get(nc,\u0026#39;latitude\u0026#39;)\rlon \u0026lt;- ncvar_get(nc,\u0026#39;longitude\u0026#39;)\rdim(lat);dim(lon)\r## [1] 121\r## [1] 121\r#extraemos el tiempo\rt \u0026lt;- ncvar_get(nc, \u0026quot;time\u0026quot;)\r#unidad del tiempo: horas desde 1900-01-01\rncatt_get(nc,\u0026#39;time\u0026#39;)\r## $units\r## [1] \u0026quot;hours since 1900-01-01 00:00:00.0\u0026quot;\r## ## $long_name\r## [1] \u0026quot;time\u0026quot;\r## ## $calendar\r## [1] \u0026quot;gregorian\u0026quot;\r#convertimos las horas en fecha+hora #as_datetime de lubridate espera segundos\rtimestamp \u0026lt;- as_datetime(c(t*60*60),origin=\u0026quot;1900-01-01\u0026quot;)\r#importamos los datos\rdata \u0026lt;- ncvar_get(nc,\u0026quot;t2m\u0026quot;)\r#cerramos la conexi√≥n\rnc_close(nc)\rM√°s detalles se pueden consultar en este breve manual sobre c√≥mo trabajar con netCDF aqui. En esta pr√≥xima secci√≥n hacemos uso del paquete sf la cu√°l est√° sustituyendo las m√°s conocidas sp y rgdal.\n#creamos todas las combinaciones\rlonlat \u0026lt;- expand.grid(lon=lon,lat=lat)\r#debemos convertir las coordenadas en objeto espacial sf\r#adem√°s indicamos el sistema de coordenadas en codigo EPSG\rcoord \u0026lt;- st_as_sf(lonlat,coords=c(\u0026quot;lon\u0026quot;,\u0026quot;lat\u0026quot;))%\u0026gt;%\rst_set_crs(4326)\r#lo mismo hacemos con nuestra coordenada de Madrid\rpsj \u0026lt;- st_point(c(-3.691944,40.418889))%\u0026gt;%\rst_sfc()%\u0026gt;%\rst_set_crs(4326)\r#plot de los puntos\rplot(st_geometry(coord))\rplot(psj,add=TRUE,pch = 3, col = \u0026#39;red\u0026#39;)\rEn los pr√≥ximos pasos calculamos la distancia de nuestro punto de referencia a todos los puntos del grid. Posteriormente, buscamos aquel con menos distancia.\n#a√±adimos la distancia a los puntos\rcoord \u0026lt;- mutate(coord,dist=st_distance(coord,psj))\r#creamos una matrix de distancia con las mismas dimensiones que nuestros datos\rdist_mat \u0026lt;- matrix(coord$dist,dim(data)[-3])\r#la funci√≥n arrayInd es √∫til para obtener los √≠ndices fila y columna en este caso\rmat_index \u0026lt;- as.vector(arrayInd(which.min(dist_mat), dim(dist_mat)))\r#extraemos la serie temporal y cambiamos la unidad de K a ¬∫C\r#convertimos el tiempo en fecha + hora\rdf \u0026lt;- data.frame(ta=data[mat_index[1],mat_index[2],],time=timestamp)%\u0026gt;%\rmutate(ta=ta-273.15,time=ymd_hms(time))\rPara terminar, visualizamos nuestra serie temporal.\nggplot(df,\raes(time,ta))+\rgeom_line()+\rlabs(y=\u0026quot;Temperatura (¬∫C)\u0026quot;,\rx=\u0026quot;\u0026quot;)+\rtheme_bw()\r\r\r4 Actualizaci√≥n para acceder ERA-5\rRecientemente el nuevo rean√°lisis ERA-5 con single level o pressure level fue puesto a disposici√≥n de los usarios. Es la quinta generaci√≥n del European Centre for Medium-Range Weather Forecasts (ECMWF) y accesible a trav√©s de una nueva API de Copernicus. El nuevo rean√°lisis ERA-5 tiene una cobertura temporal desde 1950 hasta la actualidad a una resoluci√≥n horizontal de 30km a nivel mundial, con 137 niveles desde la superficie hasta una altura de 80km. Una diferencia importante con respecto al ERA-Interim anterior es la resoluci√≥n temporal con datos horarios.\nEl acceso cambia a la infrastructura de Climate Data Store (CDS) con su propia API. Es posible descargar directamente desde la p√°gina o usando la Python API en una forma similar a la ya presentada en este post. Sin embargo, existen ligeras diferencias que voy a explicar a continuaci√≥n.\nEs necesario tener una cuenta en CDS de Copernicus link\rNuevamente, hace falta una clave link\rCambia la librer√≠a de Python y algo los argumentos en la consulta.\r\r#cargamos las librer√≠as library(sf)\rlibrary(ncdf4)\rlibrary(tidyverse)\rlibrary(reticulate)\r#instalamos la CDS API\rconda_install(\u0026quot;r-reticulate\u0026quot;,\u0026quot;cdsapi\u0026quot;,pip=TRUE)\rPara poder acceder a la API un requisito es crear un archivo con la informaci√≥n del usuario.\nEl archivo ‚Äú.cdsapirc‚Äù debe contener la siguiente informaci√≥n:\n\rurl: https://cds.climate.copernicus.eu/api/v2\rkey: {uid}:{api-key}\r\rLa clave la podemos obtener con la cuenta de usuario en el User profile.\nEl archivo se puede crear con el bloc de notas de Windows del mismo modo como ha sido explicado para ERA-Interim.\n#importamos la librer√≠a python CDS\rcdsapi \u0026lt;- import(\u0026#39;cdsapi\u0026#39;)\r#en este paso debe existir el archivo .cdsapirc\rserver = cdsapi$Client() #iniciamos la conexi√≥n\rCon la sintaxis del script que nos da la Show API request podemos crear la consulta en R.\n#creamos la consulta\rquery \u0026lt;- r_to_py(list(\rvariable= \u0026quot;2m_temperature\u0026quot;,\rproduct_type= \u0026quot;reanalysis\u0026quot;,\ryear= \u0026quot;2018\u0026quot;,\rmonth= \u0026quot;07\u0026quot;, #formato: \u0026quot;01\u0026quot;,\u0026quot;01\u0026quot;, etc.\rday= str_pad(1:31,2,\u0026quot;left\u0026quot;,\u0026quot;0\u0026quot;), time= str_c(0:23,\u0026quot;00\u0026quot;,sep=\u0026quot;:\u0026quot;)%\u0026gt;%str_pad(5,\u0026quot;left\u0026quot;,\u0026quot;0\u0026quot;),\rformat= \u0026quot;netcdf\u0026quot;,\rarea = \u0026quot;45/-20/35/5\u0026quot; # North, West, South, East\r))\rserver$retrieve(\u0026quot;reanalysis-era5-single-levels\u0026quot;,\rquery,\r\u0026quot;era5_ta_2018.nc\u0026quot;)\rEs posible que la primera vez se reciba un mensaje de error, dado que todav√≠a no se han aceptado los t√©rminos y las condiciones requeridas. √önicamente se debe seguir el enlace indicado.\nError in py_call_impl(callable, dots$args, dots$keywords) : Exception: Client has not agreed to the required terms and conditions.. To access this resource, you first need to accept the termsof \u0026#39;Licence to Use Copernicus Products\u0026#39; at https://cds.climate.copernicus.eu/cdsapp/#!/terms/licence-to-use-copernicus-products\rA partir de aqu√≠ podemos seguir los mismos pasos como los hechos con ERA-Interim.\n#abrimos la conexi√≥n con el archivo\rnc \u0026lt;- nc_open(\u0026quot;era5_ta_2018.nc\u0026quot;)\r#extraemos lon y lat\rlat \u0026lt;- ncvar_get(nc,\u0026#39;latitude\u0026#39;)\rlon \u0026lt;- ncvar_get(nc,\u0026#39;longitude\u0026#39;)\rdim(lat);dim(lon)\r## [1] 41\r## [1] 101\r#extraemos el tiempo\rt \u0026lt;- ncvar_get(nc, \u0026quot;time\u0026quot;)\r#unidad del tiempo: horas desde 1900-01-01\rncatt_get(nc,\u0026#39;time\u0026#39;)\r## $units\r## [1] \u0026quot;hours since 1900-01-01 00:00:00.0\u0026quot;\r## ## $long_name\r## [1] \u0026quot;time\u0026quot;\r## ## $calendar\r## [1] \u0026quot;gregorian\u0026quot;\r#convertimos las horas en fecha+hora #as_datetime de lubridate espera segundos\rtimestamp \u0026lt;- as_datetime(c(t*60*60),origin=\u0026quot;1900-01-01\u0026quot;)\r#temperatura en K de julio 2018\rhead(timestamp)\r## [1] \u0026quot;2018-07-01 00:00:00 UTC\u0026quot; \u0026quot;2018-07-01 01:00:00 UTC\u0026quot;\r## [3] \u0026quot;2018-07-01 02:00:00 UTC\u0026quot; \u0026quot;2018-07-01 03:00:00 UTC\u0026quot;\r## [5] \u0026quot;2018-07-01 04:00:00 UTC\u0026quot; \u0026quot;2018-07-01 05:00:00 UTC\u0026quot;\r#importamos los datos\rdata \u0026lt;- ncvar_get(nc,\u0026quot;t2m\u0026quot;)\r#plot\rfilled.contour(data[,,1])\rplot(data.frame(date=timestamp,ta=data[1,5,]),\rtype=\u0026quot;l\u0026quot;)\r#cerramos la conexi√≥n\rnc_close(nc)\r\r","date":1537005584,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1537005584,"objectID":"8f8afa591ee1e2a60bf271add5ba14b3","permalink":"/es/2018/acceso-a-datos-de-los-rean%C3%A1lisis-clim%C3%A1ticos-desde-r/","publishdate":"2018-09-15T10:59:44+01:00","relpermalink":"/es/2018/acceso-a-datos-de-los-rean%C3%A1lisis-clim%C3%A1ticos-desde-r/","section":"post","summary":"En este post ense√±ar√© c√≥mo podemos descargar y trabajar directamente con datos provinientes de los rean√°lisis clim√°ticos en R. Se trata de sistemas de asimilaci√≥n de datos que combinan modelos de pron√≥stico meteorol√≥gico y observaciones de distintas fuentes de forma objetiva con el fin de sintetizar el estado actual y la evoluci√≥n de multiples variables de la atm√≥sfera, la superficie de la tierra y los oc√©anos.","tags":["reanalisis","interim","NCEP/NCAR","era","descarga","ncdf","acceso","api","python","ECMWF"],"title":"Acceso a datos de los rean√°lisis clim√°ticos desde R","type":"post"},{"authors":null,"categories":["visualizaci√≥n","R","R:elemental"],"content":"\rBienvenido a mi blog! Soy Dominic Roy√©, investigador y docente de geograf√≠a f√≠sica en la Universidad de Santiago de Compostela. Una de mis pasiones es la programaci√≥n en R para visualizar y analizar cualquier tipo de datos. Por eso, mi idea de iniciar este blog tiene su origen en las publicaciones que he ido haciendo en el √∫timo a√±o en Twitter sobre diferentes temas visualizando datos que describen el mundo. Adem√°s, me gustar√≠a aprovechar la posibilidad del blog e ir publicando breves ensayos sobre visualizaci√≥n, gesti√≥n y manipulaci√≥n de datos en R. Espero que os guste. Cualquier sugerencia o idea, ser√° bienvenida.\nPre√°mbulo\rSiempre he querido escribir sobre el uso del gr√°fico de tarta. El gr√°fico circular es ampliamente usado en investigaci√≥n, docencia, periodismo o en informes t√©cnicos. Es m√°s, no s√© si es debido a Excel, pero todav√≠a peor que el mismo gr√°fico de tarta es su versi√≥n en 3D (tambi√©n para el gr√°fico de barras). Sobre las versiones 3D √∫nicamente debo decir que no es recomendable, ya que en estos casos la tercera dimensi√≥n no contiene ninguna informaci√≥n y por tanto no ayuda en leer correctamente la informaci√≥n del gr√°fico. Respecto al gr√°fico de tarta, entre muchos expertos no se aconseja claramente su uso. Pero, ¬øpor qu√©?\nYa en un estudio hecho por Simkin y Hastie (1987) encontraron que la interpretaci√≥n y el procesamiento de √°ngulos es m√°s d√≠ficil que el de formas lineales. Mayormente es m√°s f√°cil leer un gr√°fico de barras que uno de tarta. Un problema que se hace muy visible cuando nos encontramos con; 1) demasiadas categor√≠as 2) pocas diferencias entre las categor√≠as 3) un mal uso de colores como leyenda √≥ 4) comparaciones entre varios gr√°ficos de tarta.\nPara decidir qu√© posibles representaciones gr√°ficas existen para nuestros datos, recomiendo ir a la p√°gina web www.data-to-viz.com o usar Financial Times Visual Vocabulary.\n\nAhora bien, ¬øqu√© alternativas podemos usar en R?\n\rAlternativas al gr√°fico de tarta\rLos datos sobre el estado de la enfermedad sarampi√≥n corresponden a junio de 2018 en Europa y vienen del ECDC.\n#librer√≠as\rlibrary(tidyverse)\rlibrary(scales)\rlibrary(RColorBrewer)\r#datos\rmeasles \u0026lt;- data.frame(\rvacc_status=c(\u0026quot;Unvaccinated\u0026quot;,\u0026quot;1 Dose\u0026quot;,\r\u0026quot;\u0026gt;= 2 Dose\u0026quot;,\u0026quot;Unkown Dose\u0026quot;,\u0026quot;Unkown\u0026quot;),\rprop=c(0.75,0.091,0.05,0.012,0.096)\r)\r#ordenamos de mayor a menor y lo fijamos con un factor measles \u0026lt;- arrange(measles,\rdesc(prop))%\u0026gt;%\rmutate(vacc_status=factor(vacc_status,vacc_status))\r\r\rvacc_status\rprop\r\r\r\rUnvaccinated\r0.750\r\rUnkown\r0.096\r\r1 Dose\r0.091\r\r\u0026gt;= 2 Dose\r0.050\r\rUnkown Dose\r0.012\r\r\r\rGr√°fico de barra o similar\rggplot(measles,aes(vacc_status,prop))+\rgeom_bar(stat=\u0026quot;identity\u0026quot;)+\rscale_y_continuous(breaks=seq(0,1,.1),\rlabels=percent, #convertimos en %\rlimits=c(0,1))+\rlabs(x=\u0026quot;\u0026quot;,y=\u0026quot;\u0026quot;)+\rtheme_minimal()\rggplot(measles,aes(x=vacc_status,prop,ymin=0,ymax=prop))+\rgeom_pointrange()+\rscale_y_continuous(breaks=seq(0,1,.1),\rlabels=percent, #convertimos en %\rlimits=c(0,1))+\rlabs(x=\u0026quot;\u0026quot;,y=\u0026quot;\u0026quot;)+\rtheme_minimal()\r#definiciones sobre el theme que usamos\rtheme_singlebar \u0026lt;- theme_bw()+\rtheme(\rlegend.position = \u0026quot;bottom\u0026quot;,\raxis.title = element_blank(),\raxis.ticks.y = element_blank(),\raxis.text.y = element_blank(),\rpanel.border = element_blank(),\rpanel.grid=element_blank(),\rplot.title=element_text(size=14, face=\u0026quot;bold\u0026quot;)\r)\rmutate(measles,\rvacc_status=factor(vacc_status, #cambiamos el orden de las categor√≠as\rrev(levels(vacc_status))))%\u0026gt;%\rggplot(aes(1,prop,fill=vacc_status))+ #ponemos 1 en x para crear una barra √∫nica\rgeom_bar(stat=\u0026quot;identity\u0026quot;)+\rscale_y_continuous(breaks=seq(0,1,.1),\rlabels=percent,\rlimits=c(0,1),\rexpand=c(.01,.01))+\rscale_x_continuous(expand=c(0,0))+\rscale_fill_brewer(\u0026quot;\u0026quot;,palette=\u0026quot;Set1\u0026quot;)+\rcoord_flip()+\rtheme_singlebar\r#ampliamos los datos con las cifras de Italia\rmeasles2 \u0026lt;- mutate(measles,\ritaly=c(0.826,0.081,0.053,0.013,0.027),\rvacc_status=factor(vacc_status,rev(levels(vacc_status))))%\u0026gt;%\rrename(europe=\u0026quot;prop\u0026quot;)%\u0026gt;%\rgather(region,prop,europe:italy)\rggplot(measles2,aes(region,prop,fill=vacc_status))+\rgeom_bar(stat=\u0026quot;identity\u0026quot;,position=\u0026quot;stack\u0026quot;)+ #stack: columna 100%\rscale_y_continuous(breaks=seq(0,1,.1),\rlabels=percent, #convertimos en %\rlimits=c(0,1),\rexpand=c(0,0))+\rscale_fill_brewer(palette = \u0026quot;Set1\u0026quot;)+\rlabs(x=\u0026quot;\u0026quot;,y=\u0026quot;\u0026quot;,fill=\u0026quot;Vaccination Status\u0026quot;)+\rtheme_minimal()\r\rGr√°fico de Waffle\r#liber√≠a\rlibrary(waffle)\r#la funci√≥n de waffle usa un vector con nombres\rval_measles \u0026lt;- round(measles$prop*100)\rnames(val_measles) \u0026lt;- measles$vacc_status\rwaffle(val_measles, #datos\rcolors=brewer.pal(5,\u0026quot;Set1\u0026quot;), #colores\rrows=5) #n√∫mero de filas \rEl gr√°fico de Waffle me parece muy interesante cuando queramos mostrar una proporci√≥n de una categor√≠a individual.\nmedida \u0026lt;- c(41,59) #datos de la OECD 2015\rnames(medida) \u0026lt;- c(\u0026quot;Estudios Superiores\u0026quot;,\u0026quot;Otros estudios\u0026quot;)\rwaffle(medida,\rcolors=c(\u0026quot;#377eb8\u0026quot;,\u0026quot;#bdbdbd\u0026quot;),\rrows=5)\r\rMapa de arbol (treemap)\r#librer√≠a\rlibrary(treemap)\rtreemap(measles,\rindex=\u0026quot;vacc_status\u0026quot;, #variable de categr√≠as\rvSize=\u0026quot;prop\u0026quot;, #valores\rtype=\u0026quot;index\u0026quot;, #estilo m√°s en ?treemap\rtitle=\u0026quot;\u0026quot;, palette = brewer.pal(5,\u0026quot;Set1\u0026quot;) #colores\r)\rPersonalmente, creo que todos los tipos de representaciones gr√°ficas tienen sus ventajas y desventajas. No obstante, en la actualidad tenemos una gran variedad de alternativas para evitar el uso del gr√°fico de tarta. Si a√∫n as√≠ se quiere hacer un gr√°fico de tarta, algo que tampoco descartar√≠a, recomiendo seguir ciertas reglas que ha resumido muy bien Lisa Charlotte Rost en un reciente post. Por ejemplo, debemos ordenar de mayor a menor a no ser que haya un orden natural o usar como m√°ximo cinco categor√≠as. Por √∫ltimo, os dejo un enlace a un cheatsheet de policyviz sobre normas b√°sicas de visualizaci√≥n de datos. Una buena referencia sobre gr√°ficos, usando diferentes programas desde Excel hasta R, pod√©is encontrar en Creating more effective graphs (Robbins 2013).\n\rReferencias\rRobbins, Naomi B. 2013. Creating more effective graphs. A succinct and highly readable guide to creating effective graph. Chart House.\n\rSimkin, D, y R Hastie. 1987. ¬´An Information-Processing Analysis of Graph Perception¬ª. Journal of the American Statistical Association 82 (398): 454-65.\n\r\r\r\r","date":1534933412,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1534933412,"objectID":"f21d950903f35ea0334f02bebc23ea63","permalink":"/es/2018/el-gr%C3%A1fico-de-tarta/","publishdate":"2018-08-22T11:23:32+01:00","relpermalink":"/es/2018/el-gr%C3%A1fico-de-tarta/","section":"post","summary":"Bienvenido a mi blog! Soy Dominic Roy√©, investigador y docente de geograf√≠a f√≠sica en la Universidad de Santiago de Compostela. Una de mis pasiones es la programaci√≥n en R para visualizar y analizar cualquier tipo de datos. Por eso, mi idea de iniciar este blog tiene su origen en las publicaciones que he ido haciendo en el √∫timo a√±o en Twitter sobre diferentes temas visualizando datos que describen el mundo.","tags":["gr√°fico de tarta","datos","circular","proporciones","primera entrada","treemap","waffle","barra","visualizaci√≥n"],"title":"El gr√°fico de tarta","type":"post"},{"authors":["A V√©lez","J Martin-Vide","D Roy√©","O Santaella"],"categories":null,"content":"","date":1530403200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1530403200,"objectID":"610f81be23fa73e2a79cec7ae772bd48","permalink":"/es/publication/ci_pr_2018/","publishdate":"2018-07-01T00:00:00Z","relpermalink":"/es/publication/ci_pr_2018/","section":"publication","summary":"The present study analyzes spatial patterns of precipitation Concentration Index (CI) in Puerto Rico considering the daily precipitation data of precipitation-gauging stations during 1971-2010. The South and East interior parts of Puerto Rico are characterized by higher CI and the West and North-West parts show lower CI. The annual CI and the rainy season CI show a gradient from South-East to North-West and the dry season CI shows a gradient from South to North. Another difference between the rainy season CI and dry season CI is that the former shows the lowest values of CI while the latter shows the highest values of CI. The different types of seasonal precipitation seem to play a major role on the spatial CI distribution. However, the local relief plays a major role in the spatial patterns due to the effect of the air circulation by the mountains. These findings can contribute to basin-scale water resource management (ooding, soil erosion, etc.) and conservation of the ecological environment.","tags":["Concentration Index","Puerto Rico","precipitation","spatial‚Äìtemporal patterns"],"title":"Spatial Analysis of Daily Precipitation Concentration in Puerto Rico","type":"publication"},{"authors":["D Roy√©","MT Zarrabeitia","P Fdez-Arroyabe","A √Ålvarez-Guti√©rrez","A Santurt√∫n"],"categories":null,"content":"","date":1525132800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1525132800,"objectID":"7e652e401d5f5ce407570be119eaf98a","permalink":"/es/publication/iam_cantabria_2018/","publishdate":"2018-05-01T00:00:00Z","relpermalink":"/es/publication/iam_cantabria_2018/","section":"publication","summary":"Introducci√≥n y objetivos. El papel del entorno en la salud cardiovascular ha ganado protagonismo en el contexto del cambio global. Este trabajo persigue analizar la relaci√≥n de la temperatura aparente (TA) y los contaminantes atmosf√©ricos con los ingresos por infarto agudo de miocardio (IAM) y realizar un an√°lisis temporal de la enfermedad y la mortalidad asociada. M√©todos. Se desarroll√≥ un estudio de serie temporal de los ingresos por IAM en Cantabria entre 2001 y 2015. La asociaci√≥n entre las variables ambientales (entre ellas, se estim√≥ un √≠ndice biometeorol√≥gico, la TA) y los ingresos por IAM se analiz√≥ mediante una regresi√≥n de cuasi-Poisson, y se cre√≥ un modelo no lineal de retardo distribuido dentro de un modelo generalizado aditivo, con el fin de atender el efecto retardado y la presencia de relaciones no lineales de las variables ambientales. Resultados. La tasa de incidencia y la mortalidad por IAM siguieron una tendencia descendente durante el periodo de estudio (CC=‚Äì0,714; p=0,0002). Los ingresos por IAM ten√≠an un patr√≥n anual con m√°ximos en invierno (p=0,005); hab√≠a diferencias intrasemanales, y los m√≠nimos se registraron durante el fin de semana (p=0,000005). Se encontr√≥ una asociaci√≥n inversa entre la TA y el n√∫mero de ingresos por IAM y una relaci√≥n directa y estad√≠sticamente significativa con las concentraciones de part√≠culas de di√°metro","tags":["Infarto agudo de miocardio","Temperatura aparente","Contaminantes atmosf√©ricos","Material particulado"],"title":"Papel de la temperatura aparente y de los contaminantes atmosf√©ricos en los ingresos por infarto agudo de miocardio en el norte de Espa√±a","type":"publication"},{"authors":["D Roy√©","A Figueiras","M Taracido-Trunk"],"categories":null,"content":"","date":1522540800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1522540800,"objectID":"0548c7a9a3b7d133740e95d174a65d2c","permalink":"/es/publication/pharma_coru%C3%B1a_2018/","publishdate":"2018-04-01T00:00:00Z","relpermalink":"/es/publication/pharma_coru%C3%B1a_2018/","section":"publication","summary":"The consumption of medication, especially over-the-counter (OTC) drugs, can reflect environmental exposure with a lesser degree of severity in terms of morbidity. The non-linear effects of maximum and minimum apparent temperature on respiratory drug sales in A Coru√±a from 2006 to 2010 were examined using a distributed lag non-linear model. In particular, low apparent temperatures proved to be associated with increased sales of respiratory drugs. The strongest consistent risk estimates were found for minimum apparent temperatures in respiratory drug sales with an increase of 33.4% (95% CI: 12.5-58.0%) when the temperature changed from 2.8 ¬∫C to ‚àí1.4 ¬∫C. These findings may serve to guide the planning of public health interventions in order to predict and manage the health effects of exposure to the thermal environment for lower degrees of morbidity. More precisely, significant increases in the use of measured OTC medication could be used to identify and anticipate influenza outbreaks due to a more sensitive degree of the data source.","tags":["drug sales","pharmacoepidemiology","respiratory cause","short‚Äêterm effects","Spain","thermal environment"],"title":"Short-term effects of heat and cold on respiratory drug use. A time-series epidemiological study in A Coru√±a, Spain","type":"publication"},{"authors":["D Roy√©","N Lorenzo","J Martin-Vide"],"categories":null,"content":"","date":1522540800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1522540800,"objectID":"1aa69b47bc265ad54507411d0e9866f7","permalink":"/es/publication/lightning_galicia_2018/","publishdate":"2018-04-01T00:00:00Z","relpermalink":"/es/publication/lightning_galicia_2018/","section":"publication","summary":"The spatial-temporal patterns of cloud-to-ground (CG) lightning covering the period 2010-2015 over the northwest Iberian Peninsula were investigated. The analysis conducted employed three main methods: the circulation weather types developed by Jenkinson \u0026 Collison, the fit of a generalized additive model for geographic variables and the use of a concentration index for the ratio of lightning strikes and thunderstorm days. The main activity in the summer months can be attributed to situations with eastern or anticyclonic flow due to convection by insolation. In winter, lightning proves to have a frontal origin and is mainly associated with western or cyclonic flow situations which occur with advections of air masses of maritime origin. The largest number of CG discharges occurs under eastern flow and their hybrids with anticyclonic situations. Thunderstorms with greater CG lightning activity, highlighted by a higher Concentration Index, are located in areas with a higher density of lightning strikes, above all in mountainous areas away from the sea. The modeling of lightning density with geographic variables shows the positive influence of altitude and, particularly, distance to the sea, with nonlinear relationships due to the complex orography of the region. Likewise, areas with convex topography receive more lightning strikes than concave ones, a relation which has been demonstrated for the first time from a Generalized Additive Model (GAM).","tags":["thunderstorm","Iberian Peninsula","Concentration Index","weather types","Convexity Index","Generalized Additive Model","cloud-to-ground lightning"],"title":"Spatial‚Äìtemporal patterns of cloud-to-ground lightning over the northwest Iberian Peninsula during the period 2010‚Äì2015","type":"publication"},{"authors":["S Mathbout","JA Lopez-Bustins","D Roy√©","J Martin-Vide","J Bech","FS Rodrigo"],"categories":null,"content":"","date":1509494400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1509494400,"objectID":"1e0e817f6e2eb2b129a09511287060fa","permalink":"/es/publication/appliedgeophysics_2017/","publishdate":"2017-11-01T00:00:00Z","relpermalink":"/es/publication/appliedgeophysics_2017/","section":"publication","summary":"The Eastern Mediterranean is one of the most prominent hot spots of climate change in the world and extreme climatic phenomena in this region such as drought or extreme rainfall events are expected to become more frequent and intense. In this study climate extreme indices recommended by the joint World Meteorological Organization Expert Team on Climate Change Detection and Indices are calculated for daily precipitation data in 70 weather stations during 1961‚Äì2012. Observed trends and changes in daily precipitation extremes over the EM basin were analysed using the RClimDex package, which was developed by the Climate Research Branch of the Meteorological Service of Canada. Extreme and heavy precipitation events showed globally a statistically significant decrease in the Eastern Mediterranean and, in the southern parts, a significant decrease in total precipitation. The overall analysis of extreme precipitation indices reveals that decreasing trends are generally more frequent than increasing trends. We found statistically significant decreasing trends (reaching 74% of stations for extremely wet days) and increasing trends (reaching 36% of stations for number of very heavy precipitation days). Finally, most of the extreme precipitation indices have a statistically significant positive correlation with annual precipitation, particularly the number of heavy and very heavy precipitation days.","tags":["Eastern Mediterranean","extreme precipitation","trend","spatial temporal distribution"],"title":"Observed Changes in Daily Precipitation Extremes at Annual Timescale Over the Eastern Mediterranean During 1961‚Äì2012","type":"publication"},{"authors":["D Roy√©"],"categories":null,"content":"","date":1501545600,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1501545600,"objectID":"d09c5cdabc94931312d002ad366170e8","permalink":"/es/publication/hotnights_bcn_2017/","publishdate":"2017-08-01T00:00:00Z","relpermalink":"/es/publication/hotnights_bcn_2017/","section":"publication","summary":"Heat-related effects on mortality have been widely analyzed using maximum and minimum temperatures as exposure variables. Nevertheless, the main focus is usually on the former with the minimum temperature being limited in use as far as human health effects are concerned. Therefore, new thermal indices were used in this research to describe the duration of night hours with air temperatures higher than the 95% percentile of the minimum temperature (Hot Night hours) and intensity as the summation of these air temperatures in degrees (Hot Night degrees). An exposure-response relationship between mortality due to natural, respiratory and cardiovascular causes and summer night temperatures was assessed using data from the Barcelona region between 2003 and 2013. The non-linear relationship between the exposure and response variables was modeled using a distributed lag non-linear model. The estimated associations for both exposure variables and mortality shows a relationship with high and medium values that persist significantly up to a lag of 1‚Äì2 days. In mortality due to natural causes an increase of 1.1% per 10% (CI95% 0.6‚Äì1.5) for Hot Night hours and 5.8% per each 10¬∫ (CI95% 3.5‚Äì8.2%) for Hot Night degrees is observed. The effects of Hot Night hours reach their maximum with 100% and leads to an increase by 9.2% (CI95% 5.3‚Äì13.1%). The hourly description of night heat effects reduced to a single indicator in duration and intensity is a new approach and shows a different perspective and significant heat-related effects on human health.","tags":["heat","mortality","tropical night","hot night","effects","human health","climate change"],"title":"The effects of hot nights on mortality in Barcelona, Spain","type":"publication"},{"authors":["D Roy√©","J Martin-Vide"],"categories":null,"content":"","date":1496275200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1496275200,"objectID":"ef78992172b280763b5273081ec3915b","permalink":"/es/publication/usa_ci_2017/","publishdate":"2017-06-01T00:00:00Z","relpermalink":"/es/publication/usa_ci_2017/","section":"publication","summary":"The contiguous US exhibits a wide variety of precipitation regimes, first, because of the wide range of latitudes and altitudes. The physiographic units with a basic meridional configuration contribute to the differentiation between east and west in the country while generating some large interior continental spaces. The frequency distribution of daily precipitation amounts almost anywhere conforms to a negative exponential distribution, reflecting the fact that there are many small daily totals and few large ones. Positive exponential curves, which plot the cumulative percentages of days with precipitation against the cumulative percentage of the rainfall amounts that they contribute, can be evaluated through the Concentration Index. The Concentration Index has been applied to the contiguous United States using a gridded climate dataset of daily precipitation data, at a resolution of 0.25¬∞, provided by CPC/NOAA/OAR/Earth System Research Laboratory, for the period between 1956 and 2006. At the same time, other rainfall indices and variables such as the annual coefficient of variation, seasonal rainfall regimes and the probabilities of a day with precipitation have been presented with a view to explaining spatial CI patterns. The spatial distribution of the CI in the contiguous United States is geographically consistent, reflecting the principal physiographic and climatic units of the country. Likewise, linear correlations have been established between the CI and geographical factors such as latitude, longitude and altitude. In the latter case the Pearson correlation coefficient (r) between this factor and the CI is ‚àí0.51 (p-value ","tags":["Concentration Index","Contiguous United States","daily precipitation","precipitation indices","spatial‚Äìtemporal patterns"],"title":"Concentration of Daily Precipitation in the Contiguous United States","type":"publication"},{"authors":["P Fdez-Arroyabe","D Roy√©"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1483228800,"objectID":"395d06650f0c20c6eb0045e172f386ce","permalink":"/es/publication/chapter_springer_2017/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/es/publication/chapter_springer_2017/","section":"publication","summary":"Co-creation of scientific knowledge based on new technologies and big data sources is one of the main challenges for the digital society in the XXI century. Data management and the analysis of patterns among datasets based on machine learning and artificial intelligence has become essential for many sectors nowadays. The development of real time health-related climate services represents an example where abundant structured and unstructured information and transdisciplinary research are needed. The study of the interactions between atmospheric processes and human health through a big data approach can reveal the hidden value of data. The Oxyalert technological platform is presented as an example of a digital biometeorological infrastructure able to forecast, at an individual level, oxygen changes impacts on human health.","tags":["co-creation","interdisciplinarity","transdisciplinarity","morbidity","climate services","digital divide","big data","health"],"title":"Co-creation and Participatory Design of Big Data Infrastructures on the Field of Human Health Related Climate Services","type":"publication"},{"authors":["D Roy√©","J Taboada","A Ezpeleta-Mart√≠","N Lorenzo"],"categories":null,"content":"","date":1459468800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1459468800,"objectID":"103600468f174f2c7309eee0a4356933","permalink":"/es/publication/cwt_galicia_resp_2016/","publishdate":"2016-04-01T00:00:00Z","relpermalink":"/es/publication/cwt_galicia_resp_2016/","section":"publication","summary":"The link between various pathologies and atmospheric conditions has been a constant topic of study over recent decades in many places across the world; knowing more about it enables us to pre-empt the worsening of certain diseases, thereby optimizing medical resources. This study looked specifically at the connections in winter between respiratory diseases and types of atmospheric weather conditions (Circulation Weather Types, CWT) in Galicia, a region in the north-western corner of the Iberian Peninsula. To do this, the study used hospital admission data associated with these pathologies as well as an automatic classification of weather types. The main result obtained was that weather types giving rise to an increase in admissions due to these diseases are those associated with cold, dry weather, such as those in the east and south-east, or anticyclonic types. A second peak was associated with humid, hotter weather, generally linked to south-west weather types. In the future, this result may help to forecast the increase in respiratory pathologies in the region some days in advance.","tags":["weather type","respiratory diseases","hospital admissions","human health","Spain"],"title":"Winter circulation weather types and hospital admissions for respiratory diseases in Galicia, Spain","type":"publication"},{"authors":["D Roy√©","A Ezpeleta-Mart√≠"],"categories":null,"content":"","date":1448928000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1448928000,"objectID":"b3b3af88b0383548a9a15d5635968b2a","permalink":"/es/publication/hotnights_age_2015/","publishdate":"2015-12-01T00:00:00Z","relpermalink":"/es/publication/hotnights_age_2015/","section":"publication","summary":"En este trabajo se aplica una metodolog√≠a nueva al estudio de las noches calurosas, tambi√©n denominadas ¬´tropicales¬ª, en Galicia y en Portugal de cara a identificar aquellas noches en las que la poblaci√≥n pueda verse afectada por estr√©s t√©rmico. La utilizaci√≥n de dos indicadores obtenidos a trav√©s de datos semihorarios ha permitido definir con m√°s detalle las caracter√≠sticas t√©rmicas de las noches entre mayo y octubre, pudiendo as√≠ evaluar con m√°s precisi√≥n el riesgo para el bienestar y la salud de la poblaci√≥n. Se produce un importante aumento de la frecuencia de noches tropicales y noches c√°lidas en la fachada atl√°ntica, desde el norte de Galicia hasta el sur de Portugal. La menor latitud y la proximidad al litoral est√°n relacionadas con la mayor persistencia del calor y del estr√©s t√©rmico durante estas noches. En √°reas de interior la persistencia es menor. Las noches calurosas son m√°s frecuentes e intensas en el centro de las ciudades, por el efecto de la isla de calor urbana.","tags":["noches tropicales","estr√©s t√©rmico","isla de calor","Galicia","Portugal"],"title":"An√°lisis de las noches tropicales en la fachada atl√°ntica de la Pen√≠nsula Ib√©rica. Una propuesta metodol√≥gica","type":"publication"},{"authors":["D Roy√©"],"categories":null,"content":"Los datos usados est√°n disponibles aqu√≠. Otras bases de datos para Espa√±a en formato ncdf pueden ser descargadas:\nAEMET\n Rejilla 20km y 50km (precipitaci√≥n y temperatura)\n Rejilla 5km (precipitaci√≥n)\n  CSIC\n Rejilla 5km (precipitaci√≥n)  ","date":1448928000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1448928000,"objectID":"df5e959cdcb892f902f61f17b25f9552","permalink":"/es/publication/ncdf_2015/","publishdate":"2015-12-01T00:00:00Z","relpermalink":"/es/publication/ncdf_2015/","section":"publication","summary":"La informaci√≥n espacio-temporal es en la actualidad un elemento clave en disciplinas como la Climatolog√≠a y la Meteorolog√≠a. Un formato de uso muy extendido es el de las bases de datos netCDF, que permiten obtener una estructura multidimensional e intercambiar los datos de forma independiente al sistema operativo empleado. En este art√≠culo se introduce el uso de estas bases de datos con el entorno de software libre R. Para ello se utiliza una cuadr√≠cula de la temperatura m√°xima de la Pen√≠nsula Ib√©rica para el per√≠odo 1971-2007. El objetivo es poder leer y visualizar el formato netCDF realizando ejemplos de c√°lculos globales y otros m√°s espec√≠ficos. Finalmente se muestra la aplicabilidad en un caso de estudio: la amplitud diurna en la Pen√≠nsula Ib√©rica para los meses de enero y agosto 2006.","tags":["netCDF","R","climatolog√≠a","temperatura","matriz","base de datos"],"title":"El uso de bases de datos clim√°ticos netCDF con estructura matricial en el entorno de R","type":"publication"}]