<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ncdf | Dr. Dominic Royé</title>
    <link>https://dominicroye.github.io/es/tag/ncdf/</link>
      <atom:link href="https://dominicroye.github.io/es/tag/ncdf/index.xml" rel="self" type="application/rss+xml" />
    <description>ncdf</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>es-ES</language><copyright>© 2018-2022 Dominic Royé. All rights reserved</copyright><lastBuildDate>Tue, 08 Mar 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://dominicroye.github.io/media/logo_hu6637600e1c36fe7812a10a6623aaebda_116520_300x300_fit_lanczos_3.png</url>
      <title>ncdf</title>
      <link>https://dominicroye.github.io/es/tag/ncdf/</link>
    </image>
    
    <item>
      <title>Uso de datos multidimensionales espaciales</title>
      <link>https://dominicroye.github.io/es/2022/uso-de-datos-multidimensionales-espaciales/</link>
      <pubDate>Tue, 08 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://dominicroye.github.io/es/2022/uso-de-datos-multidimensionales-espaciales/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/es/2022/uso-de-datos-multidimensionales-espaciales/index.es_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;consideraciones-iniciales&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Consideraciones iniciales&lt;/h1&gt;
&lt;p&gt;La información espacio-temporal es clave en muchas disciplinas, especialmente en la climatología o la meteorología, y ello hace necesario disponer de un formato que permita una estructura multidimensional. Además es importante que ese formato tenga un alto grado de compatibilidad de intercambio y pueda almacenar un elevado número de datos. Estas características llevaron al desarrollo del estándar abierto netCDF (NetworkCommon Data Form). El formato netCDF es un estándar abierto de intercambio de datos científicos multidimensionales que se utiliza con datos de observaciones o modelos, principalmente en disciplinas como la climatología, la meteorología y la oceanografía. La convención netCDF es gestionada por Unidata (unidata.ucar.edu/software/netcdf). Se trata de un formato espacio-temporal con una cuadrícula regular o irregular. La estructura multidimensional en forma de matriz (array) permite usar no sólo datos espacio-temporales, sino también multivariables. Las características generales del netCDF se refieren al uso de un sistema de coordenadas n-dimensional, de múltiples variables y de una rejilla regular o irregular. Además se incluyen metadatos que describen los contenidos. La extensión del formato netCDF es “nc”.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;3d_ncdf.es.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Recientemente hice uso de datos de sequía de España en formato netCDF con una resolución de 1 km para representar el estado de sequía de cada año desde 1960 (&lt;a href=&#34;https://monitordesequia.csic.es/historico/&#34; class=&#34;uri&#34;&gt;https://monitordesequia.csic.es/historico/&lt;/a&gt;). El índice SPEI (Standardized Precipitation-Evapotranspiration Index) es ampliamente usado para describir la situación de sequía con referencia a diferentes intervalos temporales (3, 6, 12 meses etc).&lt;/p&gt;
&lt;p&gt;{{&amp;lt; tweet 1490260694851362821 &amp;gt;}}&lt;/p&gt;
&lt;p&gt;He sido preguntado en varias ocaciones sobre el manejo del formato netCDF, por esta razón, en este post hacemos uso de un subconjunto, el año 2017 del SPEI 12 meses, de estos mismos datos.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;paquetes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Paquetes&lt;/h1&gt;
&lt;p&gt;El manejo de datos en formato netCDF es posible a través de varios paquetes de forma directa o indirecta. Destaca el paquete &lt;code&gt;{ncdf4}&lt;/code&gt; específicamente diseñado, del que hacen uso también otros paquetes aunque no lo veamos. El manejo con &lt;code&gt;{ncdf4}&lt;/code&gt; es algo complejo, particularmente por la necesidad de gestionar la memoria RAM cuando tratamos grandes conjuntos de datos o también por la forma de manejar la clase &lt;em&gt;array&lt;/em&gt;. Otro paquete muy potente es &lt;code&gt;{terra}&lt;/code&gt;, que conocemos cuando trabajamos con datos raster y permite usar sus funciones también para el manejo del formato netCDF.&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;10%&#34; /&gt;
&lt;col width=&#34;89%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Paquete&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Descripción&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Conjunto de paquetes (visualización y manipulación de datos): ggplot2, dplyr, purrr,etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Simple Feature: importar, exportar y manipular datos vectoriales&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lubridate&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Fácil manipulación de fechas y tiempos&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;terra&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Importar, exportar y manipular raster (paquete sucesor de raster)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mapSpain&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Límites administrativos de España&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# instalamos los paquetes si hace falta

if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;sf&amp;quot;)) install.packages(&amp;quot;sf&amp;quot;)
if(!require(&amp;quot;lubridate&amp;quot;)) install.packages(&amp;quot;lubridate&amp;quot;)
if(!require(&amp;quot;terra&amp;quot;)) install.packages(&amp;quot;terra&amp;quot;)
if(!require(&amp;quot;mapSpain&amp;quot;)) install.packages(&amp;quot;mapSpain&amp;quot;)

# paquetes
library(tidyverse)
library(sf)
library(terra)
library(lubridate)
library(mapSpain)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Para aquellos con menos experiencia con &lt;code&gt;tidyverse&lt;/code&gt;, recomiendo una breve introducción en este blog &lt;a href=&#34;https://dominicroye.github.io/es/2020/una-muy-breve-introducci%C3%B3n-a-tidyverse/&#34;&gt;post&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;datos&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Datos&lt;/h1&gt;
&lt;p&gt;Primero descargamos los datos &lt;a href=&#34;https://www.dropbox.com/s/ioo2ky7wb3zxkdx/spei12_2017.nc?dl=0&#34;&gt;aquí&lt;/a&gt;. Importamos los datos del índice SPEI-12 del año 2017 usando la función &lt;code&gt;rast()&lt;/code&gt;. En realidad en este paso sólo hemos creado una referencia al archivo sin importar todos los datos a la memoria. Vemos en los metadatos el número de capas (&lt;em&gt;layers&lt;/em&gt;) disponibles. El índice SPEI-12 está calculado semanalmente con 4 semanas por mes. Si nos fijamos en los metadatos, falta la definicón del sistema de coordenadas, por ello la definimos asignando el código EPSG:25830 (ETRS89/UTM 30N).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# importamos
spei &amp;lt;- rast(&amp;quot;spei12_2017.nc&amp;quot;)
# metadatos
spei&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class       : SpatRaster 
## dimensions  : 834, 1115, 48  (nrow, ncol, nlyr)
## resolution  : 1100, 1100  (x, y)
## extent      : -80950, 1145550, 3979450, 4896850  (xmin, xmax, ymin, ymax)
## coord. ref. :  
## source      : spei12_2017.nc 
## names       : spei1~017_1, spei1~017_2, spei1~017_3, spei1~017_4, spei1~017_5, spei1~017_6, ... 
## time        : 2017-01-01 to 2017-12-23&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# definimos el sistema de coordenadas
crs(spei) &amp;lt;- &amp;quot;EPSG:25830&amp;quot;

# mapeamos las primeras semanas
plot(spei)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/es/2022/uso-de-datos-multidimensionales-espaciales/index.es_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;extraer-metadatos&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Extraer metadatos&lt;/h1&gt;
&lt;p&gt;Existen diferentes funciones para acceder a metadatos como las fechas, los nombres de las capas o de las variables. Recordemos que los archivos netCDF también pueden contener varias variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fechas
t &amp;lt;- time(spei)
head(t)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2017-01-01 UTC&amp;quot; &amp;quot;2017-01-09 UTC&amp;quot; &amp;quot;2017-01-16 UTC&amp;quot; &amp;quot;2017-01-23 UTC&amp;quot;
## [5] &amp;quot;2017-02-01 UTC&amp;quot; &amp;quot;2017-02-09 UTC&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# nombres de capas
names(spei) %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;spei12_2017_1&amp;quot; &amp;quot;spei12_2017_2&amp;quot; &amp;quot;spei12_2017_3&amp;quot; &amp;quot;spei12_2017_4&amp;quot;
## [5] &amp;quot;spei12_2017_5&amp;quot; &amp;quot;spei12_2017_6&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# nombres de variables
varnames(spei)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;spei12_2017&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;extracción-de-series-temporales&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Extracción de series temporales&lt;/h1&gt;
&lt;p&gt;Una posibiliad que permiten los datos netCDF es la extracción de series temporales, bien a partir de puntos o áreas. Creamos la series temporales del SPEI-12 para la ciudad de Zaragoza y el promedio de toda la comunidad autónoma de Aragón.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# coordenadas de Zaragoza
zar &amp;lt;- st_point(c(-0.883333, 41.65)) %&amp;gt;% 
          st_sfc(crs = 4326) %&amp;gt;% 
           st_as_sf() %&amp;gt;% 
            st_transform(25830)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;El paquete &lt;code&gt;{terra}&lt;/code&gt; sólo acepta su propia clase vectorial &lt;em&gt;SpatVector&lt;/em&gt;, por eso es necesario convertir el punto de clase &lt;em&gt;sf&lt;/em&gt; con la función &lt;code&gt;vect()&lt;/code&gt;. Para extraer la serie temporal empleamos la función &lt;code&gt;extract()&lt;/code&gt;. Los datos extraídos los encontramos en forma de una tabla, cada fila es un elemento de los datos vectoriales y cada columna una capa. En nuestro caso sólo es una fila correspondiente a la ciudad de Zaragoza.&lt;/p&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Algunas funciones pueden tener conflictos con nombres de otros paquetes, para evitarlo podemos escribir el nombre del paquete delante de la función que queremos usar, separados por el símbolo de dos puntos escrito dos veces (&lt;code&gt;package_name::function_name&lt;/code&gt;).
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extraer la serie temporal
spei_zar &amp;lt;- terra::extract(spei, vect(zar))

# dimensiones
dim(spei_zar)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  1 49&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# creamos un data.frame
spei_zar &amp;lt;- tibble(date = t, zar = unlist(spei_zar)[-1])
head(spei_zar)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 2
##   date                  zar
##   &amp;lt;dttm&amp;gt;              &amp;lt;dbl&amp;gt;
## 1 2017-01-01 00:00:00 0.280
## 2 2017-01-09 00:00:00 0.25 
## 3 2017-01-16 00:00:00 0.220
## 4 2017-01-23 00:00:00 0.210
## 5 2017-02-01 00:00:00 0.350
## 6 2017-02-09 00:00:00 0.220&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;El promedio de la comunidad autónoma de Aragón lo obtenemos usando la geometría de polígono e indicando el tipo de función con la que queremos resumir el área. La función &lt;code&gt;esp_get_ccaa()&lt;/code&gt; del paquete &lt;code&gt;mapSpain()&lt;/code&gt; es muy útil a la hora de importar límites administrativos españoles de diferentes niveles. En la extracción es importante que pasemos el argumento &lt;code&gt;na.rm = TRUE&lt;/code&gt; de la función &lt;code&gt;mean()&lt;/code&gt; para excluir píxeles sin valor.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# límites de Aragón
aragon &amp;lt;- esp_get_ccaa(&amp;quot;Aragón&amp;quot;) %&amp;gt;% 
            st_transform(25830)

# extraemos los valores medios del SPEI-12
spei_arag &amp;lt;- terra::extract(spei, vect(aragon), fun = &amp;quot;mean&amp;quot;, na.rm = TRUE)

# añadimos los nuevos valores a nuestro data.frame
spei_zar &amp;lt;- mutate(spei_zar, arag = unlist(spei_arag)[-1])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;En el seguiente paso transformamos la tabla al formato largo con &lt;code&gt;pivot_longer()&lt;/code&gt;, fusionando el valor del índice SPEI de Zaragoza y Aragón. Además añadiremos una columna con la interpretación del índice y cambiaremos las etiquetas.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spei_zar &amp;lt;-  pivot_longer(spei_zar, 2:3, names_to = &amp;quot;reg&amp;quot;, values_to = &amp;quot;spei&amp;quot;) %&amp;gt;%
             mutate(sign = case_when(spei &amp;lt; -0.5 ~ &amp;quot;sequía&amp;quot;, 
                                    spei &amp;gt; 0.5 ~ &amp;quot;húmedo&amp;quot;,
                                    TRUE ~ &amp;quot;normal&amp;quot;),
                    date = as_date(date),
                    reg = factor(reg, c(&amp;quot;zar&amp;quot;, &amp;quot;arag&amp;quot;), c(&amp;quot;Zaragoza&amp;quot;, &amp;quot;Aragón&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ahora falta por construir el gráfico en el que comparamos el SPEI-12 de Zaragoza con el promedio de Aragón. La función &lt;code&gt;geom_rect()&lt;/code&gt; nos ayuda a dibujar diferentes rectángulos de fondo para marcar la sequía, episodio normal o húmedo.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# gráfico de serie temporal
ggplot(spei_zar) +
      geom_rect(aes(xmin = min(date), xmax = max(date), 
                    ymin = -0.5, ymax = 0.5), 
                fill = &amp;quot;#41ab5d&amp;quot;) +
      geom_rect(aes(xmin = min(date), xmax = max(date), 
                    ymin = -1, ymax = -0.5), 
                fill = &amp;quot;#ffffcc&amp;quot;) +
      geom_rect(aes(xmin = min(date), xmax = max(date), 
                    ymin = -1.5, ymax = -1), 
                fill = &amp;quot;#F3641D&amp;quot;) +
      geom_hline(yintercept = 0, size = 1, colour = &amp;quot;white&amp;quot;) +
      geom_line(aes(date, spei, linetype = reg), size = 1, alpha = .7) +
  scale_x_date(date_breaks = &amp;quot;month&amp;quot;, date_labels = &amp;quot;%b&amp;quot;) +
  labs(linetype = &amp;quot;&amp;quot;, y = &amp;quot;SPEI-12&amp;quot;, x = &amp;quot;&amp;quot;) +
  coord_cartesian(expand = FALSE) +
  theme_minimal() +
  theme(legend.position = c(.25, .9),
        panel.grid.minor = element_blank(),
        panel.ontop = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/es/2022/uso-de-datos-multidimensionales-espaciales/index.es_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mapa-de-sequía&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Mapa de sequía&lt;/h1&gt;
&lt;div id=&#34;españa&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;España&lt;/h2&gt;
&lt;p&gt;Con el objetivo de crear un mapa de la severidad de sequía en 2017, primero debemos hacer algunas modificaciones. Con la función &lt;code&gt;subset()&lt;/code&gt; obtenemos una capa o varias como subconjunto, aquí seleccionamos la última para poder ver el estado de sequía de todo el año.&lt;/p&gt;
&lt;p&gt;En el siguiente paso reemplazamos todos los valores mayores de -0,5 con &lt;code&gt;NA&lt;/code&gt;. Se considera sequía cuando el índice SPEI está debajo de -0,5 y, en cambio, si está encima de 0,5 hablaríamos de un período húmedo.&lt;/p&gt;
&lt;p&gt;La clase del raster no es directamente compatible con &lt;code&gt;ggplot&lt;/code&gt;, por eso, lo convertimos en una tabla xyz con longitud, latitud y la variable. Cuando hacemos la misma conversión de varias capas cada columna representaría una capa. Finalmente renombramos nuestra columna del índice y añadimos una nueva columna con distintos grados de severidad de sequía.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extraemos capa(s) con su índice 
spei_anual &amp;lt;- subset(spei, 48) 

# sustituimos valores de no-sequía con NA
spei_anual[spei_anual &amp;gt; -0.5] &amp;lt;- NA

# convertimos nuestro raster en una tabla de xyz
spei_df &amp;lt;- as.data.frame(spei_anual, xy = TRUE)
head(spei_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            x       y spei12_2017_48
## 38096 123100 4858900          -1.48
## 39195 105500 4857800          -1.59
## 39197 107700 4857800          -1.40
## 39211 123100 4857800          -1.47
## 39212 124200 4857800          -1.50
## 40310 105500 4856700          -1.63&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# cambiamos el nombre de la variable
names(spei_df)[3] &amp;lt;- &amp;quot;spei&amp;quot;

# categorizamos el índice y fijamos el orden del factor
spei_df &amp;lt;- mutate(spei_df, spei_cat = case_when(spei &amp;gt; -0.9 ~ &amp;quot;leve&amp;quot;,
                                                spei &amp;gt; -1.5 &amp;amp; spei &amp;lt; -0.9 ~ &amp;quot;moderada&amp;quot;,
                                                spei &amp;gt; -2 &amp;amp; spei &amp;lt;= -1.5 ~ &amp;quot;severa&amp;quot;,
                                                TRUE ~ &amp;quot;extrema&amp;quot;) %&amp;gt;% 
                                      fct_relevel(c(&amp;quot;leve&amp;quot;, &amp;quot;moderada&amp;quot;, &amp;quot;severa&amp;quot;, &amp;quot;extrema&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Un mapa de raster lo creamos con la geometría &lt;code&gt;geom_tile()&lt;/code&gt; indicando longitud, latitud y el color de los píxeles con nuestra variable categorizada.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ccaa &amp;lt;- esp_get_ccaa() %&amp;gt;% 
            filter(!ine.ccaa.name %in% c(&amp;quot;Canarias&amp;quot;, &amp;quot;Ceuta&amp;quot;, &amp;quot;Melilla&amp;quot;)) %&amp;gt;% 
              st_transform(25830)

# mapa
ggplot(spei_df) +
   geom_tile(aes(x , y, fill = spei_cat)) +
  geom_sf(data = ccaa, fill = NA, size = .1, colour = &amp;quot;white&amp;quot;, alpha = .4) +
  scale_fill_manual(values = c(&amp;quot;#ffffcc&amp;quot;, &amp;quot;#F3641D&amp;quot;, &amp;quot;#DE2929&amp;quot;, &amp;quot;#8B1A1A&amp;quot;),
                    na.value = NA) +
  guides(fill = guide_legend(keywidth = 2, keyheight = .3, label.position = &amp;quot;bottom&amp;quot;,
                             title.position = &amp;quot;top&amp;quot;)) +
  coord_sf() +
  labs(fill = &amp;quot;SEQUIA&amp;quot;) +
  theme_void() +
  theme(legend.position = &amp;quot;top&amp;quot;,
        legend.justification = 0.2,
        plot.background = element_rect(fill = &amp;quot;black&amp;quot;, colour = NA),
        legend.title = element_text(colour = &amp;quot;white&amp;quot;, size = 20, hjust = .5),
        legend.text = element_text(colour = &amp;quot;white&amp;quot;),
        plot.margin = margin(t = 10))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/es/2022/uso-de-datos-multidimensionales-espaciales/index.es_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;758.4&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;aragón&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Aragón&lt;/h2&gt;
&lt;p&gt;En este último ejemplo, seleccionamos la situación de sequía a 12 meses vista, a principios y final de año. La función principal es &lt;code&gt;crop()&lt;/code&gt; que recorta a la extensión de un objeto espacial, en nuestro caso es Aragón, después aplicamos la función &lt;code&gt;mask()&lt;/code&gt; que enmascara todos aquellos píxeles dentro de los límites dejando en &lt;code&gt;NA&lt;/code&gt; los demás.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# subconjunto primera y ultima semana 2017
spei_sub &amp;lt;- subset(spei, c(1, 48)) 

# recortamos y enmascaramos Aragón
spei_arag &amp;lt;- crop(spei_sub, aragon) %&amp;gt;% 
                    mask(vect(aragon)) 

# convertimos los datos a xyz
spei_df_arag &amp;lt;- as.data.frame(spei_arag, xy = TRUE)

# renombramos las dos capas
names(spei_df_arag)[3:4] &amp;lt;- c(&amp;quot;Enero&amp;quot;, &amp;quot;Diciembre&amp;quot;)

# pasamos al formato de tabla larga fusionando ambos meses
spei_df_arag &amp;lt;- pivot_longer(spei_df_arag, 3:4, 
                             names_to = &amp;quot;mes&amp;quot;, 
                             values_to = &amp;quot;spei&amp;quot;) %&amp;gt;% 
                mutate(mes = fct_relevel(mes, c(&amp;quot;Enero&amp;quot;, &amp;quot;Diciembre&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Los dos mapas los hacemos de la misma forma como el de España. La diferencia principal es que usamos el índice SPEI directamente como variable continua. Además, para crear dos mapas con una fila añadimos la función &lt;code&gt;facet_grid()&lt;/code&gt;. Por último, el índice muestra valores negativos y positivos, por tanto, es necesario una gama divergente de colores. Con el objetivo de centrar el punto medio en 0 debemos reescalar con ayuda de la función &lt;code&gt;rescale()&lt;/code&gt; del paquete &lt;code&gt;scales&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# mapa de Aragón
ggplot(spei_df_arag) +
   geom_tile(aes(x , y, fill = spei)) +
  geom_sf(data = aragon, fill = NA, size = .1, colour = &amp;quot;white&amp;quot;, alpha = .4) +
  scale_fill_distiller(palette = &amp;quot;RdYlGn&amp;quot;, direction = 1, 
                       values = scales::rescale(c(-2.1, 0, 0.9)),
                       breaks = seq(-2, 1, .5)) +
  guides(fill = guide_colorbar(barwidth = 8, barheight = .3, label.position = &amp;quot;bottom&amp;quot;)) +
  facet_grid(. ~ mes) +
  coord_sf() +
  labs(fill = &amp;quot;SPEI-12&amp;quot;, title = &amp;quot;Aragón&amp;quot;) +
  theme_void() +
  theme(legend.position = &amp;quot;top&amp;quot;,
        legend.justification = 0.5,
        legend.title = element_text(colour = &amp;quot;white&amp;quot;, vjust = 1.1),
        strip.text = element_text(colour = &amp;quot;white&amp;quot;),
        plot.background = element_rect(fill = &amp;quot;black&amp;quot;, colour = NA),
        plot.title = element_text(colour = &amp;quot;white&amp;quot;, size = 20, hjust = .5, vjust = 2.5,
                                  margin = margin(b = 10, t = 10)),
        legend.text = element_text(colour = &amp;quot;white&amp;quot;),
        plot.margin = margin(10, 10, 10, 10))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/es/2022/uso-de-datos-multidimensionales-espaciales/index.es_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;más-posibilidades&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Más posibilidades&lt;/h1&gt;
&lt;p&gt;Es posible agrupar las diferentes capas aplicando una función. Usando los meses de cada semana del SPEI-12 podemos calcular el promedio mensual en 2017. Para ello hacemos uso de la función &lt;code&gt;tapp()&lt;/code&gt; que a su vez aplica sobre índices otra función. Es imporante que el grupo o bien sea un factor o el índice de cada capa. Las funciónes &lt;code&gt;tapp()&lt;/code&gt; y &lt;code&gt;app()&lt;/code&gt; tienen un argumento para procesar en paralelo usando más de un núcleo.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# meses como factor
mo &amp;lt;- month(t, label = TRUE)
mo&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] ene ene ene ene feb feb feb feb mar mar mar mar abr abr abr abr may may may
## [20] may jun jun jun jun jul jul jul jul ago ago ago ago sep sep sep sep oct oct
## [39] oct oct nov nov nov nov dic dic dic dic
## 12 Levels: ene &amp;lt; feb &amp;lt; mar &amp;lt; abr &amp;lt; may &amp;lt; jun &amp;lt; jul &amp;lt; ago &amp;lt; sep &amp;lt; ... &amp;lt; dic&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# promedio por mes
spei_mo &amp;lt;- tapp(spei, mo, mean)
spei_mo&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class       : SpatRaster 
## dimensions  : 834, 1115, 12  (nrow, ncol, nlyr)
## resolution  : 1100, 1100  (x, y)
## extent      : -80950, 1145550, 3979450, 4896850  (xmin, xmax, ymin, ymax)
## coord. ref. : ETRS89 / UTM zone 30N (EPSG:25830) 
## source      : memory 
## names       :     ene,     feb,     mar,     abr,     may,     jun, ... 
## min values  : -1.2800, -1.4675, -2.2400, -2.6500, -2.5775, -2.4675, ... 
## max values  :  1.3875,  1.9175,  1.7475,  1.8375,  1.7500,  1.7000, ...&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# mapas
plot(spei_mo)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/es/2022/uso-de-datos-multidimensionales-espaciales/index.es_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;La función &lt;code&gt;mean()&lt;/code&gt; directamente usado sobre un objeto de clase &lt;code&gt;SpatRaster&lt;/code&gt; multidimensional devuelve el promedio por celda. El mismo resultado lo podemos obtener con la función &lt;code&gt;app()&lt;/code&gt; que aplica cualquier función. El número de capas resultante depende de la función, por ejemplo, al aplicar &lt;code&gt;range()&lt;/code&gt; el resultado son dos capas, una del valor mínimo y otra del máximo. Por último, la función &lt;code&gt;global()&lt;/code&gt; resume con la función indicada cada capa en forma de una tabla.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# promedio sobre capas
spei_mean &amp;lt;- mean(spei)
spei_mean&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class       : SpatRaster 
## dimensions  : 834, 1115, 1  (nrow, ncol, nlyr)
## resolution  : 1100, 1100  (x, y)
## extent      : -80950, 1145550, 3979450, 4896850  (xmin, xmax, ymin, ymax)
## coord. ref. : ETRS89 / UTM zone 30N (EPSG:25830) 
## source      : memory 
## name        :      mean 
## min value   : -2.127083 
## max value   :  1.568542&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# mapa
plot(spei_mean)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/es/2022/uso-de-datos-multidimensionales-espaciales/index.es_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# alternativa
spei_min &amp;lt;- app(spei, min)
spei_min&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class       : SpatRaster 
## dimensions  : 834, 1115, 1  (nrow, ncol, nlyr)
## resolution  : 1100, 1100  (x, y)
## extent      : -80950, 1145550, 3979450, 4896850  (xmin, xmax, ymin, ymax)
## coord. ref. : ETRS89 / UTM zone 30N (EPSG:25830) 
## source      : memory 
## name        :   min 
## min value   : -3.33 
## max value   :  0.29&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spei_range &amp;lt;- app(spei, range)
names(spei_range) &amp;lt;- c(&amp;quot;min&amp;quot;, &amp;quot;max&amp;quot;)
spei_range&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class       : SpatRaster 
## dimensions  : 834, 1115, 2  (nrow, ncol, nlyr)
## resolution  : 1100, 1100  (x, y)
## extent      : -80950, 1145550, 3979450, 4896850  (xmin, xmax, ymin, ymax)
## coord. ref. : ETRS89 / UTM zone 30N (EPSG:25830) 
## source      : memory 
## names       :   min,   max 
## min values  : -3.33, -1.06 
## max values  :  0.29,  2.02&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# mapa
plot(spei_range)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/es/2022/uso-de-datos-multidimensionales-espaciales/index.es_files/figure-html/unnamed-chunk-15-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# resumen estadístico por capa
global(spei, &amp;quot;mean&amp;quot;, na.rm = TRUE) %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                      mean
## spei12_2017_1 -0.03389126
## spei12_2017_2 -0.17395742
## spei12_2017_3 -0.13228593
## spei12_2017_4 -0.07536089
## spei12_2017_5  0.06718260
## spei12_2017_6 -0.03461822&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Acceso a datos de los reanálisis climáticos desde R</title>
      <link>https://dominicroye.github.io/es/2018/acceso-a-datos-de-los-reanalisis-climaticos-desde-r/</link>
      <pubDate>Sat, 15 Sep 2018 10:59:44 +0100</pubDate>
      <guid>https://dominicroye.github.io/es/2018/acceso-a-datos-de-los-reanalisis-climaticos-desde-r/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/es/2018/acceso-a-datos-de-los-reanalisis-climaticos-desde-r/index.es_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introducción&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;1&lt;/span&gt; Introducción&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ncep&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2&lt;/span&gt; NCEP&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#paquetes&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.1&lt;/span&gt; Paquetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#descarga-de-datos&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.2&lt;/span&gt; Descarga de datos&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#promedio-mensual&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.3&lt;/span&gt; Promedio mensual&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#visualización&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.4&lt;/span&gt; Visualización&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#era-interim&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3&lt;/span&gt; ERA-Interim&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#instalación&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.1&lt;/span&gt; Instalación&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conexión-y-descarga-con-la-ecmwf-api&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.2&lt;/span&gt; Conexión y descarga con la ECMWF API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#procesar-ncdf&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.3&lt;/span&gt; Procesar ncdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#actualización-para-acceder-era-5&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4&lt;/span&gt; Actualización para acceder ERA-5&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;Un amigo me propuso que presentara los niveles de aprendizaje de R como categorías. Una idea que ahora introduzco para cada entrada del blog. Hay tres niveles: elemental, intermedio y avanzado. Espero que ayude al lector y al usuario R.&lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;introducción&#34; class=&#34;section level1&#34; number=&#34;1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Introducción&lt;/h1&gt;
&lt;p&gt;En este post enseñaré cómo podemos descargar y trabajar directamente con datos provenientes de los reanálisis climáticos en R. Se trata de sistemas de asimilación de datos que combinan modelos de pronóstico meteorológico y observaciones de distintas fuentes de forma objetiva con el fin de sintetizar el estado actual y la evolución de multiples variables de la atmósfera, la superficie de la tierra y los océanos. Los dos reanálisis más usados son &lt;a href=&#34;https://climatedataguide.ucar.edu/climate-data/ncep-reanalysis-r2&#34;&gt;NCEP-DO&lt;/a&gt; (Reanalysis II) de la &lt;em&gt;NOAA/OAR/ESRL&lt;/em&gt;, una versión mejorada de &lt;em&gt;NCEP-NCAR&lt;/em&gt; (Reanalysis I), y &lt;em&gt;ERA-Interim&lt;/em&gt; del &lt;a href=&#34;https://www.ecmwf.int/en/research/climate-reanalysis&#34;&gt;ECMWF&lt;/a&gt;. Dado que &lt;em&gt;NCEP-DO&lt;/em&gt; es de la primera generacióm, se recomienda usar reanálisis de tercera generación, especialmente &lt;em&gt;ERA-Interim&lt;/em&gt;. Una visión general de los actuales reanálisis atmosféricos la podemos encontrar &lt;a href=&#34;https://reanalyses.org/index.php/atmosphere/overview-current-atmospheric-reanalyses&#34;&gt;aquí&lt;/a&gt;. Primero vamos a ver cómo acceder a los datos del &lt;em&gt;NCEP&lt;/em&gt; a través de un paquete de R en &lt;em&gt;CRAN&lt;/em&gt; que facilita la descarga y el manejo de los datos. Después haremos lo mismo con &lt;em&gt;ERA-Interim&lt;/em&gt;, no obstante, para acceder a este último dataset de reanálisis es necesario usar &lt;em&gt;python&lt;/em&gt; y la correspondiente API del &lt;em&gt;ECMWF&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ncep&#34; class=&#34;section level1&#34; number=&#34;2&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; NCEP&lt;/h1&gt;
&lt;p&gt;Para acceder a los reanálisis del &lt;em&gt;NCEP&lt;/em&gt; es necesario instalar el paquete correspondiente &lt;em&gt;RNCEP&lt;/em&gt;. La función principal es &lt;code&gt;NCEP.gather( )&lt;/code&gt;. La resolución del reanálisis del &lt;em&gt;NCEP&lt;/em&gt; es de 2,5º X 2,5º.&lt;/p&gt;
&lt;div id=&#34;paquetes&#34; class=&#34;section level2&#34; number=&#34;2.1&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.1&lt;/span&gt; Paquetes&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#instalamos los paquetes RNCEP, lubridate y tidyverse
if(!require(&amp;quot;RNCEP&amp;quot;)) install.packages(&amp;quot;RNCEP&amp;quot;)
if(!require(&amp;quot;lubridate&amp;quot;)) install.packages(&amp;quot;lubridate&amp;quot;)
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;sf&amp;quot;)) install.packages(&amp;quot;sf&amp;quot;)

#cargamos las librerías
library(RNCEP)
library(lubridate) #la necesitamos para manipular fechas
library(tidyverse) #para visualizar y manipular 
library(RColorBrewer) #colores para la visualización
library(sf) #para importar un shapefile y trabajar con geom_sf&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;descarga-de-datos&#34; class=&#34;section level2&#34; number=&#34;2.2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.2&lt;/span&gt; Descarga de datos&lt;/h2&gt;
&lt;p&gt;Descargaremos la temperatura del aire a la altura de 850haPa para el año 2016. Las variables y niveles de presión pueden ser consultados en los detalles de la función &lt;code&gt;?NCEP.gather&lt;/code&gt;. El argumento &lt;em&gt;reanalysis2&lt;/em&gt; nos permite descargar tanto la versión I como la versión II, siendo por defecto &lt;em&gt;FALSE&lt;/em&gt;, o sea, se accede al reanálisis I. En todas las consultas obtendremos datos horarios de cada 6 horas (00:00, 06:00, 12:00 y 18:00). Esto supone un total de 1464 valores para el año 2016.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#definimos los argumentos necesarios
month_range &amp;lt;- c(1,12)     #período de meses
year_range &amp;lt;- c(2016,2016) #período de años

lat_range &amp;lt;- c(30,60)      #rango de latitud
lon_range &amp;lt;- c(-30,50)     #rango de longitud
 

data &amp;lt;- NCEP.gather(&amp;quot;air&amp;quot;,    #nombre de la variable
                    850, #altura 850hPa
                    month_range,year_range,
                    lat_range,lon_range,
                    return.units = TRUE,
                    reanalysis2=TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] Units of variable &amp;#39;air&amp;#39; are degK
## [1] Units of variable &amp;#39;air&amp;#39; are degK&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#dimensiones                     
dim(data) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]   13   33 1464&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#encontramos en dimnames( ) lon,lat y tiempo
#fechas y horas 
date_time &amp;lt;- dimnames(data)[[3]]
date_time &amp;lt;- ymd_h(date_time)
head(date_time)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2016-01-01 00:00:00 UTC&amp;quot; &amp;quot;2016-01-01 06:00:00 UTC&amp;quot;
## [3] &amp;quot;2016-01-01 12:00:00 UTC&amp;quot; &amp;quot;2016-01-01 18:00:00 UTC&amp;quot;
## [5] &amp;quot;2016-01-02 00:00:00 UTC&amp;quot; &amp;quot;2016-01-02 06:00:00 UTC&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#longitud y latitud
lat &amp;lt;- dimnames(data)[[1]]
lon &amp;lt;- dimnames(data)[[2]]
head(lon);head(lat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;-30&amp;quot;   &amp;quot;-27.5&amp;quot; &amp;quot;-25&amp;quot;   &amp;quot;-22.5&amp;quot; &amp;quot;-20&amp;quot;   &amp;quot;-17.5&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;60&amp;quot;   &amp;quot;57.5&amp;quot; &amp;quot;55&amp;quot;   &amp;quot;52.5&amp;quot; &amp;quot;50&amp;quot;   &amp;quot;47.5&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;promedio-mensual&#34; class=&#34;section level2&#34; number=&#34;2.3&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.3&lt;/span&gt; Promedio mensual&lt;/h2&gt;
&lt;p&gt;Vemos que se trata de un &lt;em&gt;array&lt;/em&gt; de tres dimensiones con [lat,lon,tiempo]. Además, extraemos latitud, longitud y el tiempo. La temperatura está dada en Kelvin. El objetivo aquí será mostrar dos mapas comparando enero y julio de 2016.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#creamos nuestra variable de agrupación 
group &amp;lt;- month(date_time) 

#estimamos el promedio por mes de la temperatura
data_month &amp;lt;- aperm(
  apply(
    data, #nuestros datos
    c(1,2), #aplicamos a cada serie temporal 1:fila, 2:columna la función mean( )
    by, #agrupar por 
    group, #meses como agrupación
    function(x)ifelse(all(is.na(x)),NA,mean(x))),
  c(2,3,1)) #reordenamos para obtener un array como el original

dim(data_month) #temperatura 850haP por mes enero a diciembre&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 13 33 12&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;visualización&#34; class=&#34;section level2&#34; number=&#34;2.4&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.4&lt;/span&gt; Visualización&lt;/h2&gt;
&lt;p&gt;Ahora, podemos visualizar con &lt;em&gt;ggplot2&lt;/em&gt; la temperatura de enero y julio. En este ejemplo, uso &lt;code&gt;geom_sf( )&lt;/code&gt; del paquetes &lt;a href=&#34;https://github.com/r-spatial/sf&#34;&gt;&lt;em&gt;sf&lt;/em&gt;&lt;/a&gt;, que hace el trabajo más fácil para visualizar en &lt;em&gt;ggplot&lt;/em&gt; objetos espaciales (en el futuro haré un post sobre sf y ggplot). En la dimensión de latitud y longitud vemos que únicamente nos indica para cada fila y columna un valor. Pero necesitamos las coordenadas de todas las celdas de la matriz. Para crear todas las combinaciones entre dos variables usamos la función &lt;code&gt;expand.grid( )&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#primero creamos todas las combinaciones de lonlat
lonlat &amp;lt;- expand.grid(lon=lon,lat=lat)

#lonlat es carácter, ya que fue un nombre, por eso lo convertimos en númerico
lonlat &amp;lt;- apply(lonlat,2,as.numeric)

#lon y lat no están en el orden como lo esperamos
#fila=lon; columna=lat
data_month &amp;lt;- aperm(data_month,c(2,1,3))

#subtraemos 273.15K para convertir K a ºC.
df &amp;lt;- data.frame(lonlat,
                 Ta01=as.vector(data_month[,,1])-273.15,
                 Ta07=as.vector(data_month[,,7])-273.15)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Antes de visualizar los datos con &lt;em&gt;ggplot2&lt;/em&gt;, tenemos que adpatar la tabla. El shapefile con los limites de los países se puede descargar &lt;a href=&#34;https://dominicroye.github.io/files/CNTR_RG_03M_2014.zip&#34;&gt;aquí&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#convertimos la tabla ancha en una larga
df &amp;lt;- gather(df,month,Ta,Ta01:Ta07)%&amp;gt;%
             mutate(month=factor(month,unique(month),c(&amp;quot;Jan&amp;quot;,&amp;quot;Jul&amp;quot;)))

#importamos el limite de países
limit &amp;lt;- st_read(&amp;quot;CNTR_RG_03M_2014.shp&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Reading layer `CNTR_RG_03M_2014&amp;#39; from data source 
##   `E:\GitHub\blog_update_2021\content\es\post\2018-09-15-acceso-a-datos-de-los-reanalisis-desde-r\CNTR_RG_03M_2014.shp&amp;#39; 
##   using driver `ESRI Shapefile&amp;#39;
## Simple feature collection with 256 features and 3 fields
## Geometry type: MULTIPOLYGON
## Dimension:     XY
## Bounding box:  xmin: -180 ymin: -90 xmax: 180 ymax: 83.66068
## Geodetic CRS:  ETRS89&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#gama de colores
colbr &amp;lt;- brewer.pal(11,&amp;quot;RdBu&amp;quot;)

ggplot(df)+
      geom_tile(aes(lon,lat,fill=Ta))+ #temperatura
      geom_sf(data=limit,fill=NA,size=.5)+ #limite
        scale_fill_gradientn(colours=rev(colbr))+
          coord_sf(ylim=c(30,60),xlim=c(-30,50))+
          scale_x_continuous(breaks=seq(-30,50,10),expand=c(0,0))+
          scale_y_continuous(breaks=seq(30,60,5),expand=c(0,0))+
          labs(x=&amp;quot;&amp;quot;,y=&amp;quot;&amp;quot;,fill=&amp;quot;Ta 850hPa (ºC)&amp;quot;)+
           facet_grid(month~.)+ #mapa por mes
             theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/es/2018/acceso-a-datos-de-los-reanalisis-climaticos-desde-r/index.es_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;era-interim&#34; class=&#34;section level1&#34; number=&#34;3&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; ERA-Interim&lt;/h1&gt;
&lt;p&gt;El &lt;em&gt;ECMWF&lt;/em&gt; ofrece acceso a sus bases de datos públicos a partir de una &lt;a href=&#34;https://confluence.ecmwf.int//display/WEBAPI/Access+ECMWF+Public+Datasets&#34;&gt;&lt;em&gt;pyhton-API&lt;/em&gt;&lt;/a&gt;. Es necesario estar registrado en la web del &lt;em&gt;ECMWF&lt;/em&gt;. Se puede darse de alta &lt;a href=&#34;https://apps.ecmwf.int/registration/&#34;&gt;aquí&lt;/a&gt;. Al tratarse de otro lenguaje de programación, en R debemos usar un interfaz entre ambos lo que nos permite el paquete &lt;a href=&#34;https://github.com/rstudio/reticulate&#34;&gt;&lt;em&gt;reticulate&lt;/em&gt;&lt;/a&gt;. También debemos que tener instalada una distribución de pyhton (versión 2.x o 3.x). En el caso de Windows podemos usar &lt;a href=&#34;https://www.anaconda.com/download/&#34;&gt;anaconda&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Recientemente se ha publicado un nuevo paquete &lt;code&gt;ecmwfr&lt;/code&gt; que facilita el acceso a los APIs de Copernicus y ECMWF. La gran ventaja es que no hace falta instalar &lt;code&gt;python&lt;/code&gt;. Más detalles &lt;a href=&#34;https://github.com/khufkens/ecmwfr&#34;&gt;aquí&lt;/a&gt;. En 2022 publiqué un nuevo post actualizado.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;div id=&#34;instalación&#34; class=&#34;section level2&#34; number=&#34;3.1&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.1&lt;/span&gt; Instalación&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if(!require(&amp;quot;reticulate&amp;quot;)) install.packages(&amp;quot;reticulate&amp;quot;)
if(!require(&amp;quot;ncdf4&amp;quot;)) install.packages(&amp;quot;ncdf4&amp;quot;) #para manejar formato netCDF

#cargamos las librerías
library(reticulate)
library(ncdf4)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Una vez que tenemos instalado &lt;em&gt;anaconda&lt;/em&gt; y el paquete &lt;em&gt;reticulate&lt;/em&gt;, podemos instalar el paquete &lt;em&gt;python ecmwfapi&lt;/em&gt;. La instalación la podemos llevar a cabo, o bien através del CMD de Windows usando el comando &lt;em&gt;conda install -c conda-forge ecmwf-api-client&lt;/em&gt;, o bien con la función &lt;code&gt;py_install( )&lt;/code&gt; del paquete &lt;em&gt;reticulate&lt;/em&gt;. La misma función permite instalar cualquier librería &lt;em&gt;python&lt;/em&gt; desde R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#instalamos la API ECMWF
py_install(&amp;quot;ecmwf-api-client&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;conexión-y-descarga-con-la-ecmwf-api&#34; class=&#34;section level2&#34; number=&#34;3.2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.2&lt;/span&gt; Conexión y descarga con la ECMWF API&lt;/h2&gt;
&lt;p&gt;Para poder acceder a la API es requisito crear un archivo con la información del usuario.&lt;/p&gt;
&lt;p&gt;El archivo “.ecmwfapirc” debe contener la siguiente información:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
    &amp;quot;url&amp;quot;   : &amp;quot;https://api.ecmwf.int/v1&amp;quot;,
    &amp;quot;key&amp;quot;   : &amp;quot;XXXXXXXXXXXXXXXXXXXXXX&amp;quot;,
    &amp;quot;email&amp;quot; : &amp;quot;john.smith@example.com&amp;quot;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;La clave podemos obtenerla con la cuenta de usuario &lt;a href=&#34;https://api.ecmwf.int/v1/key/&#34;&gt;aquí&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;El archivo se puede crear con el bloc de notas de Windows.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Creamos un documento “ecmwfapirc.txt”.&lt;/li&gt;
&lt;li&gt;Renombramos este archivo a “.ecmwfapirc.”&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;El último punto desaparece de forma automática. Después guardamos este archivo en “C:/USERNAME/.ecmwfapirc” o “C:/USERNAME/Documents/.ecmwfapirc”.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#importamos la librería python ecmwfapi
ecmwf &amp;lt;- import(&amp;#39;ecmwfapi&amp;#39;)

#en este paso debe existir el archivo .ecmwfapirc
server = ecmwf$ECMWFDataServer() #iniciamos la conexión&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Llegados a este punto, ¿cómo creamos una consulta? Lo más fácil es ir a la web del &lt;a href=&#34;http://apps.ecmwf.int/datasets/data/interim-full-daily/levtype=sfc/&#34;&gt;&lt;em&gt;ECMWF&lt;/em&gt;&lt;/a&gt; dónde elegimos la base de datos, en este caso &lt;em&gt;ERA-Interim&lt;/em&gt; en superficie, para crear un script con todos los datos necesarios. Más detalles sobre la sintaxis podemos encontrar &lt;a href=&#34;https://confluence.ecmwf.int/display/WEBAPI/Brief+request+syntax&#34;&gt;aquí&lt;/a&gt;. Cuando procedemos en la web sólamente tenemos que hacer click en “View MARS Request”. Este paso nos lleva al script en &lt;em&gt;python&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;erainterim1.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;erainterim2.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Con la sintaxis del script que nos da la &lt;em&gt;MARS Request&lt;/em&gt; podemos crear la consulta en R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#creamos la consulta
query &amp;lt;-r_to_py(list(
  class=&amp;#39;ei&amp;#39;,
  dataset= &amp;quot;interim&amp;quot;, #base de datos
  date= &amp;quot;2017-01-01/to/2017-12-31&amp;quot;, #periodo 
  expver= &amp;quot;1&amp;quot;,
  grid= &amp;quot;0.125/0.125&amp;quot;, #resolución
  levtype=&amp;quot;sfc&amp;quot;,
  param= &amp;quot;167.128&amp;quot;, # temperatura del aire (2m)
  area=&amp;quot;45/-10/30/5&amp;quot;, #N/W/S/E
  step= &amp;quot;0&amp;quot;,
  stream=&amp;quot;oper&amp;quot;,
  time=&amp;quot;00:00:00/06:00:00/12:00:00/18:00:00&amp;quot;, #paso de tiempo
  type=&amp;quot;an&amp;quot;,
  format= &amp;quot;netcdf&amp;quot;, #formato
  target=&amp;#39;ta2017.nc&amp;#39; #nombre del archivo
))

server$retrieve(query)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;El resultado es un archivo netCDF que podemos processar con el paquete &lt;em&gt;ncdf4&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;procesar-ncdf&#34; class=&#34;section level2&#34; number=&#34;3.3&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.3&lt;/span&gt; Procesar ncdf&lt;/h2&gt;
&lt;p&gt;A partir de aquí, el objetivo será la extracción de una serie temporal de una coordenada más próxima a una dada. Usaremos las coordenadas de Madrid (40.418889, -3.691944).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#cargamos las librerías 
library(sf)
library(ncdf4)
library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#abrimos la conexión con el archivo
nc &amp;lt;- nc_open(&amp;quot;ta2017.nc&amp;quot;)

#extraemos lon y lat
lat &amp;lt;- ncvar_get(nc,&amp;#39;latitude&amp;#39;)
lon &amp;lt;- ncvar_get(nc,&amp;#39;longitude&amp;#39;)
dim(lat);dim(lon)

#extraemos el tiempo
t &amp;lt;- ncvar_get(nc, &amp;quot;time&amp;quot;)

#unidad del tiempo: horas desde 1900-01-01
ncatt_get(nc,&amp;#39;time&amp;#39;)

#convertimos las horas en fecha+hora 
#as_datetime de lubridate espera segundos
timestamp &amp;lt;- as_datetime(c(t*60*60),origin=&amp;quot;1900-01-01&amp;quot;)

#importamos los datos
data &amp;lt;- ncvar_get(nc,&amp;quot;t2m&amp;quot;)

#cerramos la conexión
nc_close(nc)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Más detalles se pueden consultar en este breve manual sobre cómo trabajar con netCDF &lt;a href=&#34;https://dominicroye.github.io/en/publication/ncdf_2015/&#34;&gt;aqui&lt;/a&gt;. En esta próxima sección hacemos uso del paquete &lt;em&gt;sf&lt;/em&gt; la cuál está sustituyendo las más conocidas &lt;em&gt;sp&lt;/em&gt; y &lt;em&gt;rgdal&lt;/em&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#creamos todas las combinaciones
lonlat &amp;lt;- expand.grid(lon=lon,lat=lat)

#debemos convertir las coordenadas en objeto espacial sf
#además indicamos el sistema de coordenadas en codigo EPSG
coord &amp;lt;- st_as_sf(lonlat,coords=c(&amp;quot;lon&amp;quot;,&amp;quot;lat&amp;quot;))%&amp;gt;%
                    st_set_crs(4326)

#lo mismo hacemos con nuestra coordenada de Madrid
psj &amp;lt;- st_point(c(-3.691944,40.418889))%&amp;gt;%
                   st_sfc()%&amp;gt;%
                     st_set_crs(4326)

#plot de los puntos
plot(st_geometry(coord))
plot(psj,add=TRUE,pch = 3, col = &amp;#39;red&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;En los próximos pasos calculamos la distancia de nuestro punto de referencia a todos los puntos del grid. Posteriormente, buscamos aquel con menos distancia.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#añadimos la distancia a los puntos
coord &amp;lt;- mutate(coord,dist=st_distance(coord,psj))

#creamos una matrix de distancia con las mismas dimensiones que nuestros datos
dist_mat &amp;lt;- matrix(coord$dist,dim(data)[-3])

#la función arrayInd es útil para obtener los índices fila y columna en este caso
mat_index &amp;lt;- as.vector(arrayInd(which.min(dist_mat), dim(dist_mat)))

#extraemos la serie temporal y cambiamos la unidad de K a ºC
#convertimos el tiempo en fecha + hora
df &amp;lt;- data.frame(ta=data[mat_index[1],mat_index[2],],time=timestamp)%&amp;gt;%
        mutate(ta=ta-273.15,time=ymd_hms(time))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Para terminar, visualizamos nuestra serie temporal.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(df,
       aes(time,ta))+
    geom_line()+
    labs(y=&amp;quot;Temperatura (ºC)&amp;quot;,
             x=&amp;quot;&amp;quot;)+
    theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;actualización-para-acceder-era-5&#34; class=&#34;section level1&#34; number=&#34;4&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;4&lt;/span&gt; Actualización para acceder ERA-5&lt;/h1&gt;
&lt;p&gt;Recientemente el nuevo reanálisis ERA-5 con &lt;a href=&#34;https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=overview&#34;&gt;&lt;em&gt;single level&lt;/em&gt;&lt;/a&gt; o &lt;a href=&#34;https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-pressure-levels?tab=overview&#34;&gt;&lt;em&gt;pressure level&lt;/em&gt;&lt;/a&gt; fue puesto a disposición de los usarios. Es la quinta generación del European Centre for Medium-Range Weather Forecasts (ECMWF) y accesible a través de una nueva API de Copernicus. El nuevo reanálisis ERA-5 tiene una cobertura temporal desde 1950 hasta la actualidad a una resolución horizontal de 30km a nivel mundial, con 137 niveles desde la superficie hasta una altura de 80km. Una diferencia importante con respecto al ERA-Interim anterior es la resolución temporal con datos horarios.&lt;/p&gt;
&lt;p&gt;El acceso cambia a la infrastructura de Climate Data Store (CDS) con su propia API. Es posible descargar directamente desde la página o usando la Python API en una forma similar a la ya presentada en este post. Sin embargo, existen ligeras diferencias que voy a explicar a continuación.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Es necesario tener una cuenta en CDS de Copernicus &lt;a href=&#34;https://cds.climate.copernicus.eu/user/register&#34;&gt;link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Nuevamente, hace falta una clave &lt;a href=&#34;https://cds.climate.copernicus.eu/api-how-to&#34;&gt;link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Cambia la librería de Python y algo los argumentos en la consulta.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#cargamos las librerías 
library(sf)
library(ncdf4)
library(tidyverse)
library(reticulate)

#instalamos la CDS API
conda_install(&amp;quot;r-reticulate&amp;quot;,&amp;quot;cdsapi&amp;quot;,pip=TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Para poder acceder a la API un requisito es crear un archivo con la información del usuario.&lt;/p&gt;
&lt;p&gt;El archivo “.cdsapirc” debe contener la siguiente información:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
url: https://cds.climate.copernicus.eu/api/v2
key: {uid}:{api-key}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;La clave la podemos obtener con la cuenta de usuario en el &lt;em&gt;User profile&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;El archivo se puede crear con el bloc de notas de Windows del mismo modo como ha sido explicado para ERA-Interim.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#importamos la librería python CDS
cdsapi &amp;lt;- import(&amp;#39;cdsapi&amp;#39;)

#en este paso debe existir el archivo .cdsapirc
server = cdsapi$Client() #iniciamos la conexión&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Con la sintaxis del script que nos da la &lt;em&gt;Show API request&lt;/em&gt; podemos crear la consulta en R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#creamos la consulta
query &amp;lt;- r_to_py(list(
    variable= &amp;quot;2m_temperature&amp;quot;,
    product_type= &amp;quot;reanalysis&amp;quot;,
    year= &amp;quot;2018&amp;quot;,
    month= &amp;quot;07&amp;quot;, #formato: &amp;quot;01&amp;quot;,&amp;quot;01&amp;quot;, etc.
    day= str_pad(1:31,2,&amp;quot;left&amp;quot;,&amp;quot;0&amp;quot;),   
    time= str_c(0:23,&amp;quot;00&amp;quot;,sep=&amp;quot;:&amp;quot;)%&amp;gt;%str_pad(5,&amp;quot;left&amp;quot;,&amp;quot;0&amp;quot;),
    format= &amp;quot;netcdf&amp;quot;,
    area = &amp;quot;45/-20/35/5&amp;quot; # North, West, South, East
  ))

server$retrieve(&amp;quot;reanalysis-era5-single-levels&amp;quot;,
                  query,
                 &amp;quot;era5_ta_2018.nc&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Es posible que la primera vez se reciba un mensaje de error, dado que todavía no se han aceptado los términos y las condiciones requeridas. Únicamente se debe seguir el enlace indicado.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Error in py_call_impl(callable, dots$args, dots$keywords) : 
  Exception: Client has not agreed to the required terms and conditions.. To access this resource, you first need to accept the termsof &amp;#39;Licence to Use Copernicus Products&amp;#39; at https://cds.climate.copernicus.eu/cdsapp/#!/terms/licence-to-use-copernicus-products&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A partir de aquí podemos seguir los mismos pasos como los hechos con ERA-Interim.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#abrimos la conexión con el archivo
nc &amp;lt;- nc_open(&amp;quot;era5_ta_2018.nc&amp;quot;)

#extraemos lon y lat
lat &amp;lt;- ncvar_get(nc,&amp;#39;latitude&amp;#39;)
lon &amp;lt;- ncvar_get(nc,&amp;#39;longitude&amp;#39;)
dim(lat);dim(lon)

#extraemos el tiempo
t &amp;lt;- ncvar_get(nc, &amp;quot;time&amp;quot;)

#unidad del tiempo: horas desde 1900-01-01
ncatt_get(nc,&amp;#39;time&amp;#39;)

#convertimos las horas en fecha+hora 
#as_datetime de lubridate espera segundos
timestamp &amp;lt;- as_datetime(c(t*60*60),origin=&amp;quot;1900-01-01&amp;quot;)

#temperatura en K de julio 2018
head(timestamp)

#importamos los datos
data &amp;lt;- ncvar_get(nc,&amp;quot;t2m&amp;quot;)

#plot
filled.contour(data[,,1])

plot(data.frame(date=timestamp,ta=data[1,5,]),
     type=&amp;quot;l&amp;quot;)

#cerramos la conexión
nc_close(nc)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
