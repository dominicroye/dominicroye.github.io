[
  {
    "objectID": "publication/index.html",
    "href": "publication/index.html",
    "title": "Publications",
    "section": "",
    "text": "Filter by topic:"
  },
  {
    "objectID": "publication/index.html#journal-articles",
    "href": "publication/index.html#journal-articles",
    "title": "Publications",
    "section": "Journal Articles",
    "text": "Journal Articles\n2025\n\n\nGaliano L, Monjo R, Royé D, Martin-Vide J (2025). Will the world experience more fractal droughts?. Atmospheric Research, vol. 316(1), art. no. 107941.  10.1016/j.atmosres.2025.107941. \n\n\nMeteorological droughts will become the principal factor driving compound hot-dry events and analysis thereof is therefore fundamental with regard to understanding future climate patterns. The average citizen knows little of geometry, but it plays an essential role in the characteristics of the droughts, by means of “fractional lengths”. We analyzed the fractality of the meteorological droughts under the most recent climate change scenarios. A temporal fractality measure based upon the Cantor set reveals consensual changes in the behavior of droughts worldwide. Most regions will undergo a slight increase in fractality (up to +10 % on average), particularly associated with an acceleration of the hydrological cycle and the Hadley cell expansion, with a shift towards the higher latitudes of the tropical edge in both hemispheres. Geometrical measures were applied to the dry spells (1 mm) at a daily scale simulated by the SSP2–4.5 and SSP5–8.5 scenarios from 10 different Earth System Models of the Coupled Model Intercomparison Project Phase 6 (CMIP6). The historical experiment was used as a baseline (1981–2010) and also compared to the ERA5 reanalysis. The results show an increasingly concentrated or uneven distribution of droughts in mid-latitudes towards the end of the century, becoming more intense the more pessimistic the scenario selected. Simultaneously, the polar regions might benefit from more regular precipitation patterns. Other inequality measures, such as the indices of Gini and Monjo, showed similar results. In general terms, the earth’s climate will be more fractal in the rainfall-related patterns, which likely means that the consequences will be more catastrophic for the human population.\n\n\nfractal droughtsclimate changeprecipitation patternsglobaldry spells\n\n\n\n\n\nBatibeniz F, Seneviratne SI, Jha S, Ribeiro A, Suarez Gutierrez L, Raible CC, Malhotra A, Armstrong B, Bell ML, Lavigne E, Gasparrini A, Guo Y, Hashizume M, Masselot P, da Silva S, Royé D, Sera F, Tong S, Urban A, Vicedo-Cabrera AM (2025). Rapid climate action is needed: comparing heat vs. COVID-19-related mortality. Scientific Reports, vol. 15, art. no. 1002.  10.1038/s41598-024-82788-8. \n\n\nThe impacts of climate change on human health are often underestimated or perceived to be in a distant future. Here, we present the projected impacts of climate change in the context of COVID-19, a recent human health catastrophe. We compared projected heat mortality with COVID-19 deaths in 38 cities worldwide and found that in half of these cities, heat-related deaths could exceed annual COVID-19 deaths in less than ten years (at + 3.0 °C increase in global warming relative to preindustrial). In seven of these cities, heat mortality could exceed COVID-19 deaths in less than five years. Our results underscore the crucial need for climate action and for the integration of climate change into public health discourse and policy.\n\n\nclimate actionheat mortalitycovid-19public healthglobal warming\n\n\n\n\n2024\n\n\nXu R, Ye T, Huang W, Yue X, Morawska L, Abramson M, Chen G, Yu P, Liu Y, Yang Z, Zhang Y, Wu Y, Yu W, Wen B, Zhang Y, Hales S, Lavigne E, Saldiva P, Coelho M, Matus P, Royé D, Klompmaker J, Mistry M, Breitner S, Zeka A, Raz R, Tong S, Johnston F, Schwartz J, Gasparrini A, Guo Y, Li S (2024). Global, regional, and national mortality burden attributable to air pollution from landscape fires: a health impact assessment study. The Lancet, vol. 404(10470), pp. 2447-2459.  10.1016/S0140-6736(24)02251-7. \n\n\nBackground: Landscape fire-sourced (LFS) air pollution is an increasing public health concern in the context of climate change. However, little is known about the attributable global, regional, and national mortality burden related to LFS air pollution. Methods: We calculated country-specific population-weighted average daily and annual LFS fine particulate matter (PM2·5) and surface ozone (O3) during 2000-19 from a validated dataset. We obtained the relative risks (RRs) for both short-term and long-term impact of LFS PM2·5 and O3 on all-cause, cardiovascular, and respiratory mortality. The short-term RRs were pooled from community-specific standard time-series regressions in 2267 communities across 59 countries or territories. The long-term RRs were obtained from published meta-analyses of cohort studies on all-source PM2·5 and O3. Annual mortality, population, and socio-demographic data for each country or territory were extracted from the Global Burden of Diseases Study 2019. These data were used to estimate country-specific annual deaths attributable to LFS air pollution using standard algorithms. Findings: Globally, 1·53 million all-cause deaths per year (95% empirical confidence interval [eCI] 1·24-1·82) were attributable to LFS air pollution during 2000-19, including 0·45 million (0·32-0·57) cardiovascular deaths and 0·22 million respiratory deaths (0·08-0·35). LFS PM2·5 and O3 contributed to 77·6% and 22·4% of the total attributable deaths, respectively. Over 90% of all attributable deaths were in low-income and middle-income countries, particularly in sub-Saharan Africa (606 769 deaths per year), southeast Asia (206 817 deaths), south Asia (170 762 deaths), and east Asia (147 291 deaths). The global cardiovascular attributable deaths saw an average 1·67% increase per year (ptrend 0·001), although the trends for all-cause and respiratory attributable deaths were not statistically significant. The five countries with the largest all-cause attributable deaths were China, the Democratic Republic of the Congo, India, Indonesia, and Nigeria, although the order changed in the second decade. The leading countries with the greatest attributable mortality rates (AMRs) were all in sub-Saharan Africa, despite decreasing trends from 2000 to 2019. North and central America, and countries surrounding the Mediterranean, showed increasing trends of all-cause, cardiovascular, and respiratory AMRs. Increasing cardiovascular AMR was also observed in southeast Asia, south Asia, and east Asia. In 2019, the AMRs in low-income countries remained four times those in high-income countries, though this had reduced from nine times in 2000. AMRs negatively correlated with a country-specific socio-demographic index (Spearman correlation coefficients r around -0·60). Interpretation: LFS air pollution induced a substantial global mortality burden, with notable geographical and socioeconomic disparities. Urgent actions are required to address such substantial health impact and the associated environmental injustice in a warming climate.\n\n\nair pollutionlandscape firesmortality burdenhealth impactglobal assessment\n\n\n\n\n\nCarbone J, Sanchez B, Román-Cascón C, Martilli A, Royé D, Yagüe C (2024). Effects of the urban development on the nearsurface air temperature and surface energy balance: The case study of Madrid from 1970 to 2020. Urban Climate, vol. 58, art. no. 102198.  10.1016/j.uclim.2024.102198. \n\n\nThe aim of the present study is to examine the impact of Madrid’s urban growth over the last 50 years (1970–2020). We conduct a modelling study using WRF-ARW with the multilayer urban parameterization BEP-BEM, in which different urban parameters have been incorporated at each point within the model’s inner domain according to urban expansion from 1970 to 2020. Two scenarios of important societal interest with different meteorological conditions are selected for this study: a period of intense heatwave during the summer season and a short period of strongly stable atmospheric conditions in winter, both in 2020. The results show that in areas where the urban fraction becomes greater an increase in near-surface air temperature is found for both simulated periods, especially during the night. The urbanization modifies the surface energy balance and turbulent transport in Madrid and its surroundings. It leads to a decrease in latent heat flux due to the high impermeability and reduced vegetation in urban areas. Additionally, the urban areas with a higher density of buildings have a high heat capacity, increasing heat flux storage during the day through solar radiation absorption. This stored energy is released at night, exacerbating the increase in nighttime near-surface air temperature in both periods.\n\n\nurban climateurban growthnear-surface air temperaturessurface energy balanceturbulenceheatwavestable atmospheric conditionsmadrid\n\n\n\n\n\nFeurer D, Riffe T, Kniffka M, Acosta E, Armstrong B, Mistry M, Lowe R, Royé D, Hashizume M, Madaniyazi L, Ng C, Tobias A, Íñiguez C, Vicedo-Cabrera A, Ragettli M, Lavigne E, Correa P, Ortega N, Kyselý J, Urban A, Orru H, Indermitte E, Maasikmets M, Dallavalle M, Schneider A, Honda Y, Alahmad B, Zanobetti A, Schwartz J, Carrasco G, Holobâca I, Kim H, Lee W, Bell M, Scovronick N, Acquaotta F, Coélho M, Diaz M, Arellano E, Michelozzi P, Stafoggia M, de’Donato F, Rao S, Di Ruscio F, Seposo X, Guo Y, Tong S, Masselot P, Gasparrini A, Sera F (2024). Meteorological factors, population immunity, and COVID19 incidence: A global multicity analysis. Environmental Epidemiology, vol. 8(6), art. no. e338.  10.1097/ee9.0000000000000338. \n\n\nObjectives: While COVID-19 continues to challenge the world, meteorological variables are thought to impact COVID-19 transmission. Previous studies showed evidence of negative associations between high temperature and absolute humidity on COVID-19 transmission. Our research aims to fill the knowledge gap on the modifying effect of vaccination rates and strains on the weather-COVID-19 association. Methods: Our study included COVID-19 data from 439 cities in 22 countries spanning 3 February 2020 - 31 August 2022 and meteorological variables (temperature, relative humidity, absolute humidity, solar radiation, and precipitation). We used a two-stage time-series design to assess the association between meteorological factors and COVID-19 incidence. For the exposure modeling, we used distributed lag nonlinear models with a lag of up to 14 days. Finally, we pooled the estimates using a random effect meta-analytic model and tested vaccination rates and dominant strains as possible effect modifiers. Results: Our results showed an association between temperature and absolute humidity on COVID-19 transmission. At 5 °C, the relative risk of COVID-19 incidence is 1.22-fold higher compared to a reference level at 17 °C. Correlated with temperature, we observed an inverse association for absolute humidity. We observed a tendency of increased risk on days without precipitation, but no association for relative humidity and solar radiation. No interaction between vaccination rates or strains on the weather-COVID-19 association was observed. Conclusions: This study strengthens previous evidence of a relationship of temperature and absolute humidity with COVID-19 incidence. Furthermore, no evidence was found that vaccinations and strains significantly modify the relationship between environmental factors and COVID-19 transmission.\n\n\ncovid-19distributed lag nonlinear modelshumiditymulti-country multi-city collaborative research networkprecipitationsolar radiationtemperaturetime-series design\n\n\n\n\n\nLee W, Kang C, Park C, Bell M, Armstrong B, Royé D, Hashizume M, Gasparrini A, Tobias A, Sera F, Honda Y, Urban A, Kyselý J, Íñiguez C, Ryti N, Guo Y, Tong S, de Sousa Zanotti Stagliorio Coelho M, Lavigne E, de’Donato F, Guo Y, Schwartz J, Schneider A, Breitner S, Chung Y, Kim S, Ha E, Kim H, Kim Y (2024). Association of holidays and the day of the week with suicide risk: multicountry, two stage, time series study. BMJ, vol. 387, art. no. e077262.  10.1136/bmj-2024-077262. \n\n\nObjectives To assess the short term temporal variations in suicide risk related to the day of the week and national holidays in multiple countries. Design Multicountry, two stage, time series design. Setting Data from 740 locations in 26 countries and territories, with overlapping periods between 1971 and 2019, collected from the Multi-city Multi-country Collaborative Research Network database. Participants All suicides were registered in these locations during the study period (overall 1 701  286 cases). Main outcome measures Daily suicide mortality. Results Mondays had peak suicide risk during weekdays (Monday-Friday) across all countries, with relative risks (reference: Wednesday) ranging from 1.02 (95% confidence interval (CI) 0.95 to 1.10) in Costa Rica to 1.17 (1.09 to 1.25) in Chile. Suicide risks were lowest on Saturdays or Sundays in many countries in North America, Asia, and Europe. However, the risk increased during weekends in South and Central American countries, Finland, and South Africa. Additionally, evidence suggested strong increases in suicide risk on New Year’s day in most countries with relative risks ranging from 0.93 (95% CI 0.75 to 1.14) in Japan to 1.93 (1.31 to 2.85) in Chile, whereas the evidence on Christmas day was weak. Suicide risk was associated with a weak decrease on other national holidays, except for Central and South American countries, where the risk generally increased one or two days after these holidays. Conclusions Suicide risk was highest on Mondays and increased on New Year’s day in most countries. However, the risk of suicide on weekends and Christmas varied by country and territory. The results of this study can help to better understand the short term variations in suicide risks and define suicide prevention action plans and awareness campaigns.\n\n\nsuicide riskholidaysday of the weektime series analysismulticountry study\n\n\n\n\n\nOrlov A, De Hertog S, Havermann F, Guo S, Manola I, Lejeune Q, Schleussner C, Thiery W, Pongratz J, Humpenöder F, Popp A, Aunan K, Armstrong B, Royé D, Cvijanovic I, Lavigne E, Achilleos S, Bell M, Masselot P, Sera F, Vicedo-Cabrera A, Gasparrini A, Mistry M (2024). Impacts of landuse and landcover changes on temperature related mortality. Environmental Epidemiology, vol. 8(6), art. no. e337.  10.1097/ee9.0000000000000337. \n\n\nBackground: Land-use and land-cover change (LULCC) can substantially affect climate through biogeochemical and biogeophysical effects. Here, we examine the future temperature–mortality impact for two contrasting LULCC scenarios in a background climate of low greenhouse gas concentrations. The first LULCC scenario implies a globally sustainable land use and socioeconomic development (sustainability). In the second LULCC scenario, sustainability is implemented only in the Organisation for Economic Cooperation and Development countries (inequality). Methods: Using the Multi-Country Multi-City (MCC) dataset on mortality from 823 locations in 52 countries and territories, we estimated the temperature–mortality exposure–response functions (ERFs). The LULCC and noLULCC scenarios were implemented in three fully coupled Earth system models (ESMs): Community Earth System Model, Max Planck Institute Earth System Model, and European Consortium Earth System Model. Next, using temperature from the ESMs’ simulations and the estimated location-specific ERFs, we assessed the temperature-related impact on mortality for the LULCC and noLULCC scenarios around the mid and end century. Results: Under sustainability, the multimodel mean changes in excess mortality range from −1.1 to +0.6 percentage points by 2050–2059 across all locations and from −1.4 to +0.5 percentage points by 2090–2099. Under inequality, these vary from −0.7 to +0.9 percentage points by 2050–2059 and from −1.3 to +2 percentage points by 2090–2099. Conclusions: While an unequal socioeconomic development and unsustainable land use could increase the burden of heat-related mortality in most regions, globally sustainable land use has the potential to reduce it in some locations. However, the total (cold and heat) impact on mortality is very location specific and strongly depends on the underlying climate change scenario due to nonlinearity in the temperature–mortality relationship.\n\n\nland-use changetemperature-related mortalityclimate impactbiogeophysical effectshealth assessment\n\n\n\n\n\nTobías A, Íñiguez C, Hurtado Díaz M, Riojas H, Cifuentes L, Royé D, Abrutzky R, Coelho M, Saldiva P, Valdés Ortega N, Matus Correa P, Osorio S, Carrasco G, Colistro V, Pascal M, Chanel O, Madaniyazi L, Gasparrini A (2024). Mortality burden and economic loss attributable to cold and heat in Central and South America. Environmental Epidemiology, vol. 8(6), art. no. e335.  10.1097/ee9.0000000000000335. \n\n\n\nBackground: We quantify the mortality burden and economic loss attributable to nonoptimal temperatures for cold and heat in the Central and South American countries in the Multi-City Multi-Country (MCC) Collaborative Research Network. Methods: We collected data for 66 locations from 13 countries in Central and South America to estimate location-specific temperature–mortality associations using time-series regression with distributed lag nonlinear models. We calculated the attributable deaths for cold and heat as the 2.5th and 97.5th temperature percentiles, above and below the minimum mortality temperature, and used the value of a life year to estimate the economic loss of delayed deaths. Results: The mortality impact of cold varied widely by country, from 9.64% in Uruguay to 0.22% in Costa Rica. The heat-attributable fraction for mortality ranged from 1.41% in Paraguay to 0.01% in Ecuador. Locations in arid and temperate climatic zones showed higher cold-related mortality (5.10% and 5.29%, respectively) than those in tropical climates (1.71%). Arid and temperate climatic zones saw lower heat-attributable fractions (0.69% and 0.58%) than arid climatic zones (0.92%). Exposure to cold led to an annual economic loss of $0.6 million in Costa Rica to $472.2 million in Argentina. In comparison, heat resulted in economic losses of $0.05 million in Ecuador to $90.6 million in Brazil. Conclusion: Most of the mortality burden for Central and South American countries is caused by cold compared to heat, generating annual economic losses of $2.1 billion and \\(290.7 million, respectively. Public health policies and adaptation measures in the region should account for the health effects associated with nonoptimal temperatures.&lt;/p&gt;&lt;p&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;mortality burden&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;economic loss&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;cold and heat&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;central and south america&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;nonoptimal temperatures&lt;/span&gt;&lt;/p&gt;&lt;br/&gt; &lt;/div&gt;&lt;/li&gt;\n  &lt;li style='position:relative;margin-bottom:0.8rem;list-style:none;' class='ref-entry is-climate is-health      is-envir   '&gt;He C, Breitner-Busch S, Huber V, Chen K, Zhang S, Gasparrini A, Bell M, Kan H, &lt;b&gt;Royé D&lt;/b&gt;, Armstrong B, Schwartz J, Sera F, Vicedo-Cabrera A, Honda Y, Jaakkola J, Ryti N, Kyselý J, Guo Y, Tong S, de’Donato F, Michelozzi P, Coelho M, Saldiva P, Lavigne E, Orru H, Indermitte E, Pascal M, Goodman P, Zeka A, Kim Y, Diaz M, Arellano E, Overcenco A, Klompmaker J, Rao S, Palomares A, Carrasco G, Seposo X, Pereira da Silva S, Madureira J, Holobaca I, Scovronick N, Acquaotta F, Kim H, Lee W, Hashizume M, Tobias A, Íñiguez C, Forsberg B, Ragettli M, Guo Y, Pan S, Osorio S, Li S, Zanobetti A, Dang T, Van Dung D, Schneider A (2024). Rainfall events and daily mortality across 645 global locations: two stage time series analysis. &lt;i&gt;BMJ&lt;/i&gt;, vol. 387, art. no. e080944. &lt;i class='ai ai-doi'&gt;&lt;/i&gt; &lt;a target='_blank' href='https://doi.org/10.1136/bmj2024080944'&gt;10.1136/bmj2024080944&lt;/a&gt;. &lt;button type='button' data-bs-toggle='collapse' data-bs-target='#ref-9'   aria-expanded='false'  aria-controls='ref-9' class='btn btn-sm btn-danger btn-pub' style='display: block; margin-top: 1rem;position: absolute;left:0;top:-5%;transform: translateX(-3em);'&gt;&lt;i class='bi bi-plus-lg'&gt;&lt;/i&gt;&lt;/button&gt;&lt;div class='collapse' id='ref-9'&gt;&lt;p class='small'&gt;&lt;br/&gt;Objective To examine the associations between characteristics of daily rainfall (intensity, duration, and frequency) and all cause, cardiovascular, and respiratory mortality.\nDesign Two stage time series analysis.Setting 645 locations across 34 countries or regions. Population Daily mortality data, comprising a total of 109954744 all cause, 31164161 cardiovascular, and 11817278 respiratory deaths from 1980 to 2020. Main outcome measure Association between daily mortality and rainfall events with return periods (the expected average time between occurrences of an extreme event of a certain magnitude) of one year, two years, and five years, with a 14 day lag period. A continuous relative intensity index was used to generate intensity-response curves to estimate mortality risks at a global scale. Results During the study period, a total of 50 913 rainfall events with a one year return period, 8362 events with a two year return period, and 3301 events with a five year return period were identified. A day of extreme rainfall with a five year return period was significantly associated with increased daily all cause, cardiovascular, and respiratory mortality, with cumulative relative risks across 0-14 lag days of 1.08 (95% confidence interval 1.05 to 1.11), 1.05 (1.02 to 1.08), and 1.29 (1.19 to 1.39), respectively. Rainfall events with a two year return period were associated with respiratory mortality only, whereas no significant associations were found for events with a one year return period. Non-linear analysis revealed protective effects (relative risk 1) with moderate-heavy rainfall events, shifting to adverse effects (relative risk 1) with extreme intensities. Additionally, mortality risks from extreme rainfall events appeared to be modified by climate type, baseline variability in rainfall, and vegetation coverage, whereas the moderating effects of population density and income level were not significant. Locations with lower variability of baseline rainfall or scarce vegetation coverage showed higher risks. Conclusion Daily rainfall intensity is associated with varying health effects, with extreme events linked to an increasing relative risk for all cause, cardiovascular, and respiratory mortality. The observed associations varied with local climate and urban infrastructure.&lt;/p&gt;&lt;p&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;rainfall events&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;daily mortality&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;time series analysis&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;global study&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;cardiovascular and respiratory mortality&lt;/span&gt;&lt;/p&gt;&lt;br/&gt; &lt;/div&gt;&lt;/li&gt;\n  &lt;li style='position:relative;margin-bottom:0.8rem;list-style:none;' class='ref-entry  is-health  is-exttemp       '&gt;Alvarez I, Diaz-Poso A, Lorenzo MN, &lt;b&gt;Royé D&lt;/b&gt; (2024). Heat index historical trends and projections due to climate change in the Mediterranean basin based on CMIP6. &lt;i&gt;Atmospheric Research&lt;/i&gt;, vol. 308, art. no. 107512. &lt;i class='ai ai-doi'&gt;&lt;/i&gt; &lt;a target='_blank' href='https://doi.org/10.1016/j.atmosres.2024.107512'&gt;10.1016/j.atmosres.2024.107512&lt;/a&gt;. &lt;button type='button' data-bs-toggle='collapse' data-bs-target='#ref-10'   aria-expanded='false'  aria-controls='ref-10' class='btn btn-sm btn-danger btn-pub' style='display: block; margin-top: 1rem;position: absolute;left:0;top:-5%;transform: translateX(-3em);'&gt;&lt;i class='bi bi-plus-lg'&gt;&lt;/i&gt;&lt;/button&gt;&lt;div class='collapse' id='ref-10'&gt;&lt;p class='small'&gt;&lt;br/&gt;Air temperature and relative humidity can be considered as two essential meteorological parameters in the determination of heat stress. The heat index (HI) includes both of them and it is appropriate for determining the thermal conditions of different climates. We investigated potential changes in the HI for the Mediterranean basin using simulations from the Coupled Model Intercomparison Project Phase 6 (CMIP6) climate models under two future scenarios (Shared Socio-economic Pathways: SSP2-4.5 and SSP5-8.5) over the period 2020–2099. Results reveal an important increase of HI at the end of the 21st century for both scenarios, with greater changes for the SSP5-8.5 scenario all over the basin. Strong significant upwards trends (around 1 °C per decade; significance level computed at 5%) are expected in the entire area and for all months at the end of the century, with greatest values during the summer months (close to 1.5 °C per decade) along the coastal areas of the basin. Many areas of the Southern Mediterranean basin (Africa and Arabian Peninsula) will be strongly affected with dangerously high heat index values (higher than 41 °C) during summer months by the end of the 21st century. A northward extension of these dangerous conditions is also expected including several areas of southern Europe.\n&lt;/p&gt;&lt;p&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;heat index&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;heat risk&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;mediterranean&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;arabian peninsula&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;africa&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;cmip6&lt;/span&gt;&lt;/p&gt;&lt;br/&gt; &lt;/div&gt;&lt;/li&gt;\n  &lt;li style='position:relative;margin-bottom:0.8rem;list-style:none;' class='ref-entry is-climate is-health  is-exttemp  is-cc     '&gt;Yang D, Hashizume M, Tobías A, Honda Y, &lt;b&gt;Royé D&lt;/b&gt;, Oh J, Dang T, Kim Y, Abrutzky R, Guo Y, Tong S, Coelho M, Saldiva P, Lavigne E, Correa P, Ortega N, Osorio S, Kyselý J, Urban A, Orru H, Indermitte E, Jaakkola J, Ryti N, Pascal M, Huber V, Schneider A, Katsouyanni K, Analitis A, Entezari A, Mayvaneh F, Goodman P, Zeka A, Michelozzi P, de’Donato F, Alahmad B, Diaz M, la Cruz Valencia C, Overcenco A, Houthuijs D, Ameling C, Rao S, Nunes B, Madureira J, Holo-bâc I, Scovronick N, Acquaotta F, Kim H, Lee W, Íñiguez C, Forsberg B, Vicedo-Cabrera A, Ragettli M, Guo Y, Pan S, Li S, Sera F, Zanobetti A, Schwartz J, Armstrong B, Gasparrini A, Chung Y (2024). Temporal change in minimum mortality temperature under changing climate: A multicountry multicommunity observational study spanning 1986–2015. &lt;i&gt;Environmental Epidemiology&lt;/i&gt;, vol. 8(5), art. no. e334. &lt;i class='ai ai-doi'&gt;&lt;/i&gt; &lt;a target='_blank' href='https://doi.org/10.1097/ee9.0000000000000334'&gt;10.1097/ee9.0000000000000334&lt;/a&gt;. &lt;button type='button' data-bs-toggle='collapse' data-bs-target='#ref-11'   aria-expanded='false'  aria-controls='ref-11' class='btn btn-sm btn-danger btn-pub' style='display: block; margin-top: 1rem;position: absolute;left:0;top:-5%;transform: translateX(-3em);'&gt;&lt;i class='bi bi-plus-lg'&gt;&lt;/i&gt;&lt;/button&gt;&lt;div class='collapse' id='ref-11'&gt;&lt;p class='small'&gt;&lt;br/&gt;Background: The minimum mortality temperature (MMT) or MMT percentile (MMTP) is an indicator of population susceptibility to nonoptimum temperatures. MMT and MMTP change over time; however, the changing directions show region-wide heterogeneity. We examined the heterogeneity of temporal changes in MMT and MMTP across multiple communities and in multiple countries.\nMethods: Daily time-series data for mortality and ambient mean temperature for 699 communities in 34 countries spanning 1986–2015 were analyzed using a two-stage meta-analysis. First, a quasi-Poisson regression was employed to estimate MMT and MMTP for each community during the designated subperiods. Second, we pooled the community-specific temporally varying estimates using mixed-effects meta-regressions to examine temporal changes in MMT and MMTP in the entire study population, as well as by climate zone, geographical region, and country.\nResults: Temporal increases in MMT and MMTP from 19.5 °C (17.9, 21.1) to 20.3 °C (18.5, 22.0) and from the 74.5 (68.3, 80.6) to 75.0 (71.0, 78.9) percentiles in the entire population were found, respectively. Temporal change was significantly heterogeneous across geographical regions (P  0.001). Temporal increases in MMT were observed in East Asia (linear slope [LS] = 0.91, P = 0.02) and South-East Asia (LS = 0.62, P = 0.05), whereas a temporal decrease in MMT was observed in South Europe (LS = −0.46, P = 0.05). MMTP decreased temporally in North Europe (LS = −3.45, P = 0.02) and South Europe (LS = −2.86, P = 0.05).\nConclusions: The temporal change in MMT or MMTP was largely heterogeneous. Population susceptibility in terms of optimum temperature may have changed under a warming climate, albeit with large region-dependent variations.&lt;/p&gt;&lt;p&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;minimum mortality temperature&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;climate change&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;temporal change&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;multicountry study&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;observational analysis&lt;/span&gt;&lt;/p&gt;&lt;br/&gt; &lt;/div&gt;&lt;/li&gt;\n  &lt;li style='position:relative;margin-bottom:0.8rem;list-style:none;' class='ref-entry  is-health  is-exttemp   is-soc    '&gt;Scovronick N, Sera F, Vu B, Vicedo-Cabrera A, &lt;b&gt;Royé D&lt;/b&gt;, Tobias A, Seposo X, Forsberg B, Guo Y, Li S, Honda Y, Abrutzky R, de Sousa Zanotti Stagliorio Coelho M, Nascimento Saldiva P, Lavigne E, Kan H, Osorio S, Kyselý J, Urban A, Orru H, Indermitte E, Jaakkola J, Ryti N, Pascal M, Katsouyanni K, Mayvaneh F, Entezari A, Goodman P, Zeka A, Michelozzi P, de’Donato F, Hashizume M, Alahmad B, Zanobetti A, Schwartz J, Hurtado Diaz M, De La Cruz Valencia C, Rao S, Madureira J, Acquaotta F, Kim H, Lee W, Iniguez C, Ragettli M, Guo Y, Dang T, Dung D, Armstrong B, Gasparrini A (2024). Temperature mortality associations by age and cause: a multicountry multicity study. &lt;i&gt;Environmental Epidemiology&lt;/i&gt;, vol. 8(5), art. no. e336. &lt;i class='ai ai-doi'&gt;&lt;/i&gt; &lt;a target='_blank' href='https://doi.org/10.1097/ee9.0000000000000336'&gt;10.1097/ee9.0000000000000336&lt;/a&gt;. &lt;button type='button' data-bs-toggle='collapse' data-bs-target='#ref-12'   aria-expanded='false'  aria-controls='ref-12' class='btn btn-sm btn-danger btn-pub' style='display: block; margin-top: 1rem;position: absolute;left:0;top:-5%;transform: translateX(-3em);'&gt;&lt;i class='bi bi-plus-lg'&gt;&lt;/i&gt;&lt;/button&gt;&lt;div class='collapse' id='ref-12'&gt;&lt;p class='small'&gt;&lt;br/&gt;Background: Heterogeneity in temperature-mortality relationships across locations may partly result from differences in the demographic structure of populations and their cause-specific vulnerabilities. Here we conduct the largest epidemiological study to date on the association between ambient temperature and mortality by age and cause using data from 532 cities in 33 countries.\nMethods: We collected daily temperature and mortality data from each country. Mortality data was provided as daily death counts within age groups from all, cardiovascular, respiratory, or noncardiorespiratory causes. We first fit quasi-Poisson regression models to estimate location-specific associations for each age-by-cause group. For each cause, we then pooled location-specific results in a dose-response multivariate meta-regression model that enabled us to estimate overall temperature-mortality curves at any age. The age analysis was limited to adults.\nResults: We observed high temperature effects on mortality from both cardiovascular and respiratory causes compared to noncardiorespiratory causes, with the highest cold-related risks from cardiovascular causes and the highest heat-related risks from respiratory causes. Risks generally increased with age, a pattern most consistent for cold and for nonrespiratory causes. For every cause group, risks at both temperature extremes were strongest at the oldest age (age 85 years). Excess mortality fractions were highest for cold at the oldest ages.\nConclusions: There is a differential pattern of risk associated with heat and cold by cause and age; cardiorespiratory causes show stronger effects than noncardiorespiratory causes, and older adults have higher risks than younger adults.&lt;/p&gt;&lt;p&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;temperature-mortality associations&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;age-specific mortality&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;cause-specific mortality&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;multi-country study&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;multi-city analysis&lt;/span&gt;&lt;/p&gt;&lt;br/&gt; &lt;/div&gt;&lt;/li&gt;\n  &lt;li style='position:relative;margin-bottom:0.8rem;list-style:none;' class='ref-entry  is-health  is-exttemp       '&gt;Guo Q, Mistry M, Zhou X, Zhao G, Kino K, Wen B, Yoshimura K, Satoh Y, Cvijanovic I, Kim Y, Ng C, Vicedo-Cabrera A, Armstrong B, Urban A, Katsouyanni K, Masselot P, Tong S, Sera F, Huber V, Bell M, Kyselý J, Gasparrini A, Hashizume M, Oki T, Abrutzky R, Guo Y, de Sousa Zanotti Stagliorio Coelho M, Nascimento Saldiva P, Lavigne E, Ortega N, Correa P, Kan H, Osorio S, &lt;b&gt;Royé D&lt;/b&gt;, Indermitte E, Orru H, Jaakkola J, Ryti N, Pascal M, Schneider A, Analitis A, Entezari A, Mayvaneh F, Zeka A, Goodman P, de'Donato F, Michelozzi P, Alahmad B, De la Cruz Valencia C, Hurtado Diaz M, Overcenco A, Ameling C, Houthuijs D, Rao S, Carrasco G, Seposo X, Madureira J, das Neves Pereira da Silva S, Holobaca I, Acquaotta F, Scovronick N, Kim H, Lee W, Tobias A, Íñiguez C, Forsberg B, Ragettli M, Pan S, Guo Y, Li S, Schneider R, Colistro V, Zanobetti A, Schwartz J, Van Dung D, Ngoc Dang T, Honda Y (2024). Regional variation in the role of humidity on citylevel heatrelated mortality. &lt;i&gt;PNAS Nexus&lt;/i&gt;, vol. 3(8), art. no. pgae290. &lt;i class='ai ai-doi'&gt;&lt;/i&gt; &lt;a target='_blank' href='https://doi.org/10.1093/pnasnexus/pgae290'&gt;10.1093/pnasnexus/pgae290&lt;/a&gt;. &lt;button type='button' data-bs-toggle='collapse' data-bs-target='#ref-13'   aria-expanded='false'  aria-controls='ref-13' class='btn btn-sm btn-danger btn-pub' style='display: block; margin-top: 1rem;position: absolute;left:0;top:-5%;transform: translateX(-3em);'&gt;&lt;i class='bi bi-plus-lg'&gt;&lt;/i&gt;&lt;/button&gt;&lt;div class='collapse' id='ref-13'&gt;&lt;p class='small'&gt;&lt;br/&gt;The rising humid heat is regarded as a severe threat to human survivability, but the proper integration of humid heat into heat-health alerts is still being explored. Using state-of-the-art epidemiological and climatological datasets, we examined the association between multiple heat stress indicators (HSIs) and daily human mortality in 739 cities worldwide. Notable differences were observed in the long-term trends and timing of heat events detected by HSIs. Air temperature (Tair) predicts heat-related mortality well in cities with a robust negative Tair-relative humidity correlation (CT-RH). However, in cities with near-zero or weak positive CT-RH, HSIs considering humidity provide enhanced predictive power compared to Tair. Furthermore, the magnitude and timing of heat-related mortality measured by HSIs could differ largely from those associated with Tair in many cities. Our findings provide important insights into specific regions where humans are vulnerable to humid heat and can facilitate the further enhancement of heat-health alert systems.&lt;/p&gt;&lt;p&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;humidity&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;heat-related mortality&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;city-level analysis&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;regional variation&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;heat stress indicators&lt;/span&gt;&lt;/p&gt;&lt;br/&gt; &lt;/div&gt;&lt;/li&gt;\n  &lt;li style='position:relative;margin-bottom:0.8rem;list-style:none;' class='ref-entry is-climate is-health      is-envir   '&gt;Chua P, Tobias A, Madaniyazi L, Ng C, Phung V, Fu S, Rodriguez P, Brown P, Coelho M, Saldiva P, Scovronick N, Deshpande A, Salazar M, Dorotan M, Tantrakarnapa K, Kliengchuay W, Abrutzky R, Carrasco-Escobar G, &lt;b&gt;Royé D&lt;/b&gt;, Hales S, Hashizume M (2024). Association between precipitation and mortality due to diarrheal diseases by climate zone: A multicountry modeling study. &lt;i&gt;Environmental Epidemiology&lt;/i&gt;, vol. 8(4), art. no. e320. &lt;i class='ai ai-doi'&gt;&lt;/i&gt; &lt;a target='_blank' href='https://doi.org/10.1097/ee9.0000000000000320'&gt;10.1097/ee9.0000000000000320&lt;/a&gt;. &lt;button type='button' data-bs-toggle='collapse' data-bs-target='#ref-14'   aria-expanded='false'  aria-controls='ref-14' class='btn btn-sm btn-danger btn-pub' style='display: block; margin-top: 1rem;position: absolute;left:0;top:-5%;transform: translateX(-3em);'&gt;&lt;i class='bi bi-plus-lg'&gt;&lt;/i&gt;&lt;/button&gt;&lt;div class='collapse' id='ref-14'&gt;&lt;p class='small'&gt;&lt;br/&gt;Background: Precipitation could affect the transmission of diarrheal diseases. The diverse precipitation patterns across different climates might influence the degree of diarrheal risk from precipitation. This study determined the associations between precipitation and diarrheal mortality in tropical, temperate, and arid climate regions.\nMethods: Daily counts of diarrheal mortality and 28-day cumulative precipitation from 1997 to 2019 were analyzed across 29 locations in eight middle-income countries (Argentina, Brazil, Costa Rica, India, Peru, the Philippines, South Africa, and Thailand). A two-stage approach was employed: the first stage is conditional Poisson regression models for each location, and the second stage is meta-analysis for pooling location-specific coefficients by climate zone.\nResults: In tropical climates, higher precipitation increases the risk of diarrheal mortality. Under extremely wet conditions (95th percentile of 28-day cumulative precipitation), diarrheal mortality increased by 17.8% (95% confidence interval [CI] = 10.4%, 25.7%) compared with minimum-risk precipitation. For temperate and arid climates, diarrheal mortality increases in both dry and wet conditions. In extremely dry conditions (fifth percentile of 28-day cumulative precipitation), diarrheal mortality risk increases by 3.8% (95% CI = 1.2%, 6.5%) for temperate and 5.5% (95% CI = 1.0%, 10.2%) for arid climates. Similarly, under extremely wet conditions, diarrheal mortality risk increases by 2.5% (95% CI = −0.1%, 5.1%) for temperate and 4.1% (95% CI = 1.1%, 7.3%) for arid climates.\nConclusions: Associations between precipitation and diarrheal mortality exhibit variations across different climate zones. It is crucial to consider climate-specific variations when generating global projections of future precipitation-related diarrheal mortality.&lt;/p&gt;&lt;p&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;precipitation&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;diarrheal diseases&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;climate zones&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;mortality&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;multi-country modeling&lt;/span&gt;&lt;/p&gt;&lt;br/&gt; &lt;/div&gt;&lt;/li&gt;\n  &lt;li style='position:relative;margin-bottom:0.8rem;list-style:none;' class='ref-entry  is-health is-poll     is-envir   '&gt;Chen G, Guo Y, Yue X, Xu R, Yu W, Ye T, Tong S, Gasparrini A, Bell M, Armstrong B, Schwartz J, Jaakkola J, Lavigne E, Saldiva P, Kan H, &lt;b&gt;Royé D&lt;/b&gt;, Urban A, Vicedo-Cabrera A, Tobias A, Forsberg B, Sera F, Lei Y, Abramson M, Li S, Abrutzky R, Alahmad B, Ameling C, Åström C, Breitner S, Carrasco-Escobar G, Coêlho M, Colistro V, Correa P, Dang T, de'Donato F, Dung D, Entezari A, Garcia S, Garland R, Goodman P, Guo Y, Hashizume M, Holobaca I, Honda Y, Houthuijs D, Hurtado-Díaz M, Íñiguez C, Katsouyanni K, Kim H, Kyselý J, Lee W, Maasikmets M, Madureira J, Mayvaneh F, Nunes B, Orru H, Ortega N, Overcenco A, Pan S, Pascal M, Ragettli M, Rao S, Ryti N, Samoli E, Schneider A, Scovronick N, Seposo X, Stafoggia M, Valencia C, Zanobetti A, Zeka A (2024). Allcause, cardiovascular, and respiratory mortality and wildfirerelated ozone: a multicountry twostage time series analysis. &lt;i&gt;The Lancet Planetary Health&lt;/i&gt;, vol. 8(7), pp. e452-e462. &lt;i class='ai ai-doi'&gt;&lt;/i&gt; &lt;a target='_blank' href='https://doi.org/10.1016/S2542-5196(24)00117-7'&gt;10.1016/S2542-5196(24)00117-7&lt;/a&gt;. &lt;button type='button' data-bs-toggle='collapse' data-bs-target='#ref-15'   aria-expanded='false'  aria-controls='ref-15' class='btn btn-sm btn-danger btn-pub' style='display: block; margin-top: 1rem;position: absolute;left:0;top:-5%;transform: translateX(-3em);'&gt;&lt;i class='bi bi-plus-lg'&gt;&lt;/i&gt;&lt;/button&gt;&lt;div class='collapse' id='ref-15'&gt;&lt;p class='small'&gt;&lt;br/&gt;Background. Wildfire activity is an important source of tropospheric ozone (O3) pollution. However, no study to date has systematically examined the associations of wildfire-related O3 exposure with mortality globally.\nMethods. We did a multicountry two-stage time series analysis. From the Multi-City Multi-Country (MCC) Collaborative Research Network, data on daily all-cause, cardiovascular, and respiratory deaths were obtained from 749 locations in 43 countries or areas, representing overlapping periods from Jan 1, 2000, to Dec 31, 2016. We estimated the daily concentration of wildfire-related O3 in study locations using a chemical transport model, and then calibrated and downscaled O3 estimates to a resolution of 0·25° × 0·25° (approximately 28 km2 at the equator). Using a random-effects meta-analysis, we examined the associations of short-term wildfire-related O3 exposure (lag period of 0–2 days) with daily mortality, first at the location level and then pooled at the country, regional, and global levels. Annual excess mortality fraction in each location attributable to wildfire-related O3 was calculated with pooled effect estimates and used to obtain excess mortality fractions at country, regional, and global levels.\nFindings. Between 2000 and 2016, the highest maximum daily wildfire-related O3 concentrations (≥30 μg/m3) were observed in locations in South America, central America, and southeastern Asia, and the country of South Africa. Across all locations, an increase of 1 μg/m3 in the mean daily concentration of wildfire-related O3 during lag 0–2 days was associated with increases of 0·55% (95% CI 0·29 to 0·80) in daily all-cause mortality, 0·44% (–0·10 to 0·99) in daily cardiovascular mortality, and 0·82% (0·18 to 1·47) in daily respiratory mortality. The associations of daily mortality rates with wildfire-related O3 exposure showed substantial geographical heterogeneity at the country and regional levels. Across all locations, estimated annual excess mortality fractions of 0·58% (95% CI 0·31 to 0·85; 31 606 deaths [95% CI 17 038 to 46 027]) for all-cause mortality, 0·41% (–0·10 to 0·91; 5249 [–1244 to 11 620]) for cardiovascular mortality, and 0·86% (0·18 to 1·51; 4657 [999 to 8206]) for respiratory mortality were attributable to short-term exposure to wildfire-related O3.\nInterpretation. In this study, we observed an increase in all-cause and respiratory mortality associated with short-term wildfire-related O3 exposure. Effective risk and smoke management strategies should be implemented to protect the public from the impacts of wildfires.&lt;/p&gt;&lt;p&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;wildfire-related ozone&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;all-cause mortality&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;cardiovascular mortality&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;respiratory mortality&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;two-stage time series&lt;/span&gt;&lt;/p&gt;&lt;br/&gt; &lt;/div&gt;&lt;/li&gt;\n  &lt;li style='position:relative;margin-bottom:0.8rem;list-style:none;' class='ref-entry           '&gt;Lemus-Canovas M, Montesinos-Ciuró E, Cearreta-Innocenti T, Serrano-Notivoli R, &lt;b&gt;Royé D&lt;/b&gt; (2024). Attribution of the unprecedented heat event of August 2023 in Barcelona (Spain) to observed and projected global warming. &lt;i&gt;Urban Climate&lt;/i&gt;, vol. 56, art. no. 102019. &lt;i class='ai ai-doi'&gt;&lt;/i&gt; &lt;a target='_blank' href='https://doi.org/10.1016/j.uclim.2024.102019'&gt;10.1016/j.uclim.2024.102019&lt;/a&gt;. &lt;button type='button' data-bs-toggle='collapse' data-bs-target='#ref-16'   aria-expanded='false'  aria-controls='ref-16' class='btn btn-sm btn-danger btn-pub' style='display: block; margin-top: 1rem;position: absolute;left:0;top:-5%;transform: translateX(-3em);'&gt;&lt;i class='bi bi-plus-lg'&gt;&lt;/i&gt;&lt;/button&gt;&lt;div class='collapse' id='ref-16'&gt;&lt;p class='small'&gt;&lt;br/&gt;The study analyses observed and numerical simulations of daily maximum and minimum temperature from 1920 onwards and to investigate the unprecedented heat event that occurred in 21–23 August 2023 in Barcelona. The historical changes in the intensity of such events, their expected future changes under scenarios of +1.5 °C, +2 °C, and + 3 °C, and the future exposure of populations to such kind of events are examined using the flow analogues approach. The findings indicate a significant increase in observed temperatures for similar heatwaves to those occurred in August 2023. The study also emphasises the impact of global warming on the intensification of heat events over the impact of urbanization. Additionally, after examining the role of natural variability in temperature changes, we concluded that global warming is the primary factor driving the increase in heatwave intensity. In terms of the frequency of such events, we found that extreme heat events, such as the August 2023 heatwave, will become 2 and 5 times more likely with a global summer warming of 2 °C and 3 °C, respectively. This will expose a large portion of the population to dangerous heat levels highlighting the importance of limiting global warming to 1.5 °C to mitigate the impacts on urban populations.&lt;/p&gt;&lt;p&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;extreme event attribution&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;heatwave&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;urban climate&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;global warming&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;barcelona&lt;/span&gt;&lt;/p&gt;&lt;br/&gt; &lt;/div&gt;&lt;/li&gt;\n  &lt;li style='position:relative;margin-bottom:0.8rem;list-style:none;' class='ref-entry is-climate is-health  is-exttemp       '&gt;Alahmad B, Khraishah H, Kamineni M, &lt;b&gt;Royé D&lt;/b&gt;, Papatheodorou S, Vicedo-Cabrera A, Guo Y, Lavigne E, Armstrong B, Sera F, Bernstein A, Zanobetti A, Garshick E, Schwartz J, Bell M, Al-Mulla F, Koutrakis P, Gasparrini A, Souzana A, Acquaotta F, Pan S, Sousa Zanotti Stagliorio Coelho M, Colistro V, Ngoc Dang T, Van Dung D, De’ Donato F, Entezari A, Leon Guo Y, Hashizume M, Honda Y, Indermitte E, Íñiguez C, Jaakkola J, Kim H, Lee W, Li S, Madureira J, Mayvaneh F, Orru H, Overcenco A, Ragettli M, Ryti N, Hilario Nascimento Saldiva P, Scovronick N, Seposo X, Pereira Silva S, Stafoggia M, Tobias A (2024). Extreme Temperatures and Stroke Mortality: Evidence From a MultiCountry Analysis. &lt;i&gt;Stroke&lt;/i&gt;, vol. 55(7), pp. 1847-1856. &lt;i class='ai ai-doi'&gt;&lt;/i&gt; &lt;a target='_blank' href='https://doi.org/10.1161/strokeaha.123.045751'&gt;10.1161/strokeaha.123.045751&lt;/a&gt;. &lt;button type='button' data-bs-toggle='collapse' data-bs-target='#ref-17'   aria-expanded='false'  aria-controls='ref-17' class='btn btn-sm btn-danger btn-pub' style='display: block; margin-top: 1rem;position: absolute;left:0;top:-5%;transform: translateX(-3em);'&gt;&lt;i class='bi bi-plus-lg'&gt;&lt;/i&gt;&lt;/button&gt;&lt;div class='collapse' id='ref-17'&gt;&lt;p class='small'&gt;&lt;br/&gt;Background: Extreme temperatures contribute significantly to global mortality. While previous studies on temperature and stroke-specific outcomes presented conflicting results, these studies were predominantly limited to single-city or single-country analyses. Their findings are difficult to synthesize due to variations in methodologies and exposure definitions. Methods: Within the Multi-Country Multi-City Network, we built a new mortality database for ischemic and hemorrhagic stroke. Applying a unified analysis protocol, we conducted a multinational case-crossover study on the relationship between extreme temperatures and stroke. In the first stage, we fitted a conditional quasi-Poisson regression for daily mortality counts with distributed lag nonlinear models for temperature exposure separately for each city. In the second stage, the cumulative risk from each city was pooled using mixed-effect meta-analyses, accounting for clustering of cities with similar features. We compared temperature-stroke associations across country-level gross domestic product per capita. We computed excess deaths in each city that are attributable to the 2.5% hottest and coldest of days based on each city’s temperature distribution. Results: We collected data for a total of 3 443 969 ischemic strokes and 2 454 267 hemorrhagic stroke deaths from 522 cities in 25 countries. For every 1000 ischemic stroke deaths, we found that extreme cold and hot days contributed 9.1 (95% empirical CI, 8.6–9.4) and 2.2 (95% empirical CI, 1.9–2.4) excess deaths, respectively. For every 1000 hemorrhagic stroke deaths, extreme cold and hot days contributed 11.2 (95% empirical CI, 10.9–11.4) and 0.7 (95% empirical CI, 0.5–0.8) excess deaths, respectively. We found that countries with low gross domestic product per capita were at higher risk of heat-related hemorrhagic stroke mortality than countries with high gross domestic product per capita (P=0.02). Conclusions: Both extreme cold and hot temperatures are associated with an increased risk of dying from ischemic and hemorrhagic strokes. As climate change continues to exacerbate these extreme temperatures, interventional strategies are needed to mitigate impacts on stroke mortality, particularly in low-income countries.&lt;/p&gt;&lt;p&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;extreme temperatures&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;stroke mortality&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;ischemic and hemorrhagic stroke&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;multi-country analysis&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;\nclimate impact&lt;/span&gt;&lt;/p&gt;&lt;br/&gt; &lt;/div&gt;&lt;/li&gt;\n  &lt;li style='position:relative;margin-bottom:0.8rem;list-style:none;' class='ref-entry is-climate is-health         '&gt;Hundessa S, Huang W, Zhao Q, Wu Y, Wen B, Alahmad B, Armstrong B, Gasparrini A, Sera F, Tong S, Madureira J, Kyselý J, Schwartz J, Vicedo-Cabrera A, Hales S, Johnson A, Li S, Guo Y, Jaakkola J, Ryti N, Urban A, Tobias A, &lt;b&gt;Royé D&lt;/b&gt;, Lavigne E, Ragettli M, Åström C, Raz R, Pascal M, Kan H, Goodman P, Zeka A, Hashizume M, Diaz M, Seposo X, Nunes B, Kim H, Lee W, Íñiguez C, Guo Y, Pan S, Zanobetti A, Dang T, Van Dung D, Schneider A, Entezari A, Analitis A, Forsberg B, Ameling C, Houthuijs D, Indermitte E, Mayvaneh F, Acquaotta F, de'Donato F, Carrasco-Escobar G, Orru H, Katsouyanni K, de Sousa Zanotti Stagliorio Coelho M, Ortega N, Scovronick N, Michelozzi P, Correa P, Nascimento Saldiva P, Abrutzky R, Osorio S, Colistro V, Huber V, Honda Y, Kim Y, Bell M, Xu R, Yang Z, Roradeh H, Félix Arellano E, Rao S, Carlos Chua P, da Silva S, da Silva S, De la Cruz Valencia C (2024). Global and Regional Cardiovascular Mortality Attributable to Nonoptimal Temperatures Over Time. &lt;i&gt;Journal of the American College of Cardiology&lt;/i&gt;, vol. 83(23), pp. 2276-2287. &lt;i class='ai ai-doi'&gt;&lt;/i&gt; &lt;a target='_blank' href='https://doi.org/10.1016/j.jacc.2024.03.425'&gt;10.1016/j.jacc.2024.03.425&lt;/a&gt;. &lt;button type='button' data-bs-toggle='collapse' data-bs-target='#ref-18'   aria-expanded='false'  aria-controls='ref-18' class='btn btn-sm btn-danger btn-pub' style='display: block; margin-top: 1rem;position: absolute;left:0;top:-5%;transform: translateX(-3em);'&gt;&lt;i class='bi bi-plus-lg'&gt;&lt;/i&gt;&lt;/button&gt;&lt;div class='collapse' id='ref-18'&gt;&lt;p class='small'&gt;&lt;br/&gt;Background. The association between nonoptimal temperatures and cardiovascular mortality risk is recognized. However, a comprehensive global assessment of this burden is lacking.\nObjectives. The goal of this study was to assess global cardiovascular mortality burden attributable to nonoptimal temperatures and investigate spatiotemporal trends.\nMethods. Using daily cardiovascular deaths and temperature data from 32 countries, a 3-stage analytical approach was applied. First, location-specific temperature–mortality associations were estimated, considering nonlinearity and delayed effects. Second, a multivariate meta-regression model was developed between location-specific effect estimates and 5 meta-predictors. Third, cardiovascular deaths associated with nonoptimal, cold, and hot temperatures for each global grid (55 km × 55 km resolution) were estimated, and temporal trends from 2000 to 2019 were explored.\nResults. Globally, 1,801,513 (95% empirical CI: 1,526,632-2,202,831) annual cardiovascular deaths were associated with nonoptimal temperatures, constituting 8.86% (95% empirical CI: 7.51%-12.32%) of total cardiovascular mortality corresponding to 26 deaths per 100,000 population. Cold-related deaths accounted for 8.20% (95% empirical CI: 6.74%-11.57%), whereas heat-related deaths accounted for 0.66% (95% empirical CI: 0.49%-0.98%). The mortality burden varied significantly across regions, with the highest excess mortality rates observed in Central Asia and Eastern Europe. From 2000 to 2019, cold-related excess death ratios decreased, while heat-related ratios increased, resulting in an overall decline in temperature-related deaths. Southeastern Asia, Sub-Saharan Africa, and Oceania observed the greatest reduction, while Southern Asia experienced an increase. The Americas and several regions in Asia and Europe displayed fluctuating temporal patterns.\nConclusions. Nonoptimal temperatures substantially contribute to cardiovascular mortality, with heterogeneous spatiotemporal patterns. Effective mitigation and adaptation strategies are crucial, especially given the increasing heat-related cardiovascular deaths amid climate change.&lt;/p&gt;&lt;p&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;cardiovascular mortality&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;nonoptimal temperatures&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;global assessment&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;spatiotemporal trends&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;climate impact&lt;/span&gt;&lt;/p&gt;&lt;br/&gt; &lt;/div&gt;&lt;/li&gt;\n  &lt;li style='position:relative;margin-bottom:0.8rem;list-style:none;' class='ref-entry is-climate is-health  is-exttemp       '&gt;Zhao Q, Li S, Ye T, Wu Y, Gasparrini A, Tong S, Urban A, Vicedo-Cabrera A, Tobias A, Armstrong B, &lt;b&gt;Royé D&lt;/b&gt;, Lavigne E, de’Donato F, Sera F, Kan H, Schwartz J, Pascal M, Ryti N, Goodman P, Saldiva P, Bell M, Guo Y (2024). Global, regional, and national burden of heatwave related mortality from 1990 to 2019: A three stage modelling study. &lt;i&gt;PLOS Medicine&lt;/i&gt;, vol. 21(5), art. no. e1004364. &lt;i class='ai ai-doi'&gt;&lt;/i&gt; &lt;a target='_blank' href='https://doi.org/10.1371/journal.pmed.1004364'&gt;10.1371/journal.pmed.1004364&lt;/a&gt;. &lt;button type='button' data-bs-toggle='collapse' data-bs-target='#ref-19'   aria-expanded='false'  aria-controls='ref-19' class='btn btn-sm btn-danger btn-pub' style='display: block; margin-top: 1rem;position: absolute;left:0;top:-5%;transform: translateX(-3em);'&gt;&lt;i class='bi bi-plus-lg'&gt;&lt;/i&gt;&lt;/button&gt;&lt;div class='collapse' id='ref-19'&gt;&lt;p class='small'&gt;&lt;br/&gt;Background. The regional disparity of heatwave-related mortality over a long period has not been sufficiently assessed across the globe, impeding the localisation of adaptation planning and risk management towards climate change. We quantified the global mortality burden associated with heatwaves at a spatial resolution of 0.5°×0.5° and the temporal change from 1990 to 2019.\nMethods and findings. We collected data on daily deaths and temperature from 750 locations of 43 countries or regions, and 5 meta-predictors in 0.5°×0.5° resolution across the world. Heatwaves were defined as location-specific daily mean temperature ≥95th percentiles of year-round temperature range with duration ≥2 days. We first estimated the location-specific heatwave-mortality association. Secondly, a multivariate meta-regression was fitted between location-specific associations and 5 meta-predictors, which was in the third stage used with grid cell-specific meta-predictors to predict grid cell-specific association. Heatwave-related excess deaths were calculated for each grid and aggregated. During 1990 to 2019, 0.94% (95% CI: 0.68–1.19) of deaths [i.e., 153,078 cases (95% eCI: 109,950–194,227)] per warm season were estimated to be from heatwaves, accounting for 236 (95% eCI: 170–300) deaths per 10 million residents. The ratio between heatwave-related excess deaths and all premature deaths per warm season remained relatively unchanged over the 30 years, while the number of heatwave-related excess deaths per 10 million residents per warm season declined by 7.2% per decade in comparison to the 30-year average. Locations with the highest heatwave-related death ratio and rate were in Southern and Eastern Europe or areas had polar and alpine climates, and/or their residents had high incomes. The temporal change of heatwave-related mortality burden showed geographic disparities, such that locations with tropical climate or low incomes were observed with the greatest decline. The main limitation of this study was the lack of data from certain regions, e.g., Arabian Peninsula and South Asia.\nConclusions. Heatwaves were associated with substantial mortality burden that varied spatiotemporally over the globe in the past 30 years. The findings indicate the potential benefit of governmental actions to enhance health sector adaptation and resilience, accounting for inequalities across communities.&lt;/p&gt;&lt;p&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;heatwave-related mortality&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;global burden&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;temporal change&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;spatiotemporal analysis&lt;/span&gt;&lt;/p&gt;&lt;br/&gt; &lt;/div&gt;&lt;/li&gt;\n  &lt;li style='position:relative;margin-bottom:0.8rem;list-style:none;' class='ref-entry is-climate is-health    is-cc     '&gt;Wu Y, Wen B, Gasparrini A, Armstrong B, Sera F, Lavigne E, Li S, Guo Y, Overcenco A, Urban A, Schneider A, Entezari A, Vicedo-Cabrera A, Zanobetti A, Analitis A, Zeka A, Tobias A, Nunes B, Alahmad B, Forsberg B, Íñiguez C, Ameling C, la Cruz Valencia C, Houthuijs D, Van Dung D, &lt;b&gt;Royé D&lt;/b&gt;, Indermitte E, Mayvaneh F, Acquaotta F, de'Donato F, Carrasco-Escobar G, Kan H, Carlsen H, Orru H, Kim H, Holobaca I, Kyselý J, Madureira J, Schwartz J, Jaakkola J, Katsouyanni K, Diaz M, Ragettli M, Hashizume M, Pascal M, de Sousa Zanotti Stagliorio Coelho M, Ortega N, Ryti N, Scovronick N, Michelozzi P, Correa P, Goodman P, Nascimento Saldiva P, Raz R, Abrutzky R, Osorio S, Pan S, Rao S, Tong S, Achilleos S, Dang T, Colistro V, Huber V, Lee W, Seposo X, Honda Y, Kim Y, Guo Y, Li S, Guo Y (2024). Temperature frequency and mortality: Assessing adaptation to local temperature. &lt;i&gt;Environment International&lt;/i&gt;, vol. 187, art. no. 108691. &lt;i class='ai ai-doi'&gt;&lt;/i&gt; &lt;a target='_blank' href='https://doi.org/10.1016/j.envint.2024.108691'&gt;10.1016/j.envint.2024.108691&lt;/a&gt;. &lt;button type='button' data-bs-toggle='collapse' data-bs-target='#ref-20'   aria-expanded='false'  aria-controls='ref-20' class='btn btn-sm btn-danger btn-pub' style='display: block; margin-top: 1rem;position: absolute;left:0;top:-5%;transform: translateX(-3em);'&gt;&lt;i class='bi bi-plus-lg'&gt;&lt;/i&gt;&lt;/button&gt;&lt;div class='collapse' id='ref-20'&gt;&lt;p class='small'&gt;&lt;br/&gt;Assessing the association between temperature frequency and mortality can provide insights into human adaptation to local ambient temperatures. We collected daily time-series data on mortality and temperature from 757 locations in 47 countries/regions during 1979–2020. We used a two-stage time series design to assess the association between temperature frequency and all-cause mortality. The results were pooled at the national, regional, and global levels. We observed a consistent decrease in the risk of mortality as the normalized frequency of temperature increases across the globe. The average increase in mortality risk comparing the 10th to 100th percentile of normalized frequency was 13.03% (95% CI: 12.17–13.91), with substantial regional differences (from 4.56% in Australia and New Zealand to 33.06% in South Europe). The highest increase in mortality was observed for high-income countries (13.58%, 95% CI: 12.56–14.61), followed by lower-middle-income countries (12.34%, 95% CI: 9.27–15.51). This study observed a declining risk of mortality associated with higher temperature frequency. Our findings suggest that populations can adapt to their local climate with frequent exposure, with the adapting ability varying geographically due to differences in climatic and socioeconomic characteristics.&lt;/p&gt;&lt;p&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;temperature&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;adaptation&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;frequency&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;mortality&lt;/span&gt;&lt;span style='margin-right: 2px;margin-bottom: 5px;' class='badge rounded-pill bg-warning'&gt;climate change&lt;/span&gt;&lt;/p&gt;&lt;br/&gt; &lt;/div&gt;&lt;/li&gt;\n  &lt;li style='position:relative;margin-bottom:0.8rem;list-style:none;' class='ref-entry is-climate is-health is-poll     is-envir   '&gt;Madaniyazi L, Alpízar J, Cifuentes L, Riojas-Rodríguez H, Hurtado Díaz M, de Sousa Zanotti Stagliorio Coelho M, Abrutzky R, Osorio S, Carrasco Escobar G, Valdés Ortega N, Colistro V, &lt;b&gt;Royé D&lt;/b&gt;, Tobías A (2024). Health and Economic Benefits of Complying With the World Health Organization Air Quality Guidelines for Particulate Matter in Nine Major Latin American Cities. &lt;i&gt;International Journal of Public Health&lt;/i&gt;, vol. 69, art. no. 1606909. &lt;i class='ai ai-doi'&gt;&lt;/i&gt; &lt;a target='_blank' href='https://doi.org/10.3389/ijph.2024.1606909'&gt;10.3389/ijph.2024.1606909&lt;/a&gt;. &lt;button type='button' data-bs-toggle='collapse' data-bs-target='#ref-21'   aria-expanded='false'  aria-controls='ref-21' class='btn btn-sm btn-danger btn-pub' style='display: block; margin-top: 1rem;position: absolute;left:0;top:-5%;transform: translateX(-3em);'&gt;&lt;i class='bi bi-plus-lg'&gt;&lt;/i&gt;&lt;/button&gt;&lt;div class='collapse' id='ref-21'&gt;&lt;p class='small'&gt;&lt;br/&gt;Objectives: This study aims to estimate the short-term preventable mortality and associated economic costs of complying with the World Health Organization (WHO) air quality guidelines (AQGs) limit values for PM10 and PM2.5 in nine major Latin American cities.\nMethods: We estimated city-specific PM-mortality associations using time-series regression models and calculated the attributable mortality fraction. Next, we used the value of statistical life to calculate the economic benefits of complying with the WHO AQGs limit values.\nResults: In most cities, PM concentrations exceeded the WHO AQGs limit values more than 90% of the days. PM10 was found to be associated with an average excess mortality of 1.88% with concentrations above WHO AQGs limit values, while for PM2.5 it was 1.05%. The associated annual economic costs varied widely, between US\\) 19.5 million to 3,386.9 million for PM10, and US$ 196.3 million to 2,209.6 million for PM2.5.\nConclusion: Our findings suggest that there is an urgent need for policymakers to develop interventions to achieve sustainable air quality improvements in Latin America. Complying with the WHO AQGs limit values for PM10 and PM2.5 in Latin American cities would substantially benefits for urban populations.\n\n\nair quality guidelinesparticulate matterhealth benefitseconomic benefitslatin american cities\n\n\n\n\n\nWen B, Wu Y, Guo Y, Gasparrini A, Tong S, Overcenco A, Urban A, Schneider A, Entezari A, Vicedo-Cabrera A, Zanobetti A, Analitis A, Zeka A, Tobias A, Nunes B, Alahmad B, Armstrong B, Forsberg B, Pan S, Íñiguez C, Ameling C, Valencia C, Åström C, Houthuijs D, Van Dung D, Royé D, Indermitte E, Lavigne E, Mayvaneh F, Acquaotta F, de’Donato F, Rao S, Sera F, Carrasco-Escobar G, Kan H, Orru H, Kim H, Holobaca I, Kyselý J, Madureira J, Schwartz J, Jaakkola J, Katsouyanni K, Diaz M, Ragettli M, Hashizume M, Pascal M, Coélho M, Ortega N, Ryti N, Scovronick N, Michelozzi P, Matus Correa P, Goodman P, Saldiva P, Raz R, Abrutzky R, Osorio S, Dang T, Colistro V, Huber V, Lee W, Seposo X, Honda Y, Kim Y, Guo Y, Bell M, Li S (2024). Comparison for the effects of different components of temperature variability on mortality: A multicountry timeseries study. Environment International, vol. 187, art. no. 108712.  10.1016/j.envint.2024.108712. \n\n\nBackground. Temperature variability (TV) is associated with increased mortality risk. However, it is still unknown whether intra-day or inter-day TV has different effects. Objectives. We aimed to assess the association of intra-day TV and inter-day TV with all-cause, cardiovascular, and respiratory mortality. Methods. We collected data on total, cardiovascular, and respiratory mortality and meteorology from 758 locations in 47 countries or regions from 1972 to 2020. We defined inter-day TV as the standard deviation (SD) of daily mean temperatures across the lag interval, and intra-day TV as the average SD of minimum and maximum temperatures on each day. In the first stage, inter-day and intra-day TVs were modelled simultaneously in the quasi-Poisson time-series model for each location. In the second stage, a multi-level analysis was used to pool the location-specific estimates. Results. Overall, the mortality risk due to each interquartile range [IQR] increase was higher for intra-day TV than for inter-day TV. The risk increased by 0.59% (95% confidence interval [CI]: 0.53, 0.65) for all-cause mortality, 0.64% (95% CI: 0.56, 0.73) for cardiovascular mortality, and 0.65% (95% CI: 0.49, 0.80) for respiratory mortality per IQR increase in intra-day TV0–7 (0.9 °C). An IQR increase in inter-day TV0–7 (1.6 °C) was associated with 0.22% (95% CI: 0.18, 0.26) increase in all-cause mortality, 0.44% (95% CI: 0.37, 0.50) increase in cardiovascular mortality, and 0.31% (95% CI: 0.21, 0.41) increase in respiratory mortality. The proportion of all-cause deaths attributable to intra-day TV0–7 and inter-day TV0–7 was 1.45% and 0.35%, respectively. The mortality risks varied by lag interval, climate area, season, and climate type. Conclusions. Our results indicated that intra-day TV may explain the main part of the mortality risk related to TV and suggested that comprehensive evaluations should be proposed in more countries to help protect human health.\n\n\ntemperature variabilitymortalityinter-dayintra-day\n\n\n\n\n\nGincheva A, Pausas J, Edwards A, Provenzale A, Cerdà A, Hanes C, Royé D, Chuvieco E, Mouillot F, Vissio G, Rodrigo J, Bedía J, Abatzoglou J, Senciales González J, Short K, Baudena M, Llasat M, Magnani M, Boer M, González M, Torres-Vázquez M, Fiorucci P, Jacklyn P, Libonati R, Trigo R, Herrera S, Jerez S, Wang X, Turco M (2024). A monthly gridded burned area database of national wildland fire data. Scientific Data, vol. 11(352).  10.1038/s41597-024-03141-2. \n\n\nWe assembled the first gridded burned area (BA) database of national wildfire data (ONFIRE), a comprehensive and integrated resource for researchers, non-government organisations, and government agencies analysing wildfires in various regions of the Earth. We extracted and harmonised records from different regions and sources using open and reproducible methods, providing data in a common framework for the whole period available (starting from 1950 in Australia, 1959 in Canada, 1985 in Chile, 1980 in Europe, and 1984 in the United States) up to 2021 on a common 1° × 1° grid. The data originate from national agencies (often, ground mapping), thus representing the best local expert knowledge. Key opportunities and limits in using this dataset are discussed as well as possible future expansions of this open-source approach that should be explored. This dataset complements existing gridded BA data based on remote sensing and offers a valuable opportunity to better understand and assess fire regime changes, and their drivers, in these regions. The ONFIRE database can be freely accessed at https://zenodo.org/record/8289245.\n\n\nurned area databasewildland firegridded datanational fire dataonfire database\n\n\n\n\n\nChen K, de Schrijver E, Sivaraj S, Sera F, Scovronick N, Jiang L, Royé D, Lavigne E, Kyselý J, Urban A, Schneider A, Huber V, Madureira J, Mistry M, Cvijanovic I, Armstrong B, Schneider R, Tobias A, Astrom C, Guo Y, Honda Y, Abrutzky R, Tong S, de Sousa Zanotti Stagliorio Coelho M, Saldiva P, Correa P, Ortega N, Kan H, Osorio S, Orru H, Indermitte E, Jaakkola J, Ryti N, Pascal M, Katsouyanni K, Analitis A, Mayvaneh F, Entezari A, Goodman P, Zeka A, Michelozzi P, de’Donato F, Hashizume M, Alahmad B, Diaz M, De la Cruz Valencia C, Overcenco A, Houthuijs D, Ameling C, Rao S, Carrasco-Escobar G, Seposo X, da Silva S, Holobaca I, Acquaotta F, Kim H, Lee W, Íñiguez C, Forsberg B, Ragettli M, Guo Y, Pan S, Li S, Colistro V, Zanobetti A, Schwartz J, Dang T, Van Dung D, Carlsen H, Cauchi J, Achilleos S, Raz R, Gasparrini A, Vicedo-Cabrera A (2024). Impact of population aging on future temperature related mortality at different global warming levels. Nature Communications, vol. 15, art. no. 1796.  10.1038/s41467-024-45901-z. \n\n\nOlder adults are generally amongst the most vulnerable to heat and cold. While temperature-related health impacts are projected to increase with global warming, the influence of population aging on these trends remains unclear. Here we show that at 1.5 °C, 2 °C, and 3 °C of global warming, heat-related mortality in 800 locations across 50 countries/areas will increase by 0.5%, 1.0%, and 2.5%, respectively; among which 1 in 5 to 1 in 4 heat-related deaths can be attributed to population aging. Despite a projected decrease in cold-related mortality due to progressive warming alone, population aging will mostly counteract this trend, leading to a net increase in cold-related mortality by 0.1%–0.4% at 1.5–3 °C global warming. Our findings indicate that population aging constitutes a crucial driver for future heat- and cold-related deaths, with increasing mortality burden for both heat and cold due to the aging population.\n\n\npopulation agingtemperature-related mortalityglobal warming levelsheat and cold mortalityfuture projections\n\n\n\n\n\nGao Y, Huang W, Zhao Q, Ryti N, Armstrong B, Gasparrini A, Tong S, Pascal M, Urban A, Zeka A, Lavigne E, Madureira J, Goodman P, Huber V, Forsberg B, Kyselý J, Sera F, Guo Y, Li S, Gao Y, Huang W, Zhao Q, Ryti N, Armstrong B, Gasparrini A, Tong S, Pascal M, Urban A, Zeka A, Lavigne E, Madureira J, Goodman P, Huber V, Forsberg B, Kyselý J, Sera F, Bell M, Hales S, Honda Y, Jaakkola J, Tobias A, Vicedo-Cabrera A, Abrutzky R, Coelho M, Saldiva P, Correa P, Ortega N, Kan H, Osorio S, Royé D, Orru H, Indermitte E, Schneider A, Katsouyanni K, Analitis A, Carlsen H, Mayvaneh F, Roradeh H, Raz R, Michelozzi P, de’Donato F, Hashizume M, Kim Y, Alahmad B, Cauchy J, Diaz M, Arellano E, Valencia C, Overcenco A, Houthuijs D, Ameling C, Rao S, Carrasco G, Seposo X, Chua P, Silva S, Nunes B, Holobaca I, Cvijanovic I, Mistry M, Scovronick N, Acquaotta F, Kim H, Lee W, Íñiguez C, Åström C, Ragettli M, Guo Y, Pan S, Colistro V, Zanobetti A, Schwartz J, Dang T, Dung D, Guo Y, Li S (2024). Global, regional, and national burden of mortality associated with cold spells during 2000–19: a three stage modelling study. The Lancet Planetary Health, vol. 8(2), pp. e108-e116.  10.1016/S2542-5196(23)00277-2. \n\n\nBackground. Exposure to cold spells is associated with mortality. However, little is known about the global mortality burden of cold spells. Methods. A three-stage meta-analytical method was used to estimate the global mortality burden associated with cold spells by means of a time series dataset of 1960 locations across 59 countries (or regions). First, we fitted the location-specific, cold spell-related mortality associations using a quasi-Poisson regression with a distributed lag non-linear model with a lag period of up to 21 days. Second, we built a multivariate meta-regression model between location-specific associations and seven predictors. Finally, we predicted the global grid-specific cold spell-related mortality associations during 2000–19 using the fitted meta-regression model and the yearly grid-specific meta-predictors. We calculated the annual excess deaths, excess death ratio (excess deaths per 1000 deaths), and excess death rate (excess deaths per 100 000 population) due to cold spells for each grid across the world. Findings.Globally, 205 932 (95% empirical CI [eCI] 162 692–250 337) excess deaths, representing 3·81 (95% eCI 2·93–4·71) excess deaths per 1000 deaths (excess death ratio), and 3·03 (2·33–3·75) excess deaths per 100 000 population (excess death rate) were associated with cold spells per year between 2000 and 2019. The annual average global excess death ratio in 2016–19 increased by 0·12 percentage points and the excess death rate in 2016–19 increased by 0·18 percentage points, compared with those in 2000–03. The mortality burden varied geographically. The excess death ratio and rate were highest in Europe, whereas these indicators were lowest in Africa. Temperate climates had higher excess death ratio and rate associated with cold spells than other climate zones. Interpretation. Cold spells are associated with substantial mortality burden around the world with geographically varying patterns. Although the number of cold spells has on average been decreasing since year 2000, the public health threat of cold spells remains substantial. The findings indicate an urgency of taking local and regional measures to protect the public from the mortality burdens of cold spells. Funding.Australian Research Council, Australian National Health and Medical Research Council, EU’s Horizon 2020 Project Exhaustion.\n\n\ncold spellsmortality burdenthree-stage modellingglobal assessmentclimate impact\n\n\n\n\n\nMadaniyazi L, Armstrong B, Tobias A, Mistry M, Bell M, Urban A, Kyselý J, Ryti N, Cvijanovic I, Ng C, Royé D, Vicedo-Cabrera A, Tong S, Lavigne E, Íñiguez C, da Silva S, Madureira J, Jaakkola J, Sera F, Honda Y, Gasparrini A, Hashizume M, Abrutzky R, Acquaotta F, Alahmad B, Analitis A, Carlsen H, Carrasco-Escobar G, de Sousa Zanotti Stagliorio Coelho M, Colistro V, Matus Correa P, Dang T, de’Donato F, Hurtado Diaz M, Dung D, Entezari A, Forsberg B, Goodman P, Guo Y, Guo Y, Holobaca I, Houthuijs D, Huber V, Indermitte E, Kan H, Katsouyanni K, Kim Y, Kim H, Lee W, Li S, Mayvaneh F, Michelozzi P, Orru H, Valdés Ortega N, Osorio S, Overcenco A, Pan S, Pascal M, Ragettli M, Rao S, Raz R, Saldiva P, Schneider A, Schwartz J, Scovronick N, Seposo X, De la Cruz Valencia C, Zanobetti A, Zeka A (2024). Seasonality of mortality under climate change: a multicountry projection study. The Lancet Planetary Health, vol. 8(2), pp. e86-e94.  10.1016/s25425196(23)00269-3. \n\n\nBackground. Climate change can directly impact temperature-related excess deaths and might subsequently change the seasonal variation in mortality. In this study, we aimed to provide a systematic and comprehensive assessment of potential future changes in the seasonal variation, or seasonality, of mortality across different climate zones. Methods. In this modelling study, we collected daily time series of mean temperature and mortality (all causes or non-external causes only) via the Multi-Country Multi-City Collaborative (MCC) Research Network. These data were collected during overlapping periods, spanning from Jan 1, 1969 to Dec 31, 2020. We projected daily mortality from Jan 1, 2000 to Dec 31, 2099, under four climate change scenarios corresponding to increasing emissions (Shared Socioeconomic Pathways [SSP] scenarios SSP1-2.6, SSP2-4.5, SSP3-7.0, and SSP5-8.5). We compared the seasonality in projected mortality between decades by its shape, timings (the day-of-year) of minimum (trough) and maximum (peak) mortality, and sizes (peak-to-trough ratio and attributable fraction). Attributable fraction was used to measure the burden of seasonality of mortality. The results were summarised by climate zones. Findings. The MCC dataset included 126 809 537 deaths from 707 locations within 43 countries or areas. After excluding the only two polar locations (both high-altitude locations in Peru) from climatic zone assessments, we analysed 126 766 164 deaths in 705 locations aggregated in four climate zones (tropical, arid, temperate, and continental). From the 2000s to the 2090s, our projections showed an increase in mortality during the warm seasons and a decrease in mortality during the cold seasons, albeit with mortality remaining high during the cold seasons, under all four SSP scenarios in the arid, temperate, and continental zones. The magnitude of this changing pattern was more pronounced under the high-emission scenarios (SSP3-7.0 and SSP5-8.5), substantially altering the shape of seasonality of mortality and, under the highest emission scenario (SSP5-8.5), shifting the mortality peak from cold seasons to warm seasons in arid, temperate, and continental zones, and increasing the size of seasonality in all zones except the arid zone by the end of the century. In the 2090s compared with the 2000s, the change in peak-to-trough ratio (relative scale) ranged from 0·96 to 1·11, and the change in attributable fraction ranged from 0·002% to 0·06% under the SSP5-8.5 (highest emission) scenario. Interpretation. A warming climate can substantially change the seasonality of mortality in the future. Our projections suggest that health-care systems should consider preparing for a potentially increased demand during warm seasons and sustained high demand during cold seasons, particularly in regions characterised by arid, temperate, and continental climates.\n\n\nseasonality of mortalityclimate changemulticountry projectiontemperature-related deathsfuture climate scenarios\n\n\n\n\n\nRoyé D, Íñiguez C, Tobías A (2024). Comparison of Air Pollution–Mortality Associations Using Observed Particulate Matter Concentrations and Reanalysis Data in 33 Spanish Cities. Environment & Health, vol. 2(3), pp. 161-169.  10.1021/envhealth.3c00128. \n\n\nAir pollution poses a health hazard in all countries. However, complete data on ambient particulate matter (PM) concentrations are not available in all world regions. Reanalysis data is already a valuable source of exposure data in epidemiological studies examining the relationship between temperature and health. Nevertheless, the performance of reanalysis data in assessing the short-term health effects of particulate air pollution remains unclear. We assessed the performance of CAMS reanalysis (EAC4) data from the European Centre for Medium-Range Weather Forecasts, compared with daily PM concentrations from field monitoring stations, to estimate short-term exposure to PM with an aerodynamic diameter less than 10 μm (PM10) on daily mortality in 33 Spanish provincial capital cities using a two-stage time series regression design. The shape of the PM10 distribution varied substantially between PM observations and CAMS global reanalysis of atmospheric composition (EAC4) reanalysis data, with correlation ranging from 0.21 to 0.58. The pooled mortality risk for a 10 μg/m3 increase in PM10 showed similar estimates using PM concentrations {relative risks (RR) = 1.007, 95% confidence intervals (95% CI) = [1.002, 1.011]} and EAC4 reanalysis data (RR = 1.011, 95% CI = [1.006, 1.015]). However, the city-specific PM10 beta coefficients estimated using PM concentrations and EAC4 reanalysis data showed a low correlation (r = 0.22). The use of reanalysis data should be approached with caution when assessing the association between particulate matter air pollution and health outcomes, particularly in cities with small populations.\n\n\nair pollutionparticulate matterpm10reanalysiseac4mortalityspaintime series regression\n\n\n\n\n2023\n\n\nStafoggia M, Michelozzi P, Schneider A, Armstrong B, Scortichini M, Rai M, Achilleos S, Alahmad B, Analitis A, Åström C, Bell M, Calleja N, Krage Carlsen H, Carrasco G, Paul Cauchi J, DSZS Coelho M, Correa P, Diaz M, Entezari A, Forsberg B, Garland R, Leon Guo Y, Guo Y, Hashizume M, Holobaca I, Íñiguez C, Jaakkola J, Kan H, Katsouyanni K, Kim H, Kyselý J, Lavigne E, Lee W, Li S, Maasikmets M, Madureira J, Mayvaneh F, Fook Sheng Ng C, Nunes B, Orru H, V Ortega N, Osorio S, Palomares A, Pan S, Pascal M, Ragettli M, Rao S, Raz R, Royé D, Ryti N, HN Saldiva P, Samoli E, Schwartz J, Scovronick N, Sera F, Tobias A, Tong S, DLC Valencia C, Maria Vicedo-Cabrera A, Urban A, Gasparrini A, Breitner S, de’ Donato F (2023). Joint effect of heat and air pollution on mortality in 620 cities of 36 countries. Environment International, vol. 181, art. no. 108258.  10.1016/j.envint.2023.108258. \n\n\nBackground. The epidemiological evidence on the interaction between heat and ambient air pollution on mortality is still inconsistent. Objectives. To investigate the interaction between heat and ambient air pollution on daily mortality in a large dataset of 620 cities from 36 countries. Methods. We used daily data on all-cause mortality, air temperature, particulate matter ≤ 10 μm (PM10), PM ≤ 2.5 μm (PM2.5), nitrogen dioxide (NO2), and ozone (O3) from 620 cities in 36 countries in the period 1995–2020. We restricted the analysis to the six consecutive warmest months in each city. City-specific data were analysed with over-dispersed Poisson regression models, followed by a multilevel random-effects meta-analysis. The joint association between air temperature and air pollutants was modelled with product terms between non-linear functions for air temperature and linear functions for air pollutants. Results. We analyzed 22,630,598 deaths. An increase in mean temperature from the 75th to the 99th percentile of city-specific distributions was associated with an average 8.9 % (95 % confidence interval: 7.1 %, 10.7 %) mortality increment, ranging between 5.3 % (3.8 %, 6.9 %) and 12.8 % (8.7 %, 17.0 %), when daily PM10 was equal to 10 or 90 μg/m3, respectively. Corresponding estimates when daily O3 concentrations were 40 or 160 μg/m3 were 2.9 % (1.1 %, 4.7 %) and 12.5 % (6.9 %, 18.5 %), respectively. Similarly, a 10 μg/m3 increment in PM10 was associated with a 0.54 % (0.10 %, 0.98 %) and 1.21 % (0.69 %, 1.72 %) increase in mortality when daily air temperature was set to the 1st and 99th city-specific percentiles, respectively. Corresponding mortality estimate for O3 across these temperature percentiles were 0.00 % (-0.44 %, 0.44 %) and 0.53 % (0.38 %, 0.68 %). Similar effect modification results, although slightly weaker, were found for PM2.5 and NO2. Conclusions. Suggestive evidence of effect modification between air temperature and air pollutants on mortality during the warm period was found in a global dataset of 620 cities.\n\n\nair temperatureair pollutioneffect modificationepidemiologymortality\n\n\n\n\n\nDíaz-Poso A, Lorenzo N, Martí A, Royé D (2023). Cold wave intensity on the Iberian Peninsula: Future climate projections. Atmospheric Research, vol. 295, art. no. 107011.  10.1016/j.atmosres.2023.107011. \n\n\nIn the context of global warming, cold waves have generated less interest in the scientific community than heat waves, despite their impacts on public health, transport infrastructures and energy consumption. The present study analyses climate change scenarios with simulations of the EURO-CORDEX project, using the Excess Cold Factor (ECF) index for the Iberian Peninsula and Balearic Islands (IPB). The dimensions of intensity, frequency, duration and spatial extent are evaluated for the near future (2021–2050) with respect to the historical period of reference (1971–2000). The projections show a significant overall decrease in all dimensions. The mean change in maximum cold wave intensity is −50% over most of the IPB as a whole in the near future (2021–2050). The largest changes occur in the interior of the Peninsula, where the decrease is around −100%. The annual mean number of cold wave days decreases for the IPB as a whole by −50% compared to 1971–2000, with the maximum extent decreasing by more than the mean, with decreases of between −2.4%/decade and − 5.5%/decade. Although a smaller number of cold waves suggests less human exposure, the acclimatisation of the population to higher temperatures will imply that cold waves will continue to pose a serious local threat.\n\n\necfcold waveintensityspatial extentclimate changefuture projections\n\n\n\n\n\nUhl J, Royé D, Burghardt K, Aldrey Vázquez J, Borobio Sanchiz M, Leyk S (2023). HISDACES: historical settlement data compilation for Spain (1900–2020). Earth System Science Data, vol. 15(10), pp. 4713-4747.  10.5194/essd-15-4713-2023. \n\n\nMulti-temporal measurements quantifying the changes to the Earth’s surface are critical for understanding many natural, anthropogenic, and social processes. Researchers typically use remotely sensed Earth observation data to quantify and characterize such changes in land use and land cover (LULC). However, such data sources are limited in their availability prior to the 1980s. While an observational window of 40 to 50 years is sufficient to study most recent LULC changes, processes such as urbanization, land development, and the evolution of urban and coupled nature–human systems often operate over longer time periods covering several decades or even centuries. Thus, to quantify and better understand such processes, alternative historical–geospatial data sources are required that extend farther back in time. However, such data are rare, and processing is labor-intensive, often involving manual work. To overcome the resulting lack in quantitative knowledge of urban systems and the built environment prior to the 1980s, we leverage cadastral data with rich thematic property attribution, such as building usage and construction year. We scraped, harmonized, and processed over 12 000 000 building footprints including construction years to create a multi-faceted series of gridded surfaces, describing the evolution of human settlements in Spain from 1900 to 2020, at 100 m spatial and 5-year temporal resolution. These surfaces include measures of building density, built-up intensity, and built-up land use. We evaluated our data against a variety of data sources including remotely sensed human settlement data and land cover data, model-based historical land use depictions, and historical maps and historical aerial imagery and find high levels of agreement. This new data product, the Historical Settlement Data Compilation for Spain (HISDAC-ES), is publicly available (https://doi.org/10.6084/m9.figshare.22009643, Uhl et al., 2023a) and represents a rich source for quantitative, long-term analyses of the built environment and related processes over large spatial and temporal extents and at fine resolutions.\n\n\nhistorical settlement dataspainland use and land coverurbanizationgeospatial analysis\n\n\n\n\n\nTobías A, Íñiguez C, Royé D (2023). From Research to the Development of an Innovative Application for Monitoring HeatRelated Mortality in Spain. Environment & Health, vol. 1(6).  10.1021/envhealth.3c00134. \n\n\nExposure to heat poses a major threat to high-risk populations by substantially contributing to increased mortality and morbidity. Heat-related mortality has been a significant concern since the summer of 2003, when Europe experienced a heatwave, leading to an excess of more than 70,000 deaths during the summer months, with 3,166 of those occurring in Spain. Heat-health early warning systems can reduce the burden of high ambient temperatures. However, the evidence of their effectiveness is limited. Therefore, developing innovative tools for real-time monitoring and forecast of health impacts from heat becomes essential for effective public health interventions and resource allocation strategies. We developed a user-friendly and accessible tool for monitoring heat-attributable mortality in Spain during the summer season between June and August. https://ficlima.shinyapps.io/mace/\n\n\nheat-related mortalityinnovative applicationreal-time monitoringpublic healthspain\n\n\n\n\n\nLiu C, Chen R, Sera F, Vicedo-Cabrera A, Guo Y, Tong S, Lavigne E, Correa P, Ortega N, Achilleos S, Royé D, Jaakkola J, Ryti N, Pascal M, Schneider A, Breitner S, Entezari A, Mayvaneh F, Raz R, Honda Y, Hashizume M, Ng C, Gaio V, Madureira J, Holobaca I, Tobias A, Íñiguez C, Guo Y, Pan S, Masselot P, Bell M, Zanobetti A, Schwartz J, Gasparrini A, Kan H (2023). Interactive effects of ambient fine particulate matter and ozone on daily mortality in 372 cities: two stage time series analysis. BMJ, vol. 383, art. no. e075203.  10.1136/bmj-2023-075203. \n\n\nObjective: To investigate potential interactive effects of fine particulate matter (PM2.5) and ozone (O3) on daily mortality at global level. Design: Two stage time series analysis. Setting: 372 cities across 19 countries and regions. Population: Daily counts of deaths from all causes, cardiovascular disease, and respiratory disease. Main outcome measure: Daily mortality data during 1994-2020. Stratified analyses by co-pollutant exposures and synergy index (1 denotes the combined effect of pollutants is greater than individual effects) were applied to explore the interaction between PM2.5 and O3 in association with mortality. Results: During the study period across the 372 cities, 19.3 million deaths were attributable to all causes, 5.3 million to cardiovascular disease, and 1.9 million to respiratory disease. The risk of total mortality for a 10 μg/m3 increment in PM2.5 (lag 0-1 days) ranged from 0.47% (95% confidence interval 0.26% to 0.67%) to 1.25% (1.02% to 1.48%) from the lowest to highest fourths of O3 concentration; and for a 10 μg/m3 increase in O3 ranged from 0.04% (-0.09% to 0.16%) to 0.29% (0.18% to 0.39%) from the lowest to highest fourths of PM2.5 concentration, with significant differences between strata (P for interaction 0.001). A significant synergistic interaction was also identified between PM2.5 and O3 for total mortality, with a synergy index of 1.93 (95% confidence interval 1.47 to 3.34). Subgroup analyses showed that interactions between PM2.5 and O3 on all three mortality endpoints were more prominent in high latitude regions and during cold seasons. Conclusion: The findings of this study suggest a synergistic effect of PM2.5 and O3 on total, cardiovascular, and respiratory mortality, indicating the benefit of coordinated control strategies for both pollutants.\n\n\nfine particulate matter (pm2.5)ozone (o3)daily mortalitytwo-stage time seriessynergistic effects\n\n\n\n\n\nLüthi S, Fairless C, Fischer EM, Scovronick N, Armstrong B, De Sousa Zanotti Stagliorio Coelho M, Guo YL, Guo Y, Honda Y, Huber V, Kyselý J, Lavigne E, Royé D, Ryti N, Silva S, Urban A, Gasparrini A, Bresch DN, Vicedo-Cabrera AM (2023). Rapid increase in the risk of heatrelated mortality. Nature Communications, vol. 14, art. no. 4894.  10.1038/s41467-023-40599-x. \n\n\nHeat-related mortality has been identified as one of the key climate extremes posing a risk to human health. Current research focuses largely on how heat mortality increases with mean global temperature rise, but it is unclear how much climate change will increase the frequency and severity of extreme summer seasons with high impact on human health. In this probabilistic analysis, we combined empirical heat-mortality relationships for 748 locations from 47 countries with climate model large ensemble data to identify probable past and future highly impactful summer seasons. Across most locations, heat mortality counts of a 1-in-100 year season in the climate of 2000 would be expected once every ten to twenty years in the climate of 2020. These return periods are projected to further shorten under warming levels of 1.5 °C and 2 °C, where heat-mortality extremes of the past climate will eventually become commonplace if no adaptation occurs. Our findings highlight the urgent need for strong mitigation and adaptation to reduce impacts on human lives.\n\n\nextreme heatclimate changeheatwavespublic healthrisk assessment\n\n\n\n\n\nHuang W, Li S, Vogt T, Xu R, Tong S, Molina T, Masselot P, Gasparrini A, Armstrong B, Pascal M, Royé D, Sheng Ng C, Vicedo-Cabrera A, Schwartz J, Lavigne E, Kan H, Goodman P, Zeka A, Hashizume M, Diaz M, De la Cruz Valencia C, Seposo X, Nunes B, Madureira J, Kim H, Lee W, Tobias A, Íñiguez C, Guo Y, Pan S, Zanobetti A, Dang T, Van Dung D, Geiger T, Otto C, Johnson A, Hales S, Yu P, Yang Z, Ritchie E, Guo Y (2023). Global shortterm mortality risk and burden associated with tropical cyclones from 1980 to 2019: a multicountry timeseries study. The Lancet Planetary Health, vol. 7(8), pp. e694-e705.  10.1016/S2542-5196(23)00143-2. \n\n\nBackground. The global spatiotemporal pattern of mortality risk and burden attributable to tropical cyclones is unclear. We aimed to evaluate the global short-term mortality risk and burden associated with tropical cyclones from 1980 to 2019. Methods. The wind speed associated with cyclones from 1980 to 2019 was estimated globally through a parametric wind field model at a grid resolution of 0·5° × 0·5°. A total of 341 locations with daily mortality and temperature data from 14 countries that experienced at least one tropical cyclone day (a day with maximum sustained wind speed associated with cyclones ≥17·5 m/s) during the study period were included. A conditional quasi-Poisson regression with distributed lag non-linear model was applied to assess the tropical cyclone–mortality association. A meta-regression model was fitted to evaluate potential contributing factors and estimate grid cell-specific tropical cyclone effects. Findings. Tropical cyclone exposure was associated with an overall 6% (95% CI 4–8) increase in mortality in the first 2 weeks following exposure. Globally, an estimate of 97 430 excess deaths (95% empirical CI [eCI] 71 651–126 438) per decade were observed over the 2 weeks following exposure to tropical cyclones, accounting for 20·7 (95% eCI 15·2–26·9) excess deaths per 100 000 residents (excess death rate) and 3·3 (95% eCI 2·4–4·3) excess deaths per 1000 deaths (excess death ratio) over 1980–2019. The mortality burden exhibited substantial temporal and spatial variation. East Asia and south Asia had the highest number of excess deaths during 1980–2019: 28 744 (95% eCI 16 863–42 188) and 27 267 (21 157–34 058) excess deaths per decade, respectively. In contrast, the regions with the highest excess death ratios and rates were southeast Asia and Latin America and the Caribbean. From 1980–99 to 2000–19, marked increases in tropical cyclone-related excess death numbers were observed globally, especially for Latin America and the Caribbean and south Asia. Grid cell-level and country-level results revealed further heterogeneous spatiotemporal patterns such as the high and increasing tropical cyclone-related mortality burden in Caribbean countries or regions. Interpretation. Globally, short-term exposure to tropical cyclones was associated with a significant mortality burden, with highly heterogeneous spatiotemporal patterns. In-depth exploration of tropical cyclone epidemiology for those countries and regions estimated to have the highest and increasing tropical cyclone-related mortality burdens is urgently needed to help inform the development of targeted actions against the increasing adverse health impacts of tropical cyclones under a changing climate.\n\n\ntropical cyclonesshort-term mortalityglobal burden,time-series analysisspatiotemporal patterns\n\n\n\n\n\nDíaz-Poso A, Royé D, Martínez-Ibarra E (2023). Turismo y Cambio Climático: Aplicación del Holiday Climate Index (HCI:Urban) en España en los meses de verano para mediados y finales de siglo. Investigaciones Turísticas, vol. 26.  10.14198/inturi.23493. \n\n\nEn las últimas décadas el turismo ha adquirido una importancia cada vez mayor en la economía española. Con 83,5 millones de turistas en 2019, el 11.7% del PIB nacional proviene del sector turístico. El clima es uno de los principales aspectos a tener en cuenta por las personas para elegir un destino turístico. El índice Holiday Climate Index (HCI) es un indicador bioclimático que tiene en cuenta diferentes variables climáticas (temperatura, precipitación, humedad, viento y nubosidad), con el fin de determinar si las condiciones climáticas son adecuadas para las actividades turísticas de carácter urbano. Utilizando el HCI:Urban, se ha analizado la evolución de los niveles de confortabilidad climática para la Península y Baleares (PB) en verano (junio, julio y agosto) para mediados (2041-2060) y finales de siglo (2081-2100) bajo los escenarios climáticos RCP 4.5 y 8.5. Tomando como referencia el periodo 1986-2005, los resultados indican un aumento considerable del confort climático especialmente a finales de siglo en las comunidades autónomas del norte y noroeste del país, donde los valores, alcanzan la calificación de “excelente” (HCI 80-90). Paralelamente, la progresiva pérdida de confort a consecuencia del cambio climático en comunidades autónomas meridionales como Extremadura, Murcia, Andalucía e Islas Baleares, dará lugar a cambios en la distribución espacio-temporal de los flujos turísticos. Pese a que su formulación es susceptible de mejora, los datos proporcionados por el índice HCI:Urban pueden ser útiles en el desarrollo de instrumentos de planificación urbana, facilitando a las autoridades la toma de decisiones en un nuevo contexto turístico.\n\n\nhci (holiday climate index)cambio climáticoconfort climáticoturismoespaña.\n\n\n\n\n\nLo Y, Mitchell D, Buzan J, Zscheischler J, Schneider R, Mistry M, Kyselý J, Lavigne É, da Silva S, Royé D, Urban A, Armstrong B, Gasparrini A, Vicedo‐Cabrera A (2023). Optimal heat stress metric for modelling heat‐related mortality varies from country to country. International Journal of Climatology, vol. 43(12), pp. 5553-5568.  10.1002/joc.8160. \n\n\nCombined heat and humidity is frequently described as the main driver of human heat-related mortality, more so than dry-bulb temperature alone. While based on physiological thinking, this assumption has not been robustly supported by epidemiological evidence. By performing the first systematic comparison of eight heat stress metrics (i.e., temperature combined with humidity and other climate variables) with warm-season mortality, in 604 locations over 39 countries, we find that the optimal metric for modelling mortality varies from country to country. Temperature metrics with no or little humidity modification associates best with mortality in ~40% of the studied countries. Apparent temperature (combined temperature, humidity and wind speed) dominates in another 40% of countries. There is no obvious climate grouping in these results. We recommend, where possible, that researchers use the optimal metric for each country. However, dry-bulb temperature performs similarly to humidity-based heat stress metrics in estimating heat-related mortality in present-day climate.\n\n\nheat stress metricsheat-related mortalitycountry-specific analysisclimate variablesepidemiological evidence\n\n\n\n\n\nGestal Romaní S, Figueiras A, Royé D (2023). Effect of Temperature on Emergency Ambulance Call Outs for Cardiovascular Causes: A Scoping Review. Environment & Health, vol. 1(1).  10.1021/envhealth.3c00003. \n\n\nClimate change has increased interest in the effects of the thermal environment on cardiovascular health. Most studies have focused on mortality data. However, pre-hospital care data are better able to evaluate these effects, as they can register the full spectrum of the disease in real time. This scoping review aims to synthesize the epidemiological evidence regarding the effects of the thermal environment on cardiovascular morbidity in the pre-hospital setting, evaluated through ambulance calls. A staged literature search was performed using the PubMed database for the period between 1st January 2000 and 30th March 2023, using the MeSH terms “Weather” AND “Emergency Medical Services”. A total of 987 publications were identified that examined the correlation between the thermal environment and ambulance call-outs for cardiovascular causes. The studies were mostly ecological time series, with significant variability in the methodological aspects employed. An increase in the number of ambulance call-outs has been observed in association with low temperatures, both for overall cardiovascular pathologies and for certain pathological subtypes. For high temperatures, no effect has been observed in overall call-outs, although an increase has been observed during heat waves. The demand for ambulances for cardiac arrests is increased by both low and high temperatures and during heat waves. Ambulance call-outs for cardiovascular causes increase with low temperatures and heat waves, with no significant increase in the overall demand associated with high temperatures. Ambulance call-outs for cardiac arrests are the only subtype that is increased by high temperatures.\n\n\ncardiovascular diseasesweathercold exposureheat exposure ambulance call-outemergency medical services\n\n\n\n\n\nO’Brien E, Masselot P, Sera F, Royé D, Breitner S, Ng C, de Sousa Zanotti Stagliorio Coelho M, Madureira J, Tobias A, Vicedo-Cabrera A, Bell M, Lavigne E, Kan H, Gasparrini (2023). ShortTerm Association between Sulfur Dioxide and Mortality: A Multicountry Analysis in 399 Cities. Environmental Health Perspectives, vol. 131(3).  10.1289/ehp11112. \n\n\nBackground: Epidemiological evidence on the health risks of sulfur dioxide (SO2) is more limited compared with other pollutants, and doubts remain on several aspects, such as the form of the exposure–response relationship, the potential role of copollutants, as well as the actual risk at low concentrations and possible temporal variation in risks. Objectives: Our aim was to assess the short-term association between exposure to SO2 and daily mortality in a large multilocation data set, using advanced study designs and statistical techniques. Methods: The analysis included 43,729,018 deaths that occurred in 399 cities within 23 countries between 1980 and 2018. A two-stage design was applied to assess the association between the daily concentration of SO2 and mortality counts, including first-stage time-series regressions and second-stage multilevel random-effect meta-analyses. Secondary analyses assessed the exposure–response shape and the lag structure using spline terms and distributed lag models, respectively, and temporal variations in risk using a longitudinal meta-regression. Bi-pollutant models were applied to examine confounding effects of particulate matter with an aerodynamic diameter of ≤10μ⁢m (PM10) and 2.5μ⁢m (PM2.5), ozone, nitrogen dioxide, and carbon monoxide. Associations were reported as relative risks (RRs) and fractions of excess deaths. Results: The average daily concentration of SO2 across the 399 cities was 11⁢.7⁢ μ⁢g/m3, with 4.7% of days above the World Health Organization (WHO) guideline limit (40⁢ μ⁢g/m3, 24-h average), although the exceedances occurred predominantly in specific locations. Exposure levels decreased considerably during the study period, from an average concentration of 19.0 μ⁢g/m3 in 1980–1989 to 6.3⁢ μ⁢g/m3 in 2010–2018. For all locations combined, a 10-μ⁢g/m3 increase in daily SO2 was associated with an RR of mortality of 1.0045 [95% confidence interval (CI): 1.0019, 1.0070], with the risk being stable over time but with substantial between-country heterogeneity. Short-term exposure to SO2 was associated with an excess mortality fraction of 0.50% [95% empirical CI (eCI): 0.42%, 0.57%] in the 399 cities, although decreasing from 0.74% (0.61%, 0.85%) in 1980–1989 to 0.37% (0.27%, 0.47%) in 2010–2018. There was some evidence of nonlinearity, with a steep exposure–response relationship at low concentrations and the risk attenuating at higher levels. The relevant lag window was 0–3 d. Significant positive associations remained after controlling for other pollutants. Discussion: The analysis revealed independent mortality risks associated with short-term exposure to SO2, with no evidence of a threshold. Levels below the current WHO guidelines for 24-h averages were still associated with substantial excess mortality, indicating the potential benefits of stricter air quality standards. https://doi.org/10.1289/EHP11112\n\n\nsulfur dioxide (so2)daily mortalitymulticountry analysisair pollutiontime-series study\n\n\n\n\n\nde Schrijver E, Royé D, Gasparrini A, Franco O, Vicedo-Cabrera A (2023). Exploring vulnerability to heat and cold across urban and rural populations in Switzerland. Environmental Research: Health, vol. 1(2), art. no. 25003.  10.1088/2752-5309/acab78. \n\n\nHeat- and cold-related mortality risks are highly variable across different geographies, suggesting a differential distribution of vulnerability factors between and within countries, which could partly be driven by urban-to-rural disparities. Identifying these drivers of risk is crucial to characterize local vulnerability and design tailored public health interventions to improve adaptation of populations to climate change. We aimed to assess how heat- and cold-mortality risks change across urban, peri-urban and rural areas in Switzerland and to identify and compare the factors associated with increased vulnerability within and between different area typologies. We estimated the heat- and cold-related mortality association using the case time-series design and distributed lag non-linear models over daily mean temperature and all-cause mortality series between 1990-2017 in each municipality in Switzerland. Then, through multivariate meta-regression, we derived pooled heat and cold-mortality associations by typology (i.e. urban/rural/peri-urban) and assessed potential vulnerability factors among a wealth of demographic, socioeconomic, topographic, climatic, land use and other environmental data. Urban clusters reported larger pooled heat-related mortality risk (at 99th percentile, vs. temperature of minimum mortality (MMT)) (relative risk=1.17(95%CI:1.10;1.24, vs peri-urban 1.03(1.00;1.06), and rural 1.03 (0.99;1.08)), but similar cold-mortality risk (at 1st percentile, vs. MMT) (1.35(1.28;1.43), vs rural 1.28(1.14;1.44) and peri-urban 1.39 (1.27-1.53)) clusters. We found different sets of vulnerability factors explaining the differential risk patterns across typologies. In urban clusters, mainly environmental factors (i.e. PM2.5) drove differences in heat-mortality association, while for peri-urban/rural clusters socio-economic variables were also important. For cold, socio-economic variables drove changes in vulnerability across all typologies, while environmental factors and ageing were other important drivers of larger vulnerability in peri-urban/rural clusters, with heterogeneity in the direction of the association. Our findings suggest that urban populations in Switzerland may be more vulnerable to heat, compared to rural locations, and different sets of vulnerability factors may drive these associations in each typology. Thus, future public health adaptation strategies should consider local and more tailored interventions rather than a one-size fits all approach. size fits all approach.\n\n\nvulnerabilityheatcoldurban-rural differencesswitzerland\n\n\n\n\n\nDíaz-Poso A, Lorenzo N, Royé D (2023). Spatiotemporal evolution of heat waves severity and expansion across the Iberian Peninsula and Balearic islands. Environmental Research, vol. 217, art. no. 114864.  10.1016/j.envres.2022.114864. \n\n\nIn the current climate change scenario, heat waves have become one of the most concerning extreme climatic events, both because of their implications for human health and the economy, and because of their increase in intensity and frequency in recent decades. This work presents for the first time a climatological analysis of heat waves in the Iberian Peninsula and Balearic Archipelago (IPB) using the Excess Heat Factor index (EHF). This index considers the factor of intensity and the acclimatization process of human body in the study of heat waves. We focused on the intensity (also called severity), duration, frequency and spatial extension of heat waves in the IPB in the 1950–2020 period. The exceptional heat wave of August 2018 was approached in a similar way to further explore the usefulness of the EHF index. We found that the EHF index identified heat wave conditions 2 days earlier than indices that used only maximum temperatures. Results showed a significant increase in intensity, duration, frequency and spatial extension of heat waves for the whole IPB for 1950–2020 period. The average extent of heat waves increased by 4.0% per decade and the maximum extent by 4.1% per decade. This trend suggested a significant increase in human exposure, droughts, fire risk and energy demand in this region in the last decades.\n\n\nehfintensityseverityheat waveextentduration\n\n\n\n\n\nAlahmad B, Khraishah H, Royé D, Vicedo-Cabrera A, Guo Y, Papatheodorou S, Achilleos S, Acquaotta F, Armstrong B, Bell M, Pan S, de Sousa Zanotti Stagliorio Coelho M, Colistro V, Dang T, Van Dung D, De’ Donato F, Entezari A, Guo Y, Hashizume M, Honda Y, Indermitte E, Íñiguez C, Jaakkola J, Kim H, Lavigne E, Lee W, Li S, Madureira J, Mayvaneh F, Orru H, Overcenco A, Ragettli M, Ryti N, Saldiva P, Scovronick N, Seposo X, Sera F, Silva S, Stafoggia M, Tobias A, Garshick E, Bernstein A, Zanobetti A, Schwartz J, Gasparrini A, Koutrakis P (2023). Associations Between Extreme Temperatures and Cardiovascular Cause Specific Mortality: Results From 27 Countries. Circulation, vol. 147(1).  10.1161/circulationaha.122.061832. \n\n\nBackground: Cardiovascular disease is the leading cause of death worldwide. Existing studies on the association between temperatures and cardiovascular deaths have been limited in geographic zones and have generally considered associations with total cardiovascular deaths rather than cause-specific cardiovascular deaths. Methods: We used unified data collection protocols within the Multi-Country Multi-City Collaborative Network to assemble a database of daily counts of specific cardiovascular causes of death from 567 cities in 27 countries across 5 continents in overlapping periods ranging from 1979 to 2019. City-specific daily ambient temperatures were obtained from weather stations and climate reanalysis models. To investigate cardiovascular mortality associations with extreme hot and cold temperatures, we fit case-crossover models in each city and then used a mixed-effects meta-analytic framework to pool individual city estimates. Extreme temperature percentiles were compared with the minimum mortality temperature in each location. Excess deaths were calculated for a range of extreme temperature days. Results: The analyses included deaths from any cardiovascular cause (32 154  935), ischemic heart disease (11 745 880), stroke (9 351 312), heart failure (3 673 723), and arrhythmia (670 859). At extreme temperature percentiles, heat (99th percentile) and cold (1st percentile) were associated with higher risk of dying from any cardiovascular cause, ischemic heart disease, stroke, and heart failure as compared to the minimum mortality temperature, which is the temperature associated with least mortality. Across a range of extreme temperatures, hot days (above 97.5th percentile) and cold days (below 2.5th percentile) accounted for 2.2 (95% empirical CI [eCI], 2.1–2.3) and 9.1 (95% eCI, 8.9–9.2) excess deaths for every 1000 cardiovascular deaths, respectively. Heart failure was associated with the highest excess deaths proportion from extreme hot and cold days with 2.6 (95% eCI, 2.4–2.8) and 12.8 (95% eCI, 12.2–13.1) for every 1000 heart failure deaths, respectively. Conclusions: Across a large, multinational sample, exposure to extreme hot and cold temperatures was associated with a greater risk of mortality from multiple common cardiovascular conditions. The intersections between extreme temperatures and cardiovascular health need to be thoroughly characterized in the present day—and especially under a changing climate.\n\n\ncardiovascular mortalityextreme temperaturesheatcoldmulti-country analysis\n\n\n\n\n\nNottmeyer L, Armstrong B, Lowe R, Abbott S, Meakin S, O’Reilly K, von Borries R, Schneider R, Royé D, Hashizume M, Pascal M, Tobias A, Vicedo-Cabrera A, Lavigne E, Correa P, Ortega N, Kynčl J, Urban A, Orru H, Ryti N, Jaakkola J, Dallavalle M, Schneider A, Honda Y, Ng C, Alahmad B, Carrasco-Escobar G, Holobâc I, Kim H, Lee W, Íñiguez C, Bell M, Zanobetti A, Schwartz J, Scovronick N, Coélho M, Saldiva P, Diaz M, Gasparrini A, Sera F (2023). The association of COVID19 incidence with temperature, humidity, and UV radiation – A global multicity analysis. Science of The Total Environment, vol. 854, art. no. 158636.  10.1016/j.scitotenv.2022.158636. \n\n\nBackground and aim. The associations between COVID-19 transmission and meteorological factors are scientifically debated. Several studies have been conducted worldwide, with inconsistent findings. However, often these studies had methodological issues, e.g., did not exclude important confounding factors, or had limited geographic or temporal resolution. Our aim was to quantify associations between temporal variations in COVID-19 incidence and meteorological variables globally. Methods. We analysed data from 455 cities across 20 countries from 3 February to 31 October 2020. We used a time-series analysis that assumes a quasi-Poisson distribution of the cases and incorporates distributed lag non-linear modelling for the exposure associations at the city-level while considering effects of autocorrelation, long-term trends, and day of the week. The confounding by governmental measures was accounted for by incorporating the Oxford Governmental Stringency Index. The effects of daily mean air temperature, relative and absolute humidity, and UV radiation were estimated by applying a meta-regression of local estimates with multi-level random effects for location, country, and climatic zone. Results. We found that air temperature and absolute humidity influenced the spread of COVID-19 over a lag period of 15 days. Pooling the estimates globally showed that overall low temperatures (7.5 °C compared to 17.0 °C) and low absolute humidity (6.0 g/m3 compared to 11.0 g/m3) were associated with higher COVID-19 incidence (RR temp =1.33 with 95%CI: 1.08; 1.64 and RR AH =1.33 with 95%CI: 1.12; 1.57). RH revealed no significant trend and for UV some evidence of a positive association was found. These results were robust to sensitivity analysis. However, the study results also emphasise the heterogeneity of these associations in different countries. Conclusion. Globally, our results suggest that comparatively low temperatures and low absolute humidity were associated with increased risks of COVID-19 incidence. However, this study underlines regional heterogeneity of weather-related effects on COVID-19 transmission.\n\n\ntemperaturehumidityuv radiationcovid-19distributed lag non-linear modellingglobal analysis\n\n\n\n\n2022\n\n\nTobías A, Royé D, Iñiguez C (2022). Heatattributable Mortality in the Summer of 2022 in Spain. Epidemiology, vol. 34(2), pp. e5-e6.  10.1097/ede.0000000000001583. \n\n\nThe article examines heat-attributable mortality during the summer of 2022 in Spain, a period marked by exceptionally high temperatures. Using Poisson regression models with non-linear distributions, deaths attributable to moderate and extreme heat were estimated. In June, July, and August, temperatures exceeded extreme heat thresholds multiple times, resulting in a significant increase in mortality. The study highlights the importance of clearly defining reference scenarios to assess the impact of heat on health and underscores the need for adaptation measures to mitigate the effects of climate change.\n\n\nmortalityextreme heatsummer 2022spaintemperature\n\n\n\n\n\nChoi H, Lee W, Royé D, Heo S, Urban A, Entezari A, Vicedo-Cabrera A, Zanobetti A, Gasparrini A, Analitis A, Tobias A, Armstrong B, Forsberg B, Íñiguez C, Åström C, Indermitte E, Lavigne E, Mayvaneh F, Acquaotta F, Sera F, Orru H, Kim H, Kyselý J, Madueira J, Schwartz J, Jaakkola J, Katsouyanni K, Diaz M, Ragettli M, Pascal M, Ryti N, Scovronick N, Osorio S, Tong S, Seposo X, Guo Y, Guo Y, Bell M (2022). Effect modification of greenness on the association between heat and mortality: A multicity multicountry study. eBioMedicine, vol. 84, art. no. 104251.  10.1016/j.ebiom.2022.104251. \n\n\nBackground. Identifying how greenspace impacts the temperature-mortality relationship in urban environments is crucial, especially given climate change and rapid urbanization. However, the effect modification of greenspace on heat-related mortality has been typically focused on a localized area or single country. This study examined the heat-mortality relationship among different greenspace levels in a global setting. Methods. We collected daily ambient temperature and mortality data for 452 locations in 24 countries and used Enhanced Vegetation Index (EVI) as the greenspace measurement. We used distributed lag non-linear model to estimate the heat-mortality relationship in each city and the estimates were pooled adjusting for city-specific average temperature, city-specific temperature range, city-specific population density, and gross domestic product (GDP). The effect modification of greenspace was evaluated by comparing the heat-related mortality risk for different greenspace groups (low, medium, and high), which were divided into terciles among 452 locations. Findings. Cities with high greenspace value had the lowest heat-mortality relative risk of 1·19 (95% CI: 1·13, 1·25), while the heat-related relative risk was 1·46 (95% CI: 1·31, 1·62) for cities with low greenspace when comparing the 99th temperature and the minimum mortality temperature. A 20% increase of greenspace is associated with a 9·02% (95% CI: 8·88, 9·16) decrease in the heat-related attributable fraction, and if this association is causal (which is not within the scope of this study to assess), such a reduction could save approximately 933 excess deaths per year in 24 countries. Interpretation. Our findings can inform communities on the potential health benefits of greenspaces in the urban environment and mitigation measures regarding the impacts of climate change.\n\n\ngreen spacesheat mortalityurbanizationclimate changepublic health\n\n\n\n\n\nWu Y, Li S, Zhao Q, Wen B, Gasparrini A, Tong S, Overcenco A, Urban A, Schneider A, Entezari A, Vicedo-Cabrera A, Zanobetti A, Analitis A, Zeka A, Tobias A, Nunes B, Alahmad B, Armstrong B, Forsberg B, Pan S, Íñiguez C, Ameling C, De la Cruz Valencia C, Åström C, Houthuijs D, Van Dung D, Royé D, Indermitte E, Lavigne E, Mayvaneh F, Acquaotta F, de’Donato F, Rao S, Sera F, Carrasco-Escobar G, Kan H, Orru H, Kim H, Holobaca I, Kyselý J, Madureira J, Schwartz J, Jaakkola J, Katsouyanni K, Hurtado Diaz M, Ragettli M, Hashizume M, Pascal M, de Sousa Zanotti Stagliorio Coélho M, Ortega N, Ryti N, Scovronick N, Michelozzi P, Correa P, Goodman P, Nascimento Saldiva P, Abrutzky R, Osorio S, Dang T, Colistro V, Huber V, Lee W, Seposo X, Honda Y, Guo Y, Bell M, Guo Y (2022). Global, regional, and national burden of mortality associated with shortterm temperature variability from 2000–19: a threestage modelling study. The Lancet Planetary Health, vol. 6(5), pp. e410-e421.  10.1016/S2542-5196(22)00073-0. \n\n\nBackground. Increased mortality risk is associated with short-term temperature variability. However, to our knowledge, there has been no comprehensive assessment of the temperature variability-related mortality burden worldwide. In this study, using data from the MCC Collaborative Research Network, we first explored the association between temperature variability and mortality across 43 countries or regions. Then, to provide a more comprehensive picture of the global burden of mortality associated with temperature variability, global gridded temperature data with a resolution of 0·5° × 0·5° were used to assess the temperature variability-related mortality burden at the global, regional, and national levels. Furthermore, temporal trends in temperature variability-related mortality burden were also explored from 2000–19. Methods. In this modelling study, we applied a three-stage meta-analytical approach to assess the global temperature variability-related mortality burden at a spatial resolution of 0·5° × 0·5° from 2000–19. Temperature variability was calculated as the SD of the average of the same and previous days’ minimum and maximum temperatures. We first obtained location-specific temperature variability related-mortality associations based on a daily time series of 750 locations from the Multi-country Multi-city Collaborative Research Network. We subsequently constructed a multivariable meta-regression model with five predictors to estimate grid-specific temperature variability related-mortality associations across the globe. Finally, percentage excess in mortality and excess mortality rate were calculated to quantify the temperature variability-related mortality burden and to further explore its temporal trend over two decades. Findings. An increasing trend in temperature variability was identified at the global level from 2000 to 2019. Globally, 1 753 392 deaths (95% CI 1 159 901–2 357 718) were associated with temperature variability per year, accounting for 3·4% (2·2–4·6) of all deaths. Most of Asia, Australia, and New Zealand were observed to have a higher percentage excess in mortality than the global mean. Globally, the percentage excess in mortality increased by about 4·6% (3·7–5·3) per decade. The largest increase occurred in Australia and New Zealand (7·3%, 95% CI 4·3–10·4), followed by Europe (4·4%, 2·2–5·6) and Africa (3·3, 1·9–4·6). Interpretation. Globally, a substantial mortality burden was associated with temperature variability, showing geographical heterogeneity and a slightly increasing temporal trend. Our findings could assist in raising public awareness and improving the understanding of the health impacts of temperature variability.\n\n\nmortality burdentemperature variabilityclimate changeglobal analysispublic health\n\n\n\n\n\nTedim F, Leone V, Lovreglio R, Xanthopoulos G, Chas-Amil M, Ganteaume A, Efe R, Royé D, Fuerst-Bjeliš B, Nikolov N, Musa S, Milenković M, Correia F, Conedera M, Boris Pezzatti G (2022). Forest Fire Causes and Motivations in the Southern and South Eastern Europe through Experts’ Perception and Applications to Current Policies. Forests, vol. 13(4), art. no. 562.  10.3390/f13040562. \n\n\nForest fires causes and motivations are poorly understood in southern and south-eastern Europe. This research aims to identify how experts perceive the different causes of forest fires as defined in the classification proposed by the European Commission in 2013. A panel of experts (N = 271) was gathered from the EU Southern Member States (France, Greece, Italy, Portugal, and Spain) and from Central (Switzerland) and south-eastern Europe (Croatia, Serbia, Bosnia and Herzegovina, Republic of North Macedonia, and Turkey). Experts were asked to answer a questionnaire to score the importance of the 29 fire causes using a five point (1–5) Likert Scale. Agricultural burnings received the highest score, followed by Deliberate fire for profit, and Vegetation management. Most of the events stem from Negligence, whereas malicious fire setting is arguably overestimated although there are differences among the countries. This research demonstrates the importance of different techniques to enhance the knowledge of the causes of the complex anthropogenic phenomenon of forest fire occurrence.\n\n\ndelphi methodeffisforest fire causesforest fire motivationslikert scaleanthropogenic causes\n\n\n\n\n\nMistry M, Schneider R, Masselot P, Royé D, Armstrong B, Kyselý J, Orru H, Sera F, Tong S, Lavigne É, Urban A, Madureira J, García-León D, Ibarreta D, Ciscar J, Feyen L, de Schrijver E, de Sousa Zanotti Stagliorio Coelho M, Pascal M, Tobias A, Alahmad B, Abrutzky R, Saldiva P, Correa P, Orteg N, Kan H, Osorio S, Indermitte E, Jaakkola J, Ryti N, Schneider A, Huber V, Katsouyanni K, Analitis A, Entezari A, Mayvaneh F, Michelozzi P, de’Donato F, Hashizume M, Kim Y, Diaz M, De la Cruz Valencia C, Overcenco A, Houthuijs D, Ameling C, Rao S, Seposo X, Nunes B, Holobaca I, Kim H, Lee W, Íñiguez C, Forsberg B, Åström C, Ragettli M, Guo Y, Chen B, Colistro V, Zanobetti A, Schwartz J, Dang T, Van Dung D, Guo Y, Vicedo-Cabrera A, Gasparrini A (2022). Comparison of weather station and climate reanalysis data for modelling temperaturerelated mortality. Scientific Reports, vol. 12, art. no. 5178.  10.1038/s41598-022-09049-4. \n\n\nEpidemiological analyses of health risks associated with non-optimal temperature are traditionally based on ground observations from weather stations that offer limited spatial and temporal coverage. Climate reanalysis represents an alternative option that provide complete spatio-temporal exposure coverage, and yet are to be systematically explored for their suitability in assessing temperature-related health risks at a global scale. Here we provide the first comprehensive analysis over multiple regions to assess the suitability of the most recent generation of reanalysis datasets for health impact assessments and evaluate their comparative performance against traditional station-based data. Our findings show that reanalysis temperature from the last ERA5 products generally compare well to station observations, with similar non-optimal temperature-related risk estimates. However, the analysis offers some indication of lower performance in tropical regions, with a likely underestimation of heat-related excess mortality. Reanalysis data represent a valid alternative source of exposure variables in epidemiological analyses of temperature-related risk.\n\n\ntemperature-related mortalityweather stationsclimate reanalysishealth impact assessmentdata comparison\n\n\n\n\n\nWu Y, Wen B, Li S, Gasparrini A, Tong S, Overcenco A, Urban A, Schneider A, Entezari A, Vicedo-Cabrera A, Zanobetti A, Analitis A, Zeka A, Tobias A, Alahmad B, Armstrong B, Forsberg B, Íñiguez C, Ameling C, De la Cruz Valencia C, Åström C, Houthuijs D, Van Dung D, Royé D, Indermitte E, Lavigne E, Mayvaneh F, Acquaotta F, de’Donato F, Sera F, Carrasco-Escobar G, Kan H, Orru H, Kim H, Holobaca I, Kyselý J, Madureira J, Schwartz J, Katsouyanni K, Hurtado-Diaz M, Ragettli M, Hashizume M, Pascal M, de Sousa Zanotti Stagliorio Coélho M, Scovronick N, Michelozzi P, Goodman P, Nascimento Saldiva P, Abrutzky R, Osorio S, Dang T, Colistro V, Huber V, Lee W, Seposo X, Honda Y, Bell M, Guo Y (2022). Fluctuating temperature modifies heatmortality association around the globe. The Innovation, vol. 3(2), art. no. 100225.  10.1016/j.xinn.2022.100225. \n\n\nStudies have investigated the effects of heat and temperature variability (TV) on mortality. However, few assessed whether TV modifies the heat-mortality association. Data on daily temperature and mortality in the warm season were collected from 717 locations across 36 countries. TV was calculated as the standard deviation of the average of the same and previous days’ minimum and maximum temperatures. We used location-specific quasi-Poisson regression models with an interaction term between the cross-basis term for mean temperature and quartiles of TV to obtain heat-mortality associations under each quartile of TV, and then pooled estimates at the country, regional, and global levels. Results show the increased risk in heat-related mortality with increments in TV, accounting for 0.70% (95% confidence interval [CI]: −0.33 to 1.69), 1.34% (95% CI: −0.14 to 2.73), 1.99% (95% CI: 0.29–3.57), and 2.73% (95% CI: 0.76–4.50) of total deaths for Q1–Q4 (first quartile–fourth quartile) of TV. The modification effects of TV varied geographically. Central Europe had the highest attributable fractions (AFs), corresponding to 7.68% (95% CI: 5.25–9.89) of total deaths for Q4 of TV, while the lowest AFs were observed in North America, with the values for Q4 of 1.74% (95% CI: −0.09 to 3.39). TV had a significant modification effect on the heat-mortality association, causing a higher heat-related mortality burden with increments of TV. Implementing targeted strategies against heat exposure and fluctuant temperatures simultaneously would benefit public health.\n\n\ntemperature variabilityheatmodification effectmortality\n\n\n\n\n2021\n\n\nRoyé D, Tobías A, Figueiras A, Gestal S, Taracido M, Santurtun A, Iñiguez C (2021). Temperature related effects on respiratory medical prescriptions in Spain. Environmental Research, vol. 202, art. no. 111695.  10.1016/j.envres.2021.111695. \n\n\nBackground. The increased risk of mortality during periods of high and low temperatures has been well established. However, most of the studies used daily counts of deaths or hospitalisations as health outcomes, although they are the ones at the top of the health impact pyramid reflecting only a limited proportion of patients with the most severe cases. Objectives. This study evaluates the relationship between short-term exposure to the daily mean temperature and medication prescribed for the respiratory system in five Spanish cities. Methods. We fitted time series regression models to cause-specific medical prescriptions, including different respiratory subgroups and age groups. We included a distributed lag non-linear model with lags up to 14 days for daily mean temperature. City-specific associations were summarised as overall-cumulative exposure-response curves. Results. We found a positive association between cause-specific medical prescriptions and daily mean temperature with a non-linear inverted J- or V-shaped relationship in most cities. Between 0.3% and 0.6% of all respiratory prescriptions were attributed to cold for Madrid, Zaragoza and Pamplona, while in cities with only cold effects the attributable fractions were estimated as 19.2% for Murcia and 13.5% for Santander. Heat effects in Madrid, Zaragoza and Pamplona showed higher fractions between 8.7% and 17.2%. The estimated costs are in general higher for heat effects, showing annual values ranging between €191,905 and €311,076 for heat per 100,000 persons. Conclusions. This study provides novel evidence of the effects of the thermal environment on the prescription of medication for respiratory disorders in Spain, showing that low and high temperatures lead to an increase in the number of such prescriptions. The consumption of medication can reflect exposure to the environment with a lesser degree of severity in terms of morbidity.\n\n\nmedical prescriptionstemperaturerespiratoryexposurespaindrugs\n\n\n\n\n\nSera F, Armstrong B, Abbott S, Meakin S, O’Reilly K, von Borries R, Schneider R, Royé D, Hashizume M, Pascal M, Tobias A, Vicedo-Cabrera A, Hu W, Tong S, Lavigne E, Correa P, Meng X, Kan H, Kynčl J, Urban A, Orru H, Ryti N, Jaakkola J, Cauchemez S, Dallavalle M, Schneider A, Zeka A, Honda Y, Ng C, Alahmad B, Rao S, Di Ruscio F, Carrasco-Escobar G, Seposo X, Holobâcă I, Kim H, Lee W, Íñiguez C, Ragettli M, Aleman A, Colistro V, Bell M, Zanobetti A, Schwartz J, Dang T, Scovronick N, de Sousa Zanotti Stagliorio Coélho M, Diaz M, Zhang Y, Russell T, Koltai M, Kucharski A, Barnard R, Quaife M, Jarvis C, Lei J, Munday J, Chan Y, Quilty B, Eggo R, Flasche S, Foss A, Clifford S, Tully D, Edmunds W, Klepac P, Brady O, Krauer F, Procter S, Jombart T, Rosello A, Showering A, Funk S, Hellewell J, Sun F, Endo A, Williams J, Gimma A, Waterlow N, Prem K, Bosse N, Gibbs H, Atkins K, Pearson C, Jafari Y, Villabona-Arenas C, Jit M, Nightingale E, Davies N, van Zandvoort K, Liu Y, Sandmann F, Waites W, Abbas K, Medley G, Knight G, Gasparrini A, Lowe R (2021). A crosssectional analysis of meteorological factors and SARSCoV2 transmission in 409 cities across 26 countries. Nature Communications, vol. 12, art. no. 5968.  10.1038/s41467-021-25914-8. \n\n\nThere is conflicting evidence on the influence of weather on COVID-19 transmission. Our aim is to estimate weather-dependent signatures in the early phase of the pandemic, while controlling for socio-economic factors and non-pharmaceutical interventions. We identify a modest non-linear association between mean temperature and the effective reproduction number (Re) in 409 cities in 26 countries, with a decrease of 0.087 (95% CI: 0.025; 0.148) for a 10 °C increase. Early interventions have a greater effect on Re with a decrease of 0.285 (95% CI 0.223; 0.347) for a 5th - 95th percentile increase in the government response index. The variation in the effective reproduction number explained by government interventions is 6 times greater than for mean temperature. We find little evidence of meteorological conditions having influenced the early stages of local epidemics and conclude that population behaviour and government interventions are more important drivers of transmission.\n\n\nsars-cov-2 transmissionmeteorological factorstemperaturenon-pharmaceutical interventionsglobal analysis\n\n\n\n\n\nTobías A, Hashizume M, Honda Y, Sera F, Ng C, Kim Y, Royé D, Chung Y, Dang T, Kim H, Lee W, Íñiguez C, Vicedo-Cabrera A, Abrutzky R, Guo Y, Tong S, Coelho M, Saldiva P, Lavigne E, Correa P, Ortega N, Kan H, Osorio S, Kyselý J, Urban A, Orru H, Indermitte E, Jaakkola J, Ryti N, Pascal M, Huber V, Schneider A, Katsouyanni K, Analitis A, Entezari A, Mayvaneh F, Goodman P, Zeka A, Michelozzi P, de’Donato F, Alahmad B, Diaz M, De la Cruz Valencia C, Overcenco A, Houthuijs D, Ameling C, Rao S, Di Ruscio F, Carrasco G, Seposo X, Nunes B, Madureira J, Holobaca I, Scovronick N, Acquaotta F, Forsberg B, Åström C, Ragettli M, Guo Y, Chen B, Li S, Colistro V, Zanobetti A, Schwartz J, Dung D, Armstrong B, Gasparrini A (2021). Geographical Variations of the Minimum Mortality Temperature at a Global Scale. Environmental Epidemiology, vol. 5(5), art. no. e169.  10.1097/EE9.0000000000000169. \n\n\nBackground: Minimum mortality temperature (MMT) is an important indicator to assess the temperature-mortality association, indicating long-term adaptation to local climate. Limited evidence about the geographical variability of the MMT is available at a global scale. Methods: We collected data from 658 communities in 43 countries under different climates. We estimated temperature-mortality associations to derive the MMT for each community using Poisson regression with distributed lag nonlinear models. We investigated the variation in MMT by climatic zone using a mixed-effects meta-analysis and explored the association with climatic and socioeconomic indicators. Results: The geographical distribution of MMTs varied considerably by country between 14.2 and 31.1 °C decreasing by latitude. For climatic zones, the MMTs increased from alpine (13.0 °C) to continental (19.3 °C), temperate (21.7 °C), arid (24.5 °C), and tropical (26.5 °C). The MMT percentiles (MMTPs) corresponding to the MMTs decreased from temperate (79.5th) to continental (75.4th), arid (68.0th), tropical (58.5th), and alpine (41.4th). The MMTs indreased by 0.8 °C for a 1 °C rise in a community’s annual mean temperature, and by 1 °C for a 1 °C rise in its SD. While the MMTP decreased by 0.3 centile points for a 1 °C rise in a community’s annual mean temperature and by 1.3 for a 1 °C rise in its SD. Conclusions: The geographical distribution of the MMTs and MMTPs is driven mainly by the mean annual temperature, which seems to be a valuable indicator of overall adaptation across populations. Our results suggest that populations have adapted to the average temperature, although there is still more room for adaptation.\n\n\nadaptationclimatedistributed lag nonlinear modelsminimum mortality temperaturemulti-citymulti-countrytime-series\n\n\n\n\n\nChen G, Guo Y, Yue X, Tong S, Gasparrini A, Bell M, Armstrong B, Schwartz J, Jaakkola J, Zanobetti A, Lavigne E, Nascimento Saldiva P, Kan H, Royé D, Milojevic A, Overcenco A, Urban A, Schneider A, Entezari A, Vicedo-Cabrera A, Zeka A, Tobias A, Nunes B, Alahmad B, Forsberg B, Pan S, Íñiguez C, Ameling C, De la Cruz Valencia C, Åström C, Houthuijs D, Van Dung D, Samoli E, Mayvaneh F, Sera F, Carrasco-Escobar G, Lei Y, Orru H, Kim H, Holobaca I, Kyselý J, Teixeira J, Madureira J, Katsouyanni K, Hurtado-Díaz M, Maasikmets M, Ragettli M, Hashizume M, Stafoggia M, Pascal M, Scortichini M, de Sousa Zanotti Stagliorio Coêlho M, Valdés Ortega N, Ryti N, Scovronick N, Matus P, Goodman P, Garland R, Abrutzky R, Garcia S, Rao S, Fratianni S, Dang T, Colistro V, Huber V, Lee W, Seposo X, Honda Y, Guo Y, Ye T, Yu W, Abramson M, Samet J, Li S (2021). Mortality risk attributable to wildfire related PM2·5 pollution: a global time series study in 749 locations. The Lancet Planetary Health, vol. 5(9), pp. e579-e587.  10.1016/S2542-5196(21)00200-X. \n\n\nackground. Many regions of the world are now facing more frequent and unprecedentedly large wildfires. However, the association between wildfire-related PM2·5 and mortality has not been well characterised. We aimed to comprehensively assess the association between short-term exposure to wildfire-related PM2·5 and mortality across various regions of the world. Methods. For this time series study, data on daily counts of deaths for all causes, cardiovascular causes, and respiratory causes were collected from 749 cities in 43 countries and regions during 2000–16. Daily concentrations of wildfire-related PM2·5 were estimated using the three-dimensional chemical transport model GEOS-Chem at a 0·25° × 0·25° resolution. The association between wildfire-related PM2·5 exposure and mortality was examined using a quasi-Poisson time series model in each city considering both the current-day and lag effects, and the effect estimates were then pooled using a random-effects meta-analysis. Based on these pooled effect estimates, the population attributable fraction and relative risk (RR) of annual mortality due to acute wildfire-related PM2·5 exposure was calculated. Findings. 65·6 million all-cause deaths, 15·1 million cardiovascular deaths, and 6·8 million respiratory deaths were included in our analyses. The pooled RRs of mortality associated with each 10 μg/m3 increase in the 3-day moving average (lag 0–2 days) of wildfire-related PM2·5 exposure were 1·019 (95% CI 1·016–1·022) for all-cause mortality, 1·017 (1·012–1·021) for cardiovascular mortality, and 1·019 (1·013–1·025) for respiratory mortality. Overall, 0·62% (95% CI 0·48–0·75) of all-cause deaths, 0·55% (0·43–0·67) of cardiovascular deaths, and 0·64% (0·50–0·78) of respiratory deaths were annually attributable to the acute impacts of wildfire-related PM2·5 exposure during the study period. Interpretation. Short-term exposure to wildfire-related PM2·5 was associated with increased risk of mortality. Urgent action is needed to reduce health risks from the increasing wildfires.\n\n\nwildfire-related pm2.5mortality riskglobal analysiscardiovascular mortality respiratory mortality\n\n\n\n\n\nLorenzo N, Díaz-Poso A, Royé D (2021). Heatwave intensity on the Iberian Peninsula: Future climate projections. Atmospheric Research, vol. 258(15), art. no. 105655.  10.1016/j.atmosres.2021.105655. \n\n\nHeatwaves are the most relevant extreme climatic events, particularly in the context of global warming and the related increasing impacts on society and the natural environment. This work presents an analysis of climate change scenarios with simulations from the EURO-CORDEX project using the excess heat factor over the Iberian Peninsula. We focus on climate change projections of the heatwave intensity and spatial distribution, which are evaluated for the near future (2021–2050) relative to a reference past climate (1971–2000). Heatwave projections show a general significant increase in intensity, frequency, duration and spatial extent for the whole region. The average change in heatwave intensity is 104% for the whole Iberian Peninsula for the near future 2021–2050. The largest changes occur in the eastern-central region, rising to 150% for the Mediterranean coast and the Pyrenees. The greater spatial extent of heatwaves strongly suggests increased human exposure, increased energy demand, and implications for fire risk. This spatial trend is predicted to continue in the near future with increases in the maximum spatial heatwave extent ranging from 6% to 8% per decade.\n\n\nheatwavesclimate changeiberian peninsulatemperature projectionsextreme weather\n\n\n\n\n\nMathbout S, Lopez-Bustins J, Royé D, Martin-Vide J (2021). Mediterranean Scale Drought: Regional Datasets for Exceptional Meteorological Drought Events during 1975–2019. Atmosphere, vol. 12(8), art. no. 941.  10.3390/atmos12080941. \n\n\nDrought is one of the most complex climate-related phenomena and is expected to progressively affect our lives by causing very serious environmental and socioeconomic damage by the end of the 21st century. In this study, we have extracted a dataset of exceptional meteorological drought events between 1975 and 2019 at the country and subregional scales. Each drought event was described by its start and end date, intensity, severity, duration, areal extent, peak month and peak area. To define such drought events and their characteristics, separate analyses based on three drought indices were performed at 12-month timescale: the Standardized Precipitation Index (SPI), the Standardized Precipitation Evapotranspiration Index (SPEI), and the Reconnaissance Drought Index (RDI). A multivariate combined drought index (DXI) was developed by merging the previous three indices for more understanding of droughts’ features at the country and subregional levels. Principal component analysis (PCA) was used to identify five different drought subregions based on DXI-12 values for 312 Mediterranean stations and a new special score was defined to classify the multi-subregional exceptional drought events across the Mediterranean Basin (MED). The results indicated that extensive drought events occurred more frequently since the late 1990s, showing several drought hotspots in the last decades in the southeastern Mediterranean and northwest Africa. In addition, the results showed that the most severe events were more detected when more than single drought index was used. The highest percentage area under drought was also observed through combining the variations of three drought indices. Furthermore, the drought area in both dry and humid areas in the MED has also experienced a remarkable increase since the late 1990s. Based on a comparison of the drought events during the two periods—1975–1996 and 1997–2019—we find that the current dry conditions in the MED are more severe, intense, and frequent than the earlier period; moreover, the strongest dry conditions occurred in last two decades. The SPEI-12 and RDI-12 have a higher capacity in providing a more comprehensive description of the dry conditions because of the inclusion of temperature or atmospheric evaporative demand in their scheme. A complex range of atmospheric circulation patterns, particularly the Western Mediterranean Oscillation (WeMO) and East Atlantic/West Russia (EATL/WRUS), appear to play an important role in severe, intense and region-wide droughts, including the two most severe droughts, 1999–2001 and 2007–2012, with lesser influence of the NAO, ULMO and SCAND.\n\n\nclimate changedrought eventmediterranean basinmeteorological droughtspeispirdidxi\n\n\n\n\n\nMartí Ezpeleta A, Royé D (2021). Intensidad y duración del estrés térmico en verano en el área urbana de Madrid. Geographicalia, vol. 73.  10.26754/ojs_geoph/geoph.2021735202. \n\n\nEn este trabajo se aplica una metodología nueva al estudio de las noches calurosas, también denominadas “tropicales”, en el área metropolitana de Madrid, de cara a evaluar desde una perspectiva temporal y espacial aquellas noches en las que la población pueda verse afectada por estrés térmico. La utilización de dos indicadores obtenidos a través de datos horarios, junto a la información climática suministrada por el modelo UrbClim, ha permitido conocer a una escala de detalle las características térmicas de las noches del mes de julio entre 2008 y 2017, pudiendo así evaluar con más precisión el riesgo para el bienestar y la salud de la población. Los resultados muestran una gran variabilidad interurbana en cuanto a intensidad y duración del estrés térmico, así como una correlación significativa entre las intensidades de la isla de calor y los índices de exceso de calor. Asimismo se ha comprobado la existencia de una estrecha relación entre las tipologías de usos del suelo y estructuras urbanas definidas en el Urban Atlas, y los índices de exceso de calor nocturno.\n\n\nnoche calurosaestrés térmicoisla de calorurbclimmadrid\n\n\n\n\n\nZhao Q, Guo Y, Ye T, Gasparrini A, Tong S, Overcenco A, Urban A, Schneider A, Entezari A, Vicedo-Cabrera A, Zanobetti A, Analitis A, Zeka A, Tobias A, Nunes B, Alahmad B, Armstrong B, Forsberg B, Pan S, Íñiguez C, Ameling C, De la Cruz Valencia C, Åström C, Houthuijs D, Dung D, Royé D, Indermitte E, Lavigne E, Mayvaneh F, Acquaotta F, de’Donato F, Di Ruscio F, Sera F, Carrasco-Escobar G, Kan H, Orru H, Kim H, Holobaca I, Kyselý J, Madureira J, Schwartz J, Jaakkola J, Katsouyanni K, Hurtado Diaz M, Ragettli M, Hashizume M, Pascal M, de Sousa Zanotti Stagliorio Coélho M, Valdés Ortega N, Ryti N, Scovronick N, Michelozzi P, Matus Correa P, Goodman P, Nascimento Saldiva P, Abrutzky R, Osorio S, Rao S, Fratianni S, Dang T, Colistro V, Huber V, Lee W, Seposo X, Honda Y, Guo Y, Bell M, Li S (2021). Global, regional, and national burden of mortality associated with nonoptimal ambient temperatures from 2000 to 2019: a threestage modelling study. The Lancet Planetary Health, vol. 5(7), pp. e415-e425.  10.1016/S2542-5196(21)00081-4. \n\n\nBackground. Exposure to cold or hot temperatures is associated with premature deaths. We aimed to evaluate the global, regional, and national mortality burden associated with non-optimal ambient temperatures. Methods. In this modelling study, we collected time-series data on mortality and ambient temperatures from 750 locations in 43 countries and five meta-predictors at a grid size of 0·5° × 0·5° across the globe. A three-stage analysis strategy was used. First, the temperature–mortality association was fitted for each location by use of a time-series regression. Second, a multivariate meta-regression model was built between location-specific estimates and meta-predictors. Finally, the grid-specific temperature–mortality association between 2000 and 2019 was predicted by use of the fitted meta-regression and the grid-specific meta-predictors. Excess deaths due to non-optimal temperatures, the ratio between annual excess deaths and all deaths of a year (the excess death ratio), and the death rate per 100 000 residents were then calculated for each grid across the world. Grids were divided according to regional groupings of the UN Statistics Division. Findings. Globally, 5 083 173 deaths (95% empirical CI [eCI] 4 087 967–5 965 520) were associated with non-optimal temperatures per year, accounting for 9·43% (95% eCI 7·58–11·07) of all deaths (8·52% [6·19–10·47] were cold-related and 0·91% [0·56–1·36] were heat-related). There were 74 temperature-related excess deaths per 100 000 residents (95% eCI 60–87). The mortality burden varied geographically. Of all excess deaths, 2 617 322 (51·49%) occurred in Asia. Eastern Europe had the highest heat-related excess death rate and Sub-Saharan Africa had the highest cold-related excess death rate. From 2000–03 to 2016–19, the global cold-related excess death ratio changed by −0·51 percentage points (95% eCI −0·61 to −0·42) and the global heat-related excess death ratio increased by 0·21 percentage points (0·13–0·31), leading to a net reduction in the overall ratio. The largest decline in overall excess death ratio occurred in South-eastern Asia, whereas excess death ratio fluctuated in Southern Asia and Europe. Interpretation. Non-optimal temperatures are associated with a substantial mortality burden, which varies spatiotemporally. Our findings will benefit international, national, and local communities in developing preparedness and prevention strategies to reduce weather-related impacts immediately and under climate change scenarios.\n\n\nmortality burdennon-optimal temperaturesclimate changeglobal analysis public health\n\n\n\n\n\nWright B, Laffineur B, Royé D, Armstrong G, Fensham R (2021). Rainfall Linked Megafires as Innate Fire Regime Elements in Arid Australian Spinifex (Triodia spp.) Grasslands. Frontiers in Ecology and Evolution, vol. 9.  10.3389/fevo.2021.666241. \n\n\nLarge, high-severity wildfires, or “megafires,” occur periodically in arid Australian spinifex (Triodia spp.) grasslands after high rainfall periods that trigger fuel accumulation. Proponents of the patch-burn mosaic (PBM) hypothesis suggest that these fires are unprecedented in the modern era and were formerly constrained by Aboriginal patch burning that kept landscape fuel levels low. This assumption deserves scrutiny, as evidence from fire-prone systems globally indicates that weather factors are the primary determinant behind megafire incidence, and that fuel management does not mitigate such fires during periods of climatic extreme. We reviewed explorer’s diaries, anthropologist’s reports, and remotely sensed data from the Australian Western Desert for evidence of large rainfall-linked fires during the pre-contact period when traditional Aboriginal patch burning was still being practiced. We used only observations that contained empiric estimates of fire sizes. Concurrently, we employed remote rainfall data and the Oceanic Niño Index to relate fire size to likely seasonal conditions at the time the observations were made. Numerous records were found of small fires during periods of average and below-average rainfall conditions, but no evidence of large-scale fires during these times. By contrast, there was strong evidence of large-scale wildfires during a high-rainfall period in the early 1870s, some of which are estimated to have burnt areas up to 700,000 ha. Our literature review also identified several Western Desert Aboriginal mythologies that refer to large-scale conflagrations. As oral traditions sometimes corroborate historic events, these myths may add further evidence that large fires are an inherent feature of spinifex grassland fire regimes. Overall, the results suggest that, contrary to predictions of the PBM hypothesis, traditional Aboriginal burning did not modulate spinifex fire size during periods of extreme-high arid zone rainfall. The mechanism behind this is that plant assemblages in seral spinifex vegetation comprise highly flammable non-spinifex tussock grasses that rapidly accumulate high fuel loads under favorable precipitation conditions. Our finding that fuel management does not prevent megafires under extreme conditions in arid Australia has parallels with the primacy of climatic factors as drivers of megafires in the forests of temperate Australia.\n\n\nmegafiresrainfallspinifex grasslandsfire regimesaboriginal burning\n\n\n\n\n\nVicedo-Cabrera A M, Scovronick N, Sera F, Royé D, Schneider R, Tobias A, Astrom C, Guo Y, Honda Y, Hondula D M, Abrutzky R, Tong S, Coelho M de Sousa Zanotti Stagliorio, Saldiva P H Nascimento, Lavigne E, Correa P Matus, Ortega N Valdes, Kan H, Osorio S, Kyselý J, Urban A, Orru H, Indermitte E, Jaakkola J J K, Ryti N, Pascal M, Schneider A, Katsouyanni K, Samoli E, Mayvaneh F, Entezari A, Goodman P, Zeka A, Michelozzi P, de’Donato F, Hashizume M, Alahmad B, Diaz M Hurtado, Valencia C De La Cruz, Overcenco A, Houthuijs D, Ameling C, Rao S, Di Ruscio F, Carrasco-Escobar G, Seposo X, Silva S, Madureira J, Holobaca I H, Fratianni S, Acquaotta F, Kim H, Lee W, Iniguez C, Forsberg B, Ragettli M S, Guo Y L L, Chen B Y, Li S, Armstrong B, Aleman A, Zanobetti A, Schwartz J, Dang T N, Dung D V, Gillett N, Haines A, Mengel M, Huber V, Gasparrini A (2021). The burden of heatrelated mortality attributable to recent humaninduced climate change. Nature Climate Change, vol. 11, pp. 492-500.  10.1038/s41558-021-01058-x. \n\n\nClimate change affects human health; however, there have been no large-scale, systematic efforts to quantify the heat-related human health impacts that have already occurred due to climate change. Here, we use empirical data from 732 locations in 43 countries to estimate the mortality burdens associated with the additional heat exposure that has resulted from recent human-induced warming, during the period 1991–2018. Across all study countries, we find that 37.0% (range 20.5–76.3%) of warm-season heat-related deaths can be attributed to anthropogenic climate change and that increased mortality is evident on every continent. Burdens varied geographically but were of the order of dozens to hundreds of deaths per year in many locations. Our findings support the urgent need for more ambitious mitigation and adaptation strategies to minimize the public health impacts of climate change.\n\n\nheat-related mortalityclimate changeanthropogenic warmingglobal analysispublic health\n\n\n\n\n\nde Schrijver E, Folly C, Schneider R, Royé D, Franco O, Gasparrini A, Vicedo‐Cabrera A (2021). A Comparative Analysis of the Temperature‐Mortality Risks Using Different Weather Datasets Across Heterogeneous Regions. GeoHealth, vol. 5(5).  10.1029/2020GH000363. \n\n\nNew gridded climate datasets (GCDs) on spatially resolved modeled weather data have recently been released to explore the impacts of climate change. GCDs have been suggested as potential alternatives to weather station data in epidemiological assessments on health impacts of temperature and climate change. These can be particularly useful for assessment in regions that have remained understudied due to limited or low quality weather station data. However to date, no study has critically evaluated the application of GCDs of variable spatial resolution in temperature-mortality assessments across regions of different orography, climate, and size. Here we explored the performance of population-weighted daily mean temperature data from the global ERA5 reanalysis dataset in the 10 regions in the United Kingdom and the 26 cantons in Switzerland, combined with two local high-resolution GCDs (HadUK-grid UKPOC-9 and MeteoSwiss-grid-product, respectively) and compared these to weather station data and unweighted homologous series. We applied quasi-Poisson time series regression with distributed lag nonlinear models to obtain the GCD- and region-specific temperature-mortality associations and calculated the corresponding cold- and heat-related excess mortality. Although the five exposure datasets yielded different average area-level temperature estimates, these deviations did not result in substantial variations in the temperature-mortality association or impacts. Moreover, local population-weighted GCDs showed better overall performance, suggesting that they could be excellent alternatives to help advance knowledge on climate change impacts in remote regions with large climate and population distribution variability, which has remained largely unexplored in present literature due to the lack of reliable exposure data.\n\n\ntemperature-related mortalityweather datasetsheterogeneous regionsclimate datahealth impact assessment \n\n\n\n\n\nRoyé D, Sera F, Tobías A, Lowe R, Gasparrini A, Pascal M, de’Donato F, Nunes B, Teixeira J (2021). Effects of Hot Nights on Mortality in Southern Europe. Epidemiology, vol. 32(4), pp. 487-498.  10.1097/ede.0000000000001359. \n\n\nBackground: There is strong evidence concerning the impact of heat stress on mortality, particularly from high temperatures. However, few studies to our knowledge emphasize the importance of hot nights, which may prevent necessary nocturnal rest. Objectives: In this study, we use hot-night duration and excess to predict daily cause-specific mortality in summer, using multiple cities across Southern Europe. Methods: We fitted time series regression models to summer cause-specific mortality, including natural, respiratory, and cardiovascular causes, in 11 cities across four countries. We included a distributed lag nonlinear model with lags up to 7 days for hot night duration and excess adjusted by daily mean temperature. We summarized city-specific associations as overall-cumulative exposure–response curves at the country level using meta-analysis. Results: We found positive but generally nonlinear associations between relative risk (RR) of cause-specific mortality and duration and excess of hot nights. RR of duration associated with nonaccidental mortality in Portugal was 1.29 (95% confidence interval [CI] = 1.07, 1.54); other associations were imprecise, but we also found positive city-specific estimates for Rome and Madrid. Risk of hot-night excess ranged from 1.12 (95% CI = 1.05, 1.20) for France to 1.37 (95% CI = 1.26, 1.48) for Portugal. Risk estimates for excess were consistently higher than for duration. Conclusions: This study provides new evidence that, over a wider range of locations, hot night indices are strongly associated with cause-specific deaths. Modeling the impact of thermal characteristics during summer nights on mortality could improve decisionmaking for preventive public health strategies.\n\n\nhot nightsmortalitysouthern europeheat stresspublic health\n\n\n\n\n\nFdez-Arróyabe P, Marti-Ezpeleta A, Royé D, Zarrabeitia A (2021). Effects of circulation weather types on influenza hospital admissions in Spain. International Journal of Biometeorology, vol. 65.  10.1007/s00484-021-02107-y. \n\n\nIn this study, we use a statistical approach based on generalized additive models, linking atmospheric circulation and the number of influenza-related hospital admissions in the Spanish Iberian Peninsula during 2003–2013. The relative risks are estimated for administrative units in the Spanish territory, which is politically structured into 15 regions called autonomous communities. A catalog of atmospheric circulation types is defined for this purpose. The relationship between the exposure and response variables is modeled using a distributed lag nonlinear model (DLNM). Types from southwest and anticyclonic are significant in terms of the probability of having more influenza-related hospital admissions for all of Spain. The heterogeneity of the results is very high. The relative risk is also estimated for each autonomous community and weather type, with the maximum number of influenza-related hospital admissions associated with circulation types from the southwest and the south. We identify six specific situations where relative risk is considered extreme and twelve with a high risk of increasing influenza-related hospital admissions. The rest of the situations present a moderate risk. Atmospheric local conditions become a key factor for understanding influenza spread in each spatial unit of the Peninsula. Further research is needed to understand how different weather variables (temperature, humidity, and sun radiation) interact and promote the spread of influenza.\n\n\ninfluenzaatmospheric circulationhospital admissionsspainweather types\n\n\n\n\n\nIñiguez C, Royé D, Tobías A (2021). Contrasting patterns of temperature related mortality and hospitalization by cardiovascular and respiratory diseases in 52 Spanish cities. Environmental Research, vol. 192, art. no. 110191.  10.1016/j.envres.2020.110191. \n\n\nBackground. Climate change is a severe public health challenge. Understanding to what extent fatal and non-fatal consequences of specific diseases are associated with temperature may help to improve the effectiveness of preventive public health efforts. This study examines the effects of temperature on deaths and hospital admissions by cardiovascular and respiratory diseases, empathizing the difference between mortality and morbidity. Methods. Daily counts for mortality and hospital admissions by cardiovascular and respiratory diseases were collected for the 52 provincial capital cities in Spain, between 1990 and 2014. The association with temperature in each city was investigated by means of distributed lag non-linear models using quasi-Poisson regression. City-specific exposure-response curves were pooled by multivariate random-effects meta-analysis to obtain countrywide risk estimates of mortality and hospitalizations due to heat and cold, and attributable fractions were computed. Results. Heat and cold exposure were identified to be associated with increased risk of cardiovascular and respiratory mortality. Heat was not found to have an impact on hospital admissions. The estimated fraction of mortality attributable to cold was of greater magnitude in hospitalizations (17.5% for cardiovascular and 12.5% for respiratory diseases) compared to deaths (9% and 2.7%, respectively). Conclusions. There were noteworthy differences between temperature-related mortality and hospital admissions regarding cardiovascular and respiratory diseases, hence reinforcing the convenience of cause-specific measures to prevent temperature-related deaths.\n\n\ntemperature-related mortalityhospital admissionscardiovascular diseases, respiratory diseasesspain\n\n\n\n\n2020\n\n\nRomani S, Royé D, Sánchez Santos L, Figueiras A (2020). Impact of Extreme Temperatures on Ambulance Dispatches Due to Cardiovascular Causes in NorthWest Spain. International Journal of Environmental Research and Public Health, vol. 17(23), art. no. 9001.  10.3390/ijerph17239001. \n\n\nIntroduction and objectives. The increase in mortality and hospital admissions associated with high and low temperatures is well established. However, less is known about the influence of extreme ambient temperature conditions on cardiovascular ambulance dispatches. This study seeks to evaluate the effects of minimum and maximum daily temperatures on cardiovascular morbidity in the cities of Vigo and A Coruña in North-West Spain, using emergency medical calls during the period 2005–2017. Methods. For the purposes of analysis, we employed a quasi-Poisson time series regression model, within a distributed non-linear lag model by exposure variable and city. The relative risks of cold- and heat-related calls were estimated for each city and temperature model. Results. A total of 70,537 calls were evaluated, most of which were associated with low maximum and minimum temperatures on cold days in both cities. At maximum temperatures, significant cold-related effects were observed at lags of 3–6 days in Vigo and 5–11 days in A Coruña. At minimum temperatures, cold-related effects registered a similar pattern in both cities, with significant relative risks at lags of 4 to 12 days in A Coruña. Heat-related effects did not display a clearly significant pattern. Conclusions. An increase in cardiovascular morbidity is observed with moderately low temperatures without extremes being required to establish an effect. Public health prevention plans and warning systems should consider including moderate temperature range in the prevention of cardiovascular morbidity.\n\n\nambulance dispatchesextreme temperaturegaliciacardiovascular diseasesquasi-poisson regression model\n\n\n\n\n\nFdez-Arroyabe P, Kourtidis K, Haldoupis C, Savoska S, Matthews J, Mir L, Kassomenos P, Cifra M, Barbosa S, Chen X, Dragovic S, Consoulas C, Hunting E, Robert D, van der Velde O, Apollonio F, Odzimek A, Chilingarian A, Royé D, Mkrtchyan H, Price C, Bór J, Oikonomou C, Birsan M, Crespo-Facorro B, Djordjevic M, Salcines C, López-Jiménez A, Donner R, Vana M, Pedersen J, Vorenhout M, Rycroft M (2020). Glossary on atmospheric electricity and its effects on biology. International Journal of Biometeorology, vol. 65, pp. 5-29.  10.1007/s00484-020-02013-9. \n\n\nThere is an increasing interest to study the interactions between atmospheric electrical parameters and living organisms at multiple scales. So far, relatively few studies have been published that focus on possible biological effects of atmospheric electric and magnetic fields. To foster future work in this area of multidisciplinary research, here we present a glossary of relevant terms. Its main purpose is to facilitate the process of learning and communication among the different scientific disciplines working on this topic. While some definitions come from existing sources, other concepts have been re-defined to better reflect the existing and emerging scientific needs of this multidisciplinary and transdisciplinary area of research.\n\n\natmospheric electric field (aef)schumann resonancesbiological processeselectromagnetic interferencemultidisciplinary research\n\n\n\n\n\nSanturtún A, Almendra R, Fdez-Arroyabe P, Sanchez-Lorenzo A, Royé D, Zarrabeitia M, Santana P (2020). Predictive value of three thermal comfort indices in low temperatures on cardiovascular morbidity in the Iberian peninsula. Science of The Total Environment, vol. 729, art. no. 138969.  10.1016/j.scitotenv.2020.138969. \n\n\nThe natural environment has been considered an important determinant of cardiovascular morbidity. This work seeks to assess the impact of the winter thermal environment on hospital admissions from diseases of the circulatory system by using three biometeorological indices in five regions of the Iberian Peninsula. A theoretical index based on a thermophysiological model (Universal Thermal Climate Index [UTCI]) and two experimental biometeorological ones (Net Effective Temperature [NET] and Apparent Temperature [AT]) were estimated in two metropolitan areas of Portugal (Porto and Lisbon) and in three provinces of Spain (Madrid, Barcelona and Valencia). Subsequently, their relationship with hospital admissions, adjusted by NO2 concentration, time, and day of the week, was analyzed using a Generalized Additive Model. As the estimation method, a semi-parametric quasi-Poisson regression was used. Around 53% of the hospitalizations occurred during the cold periods. The admissions rate followed an upward trend over the 9-year period in both capitals (Madrid and Lisbon) as well as in Barcelona. An inverse and statistically significant relationship was found between thermal comfort and hospital admissions in the five regions (p  0.001). The highest relative risk (RR) was found after a cumulative 7-day exposure in Lisbon, where there was a 1.4% increase in hospital admissions for each NET and AT degree Celsius, and 1.0% for each UTCI degree Celsius. In conclusion, low air temperatures are a significant risk factor for hospital admissions from diseases of the circulatory system in the Iberian Peninsula, regardless of the index calculated.\n\n\nthermal comfort indiceslow temperaturescardiovascular morbidityiberian peninsulahealth impacts\n\n\n\n\n\nRoyé D, Íñiguez C, Tobías A (2020). Comparison of temperature–mortality associations using observed weather station and reanalysis data in 52 Spanish cities. Environmental Research, vol. 183, art. no. 109237.  10.1016/j.envres.2020.109237. \n\n\nBackground. Most studies use temperature observation data from weather stations near the analyzed region or city as the reference point for the exposure-response association. Climatic reanalysis data sets have already been used for climate studies, but are not yet used routinely in environmental epidemiology. Methods. We compared the mortality-temperature association using weather station temperature and ERA-5 reanalysis data for the 52 provincial capital cities in Spain, using time-series regression with distributed lag non-linear models. Results. The shape of temperature distribution is very close between the weather station and ERA-5 reanalysis data (correlation from 0.90 to 0.99). The overall cumulative exposure-response curves are very similar in their shape and risks estimates for cold and heat effects, although risk estimates for ERA-5 were slightly lower than for weather station temperature. Conclusions. Reanalysis data allow the estimation of the health effects of temperature, even in areas located far from weather stations or without any available.\n\n\ntemperature-mortalityweather stationsreanalysis datatime-seriesregression distributed lag non-linear models\n\n\n\n\n\nRoyé D, Codesido R, Tobías A, Taracido M (2020). Heat wave intensity and daily mortality in four of the largest cities of Spain. Environmental Research, vol. 182, art. no. 109027.  10.1016/j.envres.2019.109027. \n\n\nIn the current context of climate change, heat waves have become a significant problem for human health. This study assesses the effects of heat wave intensity on mortality (natural, respiratory and cardiovascular causes) in four of the largest cities of Spain (Barcelona, Bilbao, Madrid and Seville) during the period between 1990 and 2014. To model the heat wave severity the Excess Heat Factor (EHF) was used. The EHF is a two-component index. The first is the comparison of the three-day average daily mean temperature with the 95th percentile. The second component is a measure of the temperatures reached during the three-day period compared with the recent past (the previous 30 days). The city-specific exposure-response curves showed a non-linear J-shaped relationship between mortality and the EHF. Overall city-specific mortality risk estimates in natural causes for 1st vs. 99th percentile increases range from the highest mortality risk with 2.73 (95% CI: 2.34-3.18) in Seville to a risk of 1.78 (95% CI: 1.62-1.97) and 1.78 (95% CI: 1.45-2.19) in Barcelona and Bilbao, respectively. When we compare our results with risk estimates for the analyzed Spanish cities in other studies, the heat wave related mortality risks seem to be clearly higher. Furthermore, it has been demonstrated that different heat wave days of the same event do not present the same degree of severity/intensity. Thus, the intensity of a heat wave is an important mortality risk indicator during heat wave days. Due to the low number of studies on the EHF as a heat wave intensity indicator and heat-related mortality and morbidity, further research is required to validate its application in other geographic areas and focus populations.\n\n\napparent temperatureexcess heat factorheat effectsintensitymortalityspain\n\n\n\n\n\nMonjo R, Royé D, Martin-Vide J (2020). Meteorological drought lacunarity around the world and its classification. Earth System Science Data, vol. 12(1), pp. 741-752.  10.5194/essd-12-741-2020. \n\n\nThe measure of drought duration strongly depends on the definition considered. In meteorology, dryness is habitually measured by means of fixed thresholds (e.g. 0.1 or 1 mm usually define dry spells) or climatic mean values (as is the case of the standardised precipitation index), but this also depends on the aggregation time interval considered. However, robust measurements of drought duration are required for analysing the statistical significance of possible changes. Herein we climatically classified the drought duration around the world according to its similarity to the voids of the Cantor set. Dryness time structure can be concisely measured by the n index (from the regular or irregular alternation of dry or wet spells), which is closely related to the Gini index and to a Cantor-based exponent. This enables the world’s climates to be classified into six large types based on a new measure of drought duration. To conclude, outcomes provide the ability to determine when droughts start and finish. We performed the dry-spell analysis using the full global gridded daily Multi-Source Weighted-Ensemble Precipitation (MSWEP) dataset. The MSWEP combines gauge-, satellite-, and reanalysis-based data to provide reliable precipitation estimates. The study period comprises the years 1979–2016 (total of 45 165 d), and a spatial resolution of 0.5∘, with a total of 259 197 grid points. The dataset is publicly available at https://doi.org/10.5281/zenodo.3247041 (Monjo et al., 2019).\n\n\nlacunaritydrought durationcantor setdry spellsglobal classification\n\n\n\n\n\nMori-Gamarra F, Moure-Rodríguez L, Sureda X, Carbia C, Royé D, Montes-Martínez A, Cadaveira F, Caamaño-Isorna F (2020). Alcohol outlet density and alcohol consumption in Galician youth. Gaceta Sanitaria, vol. 34(1), pp. 15-20.  10.1016/j.gaceta.2018.09.005. \n\n\nObjective. To assess the influence that alcohol outlet density, off- and on-alcohol premises, and alcohol consumption wield on the consumption patterns of young pre-university students in Galicia (Spain). Method. A cross-sectional analysis of a cohort of students of the University of Santiago de Compostela (Compostela Cohort 2016) was carried out. Consumption prevalence were calculated for each of the municipalities from the first-cycle students’ home residence during the year prior to admission. The association with risky alcohol consumption (RC) and binge-drinking (BD) was assessed with a logistic model considering as independent variables the municipality population, alcohol outlet density of off- premises, density of off- and on- premises and total density of both types of premises in the municipality. Results. The prevalence of RC was 60.5% (95% confidence interval [95%CI]: 58.4-62.5) and the BD was 28.5% (95%CI: 26.7-30.2). A great variability was observed according to the municipality of provenance. The multivariate logistic model showed municipalities with a density of 8.42-9.34 of both types of premises per thousand inhabitants presented a higher risk of RC (odds ratio [OR]: 1,39; 95%CI: 1.09-1.78) and BD (OR: 1.29; 95%CI: 1.01-1.66). Conclusion. These data suggest the importance of including environmental information when studying alcohol consumption. Knowing our environment better could help plan policies that encourage healthier behaviour in the population.\n\n\nalcohol outlet densityalcoholunderage drinkingadolescents\n\n\n\n\n2019\n\n\nRoyé D, Tedim F, Martin‐Vide J, Salis M, Vendrell J, Lovreglio R, Bouillon C, Leone V (2019). Wildfire burnt area patterns and trends in Western Mediterranean Europe via the application of a concentration index. Land Degradation & Development, vol. 31(3), pp. 311-324.  10.1002/ldr.3450. \n\n\nThe most widely used metrics to characterize wildfire regime and estimate the impact of wildfires are total burnt area (BA) and the number of fire events (FE). However, these are insufficient to analyse the threat to society of a new fire regime characterized by a higher occurrence of very large events. To overcome this weakness, we propose the use of a Concentration Index (CIB) which makes it possible to identify spatio-temporal patterns. The frequency distribution of BA follows a negative exponential distribution almost everywhere, in which a small minority of FE is responsible of the majority of BA. In this article, the spatio-temporal behaviour of BA is analysed in Western Mediterranean Europe, with particular focus on Portugal, Spain, France and Italy, using data from the European Forest Fire Information System and national wildfire databases. This is the first time that the CI has been applied to wildfire events. This research shows that, in most Mediterranean European countries, the amount of BA is increasingly related with a lower number of fires. The spatio-temporal distribution of CIB shows high variability in all of the countries analysed in Europe. Portugal and Spain show increasing significant trends of CIB + 7.6% (p-value = 0.001) and + 1.3% per decade (p-value = 0.003). Statistically significant correlations for Portugal, Spain and Italy are also found between the annual CIB and several teleconnection indices. The application of the CIB demonstrates its discriminatory ability, which is a key point in detecting vulnerable areas and temporal trends under climate change.\n\n\nburnt areaconcentration indexspatial patternstemporal trendsfire regimes\n\n\n\n\n\nMathbout S, Lopez‐Bustins J, Royé D, Martin‐Vide J, Benhamrouche A (2019). Spatiotemporal variability of daily precipitation concentration and its relationship to teleconnection patterns over the Mediterranean during 1975–2015. International Journal of Climatology, vol. 40(3), pp. 1435-1455.  10.1002/joc.6278. \n\n\nThis study has addressed the spatiotemporal distribution of the daily rainfall concentration and its relation to the teleconnection patterns across the Mediterranean (MR). Daily concentration index (CI) and the ordered n index ( nor) are used at annual time scale to reveal the statistical structure of precipitation across the MR based on 233 daily rainfall series for the period 1975–2015. Eight teleconnection patterns, North Atlantic Oscillation (NAO), Mediterranean Oscillation (MO), Western Mediterranean Oscillation (WeMO), Upper-Level Mediterranean Oscillation index (ULMO), East Atlantic (EA) pattern, East Atlantic/West Russia (EATL/WRUS) pattern, Scandinavia (SCAND) pattern and Southern Oscillation (SO) at annual time scale are selected. The spatiotemporal patterns in precipitation concentration indices, annual precipitation and their teleconnections with previous large-scale circulations are investigated. Results show a strong connection between the CI and the nor (r = 0.70, p  .05) which present the same relative areas of high and low concentration. The annual values range from 0.57 to 0.70 for CI and 0.49 to 0.71 for nor index which show a high daily precipitation concentration across the MR. Trend analysis demonstrated mostly significant increasing trends for both indices. This increase is mainly found in south France, northern coastlands of the Iberian Peninsula (IP), Greece and Tunisia. An inverse relationship between the number of rainy days and concentration indices is evident. Both of WeMO and MO can play an important role in modulating rainfall in the northwest Mediterranean. The positive EATL/WRUS phase is mainly connected with positive precipitation mean anomalies in the eastern Mediterranean and vice versa in the west. The high daily precipitation concentration values over south France, northeast Spain, Croatia and Tunisia are linked to the low values of WeMO and high values of EA. These results could pave the way for new possibilities regarding the projection of precipitation concentration and precipitation irregularity in downscaling techniques.\n\n\nprecipitation concentrationteleconnection patternsspatiotemporal variabilitymediterraneanclimate indices\n\n\n\n\n\nLemus-Canovas M, Lopez-Bustins J, Martin-Vide J, Royé D (2019). synoptReg: An R package for computing a synoptic climate classification and a spatial regionalization of environmental data. Environmental Modelling & Software, vol. 118, pp. 114-119.  10.1016/j.envsoft.2019.04.006. \n\n\nSpatial knowledge of the climatic or environmental variables associated with the most frequent circulation types is essential with regard to developing strategies to address the risk of avalanches, floods, soil erosion, air pollution or other natural hazards. In order to derive an environmental regionalization, we present an Open Source R package known as synoptReg, which combines the spatialization of environmental variables based on the atmospheric circulation types. The synoptReg package contains a set of functions which we will employ (1) to perform a PCA-based synoptic classification using an atmospheric variable; (2) to map the spatial distribution of the selected environmental variable based upon the circulation types; (3) to develop a spatial environmental regionalization based on the previous results. We illustrate the usefulness of the package for a case study in the Alps area.\n\n\nsynoptic classificationclusteringenvironmental dataregionalizationcirculation types\n\n\n\n\n\nRoyé D, Zarrabeitia M, Fdez-Arroyabe P, Álvarez Gutiérrez A, Santurtún A (2019). Role of Apparent Temperature and Air Pollutants in Hospital Admissions for Acute Myocardial Infarction in the North of Spain. Revista Española de Cardiología, vol. 72(8), pp. 634-640.  10.1016/j.recesp.2018.05.032. \n\n\nIntroduction and objectives. The role of the environment on cardiovascular health is becoming more prominent in the context of global change. The aim of this study was to analyze the relationship between apparent temperature (AT) and air pollutants and acute myocardial infarction (AMI) and to study the temporal pattern of this disease and its associated mortality. Methods. We performed a time-series study of admissions for AMI in Cantabria between 2001 and 2015. The association between environmental variables (including a biometeorological index, AT) and AMI was analyzed using a quasi-Poisson regression model. To assess potential delayed and non-linear effects of these variables on AMI, a lag non-linear model was fitted in a generalized additive model. Results. The incidence rate and the mortality followed a downward trend during the study period (CC = –0.714; P = .0002). An annual pattern was found in hospital admissions (P = .005), with the highest values being registered in winter; a weekly trend was also identified, reaching a minimum during the weekends (P = .000005). There was an inverse association between AT and the number of hospital admissions due to AMI and a direct association with particulate matter with a diameter smaller than 10 μm. Conclusions. Hospital admissions for AMI followed a downward trend between 2007 and 2015. Mortality associated with admissions due to this diagnosis has decreased. Predictive factors for this disease were AT and particulate matter with a diameter smaller than 10 μm.\n\n\napparent temperatureair pollutantsacute myocardial infarctionhospital admissionsparticulate matter\n\n\n\n\n\nRoyé D, Zarrabeitia M, Riancho J, Santurtún A (2019). A time series analysis of the relationship between apparent temperature, air pollutants and ischemic stroke in Madrid, Spain. Environmental Research, vol. 173, pp. 349-358.  10.1016/j.envres.2019.03.065. \n\n\nThe understanding of the role of environment on the pathogenesis of stroke is gaining importance in the context of climate change. This study analyzes the temporal pattern of ischemic stroke (IS) in Madrid, Spain, during a 13-year period (2001-2013), and the relationship between ischemic stroke (admissions and deaths) incidence and environmental factors on a daily scale by using a quasi-Poisson regression model. To assess potential delayed and non-linear effects of air pollutants and Apparent Temperature (AT), a biometeorological index which represents human thermal comfort on IS, a lag non-linear model was fitted in a generalized additive model. The mortality rate followed a downward trend over the studied period, however admission rates progressively increased. Our results show that both increases and decreases in AT had a marked relationship with IS deaths, while hospital admissions were only associated with low AT. When analyzing the cumulative effects (for lag 0-14 days), with an AT of 1.7 °C (percentile 5%) a RR of 1.20 (95% CI, 1.05-1.37) for IS mortality and a RR of 1.09 (95% CI, 0.91-1.29) for morbidity is estimated. Concerning gender differences, men show higher risks of mortality in low temperatures and women in high temperatures. No significant relationship was found between air pollutant concentrations and IS morbi-mortality, but this result must be interpreted with caution, since there are strong spatial fluctuations of the former between nearby geographical areas that make it difficult to perform correlation analyses.\n\n\nadmissionsair pollutantsapparent temperatureischemic strokemortality\n\n\n\n\n2018\n\n\nRoyé D, Lorenzo N, Rasilla D, Martí A (2018). Spatio‐temporal variations of cloud fraction based on circulation types in the Iberian Peninsula. International Journal of Climatology, vol. 39(3), pp. 1716-1732.  10.1002/joc.5914. \n\n\nThis paper presents the first systematic study of the relationships between atmospheric circulation types (CT) and cloud fraction (CF) over the whole Iberian Peninsula, using satellite data from the MODIS (MOD09GA and MYD09GA) cloud mask for the period 2001–2017. The high level of detail, in combination with a classification for circulation patterns, provides us with relevant information about the spatio-temporal variability of cloudiness and the main mechanisms affecting the genesis of clouds. The results show that westerly CTs are the most influential, followed by cyclonic types, in cloudiness in the west of the Iberian Peninsula. Westerly flows, however, do not affect the Mediterranean coastline, which is dominated by easterly CTs, suggesting that local factors such as convective processes, orography and proximity to a body of warm water could play a major role in cloudiness processes. The Cantabrian Coast also has a particularly characteristic cloudiness dominated by northerly CTs. In general, the results found in this study are in line with the few studies that exist on cloudiness in the Iberian Peninsula. Furthermore, the results are geographically consistent, showing links to synoptic forcing in terms of atmospheric circulation patterns and the impact of the Iberian Peninsula’s complex orography upon this element of the climate system.\n\n\ncloudinesscirculation typesvariabilityorographysynoptic forcing\n\n\n\n\n\nVélez A, Martin-Vide J, Royé D, Santaella O (2018). Spatial analysis of daily precipitation concentration in Puerto Rico. Theoretical and Applied Climatology, vol. 136, pp. 1347-1355.  10.1007/s0070401825501. \n\n\nThe present study analyzes spatial patterns of precipitation Concentration Index (CI) in Puerto Rico considering the daily precipitation data of 20 precipitation-gauging stations during 1971–2010. The South and East interior parts of Puerto Rico are characterized by higher CI and the West and North-West parts show lower CI. The annual CI and the rainy season CI show a gradient from South-East to North-West and the dry season CI shows a gradient from South to North. Another difference between the rainy season CI and dry season CI is that the former shows the lowest values of CI while the latter shows the highest values of CI. The different types of seasonal precipitation seem to play a major role on the spatial CI distribution. However, the local relief plays a major role in the spatial patterns due to the effect of the air circulation by the mountains. These findings can contribute to basin-scale water resource management (flooding, soil erosion, etc.) and conservation of the ecological environment.\n\n\nprecipitation concentrationspatial patternsconcentration index (ci)seasonal variabilityclimate change\n\n\n\n\n\nRiancho-Zarrabeitia L, Rasilla D, Royé D, Fdez-Arroyabe P, Santurtún A (2018). Kawasaki disease in Spanish paediatric population and synoptic weather types: an observational study. Rheumatology International, vol. 38(7), pp. 1259-1266.  10.1007/s00296-018-4066-5. \n\n\nKawasaki disease (KD) is a vasculitis of unelucidated pathogenesis that usually occurs in paediatric patients. In this study we analyse the temporal pattern and geographical distribution of the disease in Spain, and its relationship with atmospheric circulation patterns. We performed a retrospective study in which we collected all hospital admissions due to KD in the country between 2005 and 2015 and explored their relationship with demographic and geographical characteristics. Moreover, we calculated daily surface atmospheric patterns over Spain to study the relationship between weather types (WT) and KD Admissions. The average admission rate for KD in the paediatric population was 3.90 per 100,000, with a male to female ratio of 1.56:1. The highest rate of admissions was found in the 0-4-year-old group, with an incidence of 11.7 cases per 100,000. Admissions followed an annual cyclic pattern with a peak of incidence in January (p = 0.022) and a nadir in September. There was an upwards trend in the number of KD admissions in male sex during the study period (p = 0.004). However, there were marked geographical differences in the incidence rate. Finally, the analysis of the relationship between the WT and the number of admissions by KD revealed no statistically significant association. KD admissions follow a peculiar seasonal and spatial distribution, that suggest the involvement of environmental factors in the disease; however, the absence of an association with WT should be interpreted with caution and regional studies should be done to explore this relationship.\n\n\nkawasaki diseaseseasontrendweather types\n\n\n\n\n\nRoyé D, Figueiras A, Taracido M (2018). Short‐term effects of heat and cold on respiratory drug use. A time‐series epidemiological study in A Coruña, Spain. Pharmacoepidemiology and Drug Safety, vol. 27(6), pp. 638-644.  10.1002/pds.4427. \n\n\nThe consumption of medication, especially over-the-counter drugs, can reflect environmental exposure with a lesser degree of severity in terms of morbidity. The non-linear effects of maximum and minimum apparent temperature on respiratory drug sales in A Coruña from 2006 to 2010 were examined using a distributed lag nonlinear model. In particular, low apparent temperatures proved to be associated with increased sales of respiratory drugs. The strongest consistent risk estimates were found for minimum apparent temperatures in respiratory drug sales with an increase of 33.4% (95% CI, 12.5%-58.0%) when the temperature changed from 2.8°C to −1.4 °C. These findings may serve to guide the planning of public health interventions to predict and manage the health effects of exposure to the thermal environment for lower degrees of morbidity. More precisely, significant increases in the use of measured over-the-counter medication could be used to identify and anticipate influenza outbreaks due to a more sensitive degree of the data source.\n\n\nrespiratory drug useheatcoldtime-series analysisa coruña\n\n\n\n\n\nRoyé D, Lorenzo N, Martin-Vide J (2018). Spatial–temporal patterns of cloudtoground lightning over the northwest Iberian Peninsula during the period 2010–2015. Natural Hazards, vol. 92, pp. 857-884.  10.1007/s11069-018-3228-9. \n\n\nThe spatial–temporal patterns of cloud-to-ground (CG) lightning covering the period 2010–2015 over the northwest Iberian Peninsula were investigated. The analysis conducted employed three main methods: the circulation weather types developed by Jenkinson and Collison, the fit of a generalized additive model (GAM) for geographic variables, and the use of a concentration index for the ratio of lightning strikes and thunderstorm days. The main activity in the summer months can be attributed to situations with eastern or anticyclonic flow due to convection by insolation. In winter, lightning proves to have a frontal origin and is mainly associated with western or cyclonic flow situations which occur with advections of air masses of maritime origin. The largest number of CG discharges occurs under eastern flow and their hybrids with anticyclonic situations. Thunderstorms with greater CG lightning activity, highlighted by a higher concentration index, are located in areas with a higher density of lightning strikes, above all in mountainous areas away from the sea. The modeling of lightning density with geographic variables shows the positive influence of altitude and, particularly, distance to the sea, with nonlinear relationships due to the complex orography of the region. Likewise, areas with convex topography receive more lightning strikes than concave ones, a relation which has been demonstrated for the first time from a GAM.\n\n\ncloud-to-ground lightningspatial-temporal patternsnorthwest iberian peninsulacirculation weather typesgeneralized additive model (gam)\n\n\n\n\n2017\n\n\nRoyé D, Martin-Vide J (2017). Concentration of daily precipitation in the contiguous United States. Atmospheric Research, vol. 196(1), pp. 237-247.  10.1016/j.atmosres.2017.06.011. \n\n\nThe contiguous US exhibits a wide variety of precipitation regimes, first, because of the wide range of latitudes and altitudes. The physiographic units with a basic meridional configuration contribute to the differentiation between east and west in the country while generating some large interior continental spaces. The frequency distribution of daily precipitation amounts almost anywhere conforms to a negative exponential distribution, reflecting the fact that there are many small daily totals and few large ones. Positive exponential curves, which plot the cumulative percentages of days with precipitation against the cumulative percentage of the rainfall amounts that they contribute, can be evaluated through the Concentration Index. The Concentration Index has been applied to the contiguous United States using a gridded climate dataset of daily precipitation data, at a resolution of 0.25°, provided by CPC/NOAA/OAR/Earth System Research Laboratory, for the period between 1956 and 2006. At the same time, other rainfall indices and variables such as the annual coefficient of variation, seasonal rainfall regimes and the probabilities of a day with precipitation have been presented with a view to explaining spatial CI patterns. The spatial distribution of the CI in the contiguous United States is geographically consistent, reflecting the principal physiographic and climatic units of the country. Likewise, linear correlations have been established between the CI and geographical factors such as latitude, longitude and altitude. In the latter case the Pearson correlation coefficient (r) between this factor and the CI is −0.51 (p-value 0.001). For annual probability of days with precipitation and the CI there is also a significant and negative correlation, r = −0.25 (p-value 0.001).\n\n\ndaily precipitationclimate variabilitycontiguous united statesrainfall patternshydrology\n\n\n\n\n\nMathbout S, Lopez-Bustins J A, Royé D, Martin-Vide J, Bech J, Rodrigo F S (2017). Observed Changes in Daily Precipitation Extremes at Annual Timescale Over the Eastern Mediterranean During 1961–2012. Pure and Applied Geophysics, vol. 175, pp. 3875-3890.  10.1007/s00024-017-1695-7. \n\n\nThe Eastern Mediterranean is one of the most prominent hot spots of climate change in the world and extreme climatic phenomena in this region such as drought or extreme rainfall events are expected to become more frequent and intense. In this study climate extreme indices recommended by the joint World Meteorological Organization Expert Team on Climate Change Detection and Indices are calculated for daily precipitation data in 70 weather stations during 1961–2012. Observed trends and changes in daily precipitation extremes over the EM basin were analysed using the RClimDex package, which was developed by the Climate Research Branch of the Meteorological Service of Canada. Extreme and heavy precipitation events showed globally a statistically significant decrease in the Eastern Mediterranean and, in the southern parts, a significant decrease in total precipitation. The overall analysis of extreme precipitation indices reveals that decreasing trends are generally more frequent than increasing trends. We found statistically significant decreasing trends (reaching 74% of stations for extremely wet days) and increasing trends (reaching 36% of stations for number of very heavy precipitation days). Finally, most of the extreme precipitation indices have a statistically significant positive correlation with annual precipitation, particularly the number of heavy and very heavy precipitation days.\n\n\nprecipitation extremeseastern mediterraneanclimate changehydrological cycletrend analysis\n\n\n\n\n\nRoyé D (2017). The effects of hot nights on mortality in Barcelona, Spain. International Journal of Biometeorology, vol. 61, pp. 2127-2140.  10.1007/s00484-017-1416-z. \n\n\nHeat-related effects on mortality have been widely analyzed using maximum and minimum temperatures as exposure variables. Nevertheless, the main focus is usually on the former with the minimum temperature being limited in use as far as human health effects are concerned. Therefore, new thermal indices were used in this research to describe the duration of night hours with air temperatures higher than the 95% percentile of the minimum temperature (hot night hours) and intensity as the summation of these air temperatures in degrees (hot night degrees). An exposure-response relationship between mortality due to natural, respiratory, and cardiovascular causes and summer night temperatures was assessed using data from the Barcelona region between 2003 and 2013. The non-linear relationship between the exposure and response variables was modeled using a distributed lag non-linear model. The estimated associations for both exposure variables and mortality shows a relationship with high and medium values that persist significantly up to a lag of 1–2 days. In mortality due to natural causes, an increase of 1.1% per 10% (CI95% 0.6–1.5) for hot night hours and 5.8% per each 10° (CI95% 3.5–8.2%) for hot night degrees is observed. The effects of hot night hours reach their maximum with 100% and lead to an increase by 9.2% (CI95% 5.3–13.1%). The hourly description of night heat effects reduced to a single indicator in duration and intensity is a new approach and shows a different perspective and significant heat-related effects on human health.\n\n\nhot nightsmortalitybarcelonaheat stresspublic health\n\n\n\n\n2015\n\n\nRoyé D (2015). The use of climate databases netCDF with array structure in the environment of R. Sémata: Ciencias Sociais e Humanidades, vol. 27, pp. 11-37.  https://revistas.usc.gal/index.php/semata/article/view/2690. \n\n\nA practical introduction in the use of netCDF in the environment of R Spatio-temporal data is currently key to many disciplines, especially to climatology and meteorology. A widespread format is netCDF allowing a multidimensional structure and an exchange of data machine independently. In this article, we introduce the use of these databases with the free software environment R. To do this, we will work with a grid of the maximum temperature of the Iberian Peninsula for the period 1971-2007. The goal is to read and visualize the netCDF format, and make some fist overall and specifi calculations. Finally the applicability is shown in a case study: the diurnal temperature variation in the Iberian Peninsula for January and August 2006. (Spanish)\n\n\nncdfdata cubeclimateprogrammingarray\n\n\n\n\n\nRoyé D, Martí­ Ezpeleta A (2015). Analysis of tropical nights on the atlantic coast of the Iberian Peninsula. A proposed methodology. Boletín de la Asociación de Geógrafos Españoles, vol. 69, pp. 351-368.  10.21138/bage.1900. \n\n\nAnalysis of tropical nights on the Atlantic coast of the Iberian peninsula. A proposed methodology. This paper presents a new methodology for the study of warm nights, also called «tropical», in Galicia and Portugal in order to identify those nights where people can be affected by heat stress. The use of two indicators obtained through half-hourly data has allowed us to define in more detail the thermal characteristics of the nights between May and October, thereby being able to more accurately assess the risk to the health and well-being of the population. There is a significant increase in the frequency of tropical nights and warm nights on the Atlantic coast, from the north of Galicia to the south of Portugal. The lower latitude and proximity to the coastline are associated with greater persistence of heat and thermal stress during these nights. In inland areas the persistence is less. The warmest nights are more frequent and intense in centres of the cities, due to the effect of the urban heat island.\n\n\ntropical nightsatlantic coastiberian peninsulaheat stressclimate change\n\n\n\n\n\nRoyé D, Taboada J J, Martí A, Lorenzo M N (2015). Winter circulation weather types and hospital admissions for respiratory diseases in Galicia, Spain. International Journal of Biometeorology, vol. 60.  10.1007/s00484-015-1047-1. \n\n\nThe link between various pathologies and atmospheric conditions has been a constant topic of study over recent decades in many places across the world; knowing more about it enables us to pre-empt the worsening of certain diseases, thereby optimizing medical resources. This study looked specifically at the connections in winter between respiratory diseases and types of atmospheric weather conditions (Circulation Weather Types, CWT) in Galicia, a region in the north-western corner of the Iberian Peninsula. To do this, the study used hospital admission data associated with these pathologies as well as an automatic classification of weather types. The main result obtained was that weather types giving rise to an increase in admissions due to these diseases are those associated with cold, dry weather, such as those in the east and south-east, or anticyclonic types. A second peak was associated with humid, hotter weather, generally linked to south-west weather types. In the future, this result may help to forecast the increase in respiratory pathologies in the region some days in advance.\n\n\ncirculation weather types (cwt)respiratory diseaseshospital admissionsgaliciawinter"
  },
  {
    "objectID": "publication/index.html#book-chapters",
    "href": "publication/index.html#book-chapters",
    "title": "Publications",
    "section": "Book chapters",
    "text": "Book chapters\n2024\n\n\nRoyé D, Tobías A (2024). Cambio climático: un riesgo para nuestro bienestar y salud. Cambio climático en España Tirant Lo Blanch.  https://editorial.tirant.com/es/libro/cambio-climatico-en-espana-luis-efren-rios-vega-9788411837279?busqueda=Cambio+clim%3Ftico+&. \n\n\nEl ambiente influye de forma directa e indirecta en nuestra salud, por tanto, una relación directa con el dinamismo antropogenético de las sociedades, en el sentido social, cultural, económico y político. El organismo humano y la atmósfera se encuentran en un equilibrio físico y químico en constante intercambio. Todos los seres humanos se ven forzados a reaccionar ante los elementos atmosféricos para poder garantizar su correcto y óptimo funcionamiento orgánico. En este contexto, el cambio climático es uno de los mayores desafíos que enfrenta la humanidad en el siglo XXI, porque implica consecuencias muy graves para la salud y el bienestar de las personas en todo el planeta. Se ha convertido en una inaplazable emergencia climática afectando especialmente a nuestro bienestar con hasta 3,6 millones de personas en áreas altamente susceptibles y vulnerables (IPCC, 2022). El cambio climático es un multiplicador de riesgos existentes, aumentando la frecuencia, intensidad y la duración de eventos extremos, así como de olas de calor o redistribuyendo enfermedades transmitidas por vectores. Dado que no es posible separar los impactos actuales del clima de aquellos provocados por el cambio climático antropogénico, aquí se resumen en dos los principales impactos del calentamiento global sobre la salud en España: las temperaturas extremas y la contaminación del aire, y se analizan las posibles medidas de adaptación y mitigación.\n\n\n\n\n\n\n\n\nRoyé D (2024). Geoprocesamiento en nube. Fundamentos de ciencia de datos con R Publisher: Mc Graw Hill Editors: G Fernández-Avilés, JM Montero.  https://cdr-book.github.io/geoproces.html. \n\n\nEl planteamiento de un problema basado en datos de diversos proveedores habitualmente implica la descarga de grandes volúmenes de datos. La actual proliferación de servicios de Open Data, despliegues de sensores y diversas fuentes, incluyendo los satélites, dificulta su procesamiento en equipos personales. El gran crecimiento en grandes volúmenes de datos espaciotemporales de tipo vectorial o raster lleva a la necesidad en trabajar con servicios en nube para ahorrar tiempo computacional y espacio de almacenamiento. En la actualidad existen diferentes servicios de geoprocesamiento en nube que ayudan a hacer análisis online sin necesidad de descargar los datos ni preocuparse por el rendimiento computacional. Uno de estos servicios es Google Earth Engine (GEE), donde se combina un catálogo de varios petabytes de imágenes satelitales y conjuntos de datos geoespaciales multidimensionales (vectorial y raster) de alta resolución con capacidades de análisis a escala planetaria. Este servicio gratuito para uso no comercial incluye incluso la posibilidad de crear aplicaciones.\n\n\n\n\n\n\n\n\nRoyé D (2024). Una nota sobre el cambio climático. Fundamentos de ciencia de datos con R Publisher: Mc Graw Hill Editors: G Fernández-Avilés, JM Montero.  https://cdr-book.github.io/cambioclimatico.html. \n\n\nLa temperatura media global en la superficie terrestre ha aumentado en 1,1 ºC desde la era preindustrial (1880-1900). A pesar de parecer un leve incremento en la temperatura, implica un aumento significativo en el calor acumulado del sistema Tierra. Cuando se combina el aumento de la temperatura en la superficie terrestre y en la superficie oceánica, la tasa de incremento promedio es de 0,08 ºC por década desde 1880. Sin embargo, la tasa promedio de aumento desde 1981 ha sido más del doble: 0,18 ºC por año. Los océanos se caracterizan por una menor tasa de calentamiento debido a su capacidad calorífica. No obstante, son los océanos los que absorben la mayoría del calor adicional del planeta debido al cambio climático…\n\n\n\n\n\n\n\n2020\n\n\nTedim F, Leone V, Coughlan M, Bouillon C, Xanthopoulos G, Royé D, Correia FJM, Ferreira C (2020). Extreme wildfire events: the definition.  10.1016/B978-0-12-815721-3.00001-1. \n\n\nExtreme wildfires events (EWEs) represent a minority among all wildfires but are a true challenge for societies as they exceed the current control capacity even in the best prepared regions of the world and they create destruction and a disproportionately number of fatalities. Recent events in Portugal, Chile, Greece, Australia, Canada, and the USA provide evidence that EWEs are an escalating worldwide problem, exceeding all previous records. Despite the challenges put by climate change, the occurrence of EWEs and disasters is not an ecological inevitability. In this chapter the rationale of the definition of EWEs and the integration of potential consequences on people and assets in a novel wildfire classification scheme are proposed and discussed. They are excellent instruments to enhance wildfire risk and crisis communication programs and to define appropriate prevention, mitigation, and response measures which are crucial to build up citizens’ safety.\n\n\nextreme wildfire events (ewes)climate changerisk communicationmitigation measureswildfire classification\n\n\n\n\n2017\n\n\nFdez-Arroyabe P, Royé D (2017). Co-creation and Participatory Design of Big Data Infrastructures on the Field of Human Health Related Climate Services. Internet of Things and Big Data Technologies for Next Generation HealthcareEdition: Studies in Big Data, Vol. 23 Publisher: Springer International PublishingEditors: C. Bhatt, N. Dey, A.S. Ashour.  10.1007/978-3-319-49736-5_9. \n\n\nCo-creation of scientific knowledge based on new technologies and big data sources is one of the main challenges for the digital society in the XXI century. Data management and the analysis of patterns among datasets based on machine learning and artificial intelligence has become essential for many sectors nowadays. The development of real time health-related climate services represents an example where abundant structured and unstructured information and transdisciplinary research are needed. The study of the interactions between atmospheric processes and human health through a big data approach can reveal the hidden value of data. The Oxyalert technological platform is presented as an example of a digital biometeorological infrastructure able to forecast, at an individual level, oxygen changes impacts on human health.\n\n\nco-creationinterdisciplinaritytransdisciplinaritymorbidityclimate servicesdigital dividebig datahealth"
  },
  {
    "objectID": "publication/index.html#books",
    "href": "publication/index.html#books",
    "title": "Publications",
    "section": "Books",
    "text": "Books\n2019\n\n\nRoyé D, Serrano-Notivoli R (2019). Introducción a los SIG con R. Publicaciones de la Universidad de Zaragoza .  https://puz.unizar.es/2133-introduccion-a-los-sig-con-r.html. \n\n\nR tiene, como lenguaje de programación enfocado al análisis estadístico, todos los ingredientes para ser usado como herramienta de análisis espacial y representación cartográﬁca: es gratuito, permite personalizar, replicar y compartir los análisis de cualquier nivel de diﬁcultad y no tiene ninguna limitación en cuanto a cantidad de información a procesar o tipos de formato diferentes para gestionar. Esto le sitúa en una situación de ventaja que mejora día a día, gracias a su amplia comunidad de usuarios, respecto a un SIG (Sistema de Información Geográﬁca) convencional. Este manual explica, sin necesidad de conocimientos previos, cómo desarrollar con R todos los análisis disponibles en un SIG, con ejemplos sencillos y multitud de casos prácticos. Además, se muestran las enormes posibilidades de representación cartográﬁca, que van mucho más allá de la simple creación de mapas. R permite, desde exportar a cualquier formato de archivo, hasta crear mapas dinámicos para supublicación en Internet.\n\n\n\n\n\n\n\n\nMartí A, Taboada J, Royé D, Fonseca X (2019). Os tempos e o clima de Galicia. Vigo: Xerais.  https://www.xerais.gal/libro/basicos-ciencia/os-tempos-e-o-clima-de-galicia-alberto-marti-ezpeleta-9788491215066/. \n\n\nQue récords climáticos se alcanzaron en Galicia? Cales son os lugares máis calorosos? E os máis fríos? Onde chove máis? Onde se rexistran máis días de precipitación? Que zonas gozan dun maior número de horas de sol? Cales teñen maior nebulosidade? Que lugares son os máis ventosos? Como está a afectar o cambio climático a Galicia? Neste libro atoparás as respostas a estas e a outras preguntas relacionadas co clima de Galicia e os diversos tipos de tempo que o caracterizan. Nas súas páxinas explícase como se producen os fenómenos meteorolóxicos máis habituais no noso territorio: as inversións térmicas, as néboas costeiras e orográficas, as illas de calor urbanas, os tipos de precipitación, o efecto foehn, as brisas mariñas, o arco da vella etc. A través de exemplos concretos, analízanse tamén os riscos climáticos que afectan regularmente a Galicia, como vagas de calor, temporais de neve, cicloxéneses explosivas e temporais de choiva e vento, tormentas, secas, tornados… Tamén poderás coñecer como está a cambiar o clima da nosa comunidade debido ao quecemento global e cales son os escenarios de futuro."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dr. Dominic Royé",
    "section": "",
    "text": "I am a climate scientist and R educator with a love for community. My research is focused on biometeorology, among others, the relationship between human health and the atmospheric environment. My community projects value the partnership between open source tools and data literacy and graphicacy as a way to build power and effect change.\nLearn more about me →\n\n    \n    \n  \n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "blog/visualize-urban-growth/index.html",
    "href": "blog/visualize-urban-growth/index.html",
    "title": "Visualize urban growth",
    "section": "",
    "text": "The General Directorate for the Cadastre of Spain has spatial information of the all buildings except for the Basque Country and Navarra. This data set is part of the implementation of INSPIRE, the Space Information Infrastructure in Europe. More information can be found here. We will use the links (urls) in ATOM format, which is an RSS type for web feeds, allowing us to obtain the download link for each municipality. Since 2022, a package to access the API is directly available CatastRo."
  },
  {
    "objectID": "blog/visualize-urban-growth/index.html#packages",
    "href": "blog/visualize-urban-growth/index.html#packages",
    "title": "Visualize urban growth",
    "section": "Packages",
    "text": "Packages\n\n\n\n\n\n\n\n\nPackage\nDescription\n\n\n\ntidyverse\nCollection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.\n\n\nsf\nSimple Feature: import, export and manipulate vector data\n\n\nCatastRo\nCatastro Spain API\n\n\ntmap\nEasy creation of thematic maps\n\n\nclassInt\nCreate univariate class intervals\n\n\n\n\n\n\n# install the packages if necessary\n\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"CatastRo\")) install.packages(\"CatastRo\")\nif (!require(\"sf\")) install.packages(\"sf\")\nif (!require(\"tmap\")) install.packages(\"tmap\")\nif (!require(\"classInt\")) install.packages(\"classInt\")\n\n# load packages\n\nlibrary(sf)\nlibrary(CatastRo)\nlibrary(tidyverse)\nlibrary(classInt)\nlibrary(tmap)"
  },
  {
    "objectID": "blog/visualize-urban-growth/index.html#access-the-data",
    "href": "blog/visualize-urban-growth/index.html#access-the-data",
    "title": "Visualize urban growth",
    "section": "Access the data",
    "text": "Access the data\nTo import the building data we use the catr_atom_get_buildings() function.\n\nbuildings_val &lt;- catr_atom_get_buildings(\"Valencia\", to = \"Valencia\")\n\nbuildings_val[,1:5]\n\nSimple feature collection with 36346 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 720570.9 ymin: 4351286 xmax: 734981.9 ymax: 4382906\nProjected CRS: ETRS89 / UTM zone 30N\nFirst 10 features:\n                      gml_id               lowerCorner              upperCorner\n1  ES.SDGC.BU.000100100YJ27F  725589.5805 4377132.9425 725605.5005 4377146.6725\n2  ES.SDGC.BU.000100100YJ28A  720570.9393 4382157.3445  720646.359 4382259.3929\n3  ES.SDGC.BU.000100100YJ36A  730582.5135 4362033.4165  730589.793 4362043.9665\n4  ES.SDGC.BU.000100200YJ27F    725711.36 4377093.8715     725745.63 4377124.46\n5  ES.SDGC.BU.000100200YJ28A   720851.8475 4381937.212  720866.847 4381955.6425\n6  ES.SDGC.BU.000100300YJ27F      725336.89 4376989.78     725386.83 4377084.18\n7  ES.SDGC.BU.000100300YJ36C  729967.6535 4364320.2035 729979.9435 4364324.2535\n8  ES.SDGC.BU.000100400YJ27F  724956.7325 4376895.1345  724971.625 4376909.0335\n9  ES.SDGC.BU.000100400YJ36C   729953.5525 4364259.855  730039.851 4364319.6035\n10 ES.SDGC.BU.000200100YJ26F 726653.43835 4367240.6706  726673.662 4367258.1575\n   beginLifespanVersion conditionOfConstruction                       geometry\n1   2008-10-20T00:00:00              functional MULTIPOLYGON (((725594.9 43...\n2   2022-03-10T00:00:00              functional MULTIPOLYGON (((720582.3 43...\n3   2006-01-18T00:00:00              functional MULTIPOLYGON (((730586.1 43...\n4   2016-10-04T00:00:00              functional MULTIPOLYGON (((725718.3 43...\n5   2008-10-20T00:00:00              functional MULTIPOLYGON (((720860.3 43...\n6   2016-03-15T00:00:00              functional MULTIPOLYGON (((725376.5 43...\n7   2008-10-20T00:00:00                    ruin MULTIPOLYGON (((729967.7 43...\n8   2016-03-15T00:00:00              functional MULTIPOLYGON (((724958.6 43...\n9   2008-10-20T00:00:00              functional MULTIPOLYGON (((729984.8 43...\n10  2017-01-31T00:00:00              functional MULTIPOLYGON (((726661.4 43..."
  },
  {
    "objectID": "blog/visualize-urban-growth/index.html#data-preparation",
    "href": "blog/visualize-urban-growth/index.html#data-preparation",
    "title": "Visualize urban growth",
    "section": "Data preparation",
    "text": "Data preparation\nWe only have to convert the column of the construction year (beginning) into a Date class. The date column contains some dates in --01-01 format, which does not correspond to any recognizable date. Therefore, we replace the first - with 0000.\n\nbuildings_val &lt;- mutate(buildings_val,\n  beginning = str_replace(beginning, \"^-\", \"0000\") |&gt;\n    ymd_hms() |&gt; as_date()\n)\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `beginning = as_date(ymd_hms(str_replace(beginning, \"^-\",\n  \"0000\")))`.\nCaused by warning:\n!  6 failed to parse."
  },
  {
    "objectID": "blog/visualize-urban-growth/index.html#distribution-chart",
    "href": "blog/visualize-urban-growth/index.html#distribution-chart",
    "title": "Visualize urban growth",
    "section": "Distribution chart",
    "text": "Distribution chart\nBefore creating the maps of the construction years, which will reflect urban growth, we will make a graph of distribution of the beginning variable. We can clearly identify periods of urban expansion. We will use the ggplot2 package with the geometry of geom_density() for this purpose.\n\n# limit the period after 1750\nfilter(buildings_val, beginning &gt;= \"1750-01-01\") |&gt;\n  ggplot(aes(beginning)) +\n  geom_density(fill = \"#2166ac\", alpha = 0.7) +\n  scale_x_date(\n    date_breaks = \"20 year\",\n    date_labels = \"%Y\"\n  ) +\n  labs(y = NULL, x = NULL, title = \"Evolution of urban development\") +\n  theme_minimal(base_family = \"Montserrat\") +\n  theme(panel.grid.minor = element_blank())\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database"
  },
  {
    "objectID": "blog/visualize-urban-growth/index.html#buffer-of-25-km-for-valencia",
    "href": "blog/visualize-urban-growth/index.html#buffer-of-25-km-for-valencia",
    "title": "Visualize urban growth",
    "section": "Buffer of 2,5 km for Valencia",
    "text": "Buffer of 2,5 km for Valencia\nTo visualize better the distribution of urban growth, we limit the map to a radius of 2.5 km from the city center. Therefore, we use the geocode_OSM() function of the tmaptools package to obtain the coordinates of Valencia in class sf. Then we project the points to the system we use for the buildings (EPSG: 25830). The st_crs() function returns the coordinate system of a spatial object sf. Finally, we create with the function st_buffer() a buffer with 2500 m and the intersection with our building data. It is also possible to create a buffer in the form of a rectangle indicating the style with the argument endCapStyle =\" SQUARE \".\n\n# get the coordinates of Valencia\nciudad_point &lt;- tmaptools::geocode_OSM(\"Valencia\", as.sf = TRUE)\n\n#  project the points\nciudad_point &lt;- st_transform(ciudad_point, st_crs(buildings_val))\n\n# create the buffer\npoint_bf &lt;- st_buffer(ciudad_point, 2500) # radius of 2500 m\n\n\n# get the intersection between the buffer and the building\nbuildings_val25 &lt;- st_intersection(buildings_val, point_bf)\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries"
  },
  {
    "objectID": "blog/visualize-urban-growth/index.html#prepare-data-for-mapping",
    "href": "blog/visualize-urban-growth/index.html#prepare-data-for-mapping",
    "title": "Visualize urban growth",
    "section": "Prepare data for mapping",
    "text": "Prepare data for mapping\nWe categorize the year into 15 groups using quartiles. It is also possible to modify the number of classes or the applied method (eg jenks, fisher, etc), you can find more details in the help ?classIntervals.\n\n# find 15 classes\nbr &lt;- classIntervals(year(buildings_val25$beginning), 15, \"quantile\")\n\nWarning in classIntervals(year(buildings_val25$beginning), 15, \"quantile\"): var\nhas missing values, omitted in finding classes\n\n# create labels\nlab &lt;- names(print(br, under = \"&lt;\", over = \"&gt;\", cutlabels = FALSE))\n\nstyle: quantile\n     &lt; 1890 1890 - 1913 1913 - 1926 1926 - 1930 1930 - 1940 1940 - 1950 \n        929        1368        1145         356        1687        1041 \n1950 - 1958 1958 - 1962 1962 - 1966 1966 - 1970 1970 - 1973 1973 - 1978 \n       1447        1025        1220        1156        1155        1190 \n1978 - 1989 1989 - 2000      &gt; 2000 \n       1234        1132        1216 \n\n# categorize the year\nbuildings_val25 &lt;- mutate(buildings_val25,\n  yr_cl = cut(year(beginning),\n    br$brks,\n    labels = lab,\n    include.lowest = TRUE\n  )\n)"
  },
  {
    "objectID": "blog/visualize-urban-growth/index.html#map-of-valencia",
    "href": "blog/visualize-urban-growth/index.html#map-of-valencia",
    "title": "Visualize urban growth",
    "section": "Map of Valencia",
    "text": "Map of Valencia\nFor the mapping, we will use the tmap package. It is an interesting alternative to ggplot2. It is a package of functions specialized in creating thematic maps. The philosophy of the package follows the same as in ggplot2, creating multiple layers with different functions, which always start with tm_ *and combine with +. Building a map with tmap always starts with tm_shape(), where the data, we want to draw, is defined. Then we add the corresponding geometry to the data type (tm_polygon(), tm_border(), tm_dots() or even tm_raster()). The tm_layout() function help us to configure the map style.\nWhen we need more colors than the maximum allowed by RColorBrewer, we can pass the colors to the colorRampPalette() function. This function interpolates a set of given colors.\n\n# colours\ncol_spec &lt;- RColorBrewer::brewer.pal(11, \"Spectral\")\n\n# colour ramp function\ncol_spec_fun &lt;- colorRampPalette(col_spec)\n\n# create the final map\ntm_shape(buildings_val25) +\n  tm_polygons(\"yr_cl\",\n    border.col = \"transparent\",\n    palette = col_spec_fun(15), # adapt to the number of classes\n    textNA = \"Without data\",\n    title = \"\"\n  ) +\n  tm_layout(\n    bg.color = \"black\",\n    outer.bg.color = \"black\",\n    legend.outside = TRUE,\n    legend.text.color = \"white\",\n    legend.text.fontfamily = \"Montserrat\",\n    panel.label.fontfamily = \"Montserrat\",\n    panel.label.color = \"white\",\n    panel.label.bg.color = \"black\",\n    panel.label.size = 5,\n    panel.label.fontface = \"bold\"\n  )\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\n\n\n\n\n\n\n\nWe can export our map using the function tmap_save(\"name.png\", dpi = 300). I recommend using the dpi = 300 argument for a good image quality.\nAn alternative way to the tmap package is ggplot2.\n\n# create the final map\nggplot(buildings_val25) +\n  geom_sf(aes(fill = yr_cl), colour = NA) +\n  scale_fill_manual(values = col_spec_fun(15), na.translate = FALSE) + # adapt to the number of classes\n  labs(title = \"VALÈNCIA\", fill = NULL) +\n  theme_void(base_family = \"Montserrat\") +\n  theme(\n    panel.background = element_rect(fill = \"black\"),\n    plot.background = element_rect(fill = \"black\"),\n    legend.justification = .5,\n    legend.text = element_text(colour = \"white\", size = 12),\n    legend.key.height = unit(3, \"lines\"),\n    legend.key.width = unit(.5, \"lines\"),\n    plot.title = element_text(\n      colour = \"white\", hjust = .5, size = 60,\n      margin = margin(t = 30)\n    ),\n    plot.caption = element_text(\n      colour = \"white\",\n      margin = margin(b = 20), hjust = .5, size = 16\n    ),\n    plot.margin = margin(r = 40, l = 40)\n  )\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\n\n\n\n\n\n\n\nTo export the result of ggplot we can use the function ggsave(\"name.png\")."
  },
  {
    "objectID": "blog/visualize-urban-growth/index.html#dynamic-map-with-leaflet",
    "href": "blog/visualize-urban-growth/index.html#dynamic-map-with-leaflet",
    "title": "Visualize urban growth",
    "section": "Dynamic map with leaflet",
    "text": "Dynamic map with leaflet\nA very interesting advantage is the tmap_leaflet() function of the tmap package to easily pass a map created in the same frame to leaflet.\n\n# tmap object\nm &lt;- tm_shape(buildings_val25) +\n  tm_polygons(\"yr_cl\",\n    border.col = \"transparent\",\n    palette = col_spec_fun(15), # adapt to the number of classes\n    textNA = \"Without data\",\n    title = \"\"\n  )\n\n\n# dynamic map\ntmap_leaflet(m)"
  },
  {
    "objectID": "blog/use-multidimensional-spatial-data/index.html",
    "href": "blog/use-multidimensional-spatial-data/index.html",
    "title": "Use of multidimensional spatial data",
    "section": "",
    "text": "Space-time information is vital in many disciplines, especially in climatology or meteorology, and this makes it necessary to have a format that allows a multidimensional structure. It is also important that this format has a high degree of interchange compatibility and can store a large number of data. These characteristics led to the development of the open standard netCDF (NetworkCommon Data Form). The netCDF format is an open multi-dimensional scientific data exchange standard used with observational or model data, primarily in disciplines such as climatology, meteorology, and oceanography. The netCDF convention is managed by Unidata (https://www.unidata.ucar.edu/software/netcdf/). It is a space-time format with a regular or irregular grid. The multidimensional structure in the form of an array allows the use of space-time and multivariable data. The general characteristics of netCDF refer to the use of an n-dimensional coordinate system, multiple variables, and a regular or irregular grid. In addition, metadata describing the contents are included. The extension of the netCDF format is “nc”.\n\nI recently used drought data from Spain in netCDF format with a resolution of 1 km to represent the state of drought for each year since 1960 (https://monitordesequia.csic.es/historico/). The SPEI index (Standardized Precipitation-Evapotranspiration Index) is widely used to describe the drought with different time intervals (3, 6, 12 months, etc.).\n\nI have been asked on several occasions about handling the netCDF format. For this reason, in this post, we will use a subset of these same data, the year 2017 of the SPEI 12 months."
  },
  {
    "objectID": "blog/use-multidimensional-spatial-data/index.html#spain",
    "href": "blog/use-multidimensional-spatial-data/index.html#spain",
    "title": "Use of multidimensional spatial data",
    "section": "Spain",
    "text": "Spain\nTo create a map of drought severity in 2017, we must first make some modifications. With the subset() function, we obtain a layer or several as a subset. Here we select the last one to see the state of drought for the whole year.\nWe replace all values greater than -0.5 with NA in the next step. Drought is considered when the SPEI index is below -0.5 and, on the other hand, if it is above 0.5, we would speak of a wet period.\nThe raster class is not directly compatible with ggplot, so we convert it to an xyz table with longitude, latitude and the variable. When we do the same conversion of multiple layers, each column will represent one layer. Finally, we rename our index column and add a new column with different levels of drought severity.\n\n# extract layer(s) with their index\nspei_anual &lt;- subset(spei, 48)\n\n# substitute non-drought values with NA\nspei_anual[spei_anual &gt; -0.5] &lt;- NA\n\n# convert our raster into an xyz table\nspei_df &lt;- as.data.frame(spei_anual, xy = TRUE)\nhead(spei_df)\n\n           x       y spei12_2017_48\n38096 123100 4858900          -1.48\n39195 105500 4857800          -1.59\n39197 107700 4857800          -1.40\n39211 123100 4857800          -1.47\n39212 124200 4857800          -1.50\n40310 105500 4856700          -1.63\n\n# change the name of the variable\nnames(spei_df)[3] &lt;- \"spei\"\n\n# categorize the index and fix the order of the factor\nspei_df &lt;- mutate(spei_df, spei_cat = case_when(\n  spei &gt; -0.9 ~ \"slight\",\n  spei &gt; -1.5 & spei &lt; -0.9 ~ \"moderate\",\n  spei &gt; -2 & spei &lt;= -1.5 ~ \"severe\",\n  TRUE ~ \"extreme\"\n) |&gt;\n  fct_relevel(c(\"slight\", \"moderate\", \"severe\", \"extreme\")))\n\nWe can create a raster map with the geom_tile() geometry indicating longitude, latitude and the fill of the pixels with our categorized variable.\n\n# boundaries\nccaa &lt;- esp_get_ccaa() |&gt;\n  filter(!ine.ccaa.name %in% c(\"Canarias\", \"Ceuta\", \"Melilla\")) |&gt;\n  st_transform(25830)\n\n# mapa\nggplot(spei_df) +\n  geom_tile(aes(x, y, fill = spei_cat)) +\n  geom_sf(data = ccaa, fill = NA, linewdith = .1, colour = \"white\", alpha = .4) +\n  scale_fill_manual(\n    values = c(\"#ffffcc\", \"#F3641D\", \"#DE2929\", \"#8B1A1A\"),\n    na.value = NA\n  ) +\n  coord_sf() +\n  labs(fill = \"DROUGHT\") +\n  theme_void() +\n  theme(\n    legend.position = \"top\",\n    legend.justification = 0.2,\n    plot.background = element_rect(fill = \"black\", colour = NA),\n    legend.title = element_text(colour = \"white\", size = 20, hjust = .5),\n    legend.text = element_text(colour = \"white\"),\n    plot.margin = margin(t = 10),\n    legend.key.height = unit(0.3, \"lines\"),\n    legend.key.width = unit(2, \"lines\"),\n    legend.text.position = \"bottom\",\n    legend.title.position = \"top\"\n  )\n\nWarning in layer_sf(geom = GeomSf, data = data, mapping = mapping, stat = stat,\n: Ignoring unknown parameters: `linewdith`"
  },
  {
    "objectID": "blog/use-multidimensional-spatial-data/index.html#aragon",
    "href": "blog/use-multidimensional-spatial-data/index.html#aragon",
    "title": "Use of multidimensional spatial data",
    "section": "Aragon",
    "text": "Aragon\nIn this last map example, we select the drought situation 12 months ahead, at the beginning and end of the year. The main function we use is crop() that cuts to the extent of a spatial object; in our case, it is Aragon, then we apply the mask() function that masks all those pixels within limits leaving the others in NA.\n\n# subset first and last week 2017\nspei_sub &lt;- subset(spei, c(1, 48))\n\n# crop and mask Aragon\nspei_arag &lt;- crop(spei_sub, aragon) |&gt;\n  mask(vect(aragon))\n\n# convert the data to xyz\nspei_df_arag &lt;- as.data.frame(spei_arag, xy = TRUE)\n\n# rename layers\nnames(spei_df_arag)[3:4] &lt;- c(\"January\", \"December\")\n\n# changing to the long table format by merging both months\nspei_df_arag &lt;- pivot_longer(spei_df_arag, 3:4,\n  names_to = \"mo\",\n  values_to = \"spei\"\n) |&gt;\n  mutate(mo = fct_relevel(mo, c(\"January\", \"December\")))\n\nWe will make the two maps in the same way as the one for whole Spain. The main difference is that we use the SPEI index directly as a continuous variable. Also, to create two maps as facets in one row, we add the facet_grid() function. Finally, the index shows negative and positive values; therefore, a divergent range of colours is necessary. To centre the midpoint at 0, we must rescale the index values using the rescale() function from the scales package.\n\n# map of Aragon\nggplot(spei_df_arag) +\n  geom_tile(aes(x, y, fill = spei)) +\n  scale_fill_distiller(\n    palette = \"RdYlGn\", direction = 1,\n    values = scales::rescale(c(-2.1, 0, 0.9)),\n    breaks = seq(-2, 1, .5)\n  ) +\n  facet_grid(. ~ mo) +\n  coord_sf() +\n  labs(fill = \"SPEI-12\", title = \"Aragon\") +\n  theme_void() +\n  theme(\n    legend.position = \"top\",\n    legend.justification = 0.5,\n    legend.title = element_text(colour = \"white\", vjust = 1.1),\n    strip.text = element_text(colour = \"white\"),\n    plot.background = element_rect(fill = \"black\", colour = NA),\n    plot.title = element_text(\n      colour = \"white\", size = 20, hjust = .5, vjust = 2.5,\n      margin = margin(b = 10, t = 10)\n    ),\n    legend.text = element_text(colour = \"white\"),\n      legend.key.height = unit(0.5, \"lines\"),\n    legend.key.width = unit(3, \"lines\"),\n    plot.margin = margin(10, 10, 10, 10)\n  )"
  },
  {
    "objectID": "blog/river-flow-directions/index.html",
    "href": "blog/river-flow-directions/index.html",
    "title": "River flow directions",
    "section": "",
    "text": "I recently created a visualization of the distribution of river flow directions and also of coastal orientations. Following its publication in social networks, I was asked to make a post about how I did it. Well, here we go to start with an example of rivers, coastal orientation is somewhat more complex. I did the same for a selection of European rivers here in this. However, originally I started with the orientation of the European coasts."
  },
  {
    "objectID": "blog/river-flow-directions/index.html#packages",
    "href": "blog/river-flow-directions/index.html#packages",
    "title": "River flow directions",
    "section": "Packages",
    "text": "Packages\nIn this post we will use the following packages:\n\n\n\n\n\n\n\n\nPackages\nDescription\n\n\n\ntidyverse\nCollection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.\n\n\nremotes\nInstallation from remote repositories\n\n\nqgisprocess\nInterface between R and QGIS\n\n\nsf\nSimple Feature: import, export and manipulate vector data\n\n\nggtext\nImproved text rendering support for ggplot2\n\n\ngeomtextpath\nggplot2 extension for curved text on lines\n\n\ncircular\nFunctions for working with circular data\n\n\ngeosphere\nSpherical trigonometry for geographic applications\n\n\n\n\n\nIn the case of the qgisprocess package, it is necessary to install QIGS &gt;= 3.16 here. I will explain the reason for using QGIS later.\n\n# install the packages if necessary\n\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"remotes\")) install.packages(\"remotes\")\nif (!require(\"qgisprocess\")) remotes::install_github(\"paleolimbot/qgisprocess\")\nif (!require(\"sf\")) install.packages(\"sf\")\nif (!require(\"ggtext\")) install.packages(\"ggtext\")\nif (!require(\"circular\")) install.packages(\"circular\")\nif (!require(\"geosphere\")) install.packages(\"geosphere\")\nif (!require(\"geomtextpath\")) install.packages(\"geomtextpath\")\n\n# packages\n\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(ggtext)\nlibrary(circular)\nlibrary(geosphere)\nlibrary(qgisprocess)\nlibrary(geomtextpath)"
  },
  {
    "objectID": "blog/river-flow-directions/index.html#data",
    "href": "blog/river-flow-directions/index.html#data",
    "title": "River flow directions",
    "section": "Data",
    "text": "Data\nWe download the central lines of the largest rivers in the world (here), also accessible in Zeenatul Basher et al. 2018."
  },
  {
    "objectID": "blog/river-flow-directions/index.html#import-and-project",
    "href": "blog/river-flow-directions/index.html#import-and-project",
    "title": "River flow directions",
    "section": "Import and project",
    "text": "Import and project\nThe first thing we do is to import, project the spatial lines and delete the third dimension Z, chaining the following functions: st_read() helps us import any vector format, st_zm() delete the dimension Z or M of a geometry and st_transform() projects the vector data to the new projection in proj4 format. We combine the functions with the famous pipe (|&gt;) that facilitates the application of a sequence of functions on a data set. All functions in the sf package start with st_* with reference to the spatial character, similar to PostGIS. In the same style as PostGIS, verbs are used as function names.\n\nproj_rob &lt;- \"ESRI:54030\"\n\nriver_line &lt;- st_read(\"RiverHRCenterlinesCombo.shp\") |&gt;\n  st_zm() |&gt;\n  st_transform(proj_rob)\n\nReading layer `RiverHRCenterlinesCombo' from data source \n  `C:\\Users\\xeo19\\Downloads\\dominicroye.github.io\\blog\\river-flow-directions\\RiverHRCenterlinesCombo.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 78 features and 6 fields\nGeometry type: MULTILINESTRING\nDimension:     XY, XYZ\nBounding box:  xmin: -164.7059 ymin: -36.97094 xmax: 151.5931 ymax: 72.64474\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "blog/river-flow-directions/index.html#extract-the-angles",
    "href": "blog/river-flow-directions/index.html#extract-the-angles",
    "title": "River flow directions",
    "section": "Extract the angles",
    "text": "Extract the angles\nIn the next step we have to extract the vertice angles. Unfortunately, as far as I know, it is not possible to extract the attributes with some function from the sf package. Although the function st_coordinates() returns the coordinates, it does not include other attributes. Therefore, we must use another way, and that is the open software Quantum GIS in which we can find a tool to extract all the vertice attributes. We could import the vector data into QGIS Desktop and export the vertices from there, but it is also possible to access the QGIS tools from R directly.\nFor this, we need to have QGIS installed. The qgisprocess package allows us to use very easily all the tools of the software in R. First we use the qgis_configure() function to define all the necessary QGIS paths.\n\n# paths to QGIS\nqgis_configure()\n\ngetOption('qgisprocess.path') was not found.\n\n\nSys.getenv('R_QGISPROCESS_PATH') was not found.\n\n\nTrying 'qgis_process' on PATH...\n\n\n'qgis_process' is not available on PATH.\n\n\nFound 2 QGIS installations containing 'qgis_process':\n C:/Program Files/QGIS 3.34.2/bin/qgis_process-qgis.bat\nC:/Program Files/QGIS 3.34.0/bin/qgis_process-qgis.bat\n\n\nTrying command 'C:/Program Files/QGIS 3.34.2/bin/qgis_process-qgis.bat'\n\n\nSuccess!\n\n\nNow using 'qgis_process' at 'C:/Program Files/QGIS 3.34.2/bin/qgis_process-qgis.bat'.\n\n\n&gt;&gt;&gt; If you need another installed QGIS instance, run `qgis_configure()`;\n    see `?qgis_configure` if you need to preset the path of 'qgis_process'.\n\n\n\n\n\nQGIS version is now set to: 3.34.2-Prizren\n\n\nUsing JSON for output serialization.\n\n\nUsing JSON for input serialization.\n\n\n\nStandard error message from 'qgis_process':\nProblem with GRASS installation: GRASS was not found or is not correctly installed\n\n\n2 out of 3 available processing provider plugins are enabled.\n\n\n\nStandard error message from 'qgis_process':\nProblem with GRASS installation: GRASS was not found or is not correctly installed\n\n\nYou now have access to 376 algorithms from 5 QGIS processing providers.\n\n\n\n\n\n&gt;&gt;&gt; Run `qgis_enable_plugins()` to enable 1 disabled plugin and access\n    its algorithms: otbprovider\n\n\n\nSaving configuration to 'C:\\Users\\xeo19\\AppData\\Local\\R-qgisprocess\\R-qgisprocess\\Cache/cache-0.4.1.rds'\n\n\nUse qgis_algorithms(), qgis_providers(), qgis_plugins(), qgis_path() and\nqgis_version() to inspect the cache environment.\n\n\nThe qgis_algorithms() function helps us to search for different QGIS tools. In addition the qgis_show_help() function specifies the way of usage with all the required parameters.\n\n# search tools\nqgis_algorithms()\n\n# A tibble: 376 × 24\n   provider provider_title algorithm                algorithm_id algorithm_title\n   &lt;chr&gt;    &lt;chr&gt;          &lt;chr&gt;                    &lt;chr&gt;        &lt;chr&gt;          \n 1 3d       QGIS (3D)      3d:tessellate            tessellate   Tessellate     \n 2 gdal     GDAL           gdal:aspect              aspect       Aspect         \n 3 gdal     GDAL           gdal:assignprojection    assignproje… Assign project…\n 4 gdal     GDAL           gdal:buffervectors       buffervecto… Buffer vectors \n 5 gdal     GDAL           gdal:buildvirtualraster  buildvirtua… Build virtual …\n 6 gdal     GDAL           gdal:buildvirtualvector  buildvirtua… Build virtual …\n 7 gdal     GDAL           gdal:cliprasterbyextent  cliprasterb… Clip raster by…\n 8 gdal     GDAL           gdal:cliprasterbymaskla… cliprasterb… Clip raster by…\n 9 gdal     GDAL           gdal:clipvectorbyextent  clipvectorb… Clip vector by…\n10 gdal     GDAL           gdal:clipvectorbypolygon clipvectorb… Clip vector by…\n# ℹ 366 more rows\n# ℹ 19 more variables: provider_can_be_activated &lt;lgl&gt;,\n#   provider_is_active &lt;lgl&gt;, provider_long_name &lt;chr&gt;, provider_version &lt;chr&gt;,\n#   provider_warning &lt;chr&gt;, can_cancel &lt;lgl&gt;, deprecated &lt;lgl&gt;, group &lt;chr&gt;,\n#   has_known_issues &lt;lgl&gt;, help_url &lt;chr&gt;, requires_matching_crs &lt;lgl&gt;,\n#   short_description &lt;chr&gt;, tags &lt;list&gt;, default_raster_file_extension &lt;chr&gt;,\n#   default_vector_file_extension &lt;chr&gt;, …\n\n# usage of tool\nqgis_show_help(\"native:extractvertices\")\n\nExtract vertices (native:extractvertices)\n\n----------------\nDescription\n----------------\nThis algorithm takes a line or polygon layer and generates a point layer with points representing the vertices in the input lines or polygons. The attributes associated to each point are the same ones associated to the line or polygon that the point belongs to.\n\nAdditional fields are added to the point indicating the vertex index (beginning at 0), the vertexs part and its index within the part (as well as its ring for polygons), distance along original geometry and bisector angle of vertex for original geometry.\n\n----------------\nArguments\n----------------\n\nINPUT: Input layer\n    Argument type:  source\n    Acceptable values:\n        - Path to a vector layer\nOUTPUT: Vertices\n    Argument type:  sink\n    Acceptable values:\n        - Path for new vector layer\n\n----------------\nOutputs\n----------------\n\nOUTPUT: &lt;outputVector&gt;\n    Vertices\n\n\nIn our case the tool to extract the vertices is simple and only has one input and one output. The function qgis_run_algorithm() executes a QGIS tool indicating the algorithm and its arguments. The advantage of using the algorithm directly from R is that we can pass objects of class sf (or sp) and raster that we have imported or created in R. As output we create a geojson, it could also be of another vector format, and we save it in a temporary folder. To obtain the QGIS output we need to use qgis_extract_output() function.\n\nriver_vertices &lt;- qgis_run_algorithm(\n  alg = \"native:extractvertices\",\n  INPUT = river_line,\n  OUTPUT = file.path(tempdir(), \"rivers_world_vertices.geojson\")\n)\n\nriver_vertices &lt;- st_read(qgis_extract_output(river_vertices, \"OUTPUT\"))\n\nReading layer `rivers_world_vertices' from data source \n  `C:\\Users\\xeo19\\AppData\\Local\\Temp\\RtmpSIybwj\\rivers_world_vertices.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 339734 features and 12 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -12117400 ymin: -3953778 xmax: 13751910 ymax: 7507359\nProjected CRS: World_Robinson"
  },
  {
    "objectID": "blog/river-flow-directions/index.html#selection",
    "href": "blog/river-flow-directions/index.html#selection",
    "title": "River flow directions",
    "section": "Selection",
    "text": "Selection\nBefore continuing with the distribution estimation of the angles, we filter some rivers of interest. The functions of the tidyverse collection are compatible with the sf package. In the last post I made an introduction to tidyverse here.\n\nriver_vertices &lt;- filter(\n  river_vertices,\n  NAME %in% c(\n    \"Mississippi\", \"Colorado\",\n    \"Amazon\", \"Nile\", \"Orange\",\n    \"Ganges\", \"Yangtze\", \"Danube\",\n    \"Mackenzie\", \"Lena\", \"Murray\",\n    \"Niger\"\n  )\n)\n\nriver_vertices\n\nSimple feature collection with 94702 features and 12 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -10377520 ymin: -3953778 xmax: 13124340 ymax: 7507359\nProjected CRS: World_Robinson\nFirst 10 features:\n   fid NAME SYSTEM name_alt scalerank rivernum Length_km vertex_index\n1    6 Nile   &lt;NA&gt;     &lt;NA&gt;         1        4  3343.871            0\n2    6 Nile   &lt;NA&gt;     &lt;NA&gt;         1        4  3343.871            1\n3    6 Nile   &lt;NA&gt;     &lt;NA&gt;         1        4  3343.871            2\n4    6 Nile   &lt;NA&gt;     &lt;NA&gt;         1        4  3343.871            3\n5    6 Nile   &lt;NA&gt;     &lt;NA&gt;         1        4  3343.871            4\n6    6 Nile   &lt;NA&gt;     &lt;NA&gt;         1        4  3343.871            5\n7    6 Nile   &lt;NA&gt;     &lt;NA&gt;         1        4  3343.871            6\n8    6 Nile   &lt;NA&gt;     &lt;NA&gt;         1        4  3343.871            7\n9    6 Nile   &lt;NA&gt;     &lt;NA&gt;         1        4  3343.871            8\n10   6 Nile   &lt;NA&gt;     &lt;NA&gt;         1        4  3343.871            9\n   vertex_part vertex_part_index  distance      angle                geometry\n1            0                 0     0.000  31.096005 POINT (3037149 1672482)\n2            0                 1  1208.130  22.456672 POINT (3037772 1673517)\n3            0                 2  2324.160   8.602259 POINT (3038039 1674600)\n4            0                 3  3656.452   8.573580 POINT (3038118 1675930)\n5            0                 4  5735.538  24.406889 POINT (3038612 1677950)\n6            0                 5  6758.322  25.134763 POINT (3039200 1678787)\n7            0                 6 10432.834   6.998982 POINT (3040164 1682333)\n8            0                 7 14865.136   4.239641 POINT (3040070 1686764)\n9            0                 8 16563.207 358.730530 POINT (3040356 1688438)\n10           0                 9 18376.526 347.480822 POINT (3039972 1690210)"
  },
  {
    "objectID": "blog/map-circle-packing/index.html",
    "href": "blog/map-circle-packing/index.html",
    "title": "Map of circles grouped in multiple locations",
    "section": "",
    "text": "In my first post of 2024, which unfortunately has not been possible before April, I will explain how we can group in the same location several proportional circles. In 2022 I was looking for how to represent the number of heat wave days according to the degree of severity in Spain. I found the solution using the circle packing which is also used in the Dorling cartogram."
  },
  {
    "objectID": "blog/map-circle-packing/index.html#packages",
    "href": "blog/map-circle-packing/index.html#packages",
    "title": "Map of circles grouped in multiple locations",
    "section": "Packages",
    "text": "Packages\n\n\n\n\n\n\n\n\n\nPackage\nDescription\n\n\n\n\ntidyverse\nCollection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.\n\n\nmapSpain\nAdministrative boundaries of Spain at different levels\n\n\ngiscoR\nAdministrative boundaries of the world\n\n\nsf\nSimple Feature: import, export and manipulate vector data\n\n\nggtext\nImproved text rendering support for ggplot2\n\n\nggrepel\nProvide ggplot2 geometries to repel overlapping text labels\n\n\ngeomtextpath\nAdd text to lines that can follow any path and will remain correctly spaced and angled.\n\n\npackcircles\nAlgorithms for finding non-overlapping circles.\n\n\ncartogram\nBuild different types of cartograms\n\n\n\n\n\n\n# install the packages if necessary\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"mapSpain\")) install.packages(\"mapSpain\")\nif (!require(\"sf\")) install.packages(\"sf\")\nif (!require(\"packcircles\")) install.packages(\"packcircles\")\nif (!require(\"ggtext\")) install.packages(\"ggtext\")\nif (!require(\"ggrepel\")) install.packages(\"ggrepel\")\nif (!require(\"cartogram\")) install.packages(\"cartogram\")\nif (!require(\"giscoR\")) install.packages(\"giscoR\")\nif (!require(\"rmapshaper\")) install.packages(\"rmapshaper\")\nif (!require(\"geomtextpath\")) remotes::install_github(\"AllanCameron/geomtextpath\")\n\n# packages\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(sf)\nlibrary(mapSpain)\nlibrary(ggrepel)\nlibrary(ggtext)\nlibrary(packcircles)\nlibrary(cartogram)\nlibrary(giscoR)\nlibrary(rmapshaper)\nlibrary(geomtextpath)"
  },
  {
    "objectID": "blog/map-circle-packing/index.html#data",
    "href": "blog/map-circle-packing/index.html#data",
    "title": "Map of circles grouped in multiple locations",
    "section": "Data",
    "text": "Data\nIn this post we will use a dataset of heat waves registered in the year 2022 (download). At the time I calculated the Excess Heat Factor index for different locations in Spain. You can find the formulas of the index in Díaz-Poso et al. (2023{:target=“_blank”}). It is a geojson with the number of heat wave days according to severity (low, severe, extreme) for 51 weather stations. The data needs to be projected, in this case it is ETRS89 UTM 30 (EPSG:25830). In addition, we import and modify the provincial and global boundaries to use them as a basis for the map.\n\n# import EHF heat wave 2022 data\nehf &lt;- st_read(\"ehf_2022_spain.geojson\")\n\nReading layer `ehf_2022_spain' from data source \n  `C:\\Users\\xeo19\\Downloads\\dominicroye.github.io\\blog\\map-circle-packing\\ehf_2022_spain.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 148 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -839774.5 ymin: 3150771 xmax: 1117513 ymax: 4815734\nProjected CRS: ETRS89 / UTM zone 30N\n\nehf\n\nSimple feature collection with 148 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -839774.5 ymin: 3150771 xmax: 1117513 ymax: 4815734\nProjected CRS: ETRS89 / UTM zone 30N\nFirst 10 features:\n                          stat_name  levels  n                 geometry\n1              BARCELONA AEROPUERTO     low 48 POINT (924574.5 4583673)\n2              BARCELONA AEROPUERTO  severe 21 POINT (924574.5 4583673)\n3                 GIRONA AEROPUERTO extreme  2 POINT (978052.4 4656058)\n4                 GIRONA AEROPUERTO     low 53 POINT (978052.4 4656058)\n5                 GIRONA AEROPUERTO  severe 14 POINT (978052.4 4656058)\n6  DONOSTIA / SAN SEBASTIÁN, IGELDO extreme  2 POINT (577768.2 4795286)\n7  DONOSTIA / SAN SEBASTIÁN, IGELDO     low 24 POINT (577768.2 4795286)\n8  DONOSTIA / SAN SEBASTIÁN, IGELDO  severe 14 POINT (577768.2 4795286)\n9                 BILBAO AEROPUERTO extreme  6 POINT (507593.1 4793918)\n10                BILBAO AEROPUERTO     low 31 POINT (507593.1 4793918)\n\n# basic plot\nplot(ehf)\n\n\n\n\n\n\n\n\n\n# provincial boundaries Spain\nesp &lt;- esp_get_prov(moveCAN = FALSE, epsg = \"4326\")\nplot(esp)\n\n\n\n\n\n\n\n\n\nesp_pen &lt;- filter(esp, nuts2.name != \"Canarias\")\n\n# interior boundaries of Spain\nesp_inline &lt;- rmapshaper::ms_innerlines(esp_pen)\n\n# global boundaries\neu &lt;- gisco_get_countries(res = 10) |&gt;\n  st_cast(\"MULTILINESTRING\") |&gt;\n  st_crop(\n    xmin = -10, ymin = 34.7,\n    xmax = 4.4, ymax = 43.8\n  )\nplot(eu)\n\n\n\n\n\n\n\n## Canary Islands\ncanlim &lt;- esp_get_ccaa(\"Canarias\", moveCAN = FALSE)\nbx &lt;- st_bbox(canlim)"
  },
  {
    "objectID": "blog/map-circle-packing/index.html#dorling-diagram",
    "href": "blog/map-circle-packing/index.html#dorling-diagram",
    "title": "Map of circles grouped in multiple locations",
    "section": "Dorling diagram",
    "text": "Dorling diagram\nWhen I started investigating possibilities to achieve circles in a grouped position without overlapping, I thought directly of the {cartogram_dorling() function from the {cartogram} package. The problem I faced was that it is designed for only one category or level, however, as we can see we have up to three levels of severity. If we use the function for low severity we get the following result.\n\n# Dorling low gravity map\ndor &lt;- cartogram_dorling(filter(ehf, levels == \"low\"), \"n\", k = .3)\n\n# map\nggplot(\n  dor,\n  aes(fill = n)\n) +\n  geom_sf(\n    data = esp,\n    fill = \"grey80\",\n    colour = \"white\",\n    linewidth = .3\n  ) +\n  geom_sf() +\n  scale_fill_distiller(palette = \"YlOrRd\", direction = 1) +\n  labs(fill = NULL, title = \"Number of heat weave days with low severity\") +\n  theme_void() +\n  theme(\n    legend.position = \"top\",\n    legend.key.height = unit(.5, \"lines\"),\n    legend.key.width = unit(3, \"lines\"),\n    plot.title = element_text(margin = margin(t = 5, b = 10), hjust = .5)\n  )\n\n\n\n\n\n\n\n\nSo, what can we do? We should take a closer look at the function, which facilitates the creation of the Dorling map (link). First we could create a map of small multiples, but one problem we encounter is that we cannot set a maximum value of a variable. So, we add and modify it slightly to the line where the area is calculated (dat.init$v).\n\ncartogram_dorling2.sf &lt;- function(x, weight,\n                                  limit_mx = NULL, # new argument\n                                  k = 5,\n                                  m_weight = 1,\n                                  itermax = 1000) {\n  # proj or unproj\n  if (sf::st_is_longlat(x)) {\n    stop('Using an unprojected map. This function does not give correct centroids and distances for longitude/latitude data:\\nUse \"st_transform()\" to transform coordinates to another projection.', call. = F)\n  }\n  # no 0 values\n  x &lt;- x[x[[weight]] &gt; 0, ]\n  # data prep\n  dat.init &lt;- data.frame(sf::st_coordinates(sf::st_centroid(sf::st_geometry(x))),\n    v = x[[weight]]\n  )\n  surf &lt;- (max(dat.init[, 1]) - min(dat.init[, 1])) * (max(dat.init[, 2]) - min(dat.init[, 2]))\n  # dat.init$v &lt;- dat.init$v * (surf * k / 100) / max(dat.init$v) # old\n\n  dat.init$v &lt;- dat.init$v * (surf * k / 100) / ifelse(is_null(limit_mx),\n    max(dat.init$v),\n    limit_mx\n  ) # new argument\n\n  # circles layout and radiuses\n  res &lt;- packcircles::circleRepelLayout(\n    x = dat.init, xysizecols = 1:3,\n    wrap = FALSE, sizetype = \"area\",\n    maxiter = itermax, weights = m_weight\n  )\n  # sf object creation\n  . &lt;- sf::st_buffer(\n    sf::st_as_sf(res$layout,\n      coords = c(\"x\", \"y\"),\n      crs = sf::st_crs(x)\n    ),\n    dist = res$layout$radius\n  )\n  sf::st_geometry(x) &lt;- sf::st_geometry(.)\n  return(x)\n}\n\nIf we now use the modified function, we will achieve multiple small Dorling’s. We simply map the new function on each category.\n\n# estimate the maximum value\nmax_value &lt;- max(ehf$n)\n\n# map over each category\ndor2 &lt;- split(ehf, ~levels) |&gt;\n  map(cartogram_dorling2.sf,\n    weight = \"n\",\n    k = .3,\n    limit_mx = max_value\n  )\n\n# rejoin the tables and set the order\ndor2 &lt;- bind_rows(dor2) |&gt;\n  mutate(levels = factor(levels, c(\"low\", \"severe\", \"extreme\")))\n\n# map of small multiples\nggplot(\n  dor2,\n  aes(fill = n)\n) +\n  geom_sf(\n    data = esp,\n    fill = \"grey80\",\n    colour = \"white\",\n    linewidth = .3\n  ) +\n  geom_sf() +\n  facet_grid(~levels) +\n  scale_fill_distiller(palette = \"YlOrRd\", direction = 1) +\n  labs(fill = NULL, title = \"Number of heat weave days with low severity\") +\n  theme_void() +\n  theme(\n    legend.position = \"top\",\n    legend.key.height = unit(.5, \"lines\"),\n    legend.key.width = unit(3, \"lines\"),\n    plot.title = element_text(margin = margin(t = 5, b = 10), hjust = .5)\n  )\n\n\n\n\n\n\n\n\nI found it interesting, but it was not what I was looking for. I also considered making a proportional symbol map with circles in the same location, using color mixing and transparency in the style of this map (link). Finally I decided to modify the function to achieve a grouped position with circle packing. I introduced another argument surf = null for the extension of the data set, also kept the change of introducing the possibility of the maximum value with the same aim, and I changed the circleRepelLayout() function to the circleProgressiveLayout() one. The second one arranges a set of circles, denoted by their sizes, placing consecutively each circle externally tangent to two previously placed circles avoiding overlaps. Unlike the original layout in which the circles are ordered by iterative pairwise repulsion within a bounding rectangle. Another potential alternative could be the use of networks or graphs with {ggraph}, but I have not yet gotten around to testing it.\n\npackedcircle_dodge_position.sf &lt;- function(x,\n                                           weight,\n                                           surf = NULL,\n                                           limit_mx = NULL, # new argument\n                                           k = .5) {\n  # proj or unproj\n  if (sf::st_is_longlat(x)) {\n    stop('Using an unprojected map. This function does not give correct centroids and distances for longitude/latitude data:\\nUse \"st_transform()\" to transform coordinates to another projection.', call. = F)\n  }\n  # no 0 values\n  x &lt;- x[x[[weight]] &gt; 0, ]\n  # data prep\n  dat.init &lt;- data.frame(sf::st_coordinates(sf::st_centroid(sf::st_geometry(x))),\n    v = x[[weight]]\n  )\n\n  if (is_null(surf)) surf &lt;- (max(dat.init[, 1]) - min(dat.init[, 1])) * (max(dat.init[, 2]) - min(dat.init[, 2]))\n\n  dat.init$v &lt;- dat.init$v * (surf * k / 100) / ifelse(is_null(limit_mx),\n    max(dat.init$v),\n    limit_mx\n  ) # new argument\n  # circles layout and radiuses\n  res &lt;- packcircles::circleProgressiveLayout(\n    x = dat.init,\n    sizecol = \"v\"\n  ) # other layout\n\n  res &lt;- mutate(res, x = dat.init$X + x, y = dat.init$Y + y) # reconvert to lon, lat\n\n  # sf object creation\n  . &lt;- sf::st_buffer(\n    sf::st_as_sf(res,\n      coords = c(\"x\", \"y\"),\n      crs = sf::st_crs(x)\n    ),\n    dist = res$radius\n  )\n  sf::st_geometry(x) &lt;- sf::st_geometry(.)\n\n  return(x)\n}"
  },
  {
    "objectID": "blog/map-circle-packing/index.html#creation-of-grouped-circles",
    "href": "blog/map-circle-packing/index.html#creation-of-grouped-circles",
    "title": "Map of circles grouped in multiple locations",
    "section": "Creation of grouped circles",
    "text": "Creation of grouped circles\nFirst, we must define global variables for all locations. Among others, the spatial extent of the data, the maximum value, the scale factor for the size, and the variable of interest.\n\nlimit_mx &lt;- max(ehf$n) # maximum value\nlonglat &lt;- st_coordinates(ehf) # UTM coordinates\nsurf &lt;- (max(longlat[, 1]) - min(longlat[, 1])) * (max(longlat[, 2]) - min(longlat[, 2])) # extension\nweight &lt;- \"n\" # variable\nk &lt;- .1 # size factor\n\nIn the next step, we split our data into as many subsets as locations using the split() function. Then we apply the circle packing function to each one individually with map() passing all the previously defined global arguments. After that, we would only have to gather all the spatial tables.\n\n# map over all locations\ncircle_dodge &lt;- split(ehf, ~stat_name) |&gt;\n  map(packedcircle_dodge_position.sf,\n    surf = surf, k = k,\n    weight = weight,\n    limit_mx = limit_mx\n  )\n\n# rejoin\ncircle_dodge &lt;- bind_rows(circle_dodge) |&gt;\n  mutate(levels = factor(\n    levels,\n    c(\"low\", \"severe\", \"extreme\")\n  )) # fijamos orden\n\nplot(circle_dodge[\"n\"]) # resultado"
  },
  {
    "objectID": "blog/map-circle-packing/index.html#map-construction",
    "href": "blog/map-circle-packing/index.html#map-construction",
    "title": "Map of circles grouped in multiple locations",
    "section": "Map construction",
    "text": "Map construction"
  },
  {
    "objectID": "blog/map-circle-packing/index.html#legend",
    "href": "blog/map-circle-packing/index.html#legend",
    "title": "Map of circles grouped in multiple locations",
    "section": "Legend",
    "text": "Legend\nIn the map construction the first thing we should make is the legend. We must create it manually by defining different magnitudes, in our case, number of days. Then we estimate the area and construct the circles artificially on a constant line of latitude at +45º, position where we will insert the legend as if it were a spatial object.\n\n# areas\nlegend_area &lt;- c(5, 10, 15, 30, 50) * (surf * k / 100) / limit_mx\n\n# circles construction at artificial coordinates\nlegend_dat &lt;- tibble(\n  area = legend_area, r = sqrt(area / pi),\n  n = c(5, 10, 15, 30, 50), y = 45\n) |&gt;\n  arrange(area) |&gt;\n  mutate(x = -4:0) |&gt;\n  st_as_sf(coords = c(\"x\", \"y\"), crs = st_crs(esp)) |&gt;\n  st_transform(25830) %&gt;% # switch to the other pipe for nested placehodler .\n  st_buffer(dist = .$r) |&gt;\n  st_cast(\"LINESTRING\")\n\nplot(legend_dat[\"n\"])\n\n\n\n\n\n\n\n\nA more compact alternative legend would be collapsed circles, which can be achieved by changing the position with respect to the largest circle. However, the legend in this case remains small because of the maximum size of the circles. An increase in the size of the circles would lead to overlapping between different locations.\n\n# circles construction at artificial coordinates\nlegend_dat2 &lt;- tibble(\n  area = legend_area, r = sqrt(area / pi),\n  n = c(5, 10, 15, 30, 50), y = 45\n) |&gt;\n  arrange(area) |&gt;\n  mutate(x = -3) |&gt;\n  st_as_sf(coords = c(\"x\", \"y\"), crs = st_crs(esp)) |&gt;\n  st_transform(25830)\n\nlegend_dat2 &lt;- cbind(legend_dat2, st_coordinates(legend_dat2)) |&gt;\n  mutate(Y = Y - (max(r) - r)) |&gt;\n  st_drop_geometry() |&gt;\n  st_as_sf(coords = c(\"X\", \"Y\"), crs = 25830) %&gt;%\n  st_buffer(dist = .$r) |&gt;\n  st_cast(\"LINESTRING\")\n\nplot(legend_dat2[\"n\"])"
  },
  {
    "objectID": "blog/map-circle-packing/index.html#canary-islands",
    "href": "blog/map-circle-packing/index.html#canary-islands",
    "title": "Map of circles grouped in multiple locations",
    "section": "Canary Islands",
    "text": "Canary Islands\nThe first map would correspond to the Canary Islands, which is added to the main map in a false position. In ggplot2 any simple feature geometry can be added with geom_sf() by adjusting the own characteristics of points, lines or polygons.\n\ncan &lt;- ggplot() +\n  geom_sf(data = esp, fill = \"grey20\", colour = NA) +\n  geom_sf(\n    data = esp_inline, colour = \"white\",\n    size = .2\n  ) +\n  geom_sf(\n    data = circle_dodge,\n    aes(fill = levels),\n    alpha = .8,\n    colour = \"white\",\n    stroke = .025,\n    show.legend = FALSE\n  ) +\n  scale_fill_manual(\n    values = c(\"#feb24c\", \"#fc4e2a\", \"#b10026\"),\n    guide = \"none\"\n  ) +\n  theme_void(base_family = \"Lato\") +\n  labs(title = \"Canary Islands\") +\n  theme(\n    plot.background = element_rect(fill = NA, colour = \"black\"),\n    plot.title = element_text(vjust = 8, margin = margin(b = 4, l = 3))\n  ) +\n  coord_sf(\n    xlim = bx[c(1, 3)],\n    ylim = bx[c(2, 4)],\n    crs = 4326\n  )\n\ncan"
  },
  {
    "objectID": "blog/map-circle-packing/index.html#spain",
    "href": "blog/map-circle-packing/index.html#spain",
    "title": "Map of circles grouped in multiple locations",
    "section": "Spain",
    "text": "Spain\nTo build the main map, we will exclude the locations of the Canary Islands. In addition, we need to have the new position of the Canary Islands in the southwest of the Peninsula. The main difference with the previous map is that we include the legend as a spatial object using the geom_textsf() function. It is a variant of the {geomtextpath} package to add a label following any geometry path. Unfortunately, not all possible arguments of the package (issue) can be used. It is important that the geometry must be of type LINESTRING. Therefore, we changed the type with st_cast() above. Finally, we insert the map of the Canary Islands using the annotation_custom() function. More details about inserted maps can be found here.\n\n# filter out locations in mainland Spain and the Balearic Islands\nesp_data &lt;- st_filter(circle_dodge, st_transform(esp_pen, 25830))\n\n# coordinates of the Canary Islands moved position\ncan_ext &lt;- c(xmin = -11.74, ymin = 34.92, xmax = -7, ymax = 36.70)\nclass(can_ext) &lt;- \"bbox\"\n\ncan_bbx &lt;- st_as_sfc(can_ext) |&gt;\n  st_set_crs(4326) |&gt;\n  st_transform(25830) |&gt;\n  st_bbox()\n\n# part one adding the base map limits\ng1 &lt;- ggplot() +\n  geom_sf(data = eu, colour = \"grey80\", size = .3) +\n  geom_sf(data = esp_pen, fill = \"grey20\", colour = NA) +\n  geom_sf(\n    data = esp_inline, colour = \"white\",\n    size = .2\n  )\n\n# add the grouped proportional circles\ng2 &lt;- g1 + geom_sf(\n  data = esp_data,\n  aes(fill = levels),\n  alpha = .7,\n  colour = \"white\",\n  stroke = .02,\n  show.legend = \"point\"\n) +\n  geom_sf(data = legend_dat, aes(label = n)) + \n  geom_text(\n    data = st_centroid(legend_dat), # legend in artifical\n    aes(label = n, geometry = geometry),\n    stat = \"sf_coordinates\",\n    size = 2.5, vjust = 0.5\n  ) +\n1\n  # geom_textsf(data = legend_dat,  # position lat 45º.  not working due to bug\n  #          aes(label = n),\n  #          size = 2.5, hjust = .21) +\n  annotation_custom(ggplotGrob(can), # Canary Islands\n    xmin = can_bbx[1], xmax = can_bbx[3],\n    ymin = can_bbx[2], ymax = can_bbx[4]\n  )\n\n# final adjustments of legend and style\ng2 + scale_fill_manual(values = c(\"#feb24c\", \"#fc4e2a\", \"#b10026\")) +\n  guides(fill = guide_legend(override.aes = list(size = 5, shape = 21))) +\n  labs(fill = \"severity\", title = \"HEAT WAVE DAYS 2022\") +\n  theme_void() +\n  theme(\n    legend.position = \"top\",\n    legend.text.position = \"bottom\",\n    legend.title.position = \"top\",\n    legend.text = element_text(vjust = 3),\n    legend.title = element_text(\n      hjust = .5,\n      size = 14\n    ),\n    legend.margin = margin(t = 5),\n    plot.title = element_text(\n      hjust = .5,\n      face = \"bold\",\n      size = 25,\n      margin = margin(b = 5, t = 20)\n    ),\n    plot.margin = margin(15, 2, 2, 5)\n  ) +\n  coord_sf(crs = 25830, clip = \"off\")\n\n\n1\n\nThere seems to be a bug for the geom_textsf() function from the geomtextpath package. Therefore I use here an alternative way. (30/12/2024)"
  },
  {
    "objectID": "blog/map-circle-packing/index.html#interactive-version",
    "href": "blog/map-circle-packing/index.html#interactive-version",
    "title": "Map of circles grouped in multiple locations",
    "section": "Interactive version",
    "text": "Interactive version\nAs an extra of this post, I show you how we can make the same map interactively using the {ggiraph} package. We only change the geom_sf() function for its geom_sf_interactive() variant. In addition, we indicate what we want to show in the tooltip. We put the result in an object to finish building the interactive version using giraph() and including style settings.\n\nif (!require(\"ggiraph\")) install.packages(\"ggiraph\")\nlibrary(ggiraph) # versión interactiva de geometrias ggplot\n\ng1 &lt;- ggplot() +\n  geom_sf(data = eu, colour = \"grey80\", size = .3) +\n  geom_sf(data = esp_pen, fill = \"grey20\", colour = NA) +\n  geom_sf(\n    data = esp_inline, colour = \"white\",\n    size = .2\n  )\n\ng2 &lt;- g1 + geom_sf_interactive(\n  data = esp_data,\n  aes(fill = levels, tooltip = n), # interactive version with tooltip\n  alpha = .7,\n  colour = \"white\",\n  stroke = .02,\n  show.legend = \"point\"\n) +\n  geom_sf(data = legend_dat, aes(label = n)) +\n    geom_text(\n    data = st_centroid(legend_dat), # legend in artifical\n    aes(label = n, geometry = geometry),\n    stat = \"sf_coordinates\",\n    size = 2.5, vjust = 0.5\n  )\n\ng_final &lt;- g2 + scale_fill_manual(values = c(\"#feb24c\", \"#fc4e2a\", \"#b10026\")) +\n  guides(fill = guide_legend(override.aes = list(size = 5, shape = 21))) +\n  labs(fill = \"severity\", title = \"HEAT WAVE DAYS 2022\") +\n  theme_void() +\n  theme(\n    legend.position = \"top\",\n    legend.text.position = \"bottom\",\n    legend.title.position = \"top\",\n    legend.text = element_text(vjust = 3),\n    legend.title = element_text(\n      hjust = .5,\n      size = 14\n    ),\n    legend.margin = margin(t = 5),\n    plot.title = element_text(\n      hjust = .5,\n      face = \"bold\",\n      size = 25,\n      margin = margin(b = 5, t = 20)\n    ),\n    plot.margin = margin(15, 2, 2, 5)\n  ) +\n  coord_sf(crs = 25830, clip = \"off\")\n\n# creation of the final interactive map\ngirafe(\n  ggobj = g_final,\n  width_svg = 14.69,\n  height_svg = 12,\n  options = list(\n    opts_tooltip(opacity = 0.7, use_fill = T)\n  )\n)"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Meeting People Where They R",
    "section": "",
    "text": "Always normalize you data\n\n\nI recently came across a map from the National Atlas of Spain showing the number of libraries by municipality. However, one thing directly caught my attention. There’s a saying that many maps show only the population, and this seems to be the case here. The map does not provide any remarkable information about the distribution of libraries; it merely shows where the most people live.\n\n\n\ngis\n\n\nR\n\n\nR:elementary\n\n\nvisualization\n\n\nmap\n\n\nproportional symbol\n\n\nnormalize\n\n\n\n\n\n\nJan 5, 2025\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nMap of circles grouped in multiple locations\n\n\nIn my first post of 2024, which unfortunately has not been possible before April, I will explain how we can group in the same location several proportional circles. In 2022 I was looking for how to represent the number of heat wave days according to the degree of severity in Spain. I found the solution using the circle packing which is also used in the Dorling cartogram.\n\n\n\ngis\n\n\nR\n\n\nR:advanced\n\n\nvisualization\n\n\nmap\n\n\nproportional symbol\n\n\ncircles\n\n\n\n\n\n\nApr 20, 2024\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nInserted maps with ggplot2\n\n\nA short post on how we can position an outermost territory near the main map or insert an orientation map. In this example we use the typical map of Spain where the Canary Islands are located in the southwest of the peninsula.\n\n\n\ngis\n\n\nR\n\n\nR:elementary\n\n\nvisualization\n\n\n\n\n\n\nOct 8, 2023\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nHillshade effects\n\n\nIt is very common to see relief maps with shadow effects, also known as ‘hillshade’, which generates visual depth. How can we create these effects in R and how to include them in ggplot2?\n\n\n\ngis\n\n\nR\n\n\nR:intermediate\n\n\nvisualization\n\n\nhillshade\n\n\nDEM\n\n\nelevation\n\n\n\n\n\n\nJul 20, 2022\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nUse of multidimensional spatial data\n\n\nSpace-time information is vital in many disciplines, especially in climatology or meteorology, and this makes it necessary to have a format that allows a multidimensional structure. It is also important that this format has a high degree of interchange compatibility and can store a large number of data.\n\n\n\ngis\n\n\nR\n\n\nR:advanzed\n\n\nvisualization\n\n\nncdf\n\n\ndrought\n\n\nspain\n\n\nraster\n\n\n\n\n\n\nMar 8, 2022\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nVisualize the day-night cycle on a world map\n\n\nIn April of this year, I made an animation of the 24-hour average temperature of January 2020, also showing the day-night cycle. My biggest problem was finding a way to project correctly the area at night without breaking the geometry. The easiest solution I found was rasterising the night polygon and then reprojecting it. Indeed, a vector approach could be used, but I have preferred to use raster data here.\n\n\n\ngis\n\n\nR\n\n\nR:intermediate\n\n\nvisualization\n\n\nworld map\n\n\nday-night\n\n\nanimation\n\n\n\n\n\n\nDec 20, 2021\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nClimate circles\n\n\nThe climate of a place is usually presented through climographs that combine monthly precipitation and temperature in a single chart. However, it is also interesting to visualize the climate on a daily scale showing the thermal amplitude and the daily average temperature. To do this, the averages for each day of the year of the daily minimums, maximums and averages are calculated. The annual climate cycle presents a good opportunity to use a radial or polar which allows us to clearly visualize seasonal patterns.\n\n\n\nR\n\n\nR:elementary\n\n\nvisualization\n\n\nclimate\n\n\npolar\n\n\ntemperature\n\n\n\n\n\n\nSep 4, 2021\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nFirefly cartography\n\n\nFirefly maps are promoted and described by John Nelson who published a post in 2016 about its characteristics. However, these types of maps are linked to ArcGIS, which has led me to try to recreate them in R.\n\n\n\ngis\n\n\nR\n\n\nR:intermediate\n\n\nvisualization\n\n\nfirefly\n\n\nmap\n\n\ncartography\n\n\n\n\n\n\nJun 1, 2021\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nBivariate dasymetric map\n\n\nA disadvantage of choropleth maps is that they tend to distort the relationship between the true underlying geography and the represented variable. It is because the administrative divisions do not usually coincide with the geographical reality where people live. Besides, large areas appear to have a weight that they do not really have because of sparsely populated regions. To better reflect reality, more realistic population distributions are used, such as land use. With Geographic Information Systems techniques, it is possible to redistribute the variable of interest as a function of a variable with a smaller spatial unit.\n\n\n\ngis\n\n\nR\n\n\nR:advanced\n\n\nvisualization\n\n\nbivariate\n\n\nmap\n\n\nincome\n\n\nurban\n\n\n\n\n\n\nMar 1, 2021\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nA heatmap as calendar\n\n\nRecently I was looking for a visual representation to show the daily changes of temperature, precipitation and wind in an application xeo81.shinyapps.io/MeteoExtremosGalicia (in Spanish), which led me to use a heatmap in the form of a calendar. The shiny application is updated every four hours with new data showing calendars for each weather station.\n\n\n\nvisualization\n\n\nR\n\n\nR:intermediate\n\n\ncalendar\n\n\nheatmap\n\n\nclimate\n\n\n\n\n\n\nDec 20, 2020\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nClimate animation of maximum temperatures\n\n\nIn the field of data visualization, the animation of spatial data in its temporal dimension can show fascinating changes and patterns. As a result of one of the last publications in the social networks that I have made, I was asked to make a post about how I created it. Well, here we go to start with an example of data from mainland Spain.\n\n\n\nvisualization\n\n\nR\n\n\nR:advanced\n\n\nanimation\n\n\ntemperature\n\n\nclimate\n\n\ngis\n\n\n\n\n\n\nOct 11, 2020\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nRiver flow directions\n\n\nI recently created a visualization of the distribution of river flow directions and also of coastal orientations. Following its publication in social networks, I was asked to make a post about how I did it. Well, here we go to start with an example of rivers, coastal orientation is somewhat more complex.\n\n\n\ngis\n\n\nR\n\n\nR:advanced\n\n\nriver\n\n\ndirections\n\n\ndistribution\n\n\n\n\n\n\nJul 24, 2020\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nVisualize climate anomalies\n\n\nWhen we visualize precipitation and temperature anomalies, we simply use time series as bar graph indicating negative and positive values in red and blue. However, in order to have a better overview we need both anomalies in a single graph. In this way we could more easly answer the question of whether a particular season or month was dry-warm or wet-cold, and even compare these anomalies in the context of previous years.\n\n\n\nvisualization\n\n\nR\n\n\nR:intermediate\n\n\nclimate\n\n\nanomaly\n\n\ntemperature\n\n\n\n\n\n\nMar 29, 2020\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nGeographic distance\n\n\nThe first post of this year 2020, I will dedicate to a question that I was recently asked. The question was how to calculate the shortest distance between different points and how to know which is the closest point. When we work with spatial data in R, currently the easiest thing is to use the sf package in combination with the tidyverse collection of packages. We also use the units package which is very useful for working with units of measurement.\n\n\n\nspatial analysis\n\n\nR\n\n\nR:elementary\n\n\ngis\n\n\ndistance\n\n\ncities\n\n\n\n\n\n\nJan 19, 2020\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nVisualize urban growth\n\n\nThe General Directorate for the Cadastre of Spain has spatial information of the all buildings except for the Basque Country and Navarra. This data set is part of the implementation of INSPIRE, the Space Information Infrastructure in Europe. More information can be found here. We will use the links (urls) in ATOM format, which is an RSS type for web feeds, allowing us to obtain the download links for each municipality.\n\n\n\nvisualization\n\n\nR\n\n\nR:elementary\n\n\ngis\n\n\ncity\n\n\ngeography\n\n\n\n\n\n\nNov 1, 2019\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nVisualize monthly precipitation anomalies\n\n\nNormally when we visualize monthly precipitation anomalies, we simply use a bar graph indicating negative and positive values with red and blue. However, it does not explain the general context of these anomalies. For example, what was the highest or lowest anomaly in each month? In principle, we could use a boxplot to visualize the distribution of the anomalies, but in this particular case they would not fit aesthetically, so we should look for an alternative. Here I present a very useful graphic form.\n\n\n\nvisualization\n\n\nR\n\n\nR:intermediate\n\n\nanomaly\n\n\nclimate\n\n\nprecipitation\n\n\nboxplot\n\n\n\n\n\n\nJul 7, 2019\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nTidy correlation tests in R\n\n\nWhen we try to estimate the correlation coefficient between multiple variables, the task is more complicated in order to obtain a simple and tidy result. A simple solution is to use the tidy() function from the {broom} package. As an example, in this post we are going to estimate the correlation coefficients between the annual precipitation of several Spanish cities and climate teleconnections indices.\n\n\n\nstatistics\n\n\nR\n\n\nR:advanced\n\n\ncorrelation\n\n\ntests\n\n\n\n\n\n\nApr 17, 2019\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nImport Excel sheets with R\n\n\nWe usually work with different data sources, and sometimes we can find tables distributed over several Excel sheets. In this post we are going to import the average daily temperature of Madrid and Berlin which is found in two Excel files with sheets for each year between 2000 and 2005.\n\n\n\nmanagement\n\n\nR\n\n\nR:intermediate\n\n\nexcel\n\n\nsheets\n\n\n\n\n\n\nMar 10, 2019\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nCalculating the distance to the sea in R\n\n\nThe distance to the sea is a fundamental variable in geography, especially relevant when it comes to modeling. For example, in interpolations of air temperature, the distance to the sea is usually used as a predictor variable, since there is a casual relationship between the two that explains the spatial variation. How can we estimate the (shortest) distance to the coast in R?\n\n\n\ngis\n\n\nR\n\n\nR:elementary\n\n\ndistance\n\n\nraster\n\n\n\n\n\n\nJan 8, 2019\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nHow to create ‘Warming Stripes’ in R\n\n\nThis year, the so-called warming stripes, which were created by the scientist Ed Hawkins of the University of Reading, became very famous all over the world. These graphs represent and communicate climate change in a very illustrative and effective way.\n\n\n\ndatavis\n\n\nR\n\n\nR:elementary\n\n\nwarming stripes\n\n\nglobal warming\n\n\nvisualization\n\n\n\n\n\n\nDec 5, 2018\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nAccessing OpenStreetMap data with R\n\n\nRecently I created a map of the distribution of gas stations and electric charging stations in Europe. How can you obtain this data? Well, in this case I used points of interest (POIs) from the database of Open Street Maps (OSM). Obviously OSM not only contains the streets and highways, but also information that can be useful when we use a map such as locations of hospitals or gas stations.\n\n\n\nvisualization\n\n\nR:elementary\n\n\nR\n\n\nmap\n\n\nOSM\n\n\npoint of interest\n\n\n\n\n\n\nNov 3, 2018\n\n\nDominic Royé\n\n\n\n\n\n\nNo matching items\n\n\n  \n\n Back to topReuseCC BY-NC-SA 4.0"
  },
  {
    "objectID": "blog/how-to-create-warming-stripes-in-r/index.html",
    "href": "blog/how-to-create-warming-stripes-in-r/index.html",
    "title": "How to create ‘Warming Stripes’ in R",
    "section": "",
    "text": "This year, the so-called warming stripes, which were created by the scientist Ed Hawkins of the University of Reading, became very famous all over the world. These graphs represent and communicate climate change in a very illustrative and effective way.\nIn this post I will show how you can create these strips in R with the ggplot2 library. Although I must say that there are many ways in R that can lead us to the same result or to a similar one, even within ggplot2."
  },
  {
    "objectID": "blog/how-to-create-warming-stripes-in-r/index.html#data",
    "href": "blog/how-to-create-warming-stripes-in-r/index.html#data",
    "title": "How to create ‘Warming Stripes’ in R",
    "section": "Data",
    "text": "Data\nIn this case we will use the annual temperatures of Lisbon GISS Surface Temperature Analysis, homogenized time series, comprising the period from 1880 to 2018. Monthly temperatures or other time series could also be used. The file can be downloaded here. First, we should, as long as we have not done it, install the collection of tidyverse packages that also include ggplot2. Then, we import the data of Lisbon in csv format.\n\n# install the lubridate and tidyverse libraries\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\n\n# packages\nlibrary(tidyverse)\nlibrary(RColorBrewer)\n\n# import the annual temperatures\ntemp_lisboa &lt;- read_csv(\"temp_lisboa.csv\")\n\nstr(temp_lisboa)\n\nspc_tbl_ [139 × 18] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ YEAR  : num [1:139] 1880 1881 1882 1883 1884 ...\n $ JAN   : num [1:139] 9.17 11.37 10.07 10.86 11.16 ...\n $ FEB   : num [1:139] 12 11.8 11.9 11.5 10.6 ...\n $ MAR   : num [1:139] 13.6 14.1 13.5 10.5 12.4 ...\n $ APR   : num [1:139] 13.1 14.4 14 13.8 12.2 ...\n $ MAY   : num [1:139] 15.7 17.3 15.6 14.6 16.4 ...\n $ JUN   : num [1:139] 17 19.2 17.9 17.2 19.1 ...\n $ JUL   : num [1:139] 19.1 21.8 20.3 19.5 21.4 ...\n $ AUG   : num [1:139] 20.6 23.5 21 21.6 22.4 ...\n $ SEP   : num [1:139] 20.7 20 18 18.8 19.5 ...\n $ OCT   : num [1:139] 17.9 16.3 16.4 15.8 16.4 ...\n $ NOV   : num [1:139] 12.5 14.7 13.7 13.5 12.5 ...\n $ DEC   : num [1:139] 11.07 9.97 10.66 9.46 10.25 ...\n $ D-J-F : num [1:139] 10.7 11.4 10.6 11 10.4 ...\n $ M-A-M : num [1:139] 14.1 15.2 14.3 12.9 13.6 ...\n $ J-J-A : num [1:139] 18.9 21.5 19.7 19.4 20.9 ...\n $ S-O-N : num [1:139] 17 17 16 16 16.1 ...\n $ metANN: num [1:139] 15.2 16.3 15.2 14.8 15.3 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   YEAR = col_double(),\n  ..   JAN = col_double(),\n  ..   FEB = col_double(),\n  ..   MAR = col_double(),\n  ..   APR = col_double(),\n  ..   MAY = col_double(),\n  ..   JUN = col_double(),\n  ..   JUL = col_double(),\n  ..   AUG = col_double(),\n  ..   SEP = col_double(),\n  ..   OCT = col_double(),\n  ..   NOV = col_double(),\n  ..   DEC = col_double(),\n  ..   `D-J-F` = col_double(),\n  ..   `M-A-M` = col_double(),\n  ..   `J-J-A` = col_double(),\n  ..   `S-O-N` = col_double(),\n  ..   metANN = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nWe see in the columns that we have monthly and seasonal values, and the annual temperature value. But before proceeding to visualize the annual temperature, we must replace the missing values 999.9 with NA, using the ifelse( ) function that evaluates a condition and perform the given argument corresponding to true and false.\n\n# select only the annual temperature and year column\ntemp_lisboa_yr &lt;- select(temp_lisboa, YEAR, ta = metANN)\n\n# missing values 999.9\nsummary(temp_lisboa_yr)\n\n      YEAR            ta        \n Min.   :1880   Min.   : 14.53  \n 1st Qu.:1914   1st Qu.: 15.65  \n Median :1949   Median : 16.11  \n Mean   :1949   Mean   : 37.38  \n 3rd Qu.:1984   3rd Qu.: 16.70  \n Max.   :2018   Max.   :999.90  \n\ntemp_lisboa_yr &lt;- mutate(temp_lisboa_yr, ta = ifelse(ta == 999.9, NA, ta))\n\nWhen we use the year as a variable, we do not usually convert it into a date object, however it is advisable. This allows us to use the date functions of the lubridate package and the support functions inside of ggplot2. The str_c( ) function of the library stringr, part of the collection of tidyverse, is similar to paste( ) of R Base that allows us to combine characters by specifying a separator (sep = “-”). The ymd( ) (year month day) function of the lubridate package converts a date character into a Date object. It is possible to combine several functions using the pipe operator %&gt;% or |&gt; that helps to chain without assigning the result to a new object. The first pipe in R was %&gt;% very extended especially within the tidyverse package collection. If you want to know more about its use, you can find here a tutorial or some details on differences between both here.\n\ntemp_lisboa_yr &lt;- mutate(temp_lisboa_yr, date = make_date(YEAR))"
  },
  {
    "objectID": "blog/how-to-create-warming-stripes-in-r/index.html#creating-the-strips",
    "href": "blog/how-to-create-warming-stripes-in-r/index.html#creating-the-strips",
    "title": "How to create ‘Warming Stripes’ in R",
    "section": "Creating the strips",
    "text": "Creating the strips\nFirst, we create the style of the graph, specifying all the arguments of the theme we want to adjust. We start with the default style of theme_minimal( ). In addition, we assign the colors from RColorBrewer to an object col_srip. More information about the colors used here.\n\ntheme_strip &lt;- function(){ \n  \n  theme_minimal() %+replace%\n  theme(\n    axis.text.y = element_blank(),\n    axis.line.y = element_blank(),\n    axis.title = element_blank(),\n    panel.grid.major = element_blank(),\n    legend.title = element_blank(),\n    axis.text.x = element_text(vjust = 3),\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(size = 14, face = \"bold\"),\n    legend.key.width = unit(.5, \"lines\")\n  )\n}\n\ncol_strip &lt;- brewer.pal(11, \"RdBu\")\n\n# all \nbrewer.pal.info\n\n         maxcolors category colorblind\nBrBG            11      div       TRUE\nPiYG            11      div       TRUE\nPRGn            11      div       TRUE\nPuOr            11      div       TRUE\nRdBu            11      div       TRUE\nRdGy            11      div      FALSE\nRdYlBu          11      div       TRUE\nRdYlGn          11      div      FALSE\nSpectral        11      div      FALSE\nAccent           8     qual      FALSE\nDark2            8     qual       TRUE\nPaired          12     qual       TRUE\nPastel1          9     qual      FALSE\nPastel2          8     qual      FALSE\nSet1             9     qual      FALSE\nSet2             8     qual       TRUE\nSet3            12     qual      FALSE\nBlues            9      seq       TRUE\nBuGn             9      seq       TRUE\nBuPu             9      seq       TRUE\nGnBu             9      seq       TRUE\nGreens           9      seq       TRUE\nGreys            9      seq       TRUE\nOranges          9      seq       TRUE\nOrRd             9      seq       TRUE\nPuBu             9      seq       TRUE\nPuBuGn           9      seq       TRUE\nPuRd             9      seq       TRUE\nPurples          9      seq       TRUE\nRdPu             9      seq       TRUE\nReds             9      seq       TRUE\nYlGn             9      seq       TRUE\nYlGnBu           9      seq       TRUE\nYlOrBr           9      seq       TRUE\nYlOrRd           9      seq       TRUE\n\n\nFor the final graphic we use the geometry geom_tile( ). Since the data does not have a specific value for the Y axis, we need a dummy value, here I used 1. Also, I adjust the width of the color bar in the legend.\n\nmaxmin &lt;- range(temp_lisboa_yr$ta, na.rm = T)\nmd &lt;- mean(temp_lisboa_yr$ta, na.rm = T)\n\nggplot(\n  temp_lisboa_yr,\n  aes(date, y = 1, fill = ta)\n) +\n  geom_tile() +\n  scale_x_date(\n    date_breaks = \"6 years\",\n    date_labels = \"%Y\",\n    expand = c(0, 0)\n  ) +\n  scale_fill_gradientn(colors = rev(col_strip), values = scales::rescale(c(maxmin[1], md, maxmin[2])),\n                       na.value = \"gray80\") +\n  labs(\n    title = \"LISBOA 1880-2018\",\n    caption = \"Datos: GISS Surface Temperature Analysis\"\n  ) +\n  coord_cartesian(expand = FALSE) +\n  theme_strip()\n\n\n\n\n\n\n\nIn case we want to get only the strips, we can use theme_void( ) and the argument show.legend = FALSE in geom_tile( ) to remove all style elements. We can also change the color for the NA values, including the argument na.value = “gray70” in the scale_fill_gradientn( ) function.\n\nggplot(\n  temp_lisboa_yr,\n  aes(x = date, y = 1, fill = ta)\n) +\n  geom_tile(show.legend = FALSE) +\n  scale_fill_gradientn(colors = rev(col_strip), values = scales::rescale(c(maxmin[1], md, maxmin[2])),\n                       na.value = \"gray80\") +\n  coord_cartesian(expand = FALSE) +\n  theme_void()"
  },
  {
    "objectID": "blog/geographic-distance/index.html",
    "href": "blog/geographic-distance/index.html",
    "title": "Geographic distance",
    "section": "",
    "text": "The first post of this year 2020, I will dedicate to a question that I was recently asked. The question was how to calculate the shortest distance between different points and how to know which is the closest point. When we work with spatial data in R, currently the easiest thing is to use the sf package in combination with the tidyverse collection of packages. We also use the units package which is very useful for working with units of measurement."
  },
  {
    "objectID": "blog/geographic-distance/index.html#packages",
    "href": "blog/geographic-distance/index.html#packages",
    "title": "Geographic distance",
    "section": "Packages",
    "text": "Packages\n\n\n\n\n\n\n\n\nPackage\nDescription\n\n\n\ntidyverse\nCollection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.\n\n\nsf\nSimple Feature: import, export and manipulate vector data\n\n\nunits\nSupport for measurement units in R vectors, matrices and arrays: propagation, conversion, derivation\n\n\nmaps\nDraw geographical maps\n\n\ngiscoR\nAdministrative boundaries of the world\n\n\n\n\n\n\n# install the necessary packages\n\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"units\")) install.packages(\"units\")\nif (!require(\"sf\")) install.packages(\"sf\")\nif (!require(\"maps\")) install.packages(\"maps\")\nif (!require(\"giscoR\")) install.packages(\"giscoR\")\n\n# load packages\n\nlibrary(maps)\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(units)\nlibrary(giscoR)"
  },
  {
    "objectID": "blog/geographic-distance/index.html#measurement-units",
    "href": "blog/geographic-distance/index.html#measurement-units",
    "title": "Geographic distance",
    "section": "Measurement units",
    "text": "Measurement units\nThe use of vectors and matrices with the units class allows us to calculate and transform units of measurement.\n\n# length\nl &lt;- set_units(1:10, m)\nl\n\nUnits: [m]\n [1]  1  2  3  4  5  6  7  8  9 10\n\n# convert units\nset_units(l, cm)\n\nUnits: [cm]\n [1]  100  200  300  400  500  600  700  800  900 1000\n\n# sum different units\nset_units(l, cm) + l\n\nUnits: [cm]\n [1]  200  400  600  800 1000 1200 1400 1600 1800 2000\n\n# area\na &lt;- set_units(355, ha)\nset_units(a, km2)\n\n3.55 [km2]\n\n# velocity\nvel &lt;- set_units(seq(20, 50, 10), km / h)\nset_units(vel, m / s)\n\nUnits: [m/s]\n[1]  5.555556  8.333333 11.111111 13.888889"
  },
  {
    "objectID": "blog/geographic-distance/index.html#capital-cities-of-the-world",
    "href": "blog/geographic-distance/index.html#capital-cities-of-the-world",
    "title": "Geographic distance",
    "section": "Capital cities of the world",
    "text": "Capital cities of the world\nWe will use the capital cities of the whole world with the objective of calculating the distance to the nearest capital city and indicating the name/country.\n\n# set of world cities with coordinates\nhead(world.cities) # from the maps package\n\n                name country.etc   pop   lat  long capital\n1 'Abasan al-Jadidah   Palestine  5629 31.31 34.34       0\n2 'Abasan al-Kabirah   Palestine 18999 31.32 34.35       0\n3       'Abdul Hakim    Pakistan 47788 30.55 72.11       0\n4 'Abdullah-as-Salam      Kuwait 21817 29.36 47.98       0\n5              'Abud   Palestine  2456 32.03 35.07       0\n6            'Abwein   Palestine  3434 32.03 35.20       0\n\n\nTo convert points with longitude and latitude into a spatial object of class sf, we use the function st_as_sf(), indicating the coordinate columns and the coordinate reference system (WSG84, epsg: 4326).\n\n# convert the points into an sf object with CRS WSG84\ncities &lt;- st_as_sf(world.cities, coords = c(\"long\", \"lat\"), crs = 4326)\ncities\n\nSimple feature collection with 43645 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -178.8 ymin: -54.79 xmax: 179.81 ymax: 78.93\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                 name  country.etc   pop capital            geometry\n1  'Abasan al-Jadidah    Palestine  5629       0 POINT (34.34 31.31)\n2  'Abasan al-Kabirah    Palestine 18999       0 POINT (34.35 31.32)\n3        'Abdul Hakim     Pakistan 47788       0 POINT (72.11 30.55)\n4  'Abdullah-as-Salam       Kuwait 21817       0 POINT (47.98 29.36)\n5               'Abud    Palestine  2456       0 POINT (35.07 32.03)\n6             'Abwein    Palestine  3434       0  POINT (35.2 32.03)\n7            'Adadlay      Somalia  9198       0  POINT (44.65 9.77)\n8              'Adale      Somalia  5492       0   POINT (46.3 2.75)\n9               'Afak         Iraq 22706       0 POINT (45.26 32.07)\n10              'Afif Saudi Arabia 41731       0 POINT (42.93 23.92)\n\n\nIn the next step, we filter by the capital cities encoded in the column capital with 1. The advantage of the sf package is the possibility of applying functions of the tidyverse collection to manipulate the attributes. In addition, we add a column with new labels using the str_c() function of the stringr package, which is similar to that of R Base paste().\n\n# filter the capital cities\ncapitals &lt;- filter(cities, capital == 1)\n\n# create a new label combining name and country\ncapitals &lt;- mutate(capitals, city_country = str_c(name, \" (\", country.etc, \")\"))\n\ncapitals\n\nSimple feature collection with 230 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -176.13 ymin: -51.7 xmax: 179.2 ymax: 78.21\nGeodetic CRS:  WGS 84\nFirst 10 features:\n          name          country.etc     pop capital               geometry\n1       'Amman               Jordan 1303197       1    POINT (35.93 31.95)\n2    Abu Dhabi United Arab Emirates  619316       1    POINT (54.37 24.48)\n3        Abuja              Nigeria  178462       1      POINT (7.17 9.18)\n4        Accra                Ghana 2029143       1      POINT (-0.2 5.56)\n5    Adamstown             Pitcairn      51       1  POINT (-130.1 -25.05)\n6  Addis Abeba             Ethiopia 2823167       1     POINT (38.74 9.03)\n7        Agana                 Guam    1041       1   POINT (144.75 13.47)\n8      Algiers              Algeria 2029936       1     POINT (3.04 36.77)\n9        Alofi                 Niue     627       1 POINT (-169.92 -19.05)\n10   Amsterdam          Netherlands  744159       1     POINT (4.89 52.37)\n                       city_country\n1                   'Amman (Jordan)\n2  Abu Dhabi (United Arab Emirates)\n3                   Abuja (Nigeria)\n4                     Accra (Ghana)\n5              Adamstown (Pitcairn)\n6            Addis Abeba (Ethiopia)\n7                      Agana (Guam)\n8                 Algiers (Algeria)\n9                      Alofi (Niue)\n10          Amsterdam (Netherlands)"
  },
  {
    "objectID": "blog/geographic-distance/index.html#calculate-distances",
    "href": "blog/geographic-distance/index.html#calculate-distances",
    "title": "Geographic distance",
    "section": "Calculate distances",
    "text": "Calculate distances\nGeographical distance (Euclidean or greater circle) is calculated with the st_distance() function, either between two points, between one point and others or between all points. In the latter case we obtain a symmetric matrix of distances (NxN), taken pairwise between the elements of the capital city set. In the diagonal we find the combinations between the same points giving all null values.\n\n\n\n\n\nA\nB\nC\n\n\nA\n0\n229\n272\n\n\nB\n229\n0\n181\n\n\nC\n272\n181\n0\n\n\n\n\nFor instance, when we want to know the distance from Amsterdam to Abu Dhabi, Washington and Tokyo we pass two spatial objects.\n\n# calculate distance\ndist_amsterdam &lt;- st_distance(\n  slice(capitals, 10),\n  slice(capitals, c(2, 220, 205))\n)\n\ndist_amsterdam # distance in meters\n\nUnits: [m]\n        [,1]    [,2]    [,3]\n[1,] 5163124 6187634 9293710\n\n\nThe result is a matrix with a single row or column (depending on the order of the spatial objects) with a class of units. Thus it is possible to convert easily to another unit of measure. If we want to obtain a vector without class units, we only have to apply the function as.vector().\n\n# change from m to km\nset_units(dist_amsterdam, \"km\")\n\nUnits: [km]\n         [,1]     [,2]    [,3]\n[1,] 5163.124 6187.634 9293.71\n\n# units class to vector\nas.vector(dist_amsterdam)\n\n[1] 5163124 6187634 9293710\n\n\nIn the second step, we estimate the distance matrix between all the capital cities. It is important to convert the null values to NA to subsequently obtain the correct matrix index.\n\n# calculate distance\nm_distance &lt;- st_distance(capitals)\n\n# matrix\ndim(m_distance)\n\n[1] 230 230\n\n# change m to km\nm_distance_km &lt;- set_units(m_distance, km)\n\n# replace the distance of 0 m with NA\nm_distance_km[m_distance_km == set_units(0, km)] &lt;- NA\n\n\n\n\n\n\n\nNote\n\n\n\nWhen the result is of the units class, it is necessary to use the same class to be able to make logical queries. For example, set_units(1, m) == set_units(1, m) vs. set_units(1, m) == 1.\n\n\nTo obtain the shortest distance, in addition to its position, we use the apply () function which in turn allows us to apply the function which.min() and min() on each row. It would also be possible to use the function on columns giving the same result. Finally, we add the results as new columns with the mutate() function. The indices in pos allow us to obtain the names of the nearest cities.\n\n# get the index (position) of the city and the distance\npos &lt;- apply(m_distance_km, 1, which.min)\ndist &lt;- apply(m_distance_km, 1, min, na.rm = TRUE)\n\n# add the distance and get the name of the city\ncapitals &lt;- mutate(capitals,\n  nearest_city = city_country[pos],\n  geometry_nearest = geometry[pos],\n  distance_city = dist\n)"
  },
  {
    "objectID": "blog/geographic-distance/index.html#map-of-distances-to-the-next-capital-city",
    "href": "blog/geographic-distance/index.html#map-of-distances-to-the-next-capital-city",
    "title": "Geographic distance",
    "section": "Map of distances to the next capital city",
    "text": "Map of distances to the next capital city\nFinally, we build a map representing the distance in proportional circles. To do this, we use the usual grammar of ggplot() by adding the geometry geom_sf(), first for the world map as background and then for the cities. In aes() we indicate, with the argument size = distance_city, the variable which we want to map proportionally. The theme_void() function removes all style elements. In addition, we define with the function coord_sf() a new projection indicating the proj4 format.\n\n# world map\nworld &lt;- gisco_get_countries(resolution = \"10\")\n\n# map\nggplot(world) +\n  geom_sf(fill = \"black\", colour = \"white\") +\n  geom_sf(\n    data = arrange(capitals, distance_city),\n    aes(size = distance_city),\n    alpha = 0.5,\n    colour = \"white\",\n    fill = \"#bd0026\",\n    shape = 21\n  ) +\n  scale_size(range = c(.2, 6), breaks = c(100, 250, 750, 2000)) +\n  coord_sf(crs = \"ESRI:54030\") +\n  labs(size = \"km\", title = \"Distance to the next capital city\") +\n  theme_void() +\n  theme(plot.title = element_text(hjust = .5, margin = margin(b = 10)),\n        legend.position = \"top\",\n        legend.title.position = \"right\",\n        plot.margin = margin(5, 5, 5, 5))"
  },
  {
    "objectID": "blog/climate-circles/index.html",
    "href": "blog/climate-circles/index.html",
    "title": "Climate circles",
    "section": "",
    "text": "The climate of a place is usually presented through climographs that combine monthly precipitation and temperature in a single chart. However, it is also interesting to visualize the climate on a daily scale showing the thermal amplitude and the daily average temperature. To do this, the averages for each day of the year of daily minimums, maximums and means are calculated.\nThe annual climate cycle presents a good opportunity to use a radial or polar chart which allows us to clearly visualize seasonal patterns."
  },
  {
    "objectID": "blog/climate-circles/index.html#data",
    "href": "blog/climate-circles/index.html#data",
    "title": "Climate circles",
    "section": "Data",
    "text": "Data\nWe download the temperature data for a selection of US cities here. You can access other cities of the entire world through the WMO or GHCN datasets at NCDC/NOAA."
  },
  {
    "objectID": "blog/climate-circles/index.html#import",
    "href": "blog/climate-circles/index.html#import",
    "title": "Climate circles",
    "section": "Import",
    "text": "Import\nTo import the temperature time series of each city, which we find in several files, we apply the read_csv() function using map(). The dir_ls() function of the fs package returns the list of files with csv extension. The list_rbind() function join all imported tables into a single one.\nThen we obtain the names of the weather stations and define a new vector with the new city names.\n\n# import data\nmeteo &lt;- dir_ls(regexp = \".csv$\") |&gt;\n          map(read_csv) |&gt; list_rbind()\nmeteo\n\n# A tibble: 211,825 × 12\n   STATION     NAME    LATITUDE LONGITUDE ELEVATION DATE        TAVG  TMAX  TMIN\n   &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 USW00094846 CHICAG…     42.0     -87.9      202. 1950-01-01   6.8    NA    NA\n 2 USW00094846 CHICAG…     42.0     -87.9      202. 1950-01-02   8.4    NA    NA\n 3 USW00094846 CHICAG…     42.0     -87.9      202. 1950-01-03  11      NA    NA\n 4 USW00094846 CHICAG…     42.0     -87.9      202. 1950-01-04  -7.2    NA    NA\n 5 USW00094846 CHICAG…     42.0     -87.9      202. 1950-01-05 -10.2    NA    NA\n 6 USW00094846 CHICAG…     42.0     -87.9      202. 1950-01-06  -4.6    NA    NA\n 7 USW00094846 CHICAG…     42.0     -87.9      202. 1950-01-07  -7.1    NA    NA\n 8 USW00094846 CHICAG…     42.0     -87.9      202. 1950-01-08  -5.8    NA    NA\n 9 USW00094846 CHICAG…     42.0     -87.9      202. 1950-01-09   2.9    NA    NA\n10 USW00094846 CHICAG…     42.0     -87.9      202. 1950-01-10   3.9    NA    NA\n# ℹ 211,815 more rows\n# ℹ 3 more variables: TAVG_ATTRIBUTES &lt;chr&gt;, TMAX_ATTRIBUTES &lt;chr&gt;,\n#   TMIN_ATTRIBUTES &lt;chr&gt;\n\n# station names\nstats_names &lt;- unique(meteo$NAME)\nstats_names\n\n[1] \"CHICAGO OHARE INTERNATIONAL AIRPORT, IL US\"             \n[2] \"LAGUARDIA AIRPORT, NY US\"                               \n[3] \"MIAMI INTERNATIONAL AIRPORT, FL US\"                     \n[4] \"HOUSTON INTERCONTINENTAL AIRPORT, TX US\"                \n[5] \"ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPORT, GA US\"\n[6] \"SAN FRANCISCO INTERNATIONAL AIRPORT, CA US\"             \n[7] \"SEATTLE TACOMA AIRPORT, WA US\"                          \n[8] \"DENVER INTERNATIONAL AIRPORT, CO US\"                    \n[9] \"MCCARRAN INTERNATIONAL AIRPORT, NV US\"                  \n\n# new city names\ncities &lt;- c(\n  \"CHICAGO\", \"NEW YORK\", \"MIAMI\",\n  \"HOUSTON\", \"ATLANTA\", \"SAN FRANCISCO\",\n  \"SEATTLE\", \"DENVER\", \"LAS VEGAS\"\n)"
  },
  {
    "objectID": "blog/climate-circles/index.html#preparation-1",
    "href": "blog/climate-circles/index.html#preparation-1",
    "title": "Climate circles",
    "section": "Preparation",
    "text": "Preparation\nIn the first step, we will modify the original data, 1) selecting only the columns of interest, 2) filtering the period 1991-2020, 3) defining the new city names, 4) calculating the average temperature where it is absent, 5) cleaning the column names, and 6) creating a new variable with the days of the year. The clean_names() function of the janitor package is very useful for getting clean column names.\n\nmeteo &lt;- select(meteo, NAME, DATE, TAVG:TMIN) |&gt;\n  filter(DATE &gt;= \"1991-01-01\", \n         DATE &lt;= \"2020-12-31\") |&gt;\n  mutate(\n    NAME = factor(NAME, stats_names, cities),\n    TAVG = ifelse(is.na(TAVG), (TMAX + TMIN) / 2, TAVG),\n    yd = yday(DATE)\n  ) |&gt;\n  clean_names()\n\nIn the next step, we calculate the daily maximum, minimum and mean temperature for each day of the year. It now only remains to convert the days of the year into a dummy date. Here we use the year 2000 since it is a leap year, and we have a total of 366 days.\n\n# estimate the daily averages\nmeteo_yday &lt;- group_by(meteo, name, yd) |&gt;\n  summarise(\n    ta = mean(tavg, na.rm = TRUE),\n    tmx = mean(tmax, na.rm = TRUE),\n    tmin = mean(tmin, na.rm = TRUE)\n  )\n\n`summarise()` has grouped output by 'name'. You can override using the\n`.groups` argument.\n\nmeteo_yday\n\n# A tibble: 3,294 × 5\n# Groups:   name [9]\n   name       yd    ta    tmx  tmin\n   &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 CHICAGO     1 -3.77  0.537 -7.86\n 2 CHICAGO     2 -2.64  1.03  -6.68\n 3 CHICAGO     3 -2.88  0.78  -6.93\n 4 CHICAGO     4 -2.86  0.753 -7.10\n 5 CHICAGO     5 -4.13 -0.137 -8.33\n 6 CHICAGO     6 -4.50 -1.15  -8.05\n 7 CHICAGO     7 -4.70 -0.493 -8.57\n 8 CHICAGO     8 -3.97  0.147 -8.02\n 9 CHICAGO     9 -3.47  0.547 -7.49\n10 CHICAGO    10 -3.41  1.09  -7.64\n# ℹ 3,284 more rows\n\n# convert the days of the year into a dummy date\nmeteo_yday &lt;- mutate(meteo_yday, yd = as_date(yd, origin = \"1999-12-31\"))"
  },
  {
    "objectID": "blog/climate-circles/index.html#predefinitions",
    "href": "blog/climate-circles/index.html#predefinitions",
    "title": "Climate circles",
    "section": "Predefinitions",
    "text": "Predefinitions\nWe define a divergent vector of various hues.\n\ncol_temp &lt;- c(\n  \"#cbebf6\", \"#a7bfd9\", \"#8c99bc\", \"#974ea8\", \"#830f74\",\n  \"#0b144f\", \"#0e2680\", \"#223b97\", \"#1c499a\", \"#2859a5\",\n  \"#1b6aa3\", \"#1d9bc4\", \"#1ca4bc\", \"#64c6c7\", \"#86cabb\",\n  \"#91e0a7\", \"#c7eebf\", \"#ebf8da\", \"#f6fdd1\", \"#fdeca7\",\n  \"#f8da77\", \"#fcb34d\", \"#fc8c44\", \"#f85127\", \"#f52f26\",\n  \"#d10b26\", \"#9c042a\", \"#760324\", \"#18000c\"\n)\n\nWe create a table with the x-axis grid lines.\n\ngrid_x &lt;- tibble(\n  x = seq(ymd(\"2000-01-01\"), ymd(\"2000-12-31\"), \"month\"),\n  y = rep(-10, 12),\n  xend = seq(ymd(\"2000-01-01\"), ymd(\"2000-12-31\"), \"month\"),\n  yend = rep(41, 12)\n)\n\nWe define all the style elements of the graph in our own theme theme_cc().\n\ntheme_cc &lt;- function() {\n  theme_void(base_family = \"Montserrat\") %+replace%\n    theme(\n      plot.title = element_text(hjust = 0.5, colour = \"white\", size = 30, margin = margin(b = 20)),\n      plot.caption = element_text(colour = \"white\", size = 9, hjust = .5, vjust = -30),\n      plot.background = element_rect(fill = \"black\"),\n      plot.margin = margin(1, 1, 2, 1, unit = \"cm\"),\n      axis.text.x = element_text(face = \"italic\", colour = \"white\", margin = margin()),\n      axis.title.y = element_blank(),\n      axis.text.y = element_blank(),\n      legend.title = element_text(colour = \"white\"),\n      legend.position = \"bottom\",\n      legend.justification = 0.5,\n      legend.text = element_text(colour = \"white\"),\n      strip.text = element_text(colour = \"white\", face = \"bold\", size = 14),\n      panel.spacing.y = unit(1, \"lines\"),\n      panel.background = element_rect(fill = \"black\"),\n      panel.grid = element_blank()\n    )\n}"
  },
  {
    "objectID": "blog/climate-circles/index.html#graph",
    "href": "blog/climate-circles/index.html#graph",
    "title": "Climate circles",
    "section": "Graph",
    "text": "Graph\nWe start by building a chart for New York City only. We will use geom_linerange() to define line range with the daily maximum and minimum temperature. Also, we will draw the range line colour based on the mean temperature. Finally, we can adjust alpha and size to get a nicer look.\n\n# filter New York\nny_city &lt;- filter(meteo_yday, name == \"NEW YORK\")\n\n# graph\nggplot(ny_city) +\n  geom_linerange(\n    aes(yd,\n      ymax = tmx,\n      ymin = tmin,\n      colour = ta\n    ),\n    size = 0.5,\n    alpha = .7\n  ) +\n  scale_y_continuous(\n    breaks = seq(-30, 50, 10),\n    limits = c(-11, 42),\n    expand = expansion()\n  ) +\n  scale_colour_gradientn(\n    colours = col_temp,\n    limits = c(-12, 35),\n    breaks = seq(-12, 34, 5)\n  ) +\n  scale_x_date(\n    date_breaks = \"month\",\n    date_labels = \"%b\"\n  ) +\n  labs(\n    title = \"CLIMATE CIRCLES\",\n    colour = \"Daily average temperature\"\n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nTo get the polar graph it would only be necessary to add the coord_radial() function.\n\n# polar chart\nggplot(ny_city) +\n  geom_linerange(\n    aes(yd,\n      ymax = tmx,\n      ymin = tmin,\n      colour = ta\n    ),\n    size = 0.5,\n    alpha = .7\n  ) +\n  scale_y_continuous(\n    breaks = seq(-30, 50, 10),\n    limits = c(-11, 42),\n    expand = expansion()\n  ) +\n  scale_colour_gradientn(\n    colours = col_temp,\n    limits = c(-12, 35),\n    breaks = seq(-12, 34, 5)\n  ) +\n  scale_x_date(\n    date_breaks = \"month\",\n    date_labels = \"%b\"\n  ) +\n  coord_radial(expand = F) +\n  labs(\n    title = \"CLIMATE CIRCLES\",\n    colour = \"Daily average temperature\"\n  )\n\n\n\n\n\n\n\n\nIn the final graph, we add the grid defining the lines on the y-axis with geom_hline() and those on the x-axis with geom_segement(). The most important thing here is the facet_wrap() function, which allows multiple facets of charts. The formula format is used to specify how the facets are created: row ~ column. If we do not have a second variable, a point . is indicated in the formula. In addition, we make changes to the appearance of the colour bar with guides() and guide_colourbar(), and we include the theme_cc() style.\n\nggplot(meteo_yday) +\n  geom_texthline(\n    data = tibble(y = c(-10, 0, 10, 20, 30, 40)),\n    aes(yintercept = y, label = y),\n    colour = \"white\",\n    linewidth = .4,\n    size = 2\n  ) +\n  geom_segment(\n    data = grid_x,\n    aes(\n      x = x,\n      y = y,\n      xend = xend,\n      yend = yend\n    ),\n    linetype = \"dashed\",\n    colour = \"white\",\n    linewidth = .2\n  ) +\n  geom_linerange(\n    aes(yd,\n      ymax = tmx,\n      ymin = tmin,\n      colour = ta\n    ),\n    linewidth = 0.5,\n    alpha = .7\n  ) +\n  scale_y_continuous(\n    breaks = seq(-30, 50, 10),\n    limits = c(-15, 41.5),\n    expand = expansion()\n  ) +\n  scale_colour_gradientn(\n    colours = col_temp,\n    limits = c(-12, 35),\n    breaks = seq(-12, 34, 5)\n  ) +\n  scale_x_date(\n    date_breaks = \"month\",\n    date_labels = \"%b\"\n  ) +\n  guides(colour = guide_colourbar(\n    barwidth = 15,\n    barheight = 0.5,\n    title.position = \"top\"\n  ),\n1  theta = \"axis_textpath\") +\n  facet_wrap(~name, nrow = 3) +\n  coord_radial(r.axis.inside = T, expand = F) +\n  labs(\n    title = \"CLIMATE CIRCLES\",\n    colour = \"Daily average temperature\"\n  ) +\n  theme_cc()\n\n\n1\n\nFor curved text on theta (x axis in polar coordinate systems)"
  },
  {
    "objectID": "blog/climate-animation-maximum-temperature/index.html",
    "href": "blog/climate-animation-maximum-temperature/index.html",
    "title": "Climate animation of maximum temperatures",
    "section": "",
    "text": "In the field of data visualization, the animation of spatial data in its temporal dimension can show fascinating changes and patterns. As a result of one of the last publications in the social networks that I have made, I was asked to make a post about how I created it. Well, here we go to start with an example of data from mainland Spain. You can find more animations in the graphics section of my blog."
  },
  {
    "objectID": "blog/climate-animation-maximum-temperature/index.html#packages",
    "href": "blog/climate-animation-maximum-temperature/index.html#packages",
    "title": "Climate animation of maximum temperatures",
    "section": "Packages",
    "text": "Packages\nIn this post we will use the following packages:\n\n\n\n\n\n\n\n\nPackages\nDescription\n\n\n\ntidyverse\nCollection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.\n\n\ngiscoR\nVector maps of the world\n\n\nsf\nSimple Feature: import, export and manipulate vector data\n\n\nterra\nImport, export and manipulate raster\n\n\nggthemes\nThemes for ggplot2\n\n\ngifski\nCreate gifs\n\n\n\n\n\n\n# install the packages if necessary\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"giscoR\")) install.packages(\"giscoR\")\nif (!require(\"sf\")) install.packages(\"sf\")\nif (!require(\"ggthemes\")) install.packages(\"ggthemes\")\nif (!require(\"gifski\")) install.packages(\"gifski\")\nif (!require(\"terra\")) install.packages(\"terra\")\n\n# packages\nlibrary(terra)\nlibrary(tidyverse)\nlibrary(ggthemes)\nlibrary(sf)\nlibrary(giscoR)\nlibrary(RColorBrewer)\nlibrary(gifski)"
  },
  {
    "objectID": "blog/climate-animation-maximum-temperature/index.html#data",
    "href": "blog/climate-animation-maximum-temperature/index.html#data",
    "title": "Climate animation of maximum temperatures",
    "section": "Data",
    "text": "Data\nFirst, we need to download the STEAD dataset of the maximum temperature (tmax_pen.nc) in netCDF format from the CSIC repository here (the size of the data is 2 GB). It is a set of data with a spatial resolution of 5 km and includes daily maximum temperatures from 1901 to 2014. In climatology and meteorology, a widely used format is that of netCDF databases, which allow to obtain a multidimensional structure and to exchange data independently of the usued operating system. It is a space-time format with a regular or irregular grid. The multidimensional structure in the form of arrays or cubes can handle not only spatio-temporal data but also multivariate ones. In our dataset we will have an array of three dimensions: longitude, latitude and time of the maximum temperature."
  },
  {
    "objectID": "blog/climate-animation-maximum-temperature/index.html#import-the-dataset",
    "href": "blog/climate-animation-maximum-temperature/index.html#import-the-dataset",
    "title": "Climate animation of maximum temperatures",
    "section": "Import the dataset",
    "text": "Import the dataset\nThe netCDF format with .nc extension can be imported via two main packages: 1) ncdf4 and 2) raster. Actually, the raster package use the first package to import the netCDF datasets. In this post we will use the raster package since it is somewhat easier, with some very useful and more universal functions for all types of raster format. The main import functions are: raster(), stack() and brick(). The first function only allows you to import a single layer, instead, the last two functions are used for multidimensional data. In our dataset we only have one variable, therefore it would not be necessary to use the varname argument.\n\n# import netCDF data\ntmx &lt;- rast(\"tmax_pen.nc\")\ntmx # metadata\n\nclass       : SpatRaster \ndimensions  : 190, 230, 41638  (nrow, ncol, nlyr)\nresolution  : 0.0585, 0.045  (x, y)\nextent      : -9.701833, 3.753167, 35.64247, 44.19247  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (CRS84) (OGC:CRS84) \nsource      : tmax_pen.nc \nvarname     : tx (Maximum temperature) \nnames       :       tx_Time=1,       tx_Time=2,       tx_Time=3,       tx_Time=4,       tx_Time=5,       tx_Time=6, ... \nunit        : Celsius degrees, Celsius degrees, Celsius degrees, Celsius degrees, Celsius degrees, Celsius degrees, ... \n\n\nThe SpatRaster object details show you all the necessary metadata: the resolution, the dimensions or the type of projection, or the name of the variable. It also tells us that it only points to the data source and has not imported them into the memory, which makes it easier to work with large datasets.\nTo access any layer we use [[ ]] with the corresponding index. So we can easily plot any day of the 41,638 days we have.\n\n# map any day\nplot(tmx[[200]], col = rev(heat.colors(7)))"
  },
  {
    "objectID": "blog/climate-animation-maximum-temperature/index.html#calculate-the-average-temperature",
    "href": "blog/climate-animation-maximum-temperature/index.html#calculate-the-average-temperature",
    "title": "Climate animation of maximum temperatures",
    "section": "Calculate the average temperature",
    "text": "Calculate the average temperature\nIn this step the objective is to calculate the average maximum temperature for each day of the year. Therefore, the first thing we do is to create a vector, indicating the entire time series for the SpatRaster. In the terra package we have the tapp() function that allows us to apply another function on groups of layers, or rather, indexes.\n\n\n\n\n\n\nNote\n\n\n\nFor the Europe version I did the preprocessing, the calculation of the average, in a cloud computing platform through Google Earth Engine, which makes the whole process faster. In the case of Australia the preprocessing was more complex as the dataset is separated in multiple netCDF files for each year.\n\n\n\n# define time dimension\ntime(tmx) &lt;- seq(as_date(\"1901-01-01\"), as_date(\"2014-12-31\"), \"day\")\n\n# calculate the average\ntmx_mean &lt;- tapp(tmx, \"doy\", \"mean\")"
  },
  {
    "objectID": "blog/climate-animation-maximum-temperature/index.html#smooth-the-temperature-variability",
    "href": "blog/climate-animation-maximum-temperature/index.html#smooth-the-temperature-variability",
    "title": "Climate animation of maximum temperatures",
    "section": "Smooth the temperature variability",
    "text": "Smooth the temperature variability\nBefore we start to smooth the time series of our RasterBrick, an example of why we do it. We extract a pixel from our dataset at coordinates -1º of longitude and 40º of latitude using the extract() function. Since the function with the same name appears in several packages, we must change to the form package_name::function_name. The result is a matrix with a single row corresponding to the pixel and 366 columns of the days of the year. The next step is to create a data.frame with a dummy date and the extracted maximum temperature.\n\n# extract a pixel\npoint_ts &lt;- extract(tmx_mean, matrix(c(-1, 40), nrow = 1)) |&gt; t()\ndim(point_ts) # dimensions\n\n[1] 366   1\n\n# create a data.frame\ndf &lt;- data.frame(\n  date = seq(as_date(\"2000-01-01\"), as_date(\"2000-12-31\"), \"day\"),\n  tmx = point_ts[, 1]\n)\n\n# visualize the maximum temperature\nggplot(\n  df,\n  aes(date, tmx)\n) +\n  geom_line() +\n  scale_x_date(date_breaks = \"month\", date_labels = \"%b\") +\n  scale_y_continuous(breaks = seq(5, 28, 2)) +\n  labs(y = \"maximum temperature\", x = NULL) +\n  theme_minimal()\n\n\n\n\n\n\n\nThe graph clearly shows the still existing variability, which would cause an animation to fluctuate quite a bit. Therefore, we create a smoothing function based on a local polynomial regression fit (LOESS), more details can be found in the help of the loess() function. The most important argument is span, which determines the degree of smoothing, the smaller the value the less smooth the curve will be. I found the best result showed a value of 0.5.\n\ndaily_smooth &lt;- function(x, span = 0.5) {\n  \n  if (all(is.na(x))) {\n    return(x)\n  } else {\n    \n    df &lt;- data.frame(yd = 1:366, ta = x)\n    m &lt;- loess(ta ~ yd, span = span, data = df)\n    est &lt;- predict(m, 1:366)\n\n    return(est)\n  }\n}\n\nWe apply our new smoothing function to the extracted time series and make some changes to be able to visualize the difference between the original and smoothed data.\n\n# smooth the temperature\ndf &lt;- mutate(df, tmx_smoothed = daily_smooth(tmx)) |&gt;\n           pivot_longer(2:3, names_to = \"var\", values_to = \"temp\")\n\n# visualize the difference\nggplot(df,\n  aes(date, temp,\n    colour = var)\n    ) +\n  geom_line() +\n  scale_x_date(date_breaks = \"month\", date_labels = \"%b\") +\n  scale_y_continuous(breaks = seq(5, 28, 2)) +\n  scale_colour_manual(values = c(\"#f4a582\", \"#b2182b\")) +\n  labs(y = \"maximum temperature\", x = NULL, colour = NULL) +\n  theme_minimal()\n\n\n\n\n\n\n\nAs we see in the graph, the smoothed curve follows the original curve very well. In the next step we apply our function with the app() function. The function returns as many layers as those returned by the function used for each of the time series.\n\n# smooth the time serie of each pixel\ntmx_smooth &lt;- app(tmx_mean, fun = daily_smooth, cores = 6)"
  },
  {
    "objectID": "blog/climate-animation-maximum-temperature/index.html#preparation-1",
    "href": "blog/climate-animation-maximum-temperature/index.html#preparation-1",
    "title": "Climate animation of maximum temperatures",
    "section": "Preparation",
    "text": "Preparation\nTo visualize the maximum temperatures throughout the year, first, we convert the SpatRaster to a data.frame, including longitude and latitude.\n\n# convert to data.frame\ntmx_mat &lt;- as.data.frame(tmx_smooth, xy = TRUE)\n\n# rename the columns\ntmx_mat &lt;- set_names(tmx_mat, c(\"lon\", \"lat\", str_c(\"D\", 1:366)))\nstr(tmx_mat[, 1:10])\n\n'data.frame':   20676 obs. of  10 variables:\n $ lon: num  -8.03 -7.98 -7.92 -7.86 -7.8 ...\n $ lat: num  43.8 43.8 43.8 43.8 43.8 ...\n $ D1 : num  10.5 10.3 10 10.9 11.5 ...\n $ D2 : num  10.5 10.3 10.1 10.9 11.5 ...\n $ D3 : num  10.5 10.3 10.1 10.9 11.5 ...\n $ D4 : num  10.6 10.4 10.1 10.9 11.5 ...\n $ D5 : num  10.6 10.4 10.1 11 11.6 ...\n $ D6 : num  10.6 10.4 10.1 11 11.6 ...\n $ D7 : num  10.6 10.4 10.2 11 11.6 ...\n $ D8 : num  10.6 10.4 10.2 11 11.6 ...\n\n\nSecond, we import the administrative boundaries with the gisco_get_countries() function from the giscoR package, limiting the extension to the region of the Iberian Peninsula, southern France and northern Africa.\n\n# import global boundaries\nmap &lt;- gisco_get_countries(resolution = \"10\", spatialtype = \"BN\") \n\n# limit the extension\nmap &lt;- st_crop(map, xmin = -10, xmax = 5, ymin = 35, ymax = 44)\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n# map of boundaries\nplot(map)\n\n\n\n\n\n\n\nThird, we create a vector with the day of the year as labels in order to include them later in the animation. In addition, we define the break points for the maximum temperature, adapted to the distribution of our data, to obtain a categorization with a total of 20 classes.\nFourth, we apply the cut() function with the breaks to all the columns with temperature data of each day of the year.\n\n# labels of day of the year\nlab &lt;- as_date(0:365, \"2000-01-01\") |&gt; format(\"%d %B\")\n\n# breaks for the temperature data\nct &lt;- c(-5, 0, 4, seq(6, 34, 2), 40, 45)\n\n# categorized data with fixed breaks\ntmx_mat_cat &lt;- mutate(tmx_mat, across(3:368, \\(x) cut(x, breaks = ct)))\n\nWe define the colors corresponding to the created classes.\n\n# define the color ramp\ncol_spec &lt;- colorRampPalette(rev(brewer.pal(11, \"Spectral\")))"
  },
  {
    "objectID": "blog/climate-animation-maximum-temperature/index.html#static-map",
    "href": "blog/climate-animation-maximum-temperature/index.html#static-map",
    "title": "Climate animation of maximum temperatures",
    "section": "Static map",
    "text": "Static map\nIn this first plot we make a map of May 29 (day 150). I am not going to explain all the details of the construction with ggplot2, however, it is important to note that I use the aes_string() function instead of aes() to use the column names in string format. With the geom_raster() function we add the gridded temperature data as the first layer of the graph and with geom_sf() the boundaries in sf class. Finally, the guide_colorsteps() function allows you to create a nice legend based on the classes created by the cut() function.\n\nggplot(tmx_mat_cat) +\n  geom_raster(aes_string(\"lon\", \"lat\", fill = \"D150\")) +\n  geom_sf(\n    data = map,\n    colour = \"grey50\", linewidth = 0.2\n  ) +\n  coord_sf(expand = FALSE) +\n  scale_fill_manual(values = col_spec(20), drop = FALSE, guide = guide_colorsteps()) +\n  theme_void() +\n  theme(\n    legend.position = \"top\",\n    legend.justification = 0,\n    plot.caption = element_text(\n      margin = margin(b = 5, t = 10, unit = \"pt\")\n    ),\n    plot.title = element_text(\n      size = 16, face = \"bold\",\n      margin = margin(b = 2, t = 5, unit = \"pt\")\n    ),\n    legend.key.height = unit(0.5, \"lines\"),\n    legend.key.width = unit(7, \"lines\"),\n    legend.title.position = \"right\",\n      legend.title = element_text(vjust = .08),\n    plot.subtitle = element_text(\n      size = 13,\n      margin = margin(b = 10, t = 5, unit = \"pt\")\n    )\n  ) +\n  labs(\n    title = \"Average maximum temperature during the year in Spain\",\n    subtitle = lab[150],\n    caption = \"Reference period 1901-2014. Data: STEAD\",\n    fill = \"ºC\"\n  )"
  },
  {
    "objectID": "blog/climate-animation-maximum-temperature/index.html#animation-of-the-whole-year",
    "href": "blog/climate-animation-maximum-temperature/index.html#animation-of-the-whole-year",
    "title": "Climate animation of maximum temperatures",
    "section": "Animation of the whole year",
    "text": "Animation of the whole year\nThe final animation consists of creating a gif from all the images of 366 days, in principle, the gganimate package could be used, but in my experience it is slower, since it requires a data.frame in long format. In this example a long table would have more than seven million rows. So what we do here is to walk over the columns and join all the created images with the gifski package that also uses gganimate for rendering.\nBefore mapping we create a vector with the time steps or names of the columns, and another vector with the name of the images, including the name of the folder. In order to obtain a list of images ordered by their number, we must maintain three figures, filling the positions on the left with zeros.\n\ntime_step &lt;- str_c(\"D\", 1:366)\n\nfiles &lt;- str_c(\"./ta_anima/D\", str_pad(1:366, 3, \"left\", \"0\"), \".png\")\n\nLastly, we include the above plot construction in a for loop.\n\nwalk(1:366, \\(i) {\n  ggplot(tmx_mat_cat) +\n    geom_raster(aes_string(\"lon\", \"lat\", fill = time_step[i])) +\n    geom_sf(\n      data = map,\n      colour = \"grey50\", linewidth = 0.2\n    ) +\n    coord_sf(expand = FALSE) +\n    scale_fill_manual(values = col_spec(20), drop = FALSE, guide = guide_colorsteps()) +\n    theme_void() +\n    theme(\n      legend.position = \"top\",\n      legend.justification = 0,\n      plot.caption = element_text(\n        margin = margin(b = 5, t = 10, unit = \"pt\")\n      ),\n      plot.title = element_text(\n        size = 16, face = \"bold\",\n        margin = margin(b = 2, t = 5, unit = \"pt\")\n      ),\n    legend.key.height = unit(0.5, \"lines\"),\n    legend.key.width = unit(7, \"lines\"),\n    legend.title.position = \"right\",\n    legend.title = element_text(vjust = .08),\n      plot.subtitle = element_text(\n        size = 13,\n        margin = margin(b = 10, t = 5, unit = \"pt\")\n      )\n    ) +\n    labs(\n      title = \"Average maximum temperature during the year in Spain\",\n      subtitle = lab[i],\n      caption = \"Reference period 1901-2014. Data: STEAD\",\n      fill = \"ºC\"\n    )\n\n  ggsave(files[i], width = 8.28, height = 7.33, type = \"cairo\")\n  }\n})\n\nAfter having created images for each day of the year, we only have to create the gif.\n\ngifski(files, \"tmx_spain.gif\", width = 800, height = 700, loop = FALSE, delay = 0.05)"
  },
  {
    "objectID": "blog/calculating-the-distance-to-the-sea-in-r/index.html",
    "href": "blog/calculating-the-distance-to-the-sea-in-r/index.html",
    "title": "Calculating the distance to the sea in R",
    "section": "",
    "text": "The distance to the sea is a fundamental variable in geography, especially relevant when it comes to modeling. For example, in interpolations of air temperature, the distance to the sea is usually used as a predictor variable, since there is a casual relationship between the two that explains the spatial variation. How can we estimate the (shortest) distance to the coast in R?"
  },
  {
    "objectID": "blog/calculating-the-distance-to-the-sea-in-r/index.html#packages",
    "href": "blog/calculating-the-distance-to-the-sea-in-r/index.html#packages",
    "title": "Calculating the distance to the sea in R",
    "section": "Packages",
    "text": "Packages\nIn this post we will use the following libraries:\n\n\n\n\n\n\n\n\nLibrary\nDescription\n\n\n\ntidyverse\nCollection of packages (visualization, manipulation): ggplot2, dplyr, etc.\n\n\nsf\nSimple Feature: import, export and manipulate vector data\n\n\nraster\nImport, export and manipulate raster\n\n\nrnaturalearth\nSet of vector maps ‘natural earth’\n\n\nRColorBrewer\nColor palettes\n\n\n\n\n\n\n#install the libraries if necessary\nif(!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif(!require(\"sf\")) install.packages(\"sf\")\nif(!require(\"raster\")) install.packages(\"raster\")\nif(!require(\"giscoR\")) install.packages(\"giscoR\")\n\n#packages\nlibrary(giscoR)\nlibrary(sf)\nlibrary(raster)\nlibrary(tidyverse)\nlibrary(RColorBrewer)"
  },
  {
    "objectID": "blog/calculating-the-distance-to-the-sea-in-r/index.html#the-coast-of-iceland-as-an-example",
    "href": "blog/calculating-the-distance-to-the-sea-in-r/index.html#the-coast-of-iceland-as-an-example",
    "title": "Calculating the distance to the sea in R",
    "section": "The coast of Iceland as an example",
    "text": "The coast of Iceland as an example\nOur example in this post will be Iceland, and, as it is an island territory it will facilitate the tutorial showing the process in a simple manner. The giscoR package allows you to import the boundaries of countries (with different administrative levels) from around the world. The gisco_get_countries( ) function imports the country boundaries. In this case we indicate with the argument scale the resolution (3, 10, 60m), with country we can indicate the specific country or contries of interest.\n\nworld &lt;- gisco_get_countries(resolution = \"60\") #world map with 50m resolution\n\nplot(world) #sp class by default\n\n\n\n\n\n\n#import the limits of Iceland\niceland &lt;- gisco_get_countries(resolution = \"10\", country = \"Iceland\")\n\n#info of our spatial vector object\niceland\n\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -24.31733 ymin: 63.40177 xmax: -13.55855 ymax: 66.58179\nGeodetic CRS:  WGS 84\n  CNTR_NAME ISO3_CODE CNTR_ID NAME_ENGL                       geometry\n1    Ísland       ISL      IS   Iceland MULTIPOLYGON (((-15.78316 6...\n\n#here Iceland\nplot(iceland)\n\n\n\n\n\n\n\nBy default, the plot( ) function with the class sf creates as many facets of the map as there are variables in it. To limit this behavior we can use either a variable name plot(iceland[\"admin\"]) or the limit argument plot(iceland, max.plot = 1). With the argument max.plot = 1 the function uses the first available variable of the map.\nIn addition, we see in the information of the object sf that the projection is WGS84 with decimal degrees (EPSG code: 4326). For the calculation of distances it is more convenient to use meters instead of degrees. Because of this, the first thing we do is to transform the map of Iceland to UTM Zone 27 (EPSG code: 3055). More information about EPSG and projections here. For that purpose, we use the st_transform( ) function. We simply indicate the map and the EPSG code.\n\n#transform to UTM\niceland &lt;- st_transform(iceland, 3055)"
  },
  {
    "objectID": "blog/calculating-the-distance-to-the-sea-in-r/index.html#create-a-fishnet-of-points",
    "href": "blog/calculating-the-distance-to-the-sea-in-r/index.html#create-a-fishnet-of-points",
    "title": "Calculating the distance to the sea in R",
    "section": "Create a fishnet of points",
    "text": "Create a fishnet of points\nWe still need the points where we want to know the distance. In our case it will be a regular fishnet of points in Iceland with a resolution of 5km. We do this with the function st_make_grid( ), indicating the resolution in the unit of the coordinate system (meters in our case) with the argument cellsize, and what geometry we would like to create what (polygons, centers or corners).\n\n#create the fishnet\ngrid &lt;- st_make_grid(iceland, cellsize = 5000, what = \"centers\")\n\n#our fishnet with the extension of Iceland\nplot(grid)\n\n\n\n\n\n\n\n\n#only extract the points in the limits of Iceland\ngrid &lt;- st_intersection(grid, iceland)   \n\n#our fishnet now\nplot(grid)"
  },
  {
    "objectID": "blog/calculating-the-distance-to-the-sea-in-r/index.html#calculating-the-distance",
    "href": "blog/calculating-the-distance-to-the-sea-in-r/index.html#calculating-the-distance",
    "title": "Calculating the distance to the sea in R",
    "section": "Calculating the distance",
    "text": "Calculating the distance\nTo estimate the distance we use the st_distance( ) function that returns a vector of distances for all our points in the fishnet. But first it is necessary to transform the map of Iceland from a polygon shape (MULTIPOLYGON) to a line (MULTILINESTRING). More details with ?st_cast.\n\n#transform Iceland from polygon shape to line\niceland &lt;- st_cast(iceland, \"MULTILINESTRING\")\n\n#calculation of the distance between the coast and our points\ndist &lt;- st_distance(iceland, grid)\n\n#distance with unit in meters\nhead(dist[1,])\n\nUnits: [m]\n[1] 1345.506 1330.656 1315.806 1300.956 1286.106 1101.029"
  },
  {
    "objectID": "blog/calculating-the-distance-to-the-sea-in-r/index.html#plotting-the-calculated-distance",
    "href": "blog/calculating-the-distance-to-the-sea-in-r/index.html#plotting-the-calculated-distance",
    "title": "Calculating the distance to the sea in R",
    "section": "Plotting the calculated distance",
    "text": "Plotting the calculated distance\nOnce obtained the distance for our points, we can combine them with the coordinates and plot them in ggplot2. For this, we create a data.frame. The object dist is a matrix of one column, so we have to convert it to a vector with the function as.vector( ). In addition, we divide by 1000 to convert the distance in meters to km. The st_coordinates( ) function extracts the coordinates of our points. For the final visualization we use a vector of colors with the RdGy palette (more here).\n\n#create a data.frame with the distance and the coordinates of the points\ndf &lt;- data.frame(dist = as.vector(dist)/1000,\n                    st_coordinates(grid))\n\n#structure\nstr(df)\n\n'data.frame':   4090 obs. of  3 variables:\n $ dist: num  1.35 1.33 1.32 1.3 1.29 ...\n $ X   : num  594378 599378 604378 609378 614378 ...\n $ Y   : num  7033908 7033908 7033908 7033908 7033908 ...\n\n#colors \ncol_dist &lt;- brewer.pal(11, \"RdGy\")\n\n\nggplot(df, aes(X, Y, fill = dist))+ #variables\n         geom_tile()+ #geometry\n           scale_fill_gradientn(colours = rev(col_dist))+ #colors for plotting the distance\n             labs(fill = \"Distance (km)\")+ #legend name\n             theme_void()+ #map theme\n              theme(legend.position = \"bottom\") #legend position"
  },
  {
    "objectID": "blog/calculating-the-distance-to-the-sea-in-r/index.html#export-the-distance-as-a-raster",
    "href": "blog/calculating-the-distance-to-the-sea-in-r/index.html#export-the-distance-as-a-raster",
    "title": "Calculating the distance to the sea in R",
    "section": "Export the distance as a raster",
    "text": "Export the distance as a raster\nTo be able to export the estimated distance to the sea of Iceland, we need to use the rasterize( ) function of the library raster.\n\n\nFirst, it is necessary to create an empty raster. In this raster we have to indicate the resolution, in our case it is of 5000m, the projection and the extension of the raster.\n\nWe can extract the projection from the information of the map of Iceland.\nThe extension can be extracted from our grid points with the function extent( ). However, this last function needs the class sp, so we pass the object grid in sf format, only for this time, to the class sp using the function as( ) and the argument “Spatial”.\n\n\nIn addition to the above, the data.frame df, that we created earlier, has to be converted into the sf class. Therefore, we apply the function st_as_sf( ) with the argument coords indicating the names of the coordinates. Additionally, we also define the coordinate system that we know.\n\n\n#get the extension\next &lt;- extent(as(grid, \"Spatial\"))\n\n#extent object\next\n\nclass      : Extent \nxmin       : 349377.7 \nxmax       : 844377.7 \nymin       : 7033908 \nymax       : 7383908 \n\n#raster destination\nr &lt;- raster(resolution = 5000, ext = ext, crs = \"+proj=utm +zone=27 +ellps=intl +towgs84=-73,47,-83,0,0,0,0 +units=m +no_defs\")\n\n#convert the points to a spatial object class sf\ndist_sf &lt;- st_as_sf(df, coords = c(\"X\", \"Y\")) %&gt;%\n                      st_set_crs(3055)\n\n#create the distance raster\ndist_raster &lt;- rasterize(dist_sf, r, \"dist\", fun = mean)\n\n#raster\ndist_raster\n\nclass      : RasterLayer \ndimensions : 70, 99, 6930  (nrow, ncol, ncell)\nresolution : 5000, 5000  (x, y)\nextent     : 349377.7, 844377.7, 7033908, 7383908  (xmin, xmax, ymin, ymax)\ncrs        : +proj=utm +zone=27 +ellps=intl +towgs84=-73,47,-83,0,0,0,0 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : 0.00274077, 122.3031  (min, max)\n\n#plot the raster\nplot(dist_raster)\n\n\n\n\n\n\n#export the raster\nwriteRaster(dist_raster, file = \"dist_islandia.tif\", format = \"GTiff\", overwrite = TRUE)\n\nThe rasterize( ) function is designed to create rasters from an irregular grid. In case we have a regular grid, like this one, we can use an easier alternative way. The rasterFromXYZ( ) function converts a data.frame with longitude, latitude and the variable Z into a raster object. It is important that the order should be longitude, latitude, variables.\n\nr &lt;- rasterFromXYZ(df[, c(2:3, 1)], crs = \"+proj=utm +zone=27 +ellps=intl +towgs84=-73,47,-83,0,0,0,0 +units=m +no_defs\")\n\nplot(r)\n\n\n\n\n\n\n\nWith the calculation of distance we can create art, as seen in the header of this post, which includes a world map only with the distance to the sea of all continents. A different perspective to our world (here more (spanish)) ."
  },
  {
    "objectID": "blog/always-normalize-your-data/index.html",
    "href": "blog/always-normalize-your-data/index.html",
    "title": "Always normalize you data",
    "section": "",
    "text": "I recently came across a map from the National Atlas of Spain showing the number of libraries by municipality. However, one thing directly caught my attention. There’s a saying that many maps show only the population, and this seems to be the case here. The map does not provide any remarkable information about the distribution of libraries; it merely shows where the most people live. It’s a very common pitfall. There are many phenomena that depend on population. It can be assumed that the number of libraries largely depends on the number of inhabitants in each municipality. Therefore, we see cities like Madrid, Barcelona, Seville, Valencia, and many provincial capitals with a higher number of libraries.\nNormalization of population-dependent variables can be performed in different ways, depending on the context and type of data. In our case, it involves dividing the number of libraries by the total population. To avoid very small numbers, it is common to multiply by a fixed population, such as 10,000. Another alternative, but not in this case, would be the use of percent.\n\\[\\text{Libraries per 10,000 inhabitants} = \\left( \\frac{\\text{Number of libraries}}{\\text{Total population}} \\right) \\times 10,000\\]\nIf you divide the other way around, it gives you a different perspective. You are calculating how many people, on average, have access to a single library.\n\\[\\text{Inhabitants per library} = \\frac{\\text{Total population}}{\\text{Number of libraries}}\\]\nLet’s get to work!"
  },
  {
    "objectID": "blog/always-normalize-your-data/index.html#packages",
    "href": "blog/always-normalize-your-data/index.html#packages",
    "title": "Always normalize you data",
    "section": "Packages",
    "text": "Packages\n\n\n\n\n\n\n\n\nPackage\nDescription\n\n\n\ntidyverse\nCollection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.\n\n\nmapSpain\nAdministrative boundaries of Spain at different levels\n\n\nsf\nSimple Feature: import, export and manipulate vector data\n\n\njanitor\nSimple functions for examining and cleaning dirty data\n\n\npatchwork\nSimple grammar to combine separate ggplots into the same graphic\n\n\n\n\n\n\n# install the packages if necessary\n\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"mapSpain\")) install.packages(\"mapSpain\")\nif (!require(\"sf\")) install.packages(\"sf\")\nif (!require(\"janitor\")) install.packages(\"janitor\")\nif (!require(\"patchwork\")) install.packages(\"patchwork\")\n\n# packages\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(sf)\nlibrary(mapSpain)\nlibrary(janitor)\nlibrary(patchwork)"
  },
  {
    "objectID": "blog/always-normalize-your-data/index.html#data",
    "href": "blog/always-normalize-your-data/index.html#data",
    "title": "Always normalize you data",
    "section": "Data",
    "text": "Data\nIn this post we will use a dataset of libraries from Spain for 2022 (download)1 which I obtained from the Ministry of Culture. In this step we also import the population data from the INE and municipality boundaries from the mapSpain package.\n\n# import library data\nbib &lt;- read_excel(\"datos.xlsx\") |&gt;\n  clean_names() |&gt;\n  filter(pais == \"España\")\nbib\n\n# A tibble: 7,482 × 26\n   niden       nombre nombre_ca pais  codigo_ca ca    codigo_provincia provincia\n   &lt;chr&gt;       &lt;chr&gt;  &lt;lgl&gt;     &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt;    \n 1 397-4003003 Bibli… NA        Espa… 01        Anda… 04               Almería  \n 2 397-4003001 Bibli… NA        Espa… 01        Anda… 04               Almería  \n 3 397-4003002 Bibli… NA        Espa… 01        Anda… 04               Almería  \n 4 580-4004001 Bibli… NA        Espa… 01        Anda… 04               Almería  \n 5 589-4005001 Bibli… NA        Espa… 01        Anda… 04               Almería  \n 6 398-4006001 Bibli… NA        Espa… 01        Anda… 04               Almería  \n 7 590-4007001 Bibli… NA        Espa… 01        Anda… 04               Almería  \n 8 8468-10180  Bibli… NA        Espa… 01        Anda… 04               Almería  \n 9 399-4011001 Bibli… NA        Espa… 01        Anda… 04               Almería  \n10 412-7108    Bibli… NA        Espa… 01        Anda… 04               Almería  \n# ℹ 7,472 more rows\n# ℹ 18 more variables: codigo_municipio &lt;chr&gt;, municipio &lt;chr&gt;,\n#   entidad_menor &lt;chr&gt;, direccion &lt;chr&gt;, distrito_postal &lt;chr&gt;,\n#   tipologia &lt;chr&gt;, telefono &lt;chr&gt;, correo_electronico &lt;chr&gt;,\n#   pagina_web &lt;chr&gt;, tipo_biblioteca &lt;chr&gt;, ano_fundacion &lt;dbl&gt;,\n#   telefono2 &lt;chr&gt;, longitud &lt;chr&gt;, latitud &lt;chr&gt;, correo_prestamo &lt;chr&gt;,\n#   acceso_catalogo &lt;chr&gt;, titularidad &lt;chr&gt;, gestion &lt;chr&gt;\n\n# region and municipality boundaries\nccaa &lt;- esp_get_ccaa() # for the map\nmun &lt;- esp_get_munic()\nmun\n\nSimple feature collection with 8131 features and 7 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: -13.21926 ymin: 34.70178 xmax: 4.32409 ymax: 43.7889\nGeodetic CRS:  ETRS89\nFirst 10 features:\n    codauto ine.ccaa.name cpro ine.prov.name cmun                 name LAU_CODE\n382      01     Andalucía   04       Almería  001                 Abla    04001\n379      01     Andalucía   04       Almería  002             Abrucena    04002\n374      01     Andalucía   04       Almería  003                 Adra    04003\n375      01     Andalucía   04       Almería  004            Albánchez    04004\n358      01     Andalucía   04       Almería  005            Alboloduy    04005\n373      01     Andalucía   04       Almería  006                Albox    04006\n350      01     Andalucía   04       Almería  007              Alcolea    04007\n364      01     Andalucía   04       Almería  008             Alcóntar    04008\n352      01     Andalucía   04       Almería  009 Alcudia de Monteagud    04009\n349      01     Andalucía   04       Almería  010              Alhabia    04010\n                          geometry\n382 POLYGON ((-2.77744 37.23836...\n379 POLYGON ((-2.88984 37.09213...\n374 POLYGON ((-2.93161 36.75079...\n375 POLYGON ((-2.13138 37.29959...\n358 POLYGON ((-2.70077 37.09674...\n373 POLYGON ((-2.15335 37.54576...\n350 POLYGON ((-3.05663 36.88506...\n364 POLYGON ((-2.65344 37.33238...\n352 POLYGON ((-2.27371 37.2416,...\n349 POLYGON ((-2.5425 36.97485,...\n\n# population data\npob &lt;- read_csv2(\"33570.csv\") |&gt; janitor::clean_names()\npob\n\n# A tibble: 10,739,520 × 5\n   sexo  municipios     edad_grupos_quinquenales periodo               total\n   &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;                    &lt;chr&gt;                 &lt;dbl&gt;\n 1 Total Total Nacional Todas las edades         1 de enero de 2022 47475420\n 2 Total Total Nacional Todas las edades         1 de enero de 2021 47385107\n 3 Total Total Nacional Todas las edades         1 de enero de 2020 47450795\n 4 Total Total Nacional Todas las edades         1 de enero de 2019 47026208\n 5 Total Total Nacional Todas las edades         1 de enero de 2018 46722980\n 6 Total Total Nacional Todas las edades         1 de enero de 2017 46572132\n 7 Total Total Nacional Todas las edades         1 de enero de 2016 46557008\n 8 Total Total Nacional Todas las edades         1 de enero de 2015 46624382\n 9 Total Total Nacional Todas las edades         1 de enero de 2014 46771341\n10 Total Total Nacional Todas las edades         1 de enero de 2013 47129783\n# ℹ 10,739,510 more rows"
  },
  {
    "objectID": "blog/always-normalize-your-data/index.html#preparation",
    "href": "blog/always-normalize-your-data/index.html#preparation",
    "title": "Always normalize you data",
    "section": "Preparation",
    "text": "Preparation\nFor the library data, all that is needed is to create the municipality code and count the number of libraries. Then, we use the left_join() function to join the vector data of the municipalities and the number of libraries. We also prepare the population data. Here, we must choose the whole population (any gender and age) and the year 2022. The municipality code must be extracted as a 5-digit number.\n\n# select needed columns and create municipality code\nbib &lt;- select(bib, codigo_provincia, codigo_municipio) |&gt;\n  mutate(LAU_CODE = str_c(codigo_provincia, codigo_municipio))\n\n# count libraries\nbib_count &lt;- count(bib, LAU_CODE)\n\n# join with boundaries\nmun &lt;- left_join(mun, bib_count)\n\n# filter population data\npob_mun &lt;- filter(\n  pob, sexo == \"Total\",\n  municipios != \"Total Nacional\",\n  edad_grupos_quinquenales == \"Todas las edades\",\n  str_detect(periodo, \"2022\")\n) |&gt;\n  select(municipios, total) |&gt;\n  mutate(LAU_CODE = str_extract(municipios, \"[0-9]{5}\"))"
  },
  {
    "objectID": "blog/always-normalize-your-data/index.html#visualization",
    "href": "blog/always-normalize-your-data/index.html#visualization",
    "title": "Always normalize you data",
    "section": "Visualization",
    "text": "Visualization\nTo create a proportional symbol map, we simply use the centroid of the municipality for the location. It is important to order the observations from highest to lowest, which ensures that the smaller circles are drawn on top of the larger ones.\nIn ggplot2, we use geom_sf() for the vector data and indicate size with the column n. Additionally, we set the size range with scale_size() and specify the breaks in the legend. We are also making a few small aesthetic changes.\n\nm1 &lt;- st_centroid(mun) |&gt; arrange(-n)\n\np1 &lt;- ggplot() +\n  geom_sf(data = ccaa, fill = \"grey90\", colour = \"white\") +\n  geom_sf(\n    data = m1,\n    aes(size = n),\n    alpha = .5, shape = 21, fill = \"#7a0177\", colour = \"white\"\n  ) +\n  scale_size(range = c(1, 20), breaks = c(10, 50, 150, 400)) +\n  labs(size = NULL, title = \"Absolute number of libraries\") +\n  theme_void()\np1\n\n\n\n\n\n\n\nThis map clearly resembles the one in the national atlas. Big cities, such as Madrid, Barcelona or Valencia, are highlighted.\nBut what would we see if we normalize the variable?\nTo do this, we must first join the population data and calculate the rate.\n\nm2 &lt;- st_centroid(mun) |&gt;\n  left_join(pob_mun) |&gt;\n  mutate(norm_pob = n * 10000 / total) |&gt;\n  arrange(-norm_pob)\n\nselect(m2, n, total:norm_pob)\n\nSimple feature collection with 8131 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -13.12607 ymin: 34.75565 xmax: 4.2862 ymax: 43.7256\nGeodetic CRS:  ETRS89\nFirst 10 features:\n   n total  norm_pob                    geometry\n1  1    19 526.31579   POINT (-1.30825 43.01419)\n2  1    52 192.30769  POINT (-2.812271 40.57015)\n3  1    57 175.43860  POINT (-2.868489 41.72316)\n4  1    86 116.27907  POINT (-6.472424 40.34306)\n5  1    95 105.26316 POINT (-0.4256999 40.02079)\n6  1    96 104.16667    POINT (-1.24694 42.2997)\n7  1    96 104.16667  POINT (-5.350944 39.71565)\n8  1   102  98.03922 POINT (-0.3685699 41.34055)\n9  1   104  96.15385  POINT (-5.427423 40.37489)\n10 1   104  96.15385  POINT (-5.658987 39.72373)\n\n\nNow we simply repeat the same map using the norm_pob column.\n\np2 &lt;- ggplot() +\n  geom_sf(data = ccaa, fill = \"grey90\", colour = \"white\") +\n  geom_sf(\n    data = m2,\n    aes(size = norm_pob),\n    alpha = .5, shape = 21, fill = \"#7a0177\", colour = \"white\"\n  ) +\n  scale_size(range = c(.5, 10), breaks = c(1, 10, 100, 500)) +\n  labs(size = NULL, title = \"Libraries per 10,000 inhabitants\") +\n  theme_void()\np2\n\n\n\n\n\n\n\nThis map now tells a completely different story. We see a high number of libraries per inhabitant in certain regions, while others are more homogeneous with a consistently low number of libraries. However, there are also impossible values that stand out. For example, in the north, Roncesvalles reaches 526 libraries per 10,000 inhabitants! That can’t be right, can it? This issue is caused by the very small municipalities. In this case, there is one library for every 19 inhabitants. In any case, what is also noticeable is that there are significantly fewer libraries per inhabitant in major cities like Madrid and Barcelona, with only 1 library per 10,000 inhabitants. It is not easy to find a multiplier that works uniformly to reflect both small and large municipalities.\nTo solve the problem of small municipalities, one possible good strategy would be to exclude all those with less than 100 inhabitants. It can even help in reducing overlapping.\n\np3 &lt;- ggplot() +\n  geom_sf(data = ccaa, fill = \"grey90\", colour = \"white\") +\n  geom_sf(\n    data = filter(m2, total &gt; 100),\n    aes(size = norm_pob),\n    alpha = .5, shape = 21, fill = \"#7a0177\", colour = \"white\"\n  ) +\n  scale_size(range = c(.1, 10), breaks = c(1, 10, 50, 90)) +\n  labs(size = NULL, title = \"Libraries per 10,000 inhabitants (without municipalities &lt; 100)\") +\n  theme_void()\n\np3\n\n\n\n\n\n\n\nFinally, we create a comparison with the patchwork grammar.\n\np1 + p2 + p3 & theme(plot.title = element_text(size = 20, hjust = .5),\n                     legend.text = element_text(size = 12))\n\n\n\n\n\n\n\nDifferent ways of telling different stories! A completely different question is how much the overlapping of circles prevents us from reading the map accurately. For instance, we could use a Dorling cartogram for the population and use color to show the number of libraries. Below, you see an example with the foreign population by origin. The R Code for this I will post another time."
  },
  {
    "objectID": "blog/always-normalize-your-data/index.html#footnotes",
    "href": "blog/always-normalize-your-data/index.html#footnotes",
    "title": "Always normalize you data",
    "section": "Footnotes",
    "text": "Footnotes\n\nInclude also population data.↩︎"
  },
  {
    "objectID": "bioclim/index.html",
    "href": "bioclim/index.html",
    "title": "Bioclim research group",
    "section": "",
    "text": "Welcome to BIOCLIM! We are glad you stopped by.\n\nBioclimatology and Global Change\nThe BIOCLIMA: Bioclimatology and Global Change group at the Misión Biologica de Galicia (MBG) - The Spanish National Research Council (CSIC) studies how the atmospheric environment affects the health and well-being of living beings, analyzing climatic patterns, Earth system interactions, and the adaptation of the planet and its inhabitants to climatic risks. With a multidisciplinary approach, it investigates the vulnerability of populations in the context of global change.\nThe staff associated with BIOCLIM have a multi- and interdisciplinary background and translational experience in the fields of geography, ecology, physics, biometeorology, epidemiology, and biostatistics.\nGet in touch by sending a note!"
  },
  {
    "objectID": "bioclim/index.html#about-us",
    "href": "bioclim/index.html#about-us",
    "title": "Bioclim research group",
    "section": "About us",
    "text": "About us\n\n\nResearch Lines\n\n\n The effects of the atmospheric environment on mortality and morbidity.\n\n\n Spatiotemporal and geographical behaviors of atmospheric variables.\n\n\n Interaction processes among different components of the Earth system in the context of Global Change.\n\n\n Adaptation to climate risks: vulnerability and exposure.\n\n\n Creation of open data to understand many natural, anthropogenic, and social processes.\n\n\nJoin the MBG and the BIOCLIM Group!\nThe MBG-CSIC is the perfect place to boost your career in science. If you want to grow in a collaborative environment committed to advancing knowledge, don’t hesitate to get in touch with us. We are open to receiving expressions of interest and applications for doctoral theses (PhD), master’s theses (TFM), undergraduate theses (TFG), or internships for undergraduate and vocational training programs.\nLet us know if you need anything else!\n\n\nBIOCLIM in scientific collaboration platforms"
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "Dominic Royé",
    "section": "",
    "text": "Hello, and welcome! I’m glad you stopped by.\n\nThe “where”, “why”, and the “how”\nI work as a Ramon y Cajal reseacher at the MBG-CSIC. My research interests include bioclimatology and spatial data science. I am an enthusiastic R user, with a lot of curiosity for spatial analysis, data visualizations, management and manipulation, and GIS. Keep up with my R tinkering in my blog. Learn more about my research interests in publications.\nGet in touch by sending me a note!"
  },
  {
    "objectID": "about/index.html#about-me",
    "href": "about/index.html#about-me",
    "title": "Dominic Royé",
    "section": "About me",
    "text": "About me\n\n\nClimate scientist, curious about all intersections of data and society.\nI am a climate scientist and actually, I am Ramon y Cajal researcher at the Misión Biologica de Galicia - The Spanish National Research Council (CSIC), previously I was the head of data science at the Climate Research Foundation (FIC) and researcher at the University of Santiago de Compostela. I am originally from Grevenbroich, near by Cologne, in Germany. I graduated in Geography and Hispanic Philology at the University of Cologne and RWTH-Aachen University in 2010. After I met my wife in Galicia, I came to Santiago de Compostela, in northwest Spain, and made my Ph.D. in 2015 about the relationship between health and climate at the same University.\n\n\nInterests: applied climatology, physical geography, biometeorology, public health, geographic information systems, R programming, data management, manipulation and visualization\n\n\n\n\nI am a member of the Public Health Research Group at the University of Santiago de Compostela. In addition, I am a close collaborator of two other research groups, Geobiomet at the University of Cantabria and Climatology Group at the University of Barcelona. Since 2019 I am a member of the MCC Collaborative Research Network, an international research program on the associations between environmental stressors, climate, and health.\nI’m particularly interested in biometeorology, among others, the relationship between human health and the atmospheric environment, and on the other hand, applied physical geography with a focus on atmospheric variables and their spatio-temporal behaviors.\n\n\nPhD in Physical Geography | University of Santiago de Compostela, Spain | 2015\n\n\nB.S. in Geography and Hispanic Philology | University of Cologne | RWTH-Aachen University, Germany | 2010"
  },
  {
    "objectID": "about/index.html#lately",
    "href": "about/index.html#lately",
    "title": "Dominic Royé",
    "section": "Lately …",
    "text": "Lately …\n\nBlog\n\n\n\n\n\n\n\n\n\nAlways normalize you data\n\n\nI recently came across a map from the National Atlas of Spain showing the number of libraries by municipality. However, one thing directly caught my attention. There’s a saying that many maps show only the population, and this seems to be the case here. The map does not provide any remarkable information about the distribution of libraries; it merely shows where the most people live.\n\n\n\n\n\n\n\nNo matching items\n\n\nSee all →\nPublications\n\n\n\nBatibeniz F, Seneviratne SI, Jha S, et al. (2025). Rapid climate action is needed: comparing heat vs. COVID-19-related mortality. Scientific Reports, vol. 15, art. no. 1002.  10.1038/s41598-024-82788-8.\n\n\n\n\nXu R, Ye T, Huang W, et al. (2024). Global, regional, and national mortality burden attributable to air pollution from landscape fires: a health impact assessment study. The Lancet, vol. 404(10470), pp. 2447-2459.  10.1016/S0140-6736(24)02251-7.\n\n\n\nSee all →\nData Viz\n\n\n\n\n\n\n\n\n\n\n\n\nSee all →"
  },
  {
    "objectID": "blog/accessing-osm-data-with-r/index.html",
    "href": "blog/accessing-osm-data-with-r/index.html",
    "title": "Accessing OpenStreetMap data with R",
    "section": "",
    "text": "Recently I created a map of the distribution of gas stations and electric charging stations in Europe.\n\nHow can you obtain this data?\nWell, in this case I used points of interest (POIs) from the database of Open Street Maps (OSM). Obviously OSM not only contains streets and highways, but also information that can be useful when we use a map such as locations of hospitals or gas stations. To avoid downloading the entire OSM and extracting the required information, you can use an overpass API, which allows us to query the OSM database with our own criteria.\nAn easy way to access an overpass API is through overpass-turbo.eu, which even includes a wizard to build a query and display the results on a interactive map. A detailed explanation of the previous web can be found here. However, we have at our disposal a package osmdata that allows us to create and make queries directly from the R environment. Nevertheless, the use of the overpass-turbo.eu can be useful when we are not sure what we are looking for or when we have some difficulty in building the query."
  },
  {
    "objectID": "blog/accessing-osm-data-with-r/index.html#the-database-of-open-street-maps",
    "href": "blog/accessing-osm-data-with-r/index.html#the-database-of-open-street-maps",
    "title": "Accessing OpenStreetMap data with R",
    "section": "",
    "text": "Recently I created a map of the distribution of gas stations and electric charging stations in Europe.\n\nHow can you obtain this data?\nWell, in this case I used points of interest (POIs) from the database of Open Street Maps (OSM). Obviously OSM not only contains streets and highways, but also information that can be useful when we use a map such as locations of hospitals or gas stations. To avoid downloading the entire OSM and extracting the required information, you can use an overpass API, which allows us to query the OSM database with our own criteria.\nAn easy way to access an overpass API is through overpass-turbo.eu, which even includes a wizard to build a query and display the results on a interactive map. A detailed explanation of the previous web can be found here. However, we have at our disposal a package osmdata that allows us to create and make queries directly from the R environment. Nevertheless, the use of the overpass-turbo.eu can be useful when we are not sure what we are looking for or when we have some difficulty in building the query."
  },
  {
    "objectID": "blog/accessing-osm-data-with-r/index.html#accessing-the-overpass-api-from-r",
    "href": "blog/accessing-osm-data-with-r/index.html#accessing-the-overpass-api-from-r",
    "title": "Accessing OpenStreetMap data with R",
    "section": "Accessing the overpass API from R",
    "text": "Accessing the overpass API from R\nThe first step is to install several packages, in case they are not installed. In almost all my scripts I use tidyverse which is a fundamental collection of different packages, including dplyr (data manipulation), ggplot2 (visualization), etc. The sf package is the new standard for working with spatial data and is compatible with ggplot2 and dplyr. Finally, ggmap makes it easier for us to create maps.\n\n# install the osmdata, sf, tidyverse and ggmap package\nif (!require(\"osmdata\")) install.packages(\"osmdata\")\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"sf\")) install.packages(\"sf\")\nif (!require(\"ggmap\")) install.packages(\"ggmap\")\n\n# load packages\nlibrary(tidyverse)\nlibrary(osmdata)\nlibrary(sf)\nlibrary(ggmap)"
  },
  {
    "objectID": "blog/accessing-osm-data-with-r/index.html#build-a-query",
    "href": "blog/accessing-osm-data-with-r/index.html#build-a-query",
    "title": "Accessing OpenStreetMap data with R",
    "section": "Build a query",
    "text": "Build a query\nBefore creating a query, we need to know what we can filter. The available_features( ) function returns a list of available OSM features that have different tags. More details are available in the OSM wiki here. For example, the feature shop contains several tags among others supermarket, fishing, books, etc.\n\n# the first five features\nhead(available_features())\n\n[1] \"4wd_only\"  \"abandoned\" \"abutters\"  \"access\"    \"addr\"      \"addr:city\"\n\n# amenities\nhead(available_tags(\"amenity\"))\n\n# A tibble: 6 × 2\n  Key     Value          \n  &lt;chr&gt;   &lt;chr&gt;          \n1 amenity animal_boarding\n2 amenity animal_breeding\n3 amenity animal_shelter \n4 amenity animal_training\n5 amenity arts_centre    \n6 amenity atm            \n\n# shops\nhead(available_tags(\"shop\"))\n\n# A tibble: 6 × 2\n  Key   Value                                                   \n  &lt;chr&gt; &lt;chr&gt;                                                   \n1 shop  [[ Too many Data Items entities accessed. |  hunting  ]]\n2 shop  agrarian                                                \n3 shop  alcohol                                                 \n4 shop  anime                                                   \n5 shop  antiques                                                \n6 shop  appliance                                               \n\n\nThe first query: Where are cinemas in Madrid?\nTo build the query, we use the pipe operator |&gt; from R Base, which helps to chain several functions without assigning the result to a new object. The first pipe in R was %&gt;% very extended especially within the tidyverse package collection. If you want to know more about its use, you can find here a tutorial or some details on differences between both here.\nIn the first part of the query we need to indicate the place where we want to extract the information. The getbb( ) function creates a boundering box for a given place, looking for the name. The main function is opq( ) which build the final query. We add our filter criteria with the add_osm_feature( ) function. In this first query we will look for cinemas in Madrid. That’s why we use as key amenity and cinema as tag. There are several formats to obtain the resulting spatial data of the query. The osmdata_*( ) function sends the query to the server and, depending on the suffix * sf/sp/xml, returns a simple feature, spatial or XML format.\n\n# building the query\nq &lt;- getbb(\"Madrid\") |&gt;\n  opq() |&gt;\n  add_osm_feature(\"amenity\", \"cinema\")\n\nstr(q) # query structure\n\nList of 5\n $ bbox     : chr \"40.3119774,-3.8889539,40.6437293,-3.5179163\"\n $ prefix   : chr \"[out:xml][timeout:25];\\n(\\n\"\n $ suffix   : chr \");\\n(._;&gt;;);\\nout body;\"\n $ features : chr \"[\\\"amenity\\\"=\\\"cinema\\\"]\"\n $ osm_types: chr [1:3] \"node\" \"way\" \"relation\"\n - attr(*, \"class\")= chr [1:2] \"list\" \"overpass_query\"\n - attr(*, \"nodes_only\")= logi FALSE\n\ncinema &lt;- osmdata_sf(q)\ncinema\n\nObject of class 'osmdata' with:\n                 $bbox : 40.3119774,-3.8889539,40.6437293,-3.5179163\n        $overpass_call : The call submitted to the overpass API\n                 $meta : metadata including timestamp and version numbers\n           $osm_points : 'sf' Simple Features Collection with 244 points\n            $osm_lines : 'sf' Simple Features Collection with 2 linestrings\n         $osm_polygons : 'sf' Simple Features Collection with 11 polygons\n       $osm_multilines : NULL\n    $osm_multipolygons : 'sf' Simple Features Collection with 1 multipolygons\n\n\nWe see that the result is a list of different spatial objects. In our case, we are only interested in osm_points.\nHow can we visulise these points?\nThe advantage of sf objects is that for ggplot2 already exists a geometry function geom_sf( ). Furthermore, we can include a background map using ggmap. The get_map( ) function downloads the map for a given place. Alternatively, it can be an address, latitude/longitude or a bounding box. The maptype argument allows us to indicate the style or type of map. You can find more details in the help of the ?get_map function.\nWhen we build a graph with ggplot we usually start with ggplot( ). In this case, we start with ggmap( ) that includes the object with our background map. Then we add with geom_sf( ) the points of the cinemas in Madrid. It is important to indicate with the argument inherit.aes = FALSE that it has to use the aesthetic mappings of the spatial object osm_points. In addition, we change the color, fill, transparency (alpha), type and size of the circles.\nYou need to register your key for Stadia Maps: register_stadiamaps(_key_)\n\n# our background map\nmad_map &lt;- get_map(getbb(\"Madrid\"), maptype = \"stamen_toner_background\")\n\n# final map\nggmap(mad_map) +\n  geom_sf(\n    data = cinema$osm_points,\n    inherit.aes = FALSE,\n    colour = \"#238443\",\n    fill = \"#004529\",\n    alpha = .5,\n    size = 4,\n    shape = 21\n  ) +\n theme_void()\n\n\n\n\n\n\n\nWhere can we find Mercadona supermarkets?\nInstead of obtaining a bounding box with the function getbb( ) we can build our own box. To do this, we create a vector of four elements, the order has to be West/South/East/North. In the query we use two features: name and shop to filter supermarkets that are of this particular brand. Depending on the area or volume of the query, it is necessary to extend the waiting time. By default, the limit is set at 25 seconds (timeout).\nThe map, we create in this case, consists only of the supermarket points. Therefore, we use the usual grammar by adding the geometry geom_sf( ). The theme_void( ) function removes everything except for the points.\n\n# bounding box for the Iberian Peninsula\nm &lt;- c(-10, 30, 5, 46)\n\n# building the query\nq &lt;- m |&gt;\n  opq(timeout = 25 * 100) |&gt;\n  add_osm_feature(\"name\", \"Mercadona\") |&gt;\n  add_osm_feature(\"shop\", \"supermarket\")\n\n# query\nmercadona &lt;- osmdata_sf(q)\n\n# final map\nggplot(mercadona$osm_points) +\n  geom_sf(\n    colour = \"#08519c\",\n    fill = \"#08306b\",\n    alpha = .5,\n    size = 1,\n    shape = 21\n  ) +\n  theme_void()"
  },
  {
    "objectID": "blog/bivariate-dasymetric-map/index.html",
    "href": "blog/bivariate-dasymetric-map/index.html",
    "title": "Bivariate dasymetric map",
    "section": "",
    "text": "A disadvantage of choropleth maps is that they tend to distort the relationship between the true underlying geography and the represented variable. It is because the administrative divisions do not usually coincide with the geographical reality where people live. Besides, large areas appear to have a weight that they do not really have because of sparsely populated regions. To better reflect reality, more realistic population distributions are used, such as land use. With Geographic Information Systems techniques, it is possible to redistribute the variable of interest as a function of a variable with a smaller spatial unit.\nWith point data, the redistribution process is simply clipping points with population based on land use, usually classified as urban. We could also crop and mask with land use polygons when we have a vectorial polygon layer, but an interesting alternative is the same data in raster format. We will see how we can make a dasymetric map using raster data with a resolution of 100 m. This post will use data from census sections of the median income and the Gini index for Spain. We will make a dasymetric and bivariate map, representing both variables with two ranges of colours on the same map."
  },
  {
    "objectID": "blog/bivariate-dasymetric-map/index.html#data",
    "href": "blog/bivariate-dasymetric-map/index.html#data",
    "title": "Bivariate dasymetric map",
    "section": "Data",
    "text": "Data\nFirst we download all the necessary data. With the exception of the CORINE Land Cover (~ 200 MB), the data stored on this blog can be obtained directly via the indicated links.\n\nCORINE Land Cover 2018 (geotiff): COPERNICUS\n\nIncome data and Gini index (excel) [INE]: download\n\nCensus limits of Spain (vectorial) [INE]: download"
  },
  {
    "objectID": "blog/bivariate-dasymetric-map/index.html#import",
    "href": "blog/bivariate-dasymetric-map/index.html#import",
    "title": "Bivariate dasymetric map",
    "section": "Import",
    "text": "Import\nThe first thing we do is to import the land use raster, the income and Gini index data, and the census boundaries.\n\n# raster of CORINE LAND COVER 2018\nurb &lt;- rast(\"U2018_CLC2018_V2020_20u1.tif\")\n\n# income data and Gini index\nrenta &lt;- read_excel(\"30824.xlsx\")\ngini &lt;- read_excel(\"37677.xlsx\")\n\n# census boundaries\nlimits &lt;- read_sf(\"SECC_CE_20200101.shp\")"
  },
  {
    "objectID": "blog/bivariate-dasymetric-map/index.html#land-uses",
    "href": "blog/bivariate-dasymetric-map/index.html#land-uses",
    "title": "Bivariate dasymetric map",
    "section": "Land uses",
    "text": "Land uses\nIn this first step we filter the census sections to obtain those of the Autonomous Community of Madrid, and we create the municipal limits. To dissolve the polygons of census tracts we apply the function group_by() in combination with summarise().\n\n# filter the Autonomous Community of Madrid\nlimits &lt;- filter(limits, NCA == \"Comunidad de Madrid\")\n\n# obtain the municipal limits\nmun_limit &lt;- group_by(limits, CUMUN) |&gt; summarise()\n\nIn the next step we cut the land use raster with the limits of Madrid. I recommend always using the crop() function first and then mask(), the first function crop to the required extent and the second mask the values. Subsequently, we remove all the cells that correspond to 1 or 2 (urban continuous, discontinuous). Finally, we project the raster.\n\n# project the limits\nlimits_prj &lt;- st_transform(limits, crs(urb))\n\n# crop and mask\nurb_mad &lt;- crop(urb, limits_prj) |&gt;\n  mask(limits_prj)\n\n# remove non-urban pixels\nurb_mad[!urb_mad %in% 1:2] &lt;- NA\n\n# plot the raster\nplot(urb_mad)\n\n\n\n\n\n\n# project\nurb_mad &lt;- project(urb_mad, \"EPSG:4326\")\n\nIn this step, we convert the raster data into a point sf object.\n\n# transform the raster to xyz and a sf object\nurb_mad &lt;- as.data.frame(urb_mad, xy = TRUE) |&gt;\n              st_as_sf(coords = c(\"x\", \"y\"), crs = 4326)\n\n# add the columns of the coordinates\nurb_mad &lt;- urb_mad |&gt; rename(urb = 1) |&gt;\n             cbind(st_coordinates(urb_mad))"
  },
  {
    "objectID": "blog/bivariate-dasymetric-map/index.html#income-data-and-gini-index",
    "href": "blog/bivariate-dasymetric-map/index.html#income-data-and-gini-index",
    "title": "Bivariate dasymetric map",
    "section": "Income data and Gini index",
    "text": "Income data and Gini index\nThe format of the Excels does not coincide with the original of the INE, since I have cleaned the format before in order to make this post easier. What remains is to create a column with the codes of the census sections and exclude data that correspond to another administrative level.\n\n## income and Gini index data\n\nrenta_sec &lt;- mutate(renta,\n  NATCODE = str_extract(CUSEC, \"[0-9]{5,10}\"),\n  nc_len = str_length(NATCODE),\n  mun_name = str_remove(CUSEC, NATCODE) |&gt; str_trim()\n) |&gt;\n  filter(nc_len &gt; 5)\n\ngini_sec &lt;- mutate(gini,\n  NATCODE = str_extract(CUSEC, \"[0-9]{5,10}\"),\n  nc_len = str_length(NATCODE),\n  mun_name = str_remove(CUSEC, NATCODE) |&gt; str_trim()\n) |&gt;\n  filter(nc_len &gt; 5)\n\nIn the next step we join both tables with the census tracts using left_join() and convert columns of interest in numerical mode.\n\n# join both the income and Gini tables with the census limits\nmad &lt;- left_join(limits, renta_sec, by = c(\"CUSEC\" = \"NATCODE\")) |&gt;\n            left_join(gini_sec, by = c(\"CUSEC\" = \"NATCODE\"))\n\n# convert selected columns to numeric\nmad &lt;- mutate(mad, across(c(23:27, 30:31), as.numeric))"
  },
  {
    "objectID": "blog/bivariate-dasymetric-map/index.html#bivariate-variable",
    "href": "blog/bivariate-dasymetric-map/index.html#bivariate-variable",
    "title": "Bivariate dasymetric map",
    "section": "Bivariate variable",
    "text": "Bivariate variable\nTo create a bivariate map we must construct a single variable that combines different classes of two variables. Usually we make three classes of each variable which leads to nine combinations; in our case, the average income and the Gini index. The biscale package includes helper functions to carry out this process. With the bi_class() function we create the classification variable using quantiles as algorithm. Since in both variables we find missing values, we correct those combinations between both variables where an NA appears.\n\n# create bivariate classification\nmapbivar &lt;- bi_class(mad, GINI_2017, RNMP_2017, style = \"quantile\", dim = 3) |&gt;\n             mutate(bi_class = ifelse(str_detect(bi_class, \"NA\"), NA, bi_class))\n\n# results\nhead(dplyr::select(mapbivar, GINI_2017, RNMP_2017, bi_class))\n\nSimple feature collection with 6 features and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 415538.9 ymin: 4451487 xmax: 469341.7 ymax: 4552422\nProjected CRS: ETRS89 / UTM zone 30N\n# A tibble: 6 × 4\n  GINI_2017 RNMP_2017 bi_class                                          geometry\n      &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;                                   &lt;MULTIPOLYGON [m]&gt;\n1      NA          NA &lt;NA&gt;     (((446007.9 4552348, 446133.7 4552288, 446207.8 …\n2      31       13581 2-2      (((460243.8 4487756, 460322.4 4487739, 460279 44…\n3      30       12407 2-2      (((457392.5 4486262, 457391.6 4486269, 457391.1 …\n4      34.3     13779 3-2      (((468720.8 4481374, 468695.5 4481361, 468664.6 …\n5      33.5      9176 3-1      (((417140.2 4451736, 416867.5 4451737, 416436.8 …\n6      26.2     10879 1-1      (((469251.9 4480826, 469268.1 4480797, 469292.6 …\n\n\nWe finish by redistributing the inequality variable over the pixels of urban land use. The st_join() function joins the data with the land use points.\n\n# redistribute urban pixels to inequality\nmapdasi &lt;- st_join(urb_mad, st_transform(mapbivar, 4326))"
  },
  {
    "objectID": "blog/bivariate-dasymetric-map/index.html#legend-and-font",
    "href": "blog/bivariate-dasymetric-map/index.html#legend-and-font",
    "title": "Bivariate dasymetric map",
    "section": "Legend and font",
    "text": "Legend and font\nBefore constructing both maps we must create the legend using the bi_legend() function. In the function we define the titles for each variable, the number of dimensions and the color scale. Finally, we add the Montserrat font for the final titles in the graphic.\n\n# bivariate legend\nlegend2 &lt;- bi_legend(\n  pal = \"DkViolet\",\n  dim = 3,\n  xlab = \"Higher inequality\",\n  ylab = \"Higher income\",\n  size = 9\n)"
  },
  {
    "objectID": "blog/bivariate-dasymetric-map/index.html#dasymetric-map",
    "href": "blog/bivariate-dasymetric-map/index.html#dasymetric-map",
    "title": "Bivariate dasymetric map",
    "section": "Dasymetric map",
    "text": "Dasymetric map\nWe build this map using geom_tile() for the pixels and geom_sf() for the municipal boundaries. In addition, it will be the map on the right where we also place the legend. To add the legend we use the annotation_custom() function indicating the position in the geographical coordinates of the map. The biscale package also helps us with the color definition via the bi_scale_fill() function.\n\np2 &lt;- ggplot(mapdasi) +\n  geom_tile(\n    aes(X, Y,\n      fill = bi_class\n    ),\n    show.legend = FALSE\n  ) +\n  geom_sf(\n    data = mun_limit,\n    color = \"grey80\",\n    fill = NA,\n    size = 0.2\n  ) +\n  annotation_custom(ggplotGrob(legend2),\n    xmin = -3.25, xmax = -2.65,\n    ymin = 40.55, ymax = 40.95\n  ) +\n  bi_scale_fill(\n    pal = \"DkViolet\",\n    dim = 3,\n    na.value = \"grey90\"\n  ) +\n  labs(title = \"dasymetric\", x = NULL, y = NULL) +\n  bi_theme() +\n  theme(plot.title = element_text(family = \"Montserrat\", size = 30, face = \"bold\"),\n        plot.margin = margin(5, 50, 5, 5)) +\n  coord_sf(crs = 4326, clip = \"off\")"
  },
  {
    "objectID": "blog/bivariate-dasymetric-map/index.html#choropleth-map",
    "href": "blog/bivariate-dasymetric-map/index.html#choropleth-map",
    "title": "Bivariate dasymetric map",
    "section": "Choropleth map",
    "text": "Choropleth map\nThe choropleth map is built in a similar way to the previous map with the difference that we use geom_sf().\n\np1 &lt;- ggplot(mapbivar) +\n  geom_sf(aes(fill = bi_class),\n    colour = NA,\n    size = .1,\n    show.legend = FALSE\n  ) +\n  geom_sf(\n    data = mun_limit,\n    color = \"white\",\n    fill = NA,\n    size = 0.2\n  ) +\n  bi_scale_fill(\n    pal = \"DkViolet\",\n    dim = 3,\n    na.value = \"grey90\"\n  ) +\n  labs(title = \"choropleth\", x = NULL, y = NULL) +\n  bi_theme() +\n  theme(plot.title = element_text(family = \"Montserrat\", size = 30, face = \"bold\")) +\n  coord_sf(crs = 4326)"
  },
  {
    "objectID": "blog/bivariate-dasymetric-map/index.html#merge-both-maps",
    "href": "blog/bivariate-dasymetric-map/index.html#merge-both-maps",
    "title": "Bivariate dasymetric map",
    "section": "Merge both maps",
    "text": "Merge both maps\nWith the help of the patchwork package, we combine both maps in a single row, first the choropleth map and on its right the dasymmetric map. More details of the grammar used for the combination of graphics here.\n\n# combine\np &lt;- p1 | p2\n\n# final map\np"
  },
  {
    "objectID": "blog/calendar-heatmap/index.html",
    "href": "blog/calendar-heatmap/index.html",
    "title": "A heatmap as calendar",
    "section": "",
    "text": "Recently I was looking for a visual representation to show the daily changes of temperature, precipitation and wind in an application xeo81.shinyapps.io/MeteoExtremosGalicia (in Spanish), which led me to use a heatmap in the form of a calendar. The shiny application is updated every four hours with new data showing calendars for each weather station. The heatmap as a calendar allows you to visualize any variable with a daily time reference."
  },
  {
    "objectID": "blog/calendar-heatmap/index.html#packages",
    "href": "blog/calendar-heatmap/index.html#packages",
    "title": "A heatmap as calendar",
    "section": "Packages",
    "text": "Packages\nIn this post we will use the following packages:\n\n\n\n\n\n\n\n\nPackage\nDescription\n\n\ntidyverse\nCollection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.\n\n\n\n\n\n# instalamos los paquetes si hace falta\n\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\n\n# paquetes\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "blog/calendar-heatmap/index.html#data",
    "href": "blog/calendar-heatmap/index.html#data",
    "title": "A heatmap as calendar",
    "section": "Data",
    "text": "Data\nIn this example we will use the daily precipitation of Santiago de Compostela for this year 2020 (until December 20) download.\n\n# import the data\ndat_pr &lt;- read_csv(\"precipitation_santiago.csv\")\ndat_pr\n\n# A tibble: 355 x 2\n   date          pr\n   &lt;date&gt;     &lt;dbl&gt;\n 1 2020-01-01   0  \n 2 2020-01-02   0  \n 3 2020-01-03   5.4\n 4 2020-01-04   0  \n 5 2020-01-05   0  \n 6 2020-01-06   0  \n 7 2020-01-07   0  \n 8 2020-01-08   1  \n 9 2020-01-09   3.8\n10 2020-01-10   0  \n# i 345 more rows"
  },
  {
    "objectID": "blog/calendar-heatmap/index.html#preparation",
    "href": "blog/calendar-heatmap/index.html#preparation",
    "title": "A heatmap as calendar",
    "section": "Preparation",
    "text": "Preparation\nIn the first step we must 1) complement the time series from December 21 to December 31 with NA, 2) add the day of the week, the month, the week number and the day. Depending on whether we want each week to start on Sunday or Monday, we indicate it in the wday() function.\n\ndat_pr &lt;- dat_pr |&gt;\n  complete(date = seq(\n    ymd(\"2020-01-01\"),\n    ymd(\"2020-12-31\"),\n    \"day\"\n  )) |&gt;\n  mutate(\n    weekday = wday(date, label = T, week_start = 1),\n    month = month(date, label = T, abbr = F),\n    week = isoweek(date),\n    day = day(date)\n  )\n\nIn the next step we need to make a change in the week of the year, which is because in certain years there may be, for example, a few days at the end of the year as the first week of the following year. We also create two new columns. On the one hand, we categorize precipitation into 14 classes and on the other, we define a white text color for darker tones in the heatmap.\n\ndat_pr &lt;- mutate(dat_pr,\n  week = case_when(\n    month == \"December\" & week == 1 ~ 53,\n    month == \"January\" & week %in% 52:53 ~ 0,\n    TRUE ~ week\n  ),\n  pcat = cut(pr, c(-1, 0, .5, 1:5, 7, 9, 15, 20, 25, 30, 300)),\n  text_col = ifelse(pcat %in% c(\"(15,20]\", \"(20,25]\", \"(25,30]\", \"(30,300]\"),\n    \"white\", \"black\"\n  )\n)\n\ndat_pr\n\n# A tibble: 366 x 8\n   date          pr weekday month    week   day pcat    text_col\n   &lt;date&gt;     &lt;dbl&gt; &lt;ord&gt;   &lt;ord&gt;   &lt;dbl&gt; &lt;int&gt; &lt;fct&gt;   &lt;chr&gt;   \n 1 2020-01-01   0   Wed     January     1     1 (-1,0]  black   \n 2 2020-01-02   0   Thu     January     1     2 (-1,0]  black   \n 3 2020-01-03   5.4 Fri     January     1     3 (5,7]   black   \n 4 2020-01-04   0   Sat     January     1     4 (-1,0]  black   \n 5 2020-01-05   0   Sun     January     1     5 (-1,0]  black   \n 6 2020-01-06   0   Mon     January     2     6 (-1,0]  black   \n 7 2020-01-07   0   Tue     January     2     7 (-1,0]  black   \n 8 2020-01-08   1   Wed     January     2     8 (0.5,1] black   \n 9 2020-01-09   3.8 Thu     January     2     9 (3,4]   black   \n10 2020-01-10   0   Fri     January     2    10 (-1,0]  black   \n# i 356 more rows"
  },
  {
    "objectID": "blog/calendar-heatmap/index.html#visualization",
    "href": "blog/calendar-heatmap/index.html#visualization",
    "title": "A heatmap as calendar",
    "section": "Visualization",
    "text": "Visualization\nFirst we create a color ramp from Brewer colors.\n\n# color ramp\npubu &lt;- RColorBrewer::brewer.pal(9, \"PuBu\")\ncol_p &lt;- colorRampPalette(pubu)\n\nSecond, before building the chart, we define a custom theme as a function. To do this, we specify all the elements and their modifications with the help of the theme() function.\n\ntheme_calendar &lt;- function() {\n  theme_void(base_family = \"Montserrat\") %+replace%\n  theme(\n    aspect.ratio = 1 / 2,\n    strip.text = element_text(face = \"bold\", size = 15),\n    legend.position = \"top\",\n    legend.text = element_text(hjust = .5),\n    legend.title = element_text(size = 9, hjust = 1),\n    plot.caption = element_text(hjust = 1, size = 8),\n    panel.border = element_rect(colour = \"grey\", fill = NA,linewidth = 1),\n    plot.title = element_text(\n      hjust = .5, size = 26,\n      face = \"bold\",\n      margin = margin(0, 0, 0.5, 0, unit = \"cm\")\n    ),\n    plot.subtitle = element_text(hjust = .5, size = 16)\n  )\n}\n\nFinally, we build the final chart using geom_tile() and specify the day of the week as the X axis and the week number as the Y axis. As you can see in the variable of the week number (-week), I change the sign so that the first day of each month is in the first row. With geom_text() we add the number of each day with its color according to what we defined previously. In guides we make the adjustments of the colorbar and in scale_fill/colour_manual() we define the corresponding colors. An important step is found in facet_wrap() where we specify the facets composition of each month. The facets should have free scales and the ideal would be a 4 x 3 facet distribution. It is possible to modify the position of the day number to another using the arguments nudge_* in geom_text() (eg bottom-right corner: nudge_x = .35, nudge_y = -.25).\n\nggplot(\n  dat_pr,\n  aes(weekday, -week, fill = pcat)\n) +\n  geom_tile(colour = \"white\", size = .4) +\n  geom_text(aes(label = day, colour = text_col), size = 2.5) +\n  guides(fill = guide_colorsteps(\n    barwidth = 25,\n    barheight = .4,\n    title.position = \"top\"\n  )) +\n  scale_fill_manual(\n    values = c(\"white\", col_p(13)),\n    na.value = \"grey90\", drop = FALSE\n  ) +\n  scale_colour_manual(values = c(\"black\", \"white\"), guide = FALSE) +\n  facet_wrap(~month, nrow = 4, ncol = 3, scales = \"free\") +\n  labs(\n    title = \"How is 2020 being in Santiago?\",\n    subtitle = \"Precipitation\",\n    caption = \"Data: Meteogalicia\",\n    fill = \"mm\"\n  ) +\n  theme_calendar()\n\n\n\n\n\n\n\n\nggsave(\"pr_calendar.png\", height = 10, width = 8)\n\nIn other heatmap calendars I have added the predominant wind direction of each day as an arrow using geom_arrow() from the metR package (it can be seen in the aforementioned application). Another specific package for calendar heatmaps is calendR."
  },
  {
    "objectID": "blog/climate-anomalies/index.html",
    "href": "blog/climate-anomalies/index.html",
    "title": "Visualize climate anomalies",
    "section": "",
    "text": "When we visualize precipitation and temperature anomalies, we simply use time series as bar graph indicating negative and positive values in red and blue. However, in order to have a better overview we need both anomalies in a single graph. In this way we could more easly answer the question of whether a particular season or month was dry-warm or wet-cold, and even compare these anomalies in the context of previous years."
  },
  {
    "objectID": "blog/climate-anomalies/index.html#packages",
    "href": "blog/climate-anomalies/index.html#packages",
    "title": "Visualize climate anomalies",
    "section": "Packages",
    "text": "Packages\nIn this post we will use the following packages:\n\n\n\n\n\n\n\n\nPackage\nDescription\n\n\n\ntidyverse\nCollection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.\n\n\nggrepel\nRepel overlapping text labels in ggplot2\n\n\n\n\n\n\n# we install the packages if necessary\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"ggrepel\")) install.packages(\"ggrepel\")\n\n# packages\nlibrary(tidyverse)\nlibrary(ggrepel)"
  },
  {
    "objectID": "blog/climate-anomalies/index.html#preparing-the-data",
    "href": "blog/climate-anomalies/index.html#preparing-the-data",
    "title": "Visualize climate anomalies",
    "section": "Preparing the data",
    "text": "Preparing the data\nFirst we import the daily precipitation and temperature data from the selected weather station (download). We will use the data from Tenerife South (Spain) [1981-2020] accessible through Open Data AEMET. In R there is a package called meteoland that facilitates the download with specific functions to access data from AEMET (Spanish State Meteorological Agency), Meteogalicia (Galician Meteorological Service) and Meteocat (Catalan Meteorological Service).\nStep 1: import the data\nWe import the data in csv format, the first column is the date, the second column the precipitation (pr) and the last column the average daily temperature (ta).\n\ndata &lt;- read_csv(\"meteo_tenerife.csv\")\n\nRows: 14303 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl  (2): pr, ta\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndata\n\n# A tibble: 14,303 × 3\n   date          pr    ta\n   &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1 1981-01-02   0    17.6\n 2 1981-01-03   0    16.8\n 3 1981-01-04   0    17.4\n 4 1981-01-05   0    17.6\n 5 1981-01-06   0    17  \n 6 1981-01-07   0    17.6\n 7 1981-01-08   0    18.6\n 8 1981-01-09   0    19.8\n 9 1981-01-10   0    21.5\n10 1981-01-11   3.8  17.6\n# ℹ 14,293 more rows\n\n\nStep 2: preparing the data\nIn the second step we prepare the data to calculate the anomalies. To do this, we create three new columns: the month, the year, and the season of the year. Since our objective is to analyse winter anomalies, we cannot use the calendar year, because winter includes the month of December of one year and the months of January and February of the following. The concept is similar to the hydrological year in which it starts on October 1.\nWe will use many functions of the package collection tidyverse (https://www.tidyverse.org/). The mutate() function helps to add new columns or change existing ones. To define the seasons, we use the case_when() function from the dplyr package, which has many advantages compared to a chain of ifelse(). In case_when() we use two-side formulas, on the one hand the condition and on the other the action when that condition is met. A two-sided formula in R consists of the operator ~. The binary operator %in% allows us to filter several values in a greater set.\n\ndata &lt;- mutate(data,\n  winter_yr = ifelse(month(date) == 12, year(date)+1, year(date)),\n  month = month(date),\n  season = case_when(\n    month %in% c(12, 1:2) ~ \"Winter\",\n    month %in% 3:5 ~ \"Spring\",\n    month %in% 6:8 ~ \"Summer\",\n    month %in% 9:11 ~ \"Autum\"\n  )\n)\n\ndata\n\n# A tibble: 14,303 × 6\n   date          pr    ta winter_yr month season\n   &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; \n 1 1981-01-02   0    17.6      1981     1 Winter\n 2 1981-01-03   0    16.8      1981     1 Winter\n 3 1981-01-04   0    17.4      1981     1 Winter\n 4 1981-01-05   0    17.6      1981     1 Winter\n 5 1981-01-06   0    17        1981     1 Winter\n 6 1981-01-07   0    17.6      1981     1 Winter\n 7 1981-01-08   0    18.6      1981     1 Winter\n 8 1981-01-09   0    19.8      1981     1 Winter\n 9 1981-01-10   0    21.5      1981     1 Winter\n10 1981-01-11   3.8  17.6      1981     1 Winter\n# ℹ 14,293 more rows\n\n\nStep 3: estimate winter anomalies\nIn the next step we create a subset of the winter months. Then we group by the defined meteorological year and calculate the sum and average for precipitation and temperature, respectively. To facilitate the work, the magrittr package and later R Base introduces the operator called pipe in the form %&gt;% and |&gt; with the aim of combining several functions without the need to assign the result to a new object. The pipe operator passes the output of a function applied to the first argument of the next function. This way of combining functions allows you to chain several steps simultaneously. The |&gt; must be understood and pronounced as then.\n\ndata_inv &lt;- filter(\n  data,\n  season == \"Winter\"\n) |&gt;\n  group_by(winter_yr) |&gt;\n  summarise(\n    pr = sum(pr, na.rm = TRUE),\n    ta = mean(ta, na.rm = TRUE)\n  )\n\nNow we only have to calculate the anomalies of precipitation and temperature. The columns pr_mean and ta_mean will contain the climate average, the reference for the anomalies with respect to the normal period 1981-2010. Therefore, we need to filter the values to the period before 2010, which we will do in the usual way of filtering vectors in R. Once we have the references we estimate the anomalies pr_anom and ta_anom. To facilitate the interpretation, in the case of precipitation we express the anomalies as percentage, with the average set at 0% instead of 100%.\nIn addition, we add three required columns with information for the creation of the graph: 1) labyr contains the year of each anomaly as long as it has been greater/less than -+10% or -+0.5ºC, respectively (this is for reducing the number of labels), 2) symb_point is a dummy variable in order to be able to create different symbols between the cases of (1), and 3) lab_font for highlighting in bold the year 2020.\n\ndata_inv &lt;- mutate(data_inv,\n  pr_mean = mean(pr[winter_yr &lt;= 2010]),\n  ta_mean = mean(ta[winter_yr &lt;= 2010]),\n  pr_anom = (pr * 100 / pr_mean) - 100,\n  ta_anom = ta - ta_mean,\n  labyr = case_when(\n    pr_anom &lt; -10 & ta_anom &lt; -.5 ~ winter_yr,\n    pr_anom &lt; -10 & ta_anom &gt; .5 ~ winter_yr,\n    pr_anom &gt; 10 & ta_anom &lt; -.5 ~ winter_yr,\n    pr_anom &gt; 10 & ta_anom &gt; .5 ~ winter_yr\n  ),\n  symb_point = ifelse(!is.na(labyr), \"yes\", \"no\"),\n  lab_font = ifelse(labyr == 2020, \"bold\", \"plain\")\n)"
  },
  {
    "objectID": "blog/climate-anomalies/index.html#creating-the-graph",
    "href": "blog/climate-anomalies/index.html#creating-the-graph",
    "title": "Visualize climate anomalies",
    "section": "Creating the graph",
    "text": "Creating the graph\nWe will build the chart adding layer by layer the distinctive elements: 1) the background with the different grids (Dry-Warm, Dry-Cold, etc.), 2) the points and labels, and 3) the style adjustments.\nPart 1\nThe idea is that the points with dry-warm anomalies are located in quadrant I (top-right) and those with wet-cold in quadrant III (bottom-left). Therefore, we must invert the sign in the precipitation anomalies. Then we create a data.frame with the label positions of the four quadrants. For the positions in x and y Inf and -Inf are used, which is equivalent to the maximum panel sides with respect to the data. However, it is necessary to adjust the position towards the extreme points within the panel with the known arguments of ggplot2: hjust and vjust.\n\ndata_inv_p &lt;- mutate(data_inv, pr_anom = pr_anom * -1)\n\nbglab &lt;- data.frame(\n  x = c(-Inf, Inf, -Inf, Inf),\n  y = c(Inf, Inf, -Inf, -Inf),\n  hjust = c(1, 1, 0, 0),\n  vjust = c(1, 0, 1, 0),\n  lab = c(\n    \"Wet-Warm\", \"Dry-Warm\",\n    \"Wet-Cold\", \"Dry-Cold\"\n  )\n)\n\n\nbglab\n\n     x    y hjust vjust      lab\n1 -Inf  Inf     1     1 Wet-Warm\n2  Inf  Inf     1     0 Dry-Warm\n3 -Inf -Inf     0     1 Wet-Cold\n4  Inf -Inf     0     0 Dry-Cold\n\n\nPart 2\nIn the second part we can start building the chart by adding all graphical elements. First we create the background with different colors of each quadrant. The function annotate() allows adding geometry layers without the use of variables within data.frames. With the geom_hline() and geom_vline() function we mark the quadrants horizontally and vertically using a dashed line. Finally, we draw the labels of each quadrant, using the function geom_text(). When we use other data sources than the main one used in ggplot(), we must indicate it with the argument data in the corresponding geometry function.\n\ng1 &lt;- ggplot(\n  data_inv_p,\n  aes(pr_anom, ta_anom)\n) +\n  annotate(\"rect\", xmin = -Inf, xmax = 0, ymin = 0, ymax = Inf, fill = \"#fc9272\", alpha = .6) + # wet-warm\n  annotate(\"rect\", xmin = 0, xmax = Inf, ymin = 0, ymax = Inf, fill = \"#cb181d\", alpha = .6) + # dry-warm\n  annotate(\"rect\", xmin = -Inf, xmax = 0, ymin = -Inf, ymax = 0, fill = \"#2171b5\", alpha = .6) + # wet-cold\n  annotate(\"rect\", xmin = 0, xmax = Inf, ymin = -Inf, ymax = 0, fill = \"#c6dbef\", alpha = .6) + # dry-cold\n  geom_hline(\n    yintercept = 0,\n    linetype = \"dashed\"\n  ) +\n  geom_vline(\n    xintercept = 0,\n    linetype = \"dashed\"\n  ) +\n  geom_label(\n    data = bglab,\n    aes(x, y, label = lab, hjust = hjust, vjust = vjust),\n    fontface = \"italic\", size = 5,\n    label.size = .000001,\n    fill = NA,\n    angle = 90, colour = \"white\"\n  )\n\ng1\n\n\n\n\n\n\n\nPart 3\nIn the third part we simply add the points of the anomalies and the labels of the years. The geom_text_repel() function is similar to the one known by default in ggplot2, geom_text(), but it repels overlapping text labels away from each other.\n\ng2 &lt;- g1 + geom_point(aes(fill = symb_point, colour = symb_point),\n  size = 2.8, shape = 21, show.legend = FALSE\n) +\n  geom_text_repel(aes(label = labyr, fontface = lab_font),\n    max.iter = 5000,\n    size = 3.5\n  )\ng2\n\nWarning: Removed 25 rows containing missing values or values outside the scale range\n(`geom_text_repel()`).\n\n\n\n\n\n\n\n\nPart 4\nIn the last part we adjust, in addition to the general style, the axes, the color type and the (sub)title. Remember that we changed the sign on precipitation anomalies. Hence, we must use the arguments breaks and labels in the function scale_x_continouous() to reverse the sign in the labels corresponding to the breaks.\n\ng3 &lt;- g2 + \n  scale_x_continuous(\n  breaks = seq(-100, 250, 10) * -1,\n  labels = seq(-100, 250, 10),\n  limits = c(min(data_inv_p$pr_anom), 100),\n  expand = expansion(.01)\n  ) +\n  scale_y_continuous(\n    breaks = seq(-2, 2, 0.5),\n    expand = expansion(.01)\n  ) +\n  scale_fill_manual(values = c(\"black\", \"white\")) +\n  scale_colour_manual(values = rev(c(\"black\", \"white\"))) +\n  labs(\n    y = \"Mean temperature anomaly in ºC\",\n    x = \"Precipitation anomaly in %\",\n    title = \"Winter anomalies in Tenerife South\",\n    caption = \"Data: AEMET\\nNormal period 1981-2010\"\n  ) +\n  theme_bw() +\n  theme(panel.grid.minor = element_blank())\n\ng3"
  },
  {
    "objectID": "blog/firefly-maps/index.html",
    "href": "blog/firefly-maps/index.html",
    "title": "Firefly cartography",
    "section": "",
    "text": "Firefly maps are promoted and described by John Nelson who published a post in 2016 about its characteristics. However, these types of maps are linked to ArcGIS, which has led me to try to recreate them in R. The recent ggplot2 extension ggshadow facilitates the creation of this cartographic style. It is characterized by three elements 1) a dark and unsaturated basemap (eg satellite imagery) 2) a masked vignette and highlighted area and 3) a single bright thematic layer. The essential are the colors and the brightness that is achieved with cold colors, usually neon colors. John Nelson explains more details in this post.\nWhat is the firefly style for? In the words of John Nelson: “the map style that captures our attention and dutifully honors the First Law of Geography”. John refers to what was said by Waldo Tobler “everything is related to everything else, but near things are more related than distant things” (Tobler 1970).\nIn this post we will visualize all earthquakes recorded in southwestern Europe with a magnitude greater than 3."
  },
  {
    "objectID": "blog/firefly-maps/index.html#data",
    "href": "blog/firefly-maps/index.html#data",
    "title": "Firefly cartography",
    "section": "Data",
    "text": "Data\nFirst we download all the necessary data. For the base map we will use the Blue Marble imagery via the access to worldview.earthdata.nasa.gov where I have downloaded a selection of the area of interest in geoTiff format with a resolution of 1 km. It is important to adjust the resolution to the necessary detail of the map.\n\nBlue Marble selection via worldview.earthdata.nasa.gov ( ~ 66 MB) download\n\nRecords of historical earthquakes in southwestern Europe from IGN download"
  },
  {
    "objectID": "blog/firefly-maps/index.html#import",
    "href": "blog/firefly-maps/index.html#import",
    "title": "Firefly cartography",
    "section": "Import",
    "text": "Import\nThe first thing we do is to import the RGB Blue Marble raster and the earthquake data. To import the raster I use the new package terra which is the successor of the raster package. You can find a recent comparison here.\n\n# earthquakes\n\nearthquakes &lt;- read.csv2(\"catalogoComunSV_1621713848556.csv\")\nstr(earthquakes)\n\n'data.frame':   149724 obs. of  10 variables:\n $ Evento      : chr  \"          33\" \"          34\" \"          35\" \"          36\" ...\n $ Fecha       : chr  \"  02/03/1373\" \"  03/03/1373\" \"  08/03/1373\" \"  19/03/1373\" ...\n $ Hora        : chr  \"    00:00:00\" \"    00:00:00\" \"    00:00:00\" \"    00:00:00\" ...\n $ Latitud     : chr  \"     42.5000\" \"     42.5000\" \"     42.5000\" \"     42.5000\" ...\n $ Longitud    : chr  \"      0.7500\" \"      0.7500\" \"      0.7500\" \"      0.7500\" ...\n $ Prof...Km.  : int  NA NA NA NA NA NA NA NA NA NA ...\n $ Inten.      : chr  \"     VIII-IX\" \"            \" \"            \" \"            \" ...\n $ Mag.        : chr  \"            \" \"            \" \"            \" \"            \" ...\n $ Tipo.Mag.   : int  NA NA NA NA NA NA NA NA NA NA ...\n $ Localización: chr  \"Ribagorça.L\" \"Ribagorça.L\" \"Ribagorça.L\" \"Ribagorça.L\" ...\n\n# Blue Marble RGB raster\n\nbm &lt;- rast(\"snapshot-2017-11-30T00_00_00Z.tiff\")\nbm # contains three layers (red, green, blue)\n\nclass       : SpatRaster \ndimensions  : 7156, 7156, 3  (nrow, ncol, nlyr)\nresolution  : 0.008789272, 0.008789272  (x, y)\nextent      : -33.49823, 29.39781, 15.77547, 78.67151  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource      : snapshot-2017-11-30T00_00_00Z.tiff \ncolors RGB  : 1, 2, 3 \nnames       : snapshot-2~0_00_00Z_1, snapshot-2~0_00_00Z_2, snapshot-2~0_00_00Z_3 \n\n# country boundaries\n\nlimits &lt;- gisco_get_countries(resolution = \"10\")\n\n# plot\n\nplotRGB(bm)"
  },
  {
    "objectID": "blog/firefly-maps/index.html#earthquakes",
    "href": "blog/firefly-maps/index.html#earthquakes",
    "title": "Firefly cartography",
    "section": "Earthquakes",
    "text": "Earthquakes\nIn this step we clean the imported earthquakes data. 1) We convert longitude, latitude and magnitude into numeric using the parse_number() function and clean the column names with the clean_names() function, 2) We create a spatial object sf and project it using the EPSG:3035 corresponding to ETRS89-extended/LAEA Europe.\n\n# we clean the data and create an sf object\n\nearthquakes &lt;- earthquakes |&gt;\n  clean_names() |&gt;\n  mutate(across(c(mag, latitud, longitud), parse_number)) |&gt;\n  st_as_sf(\n    coords = c(\"longitud\", \"latitud\"),\n    crs = 4326\n  ) |&gt;\n  st_transform(3035) # project to Laea"
  },
  {
    "objectID": "blog/firefly-maps/index.html#blue-marble-background-map",
    "href": "blog/firefly-maps/index.html#blue-marble-background-map",
    "title": "Firefly cartography",
    "section": "Blue Marble background Map",
    "text": "Blue Marble background Map\nWe cropped the background map to a smaller extent, but we still haven’t limited to the final area yet.\n\n# clip to the desired area\n\nbm &lt;- crop(bm, ext(-20, 10, 30, 50)) # W, E, S, N\n\nTo obtain an unsaturated version of the Blue Marble RGB raster, we must apply a function created for this purpose. In this, we use the colorize(), which helps us converting RGB to HSL and vice versa. The HSL model is defined by Hue, Saturation, Lightness. The last two parameters are expressed in ratio or percentage. The hue is defined on a color wheel from 0 to 360º. 0 is red, 120 is green, 240 is blue. To change the saturation we only have to reduce the value of S.\n\n# apply the function to unsaturate with 5%\n\nbm_desat &lt;- colorize(bm, to = \"hsl\")\nbm_desat[[2]] &lt;- .05 # ratio of saturation\nset.RGB(bm_desat, 1:3, \"hsl\")\nbm_desat &lt;- colorize(bm_desat, to = \"rgb\")\n\n# project\n\nbm_desat &lt;- terra::project(bm_desat, \"epsg:3035\")\n\n# plot new RGB image\n\nplotRGB(bm_desat)"
  },
  {
    "objectID": "blog/firefly-maps/index.html#boundaries-and-graticules",
    "href": "blog/firefly-maps/index.html#boundaries-and-graticules",
    "title": "Firefly cartography",
    "section": "Boundaries and graticules",
    "text": "Boundaries and graticules\nBefore starting to build the map, we create graticules and set the final map limits.\n\n# define the final map extent\n\nbx &lt;- tibble(x = c(-13, 6.7), y = c(31, 47)) |&gt;\n  st_as_sf(coords = c(\"x\", \"y\"), crs = 4326) |&gt;\n  st_transform(3035) |&gt;\n  st_bbox()\n\n# create map graticules\n\ngrid &lt;- st_graticule(earthquakes)"
  },
  {
    "objectID": "blog/firefly-maps/index.html#map-with-image-background",
    "href": "blog/firefly-maps/index.html#map-with-image-background",
    "title": "Firefly cartography",
    "section": "Map with image background",
    "text": "Map with image background\nThe layer_spatial() function of ggspatial allows us to add an RGB raster without major problems, however, it still does not support the newSpatRaster class. Therefore, we must convert it to the stack class with the stack() function. It is also possible to use instead of geom_sf(), the layer_spatial() function for vector objects of class sf orsp.\n\nggplot() +\n  layer_spatial(data = bm_desat) + # blue marble background map\n  geom_sf(data = limits, fill = NA, size = .3, colour = \"white\") + # country boundaries\n  coord_sf(\n    xlim = bx[c(1, 3)],\n    ylim = bx[c(2, 4)],\n    crs = 3035,\n    expand = FALSE\n  ) +\n  theme_void()"
  },
  {
    "objectID": "blog/firefly-maps/index.html#map-with-background-and-earthquakes",
    "href": "blog/firefly-maps/index.html#map-with-background-and-earthquakes",
    "title": "Firefly cartography",
    "section": "Map with background and earthquakes",
    "text": "Map with background and earthquakes\nTo create the glow effect on firefly maps, we use the geom_glowpoint() function from the ggshadow package. There is also the same function for lines. Since our data is of spatial class sf and the geometry sf is not directly supported, we must indicate as an argument stats = \"sf_coordinates\" and inside aes() indicate geometry = geometry. We will map the size of the points as a function of magnitude. In addition, we filter those earthquakes with a magnitude greater than 3.\nInside the geom_glowpoint() function, 1) we define the desired color for the point and the glow effect, 2) the degree of transparency with alpha either for the point or for the glow. Finally, in the scale_size() function we set the range (minimum, maximum) of the size that the points will have.\n\nggplot() +\n  layer_spatial(data = bm_desat) +\n  geom_sf(data = limits, fill = NA, size = .3, colour = \"white\") +\n  geom_sf(data = grid, colour = \"white\", size = .1, alpha = .5) +\n  geom_glowpoint(\n    data = filter(earthquakes, mag &gt; 3),\n    aes(geometry = geometry, size = mag),\n    alpha = .8,\n    color = \"#6bb857\",\n    shadowcolour = \"#6bb857\",\n    shadowalpha = .1,\n    stat = \"sf_coordinates\",\n    show.legend = FALSE\n  ) +\n  scale_size(range = c(.1, 1.5)) +\n  coord_sf(\n    xlim = bx[c(1, 3)],\n    ylim = bx[c(2, 4)],\n    crs = 3035,\n    expand = FALSE\n  ) +\n  theme_void()"
  },
  {
    "objectID": "blog/firefly-maps/index.html#final-map",
    "href": "blog/firefly-maps/index.html#final-map",
    "title": "Firefly cartography",
    "section": "Final map",
    "text": "Final map\nThe glow effect of firefly maps is characterized by having a white tone or a lighter tone in the center of the points. To achieve this, we must duplicate the previous created layer, changing only the color and make the glow points smaller.\nBy default, ggplot2 does not allow to use multiple scales for the same characteristic (size, color, etc) of different layers. But the ggnewscale package gives us the ability to incorporate multiple scales of a feature from different layers. The only important thing to achieve this is the order in which each layer (geom) and scale is added. First we must add the geometry and then its corresponding scale. We indicate with new_scale('size') that the next layer and scale is a new one independent of the previous one. If we used color or fill it would be done with new_scale_*().\n\nggplot() +\n  layer_spatial(data = bm_desat) +\n  geom_sf(data = limits, fill = NA, size = .3, colour = \"white\") +\n  geom_sf(data = grid, colour = \"white\", size = .1, alpha = .5) +\n  geom_glowpoint(\n    data = filter(earthquakes, mag &gt; 3),\n    aes(geometry = geometry, size = mag),\n    alpha = .8,\n    color = \"#6bb857\",\n    shadowcolour = \"#6bb857\",\n    shadowalpha = .1,\n    stat = \"sf_coordinates\",\n    show.legend = FALSE\n  ) +\n  scale_size(range = c(.1, 1.5)) +\n  new_scale(\"size\") +\n  geom_glowpoint(\n    data = filter(earthquakes, mag &gt; 3),\n    aes(geometry = geometry, size = mag),\n    alpha = .6,\n    shadowalpha = .05,\n    color = \"#ffffff\",\n    stat = \"sf_coordinates\",\n    show.legend = FALSE\n  ) +\n  scale_size(range = c(.01, .7)) +\n  labs(title = \"EARTHQUAKES\") +\n  coord_sf(\n    xlim = bx[c(1, 3)], ylim = bx[c(2, 4)], crs = 3035,\n    expand = FALSE\n  ) +\n  theme_void() +\n  theme(plot.title = element_text(size = 50, vjust = -5, colour = \"white\", hjust = .95))\n\n\n\n\n\n\n\n\nggsave(\"firefly_map.png\", width = 15, height = 10, units = \"in\", dpi = 300)"
  },
  {
    "objectID": "blog/hillshade-effect/index.html",
    "href": "blog/hillshade-effect/index.html",
    "title": "Hillshade effects",
    "section": "",
    "text": "It is very common to see relief maps with shadow effects, also known as ‘hillshade’, which generates visual depth. How can we create these effects in R and how to include them in ggplot2?\nPackages\n\n\n\n\n\n\n\n\nPackage\nDescription\n\n\n\ntidyverse\nCollection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.\n\n\nsf\nSimple Feature: import, export and manipulate vector data\n\n\nelevatr\nAccess to elevation data from various APIs\n\n\nterra\nImport, export and manipulate raster ({raster} successor package)\n\n\nwhitebox\nAn R interface to the ‘WhiteboxTools’ library, which is an advanced geospatial data analysis platform\n\n\ntidyterra\nHelper functions for working with {terra}\n\n\ngiscoR\nAdministrative boundaries of the world\n\n\nggnewscale\nExtension for ggplot2 of multiple ‘scales’\n\n\nggblend\nExtension for mixing colors in ggplot graphs\n\n\n\n\n\n\n# install the packages if necessary\n\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"sf\")) install.packages(\"sf\")\nif (!require(\"elevatr\")) install.packages(\"elevatr\")\nif (!require(\"terra\")) install.packages(\"terra\")\nif (!require(\"whitebox\")) install.packages(\"whitebox\")\nif (!require(\"tidyterra\")) install.packages(\"tidyterra\")\nif (!require(\"giscoR\")) install.packages(\"giscoR\")\nif (!require(\"ggnewscale\")) install.packages(\"ggnewscale\")\nif (!require(\"ggblend\")) install.packages(\"ggblend\")\n\n# packages\nlibrary(sf)\nlibrary(elevatr)\nlibrary(tidyverse)\nlibrary(terra)\nlibrary(whitebox)\nlibrary(ggnewscale)\nlibrary(tidyterra)\nlibrary(giscoR)\nlibrary(units)\nlibrary(ggblend)\n\nData\nAs an area of interest, we use Switzerland in this example. Except for lake boundaries download, the necessary data is obtained through APIs using different packages. For example, the giscoR package allows you to get country boundaries with different resolutions.\n\nsuiz &lt;- gisco_get_countries(country = \"Switzerland\", resolution = \"03\")\n\nplot(suiz)\n\n\n\n\n\n\n\nThe lake boundaries correspond to a layer of digital cartographic models (DKM500) provided by swisstopo. The objective is to keep only the largest lakes; therefore, we exclude all those with less than 50 km2 and also those located entirely in Italian territory. Remember that with the units package, we can indicate units and thus do calculations.\n\n# import the lakes boundaries\nsuiz_lakes &lt;- st_read(\"22_DKM500_GEWAESSER_PLY.shp\")\n\nReading layer `22_DKM500_GEWAESSER_PLY' from data source \n  `C:\\Users\\xeo19\\Downloads\\dominicroye.github.io\\blog\\hillshade-effect\\22_DKM500_GEWAESSER_PLY.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 596 features and 14 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2480000 ymin: 1062000 xmax: 2865000 ymax: 1302000\nProjected CRS: CH1903+ / LV95\n\n# filter the largest ones\nsuiz_lakes &lt;- mutate(suiz_lakes, areakm = set_units(SHP_AREA, \"m2\") |&gt;\n  set_units(\"km2\")) |&gt;\n  filter(\n    areakm &gt; set_units(50, \"km2\"),\n    !NAMN1 %in% c(\n      \"Lago di Como / Lario\",\n      \"Lago d'Iseo\",\n      \"Lago di Garda\"\n    )\n  )\n\nplot(suiz_lakes)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\nDigital Elevation Model (DEM)\nThe get_elev_raster() function allows us to download a DEM from any region of the world through different providers in raster format. By default, it uses AWS. An essential argument is the latitude-dependent resolution, which can be specified as the zoom level (see function help). For example, we use level 10, which at a latitude of 45º would correspond to approximately 100 m.\nAfter obtaining the DEM from Switzerland, we must mask the country’s boundaries. The object’s class is RasterLayer from the raster package, however, the new standard is terra with the class SpatRaster. That’s why we convert it and then apply the mask. Finally, we reproject to the Swiss coordinate system obtained from the vector data.\n\n# get the DEM with\nmdt &lt;- get_elev_raster(suiz, z = 10)\n\nMosaicing & Projecting\n\n\nNote: Elevation units are in meters.\n\nmdt # old RasterLayer class\n\nclass      : RasterLayer \ndimensions : 3869, 7913, 30615397  (nrow, ncol, ncell)\nresolution : 0.0006219649, 0.0006219649  (x, y)\nextent     : 5.625, 10.54661, 45.58354, 47.98992  (xmin, xmax, ymin, ymax)\ncrs        : +proj=longlat +datum=WGS84 +no_defs \nsource     : file50fc5a1a5c7f.tif \nnames      : file50fc5a1a5c7f \n\nplot(mdt)\n\n\n\n\n\n\n\n\n# convert to terra and mask area of interest\nmdt &lt;- rast(mdt) |&gt;\n  mask(vect(suiz))\n\n# reproject\nmdt &lt;- project(mdt, crs(suiz_lakes))\n\n# reproject vect\nsuiz &lt;- st_transform(suiz, st_crs(suiz_lakes))\n\nBefore calculating the shadow effect, we create a simple relief map. In ggplot2, we use the geom_raster() geometry, indicating the longitude, latitude and the variable to define the color. We add the boundaries of the lakes using geom_sf() since it is an sf object. Here we only indicate the fill color with a light blue. Then, with the help of scale_fill_hypso_tint_c(), we apply a range of colors corresponding to the relief, also called hypsometric tinting, and we define the breaks in the legend. We make appearance adjustments in the legend and the graph’s style in the rest of the functions.\n\n# convert the raster into a data.frame of xyz\nmdtdf &lt;- as.data.frame(mdt, xy = TRUE)\nnames(mdtdf)[3] &lt;- \"alt\"\n\n# map\nggplot() +\n  geom_raster(\n    data = mdtdf,\n    aes(x, y, fill = alt)\n  ) +\n  geom_sf(\n    data = suiz_lakes,\n    fill = \"#c6dbef\",\n    colour = NA\n  ) +\n  scale_fill_hypso_tint_c(breaks = c(\n    180, 250, 500, 1000,\n    1500, 2000, 2500,\n    3000, 3500, 4000\n  )) +\n  guides(fill = guide_colorsteps(\n    barwidth = 20,\n    barheight = .5,\n    title.position = \"right\"\n  )) +\n  labs(fill = \"m\") +\n  coord_sf() +\n  theme_void() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nCalculate the hillshade\nLet’s remember that the hillshade effect is nothing more than adding a hypothetical illumination with respect to a position of a light source to gain depth. Shadows depend on two variables, azimuth, the angle from the orientation on the surface of a sphere, and elevation, the angle from the height of the source.\n\nThe information required to simulate lighting is the digital elevation model. The slope and aspect can be derived from the DEM using the terrain() function from the terra package. The unit must be radians. Once we have all the data, we can use the shade() function to indicate the angle (elevation) and direction (azimuth). The result is a raster with values between 0 and 255, which shows shadows with low values, being 0 black and 255 white.\n\n# estimate the slope\nsl &lt;- terrain(mdt, \"slope\", unit = \"radians\")\nplot(sl)\n\n\n\n\n\n\n\n\n# estimate the aspect or orientation\nasp &lt;- terrain(mdt, \"aspect\", unit = \"radians\")\nplot(asp)\n\n\n\n\n\n\n\n\n# calculate the hillshade effect with 45º of elevation\nhill_single &lt;- shade(sl, asp,\n  angle = 45,\n  direction = 300,\n  normalize = TRUE\n)\n\n# final hillshade\nplot(hill_single, col = grey(1:100 / 100))\n\n\n\n\n\n\n\nCombine the relief and shadow effect\nThe problem with adding both the relief with its hypsometric tints and the hillshade effect inside ggplot2 is that we have two different fills or scales for each layer. The solution is to use the ggnewscale extension, which allows you to add multiple scales of the same argument. First, we add the hillshade with geom_raster(), then we define the grey tones, and before adding the altitude, we include the new_scale_fill() function to mark a different fill. To achieve the effect, it is necessary to give a degree of transparency to the relief layer; in this case, it is 70%. The choice of direction is important, which is why we must always take into account the place and the apparent path of the sun (sunearthtools).\n\n# convert the hillshade to xyz\nhilldf_single &lt;- as.data.frame(hill_single, xy = TRUE)\n\n# map\nggplot() +\n  geom_raster(\n    data = hilldf_single,\n    aes(x, y, fill = hillshade),\n    show.legend = FALSE\n  ) +\n  scale_fill_distiller(palette = \"Greys\") +\n  new_scale_fill() +\n  geom_raster(\n    data = mdtdf,\n    aes(x, y, fill = alt),\n    alpha = .7\n  ) +\n  scale_fill_hypso_tint_c(breaks = c(\n    180, 250, 500, 1000,\n    1500, 2000, 2500,\n    3000, 3500, 4000\n  )) +\n  geom_sf(\n    data = suiz_lakes,\n    fill = \"#c6dbef\", colour = NA\n  ) +\n  guides(fill = guide_colorsteps(\n    barwidth = 20,\n    barheight = .5,\n    title.position = \"right\"\n  )) +\n  labs(fill = \"m\") +\n  coord_sf() +\n  theme_void() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nMultidirectional shadows\nWe have seen a unidirectional effect; although it is the most common, we can create a smoother and even more realistic effect by combining several directions.\nWe map onto a vector of various directions to which the shade() function is applied with a fixed elevation angle. We then convert the raster list to a multi-layered object to reduce them by adding all the layers.\n\n# pass multiple directions to shade()\nhillmulti &lt;- map(c(270, 15, 60, 330), function(dir) {\n  shade(sl, asp,\n    angle = 45,\n    direction = dir,\n    normalize = TRUE\n  )\n})\n\n# create a multidimensional raster and reduce it by summing up\nhillmulti &lt;- rast(hillmulti) |&gt; sum()\n\n# multidirectional\nplot(hillmulti, col = grey(1:100 / 100))\n\n\n\n\n\n\n\n\n# unidirectional\nplot(hill_single, col = grey(1:100 / 100))\n\n\n\n\n\n\n\nWe do the same as before to visualize the relief with multidirectional shadows.\n\n# convert the hillshade to xyz\nhillmultidf &lt;- as.data.frame(hillmulti, xy = TRUE)\n\n# map\nggplot() +\n  geom_raster(\n    data = hillmultidf,\n    aes(x, y, fill = sum),\n    show.legend = FALSE\n  ) +\n  scale_fill_distiller(palette = \"Greys\") +\n  new_scale_fill() +\n  geom_raster(\n    data = mdtdf,\n    aes(x, y, fill = alt),\n    alpha = .7\n  ) +\n  scale_fill_hypso_tint_c(breaks = c(\n    180, 250, 500, 1000,\n    1500, 2000, 2500,\n    3000, 3500, 4000\n  )) +\n  geom_sf(\n    data = suiz_lakes,\n    fill = \"#c6dbef\", colour = NA\n  ) +\n  guides(fill = guide_colorsteps(\n    barwidth = 20,\n    barheight = .5,\n    title.position = \"right\"\n  )) +\n  labs(fill = \"m\") +\n  coord_sf() +\n  theme_void() +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\nThe color blending technique is very useful to obtain remarkable results in the shading effect. Recently the ggblend package offers this possibility. In order to blend several layers, it is necessary to insert the geom_raster() and the scale_fill_*() objects in a comma-separated list. Then follows the pipe with the blend(\"mix_type\") function to which we add the other ggplot2 objects. In this case we apply multiplication as a form of blending.\n\n# map\nm &lt;- ggplot() +\n  list(\n    geom_raster(\n      data = hillmultidf,\n      aes(x, y, fill = sum),\n      show.legend = FALSE\n    ),\n    scale_fill_distiller(palette = \"Greys\"),\n    new_scale_fill(),\n    geom_raster(\n      data = mdtdf,\n      aes(x, y, fill = alt),\n      alpha = .7\n    ),\n    scale_fill_hypso_tint_c(breaks = c(\n      180, 250, 500, 1000,\n      1500, 2000, 2500,\n      3000, 3500, 4000\n    ))\n  ) |&gt; blend(\"multiply\") +\n  geom_sf(\n    data = suiz_lakes,\n    fill = \"#c6dbef\", colour = NA\n  ) +\n  guides(fill = guide_colorsteps(\n    barwidth = 20,\n    barheight = .5,\n    title.position = \"right\"\n  )) +\n  labs(fill = \"m\") +\n  coord_sf() +\n  theme_void() +\n  theme(legend.position = \"top\")\n\nggsave(\"mdt_hillshade_blend.png\", m,\n  width = 10,\n  height = 8,\n  unit = \"in\",\n  device = png,\n  type = \"cairo\",\n  bg = \"white\"\n)\n\n\nAnother alternative for multidirectional shadows\nWith less control over the directions, it would also be possible to apply the wbt_multidirectional_hillshade() function from the whitebox package. WhiteboxTool contains many tools as an advanced geospatial data analysis platform. The disadvantage is that we lose control over the directions and that it is also necessary to export the DEM to geotiff to obtain another raster with the shadows.\nWe first install the library with the install_whitebox() function.\n\n# instal whitebox\ninstall_whitebox()\n\n\n# export the DEM\nwriteRaster(mdt, \"mdt.tiff\", overwrite = TRUE)\n\n# launch whitebox\nwbt_init()\n\n# create the hillshade\nwbt_multidirectional_hillshade(\n  \"mdt.tiff\",\n  \"hillshade.tiff\"\n)\n\n# re-import the hillshade\nhillwb &lt;- rast(\"hillshade.tiff\")\n\n# remask\nhillwb &lt;- mask(hillwb, vect(suiz))\n\n\n# convert the hillshade to xyz\nhillwbdf &lt;- as.data.frame(hillwb, xy = TRUE)\n\n# map\nggplot() +\n  geom_raster(\n    data = hillwbdf,\n    aes(x, y, fill = hillshade),\n    show.legend = FALSE\n  ) +\n  scale_fill_distiller(palette = \"Greys\") +\n  new_scale_fill() +\n  geom_raster(\n    data = mdtdf,\n    aes(x, y, fill = alt),\n    alpha = .7\n  ) +\n  scale_fill_hypso_tint_c(breaks = c(\n    180, 250, 500, 1000,\n    1500, 2000, 2500,\n    3000, 3500, 4000\n  )) +\n  guides(fill = guide_colorsteps(\n    barwidth = 20,\n    barheight = .5,\n    title.position = \"right\"\n  )) +\n  labs(fill = \"m\") +\n  coord_sf() +\n  theme_void() +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n\n Back to topReuseCC BY-NC-SA 4.0CitationFor attribution, please cite this work as:\nRoyé, Dominic. 2022. “Hillshade Effects.” July 20, 2022. https://dominicroye.github.io/blog/hillshade-effect/."
  },
  {
    "objectID": "blog/import-excel-sheets-with-r/index.html",
    "href": "blog/import-excel-sheets-with-r/index.html",
    "title": "Import Excel sheets with R",
    "section": "",
    "text": "We usually work with different data sources, and sometimes we can find tables distributed over several Excel sheets. In this post we are going to import the average daily temperature of Madrid and Berlin which is found in two Excel files with sheets for each year between 2000 and 2005: download."
  },
  {
    "objectID": "blog/import-excel-sheets-with-r/index.html#packages",
    "href": "blog/import-excel-sheets-with-r/index.html#packages",
    "title": "Import Excel sheets with R",
    "section": "Packages",
    "text": "Packages\nIn this post we will use the following packages:\n\n\n\n\n\n\n\n\nPackages\nDescription\n\n\n\ntidyverse\nCollection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.\n\n\nfs\nProvides a cross-platform, uniform interface to file system operations\n\n\nreadxl\nImport Excel files\n\n\n\n\n\n\n# install the packages if necessary\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"fs\")) install.packages(\"fs\")\nif (!require(\"readxl\")) install.packages(\"readxl\")\n\n\n# load packages\nlibrary(tidyverse)\nlibrary(fs)\nlibrary(readxl)"
  },
  {
    "objectID": "blog/import-excel-sheets-with-r/index.html#import-excel-files",
    "href": "blog/import-excel-sheets-with-r/index.html#import-excel-files",
    "title": "Import Excel sheets with R",
    "section": "Import excel files",
    "text": "Import excel files\nBy default, the read_excel() function imports the first sheet. To import a different sheet it is necessary to indicate the number or name with the argument sheet (second argument).\n\n# import first sheet\nread_excel(\"madrid_temp.xlsx\")\n\n# A tibble: 366 × 3\n      ta    dy    mo\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1   5.4     1     1\n 2   5       2     1\n 3   3.5     3     1\n 4   4.3     4     1\n 5   0.6     5     1\n 6   3.8     6     1\n 7   6.2     7     1\n 8   5.4     8     1\n 9   5.5     9     1\n10   4.8    10     1\n# ℹ 356 more rows\n\n# import third sheet\nread_excel(\"madrid_temp.xlsx\", 3)\n\n# A tibble: 365 × 3\n      ta    dy    mo\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1   8.7     1     1\n 2   7.4     2     1\n 3   8.5     3     1\n 4   9.2     4     1\n 5   9.3     5     1\n 6   7.3     6     1\n 7   5.4     7     1\n 8   5.6     8     1\n 9   6.8     9     1\n10   6.1    10     1\n# ℹ 355 more rows\n\n\nThe excel_sheets() function can extract the names of the sheets.\n\npath &lt;- \"madrid_temp.xlsx\"\n\npath |&gt;\n  excel_sheets()\n\n[1] \"2000\" \"2001\" \"2002\" \"2003\" \"2004\" \"2005\"\n\n\nThe results are the sheet names and we find the years from 2000 to 2005. The most important function to read multiple sheets is map() of the {purrr} package, which is part of the {tidyverse] collection. map() allows you to apply a function to each element of a vector or list.\n\npath &lt;- \"madrid_temp.xlsx\"\n\nmad &lt;- path |&gt;\n  excel_sheets() |&gt;\n  set_names() |&gt;\n  map(read_excel,\n    path = path\n  )\n\nstr(mad)\n\nList of 6\n $ 2000: tibble [366 × 3] (S3: tbl_df/tbl/data.frame)\n  ..$ ta: num [1:366] 5.4 5 3.5 4.3 0.6 3.8 6.2 5.4 5.5 4.8 ...\n  ..$ dy: num [1:366] 1 2 3 4 5 6 7 8 9 10 ...\n  ..$ mo: num [1:366] 1 1 1 1 1 1 1 1 1 1 ...\n $ 2001: tibble [365 × 3] (S3: tbl_df/tbl/data.frame)\n  ..$ ta: num [1:365] 8.2 8.8 7.5 9.2 10 9 5.5 4.6 3 7.9 ...\n  ..$ dy: num [1:365] 1 2 3 4 5 6 7 8 9 10 ...\n  ..$ mo: num [1:365] 1 1 1 1 1 1 1 1 1 1 ...\n $ 2002: tibble [365 × 3] (S3: tbl_df/tbl/data.frame)\n  ..$ ta: num [1:365] 8.7 7.4 8.5 9.2 9.3 7.3 5.4 5.6 6.8 6.1 ...\n  ..$ dy: num [1:365] 1 2 3 4 5 6 7 8 9 10 ...\n  ..$ mo: num [1:365] 1 1 1 1 1 1 1 1 1 1 ...\n $ 2003: tibble [365 × 3] (S3: tbl_df/tbl/data.frame)\n  ..$ ta: num [1:365] 9.4 10.8 9.7 9.2 6.3 6.6 3.8 6.4 4.3 3.4 ...\n  ..$ dy: num [1:365] 1 2 3 4 5 6 7 8 9 10 ...\n  ..$ mo: num [1:365] 1 1 1 1 1 1 1 1 1 1 ...\n $ 2004: tibble [366 × 3] (S3: tbl_df/tbl/data.frame)\n  ..$ ta: num [1:366] 6.6 5.9 7.8 8.1 6.4 5.7 5.2 6.9 11.8 12.2 ...\n  ..$ dy: num [1:366] 1 2 3 4 5 6 7 8 9 10 ...\n  ..$ mo: num [1:366] 1 1 1 1 1 1 1 1 1 1 ...\n $ 2005: tibble [365 × 3] (S3: tbl_df/tbl/data.frame)\n  ..$ ta: num [1:365] 7.1 7.8 6.4 5.6 4.4 6.8 7.4 6 5.2 4.2 ...\n  ..$ dy: num [1:365] 1 2 3 4 5 6 7 8 9 10 ...\n  ..$ mo: num [1:365] 1 1 1 1 1 1 1 1 1 1 ...\n\n\nThe result is a named list with the name of each sheet that contains the data.frame. To bind all rows from the list we can use the list_rbind() function, but we will lose the sheet names.\n\npath &lt;- \"madrid_temp.xlsx\"\n\nmad &lt;- path |&gt;\n  excel_sheets() |&gt;\n  set_names() |&gt;\n  map(read_excel,\n    path = path\n  ) |&gt;\n  list_rbind()\n\nmad\n\n# A tibble: 2,192 × 3\n      ta    dy    mo\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1   5.4     1     1\n 2   5       2     1\n 3   3.5     3     1\n 4   4.3     4     1\n 5   0.6     5     1\n 6   3.8     6     1\n 7   6.2     7     1\n 8   5.4     8     1\n 9   5.5     9     1\n10   4.8    10     1\n# ℹ 2,182 more rows"
  },
  {
    "objectID": "blog/import-excel-sheets-with-r/index.html#import-multiple-sheets",
    "href": "blog/import-excel-sheets-with-r/index.html#import-multiple-sheets",
    "title": "Import Excel sheets with R",
    "section": "Import multiple sheets",
    "text": "Import multiple sheets\nIn our case we don’t have a column in each sheet that differentiates each table, so we need to use the name of the sheets as a new column when joining all of them.\n\npath &lt;- \"madrid_temp.xlsx\"\n\nmad &lt;- path |&gt;\n  excel_sheets() |&gt;\n  set_names() |&gt;\n  map(read_excel,\n    path = path\n  ) |&gt;\n  list_rbind(names_to = \"yr\")\n\nstr(mad)\n\ntibble [2,192 × 4] (S3: tbl_df/tbl/data.frame)\n $ yr: chr [1:2192] \"2000\" \"2000\" \"2000\" \"2000\" ...\n $ ta: num [1:2192] 5.4 5 3.5 4.3 0.6 3.8 6.2 5.4 5.5 4.8 ...\n $ dy: num [1:2192] 1 2 3 4 5 6 7 8 9 10 ...\n $ mo: num [1:2192] 1 1 1 1 1 1 1 1 1 1 ...\n\n\nBut how do we import multiple Excel files?\nTo do this, first we must know the dir_ls() function from the {fs} package. Indeed, there is the dir() function of R Base, but the advantages of the recent package are several, especially the compatibility with the {tidyverse} collection.\n\ndir_ls()\n\n\n# we can filter the files that we want\ndir_ls(regexp = \"xlsx\")\n\nberlin_temp.xlsx madrid_temp.xlsx \n\n\nWe import the two Excel files.\n\n# without joining\ndir_ls(regexp = \"xlsx\") |&gt;\n  map(read_excel)\n\n$berlin_temp.xlsx\n# A tibble: 366 × 3\n      ta    dy    mo\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1   1.2     1     1\n 2   3.6     2     1\n 3   5.7     3     1\n 4   5.1     4     1\n 5   2.2     5     1\n 6   1.8     6     1\n 7   4.2     7     1\n 8   4.2     8     1\n 9   4.2     9     1\n10   1.7    10     1\n# ℹ 356 more rows\n\n$madrid_temp.xlsx\n# A tibble: 366 × 3\n      ta    dy    mo\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1   5.4     1     1\n 2   5       2     1\n 3   3.5     3     1\n 4   4.3     4     1\n 5   0.6     5     1\n 6   3.8     6     1\n 7   6.2     7     1\n 8   5.4     8     1\n 9   5.5     9     1\n10   4.8    10     1\n# ℹ 356 more rows\n\n# joining with a new id column\ndir_ls(regexp = \"xlsx\") |&gt;\n  map(read_excel) |&gt;\n  list_rbind(names_to = \"city\")\n\n# A tibble: 732 × 4\n   city                ta    dy    mo\n   &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 berlin_temp.xlsx   1.2     1     1\n 2 berlin_temp.xlsx   3.6     2     1\n 3 berlin_temp.xlsx   5.7     3     1\n 4 berlin_temp.xlsx   5.1     4     1\n 5 berlin_temp.xlsx   2.2     5     1\n 6 berlin_temp.xlsx   1.8     6     1\n 7 berlin_temp.xlsx   4.2     7     1\n 8 berlin_temp.xlsx   4.2     8     1\n 9 berlin_temp.xlsx   4.2     9     1\n10 berlin_temp.xlsx   1.7    10     1\n# ℹ 722 more rows\n\n\nHowever, in this case we only import the first sheet of each Excel file. To solve this problem, we must create our own function. In this function we do what we previously did individually.\n\nread_multiple_excel &lt;- function(path) {\n  path |&gt;\n    excel_sheets() |&gt;\n    set_names() |&gt;\n    map(read_excel, path = path) |&gt;\n    list_rbind()\n}\n\nWe apply our created function to import multiple sheets of several Excel files.\n\n# separately\ndata &lt;- dir_ls(regexp = \"xlsx\") |&gt;\n  map(read_multiple_excel)\n\nstr(data)\n\nList of 2\n $ berlin_temp.xlsx: tibble [2,192 × 3] (S3: tbl_df/tbl/data.frame)\n  ..$ ta: num [1:2192] 1.2 3.6 5.7 5.1 2.2 1.8 4.2 4.2 4.2 1.7 ...\n  ..$ dy: num [1:2192] 1 2 3 4 5 6 7 8 9 10 ...\n  ..$ mo: num [1:2192] 1 1 1 1 1 1 1 1 1 1 ...\n $ madrid_temp.xlsx: tibble [2,192 × 3] (S3: tbl_df/tbl/data.frame)\n  ..$ ta: num [1:2192] 5.4 5 3.5 4.3 0.6 3.8 6.2 5.4 5.5 4.8 ...\n  ..$ dy: num [1:2192] 1 2 3 4 5 6 7 8 9 10 ...\n  ..$ mo: num [1:2192] 1 1 1 1 1 1 1 1 1 1 ...\n\n# joining all data.frames\ndata_df &lt;- dir_ls(regexp = \"xlsx\") |&gt;\n  map(read_multiple_excel) |&gt;\n  list_rbind(names_to = \"city\")\n\nstr(data_df)\n\ntibble [4,384 × 4] (S3: tbl_df/tbl/data.frame)\n $ city: chr [1:4384] \"berlin_temp.xlsx\" \"berlin_temp.xlsx\" \"berlin_temp.xlsx\" \"berlin_temp.xlsx\" ...\n $ ta  : num [1:4384] 1.2 3.6 5.7 5.1 2.2 1.8 4.2 4.2 4.2 1.7 ...\n $ dy  : num [1:4384] 1 2 3 4 5 6 7 8 9 10 ...\n $ mo  : num [1:4384] 1 1 1 1 1 1 1 1 1 1 ...\n\n\n\n# clean up city names\ndata_df &lt;- mutate(data_df, city = path_ext_remove(city) |&gt; str_remove(\"_temp\"))"
  },
  {
    "objectID": "blog/inserted-map/index.html",
    "href": "blog/inserted-map/index.html",
    "title": "Inserted maps with ggplot2",
    "section": "",
    "text": "Today I present a short post on how we can position an outermost territory near the main map or insert an orientation map. In this example we use the typical map of Spain where the Canary Islands are located in the southwest of the peninsula."
  },
  {
    "objectID": "blog/inserted-map/index.html#packages",
    "href": "blog/inserted-map/index.html#packages",
    "title": "Inserted maps with ggplot2",
    "section": "Packages",
    "text": "Packages\n\n\n\n\n\n\n\n\nPaquete\nDescripción\n\n\n\ntidyverse\nCollection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.\n\n\nmapSpain\nAdministrative boundaries of Spain at different levels\n\n\nsf\nSimple Feature: import, export and manipulate vector data\n\n\ngiscoR\nAdministrative boundaries of the world\n\n\npatchwork\nSimple grammar to combine separate ggplots into the same graphic\n\n\nrmapshaper\nmapshaper library client for geospatial operations\n\n\n\n\n\n\n# install the packages if necessary\nif(!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif(!require(\"mapSpain\")) install.packages(\"mapSpain\")\nif(!require(\"sf\")) install.packages(\"sf\")\nif(!require(\"giscoR\")) install.packages(\"giscoR\")\nif(!require(\"patchwork\")) install.packages(\"patchwork\")\nif(!require(\"rmapshaper\")) install.packages(\"rmapshaper\")\n\n# packages\nlibrary(sf)\nlibrary(giscoR)\nlibrary(mapSpain)\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(rmapshaper)"
  },
  {
    "objectID": "blog/inserted-map/index.html#option-1",
    "href": "blog/inserted-map/index.html#option-1",
    "title": "Inserted maps with ggplot2",
    "section": "Option 1",
    "text": "Option 1\nWe can easily find some administrative boundaries of states such as Spain, where the actual geographical position of a remote territory has been changed, such as the Canary Islands. The default mapSpain package shifts the islands to the southwest of the Iberian Peninsula, a common position we see in many maps. However, these vector boundaries with displacement cannot be used in all assumptions, as this is a false geographical position and is not suitable for spatial calculations or other projections.\nWe obtain the vector boundaries using the esp_get_prov() function for the provincial level with the projection code EPSG:4326 (WGS84). In the construction of the map via ggplot2 we simply add the object to the geom_sf() geometry specifically designed for handling vector objects of class sf.\n\n# province boundaries with Canary Islands displacement\nesp &lt;- esp_get_prov(epsg = 4326)\n\n# simple map\nggplot(esp) +\n  geom_sf(colour = \"white\", linewidth = .2) +\n    theme_void()\n\n\n\n\n\n\n\nmapSpain also includes a function to get the separator box (esp_get_can_box()) in order to indicate the false location. With the gisco_get_countries() function we get the global country boundaries to add as geographical context, although we clipped it to the extent of the Iberian Peninsula. It may be surprising to see a curved cutout using the WGS84 projection, but this is because spherical geometry is used by default in all sf operations (sf_use_s2()).\n\n# we add the Canary Islands box and the boundaries of the environment\ncan_bx &lt;- esp_get_can_box(epsg = 4326)\nentorno &lt;- gisco_get_countries(resolution = \"10\") |&gt; \n             st_crop(xmin = -10, xmax = 5, ymin = 34, ymax = 45)\n\n# with displacement\nggplot(esp) +\n  geom_sf(data = entorno, fill = \"grey70\", colour = NA) +\n  geom_sf(colour = \"white\", linewidth = .2) +\n  geom_sf(data = can_bx, linewidth = .3, colour = \"grey80\") +\n  theme_void()"
  },
  {
    "objectID": "blog/inserted-map/index.html#option-2",
    "href": "blog/inserted-map/index.html#option-2",
    "title": "Inserted maps with ggplot2",
    "section": "Option 2",
    "text": "Option 2\nThe most correct way is to create an object for the inserted map, here the Canary Islands, and another one for the main map, mainland Spain and the Balearic Islands. In the esp_get_prov() function we must indicate that it returns the limits without displacement with the agrument moveCAN = FALSE. First, we build the map of the Canary Islands, filtering the autonomous community. The geometries geom_hline() and geom_vline() will draw the separation line to the peninsula. The second step is to create the main map excluding the Canary Islands. Then the map of the Canary Islands needs to be included as an object using the annotation_custom() function. The ggplot object must be converted to a grob with ggplotGrob() and the position area (the X and Y extreme points) must be indicated in the coordinate system of the main map. This form can be used for all types of maps.\n\n# boundaries of provinces without displacement of the Canary Islands\nesp &lt;- esp_get_prov(epsg = 4326, moveCAN = F)\n\n# Canary Island map\ncan &lt;-  filter(esp, nuts2.name == \"Canarias\") |&gt;\n          ggplot() +\n            geom_vline(xintercept = -13.3, colour = \"grey80\") +\n            geom_hline(yintercept = 29.5, colour = \"grey80\") +\n            geom_sf(fill = \"red\", colour = \"white\") +\n            coord_sf(expand = F) +\n            theme_void() \ncan\n\n\n\n\n\n\n\n\n# add ggplot map with annotation_custom() absolute position according to the SRC\nfilter(esp, nuts2.name != \"Canarias\") |&gt;\n  ggplot() +\n  geom_sf(data = entorno, fill = \"grey70\", colour = NA) +\n  geom_sf(colour = \"white\", linewidth = .2) +\n  annotation_custom(ggplotGrob(can),\n                    xmin = -14, xmax = -9,\n                    ymin = 33, ymax = 38) +\n  theme_void()\n\n\n\n\n\n\n\nIf we want to project the main map, we only need to project the position area of the inserted map first.\n\n# position box with some adjustment \npos &lt;- c(xmin = -13.5, ymin = 32.5, xmax = -8.5, ymax = 37.5) \nclass(pos) &lt;- \"bbox\" # definimos como bbox\n\n# reproject to LAEA Europe EPSG:3035\npos_prj &lt;- st_as_sfc(pos) |&gt; \n  st_set_crs(4326) |&gt;\n  st_transform(3035) |&gt; \n  st_bbox()\n\n# create the final map\nfilter(esp, nuts2.name != \"Canarias\") |&gt;\n  ggplot() +\n  geom_sf(data = entorno, fill = \"grey70\", colour = NA) +\n  geom_sf(colour = \"white\", linewidth = .2) +\n  annotation_custom(ggplotGrob(can),\n                    xmin = pos_prj[1], xmax = pos_prj[3],\n                    ymin = pos_prj[2], ymax = pos_prj[4]) +\n  coord_sf(crs = 3035) +\n  theme_void()"
  },
  {
    "objectID": "blog/inserted-map/index.html#option-3",
    "href": "blog/inserted-map/index.html#option-3",
    "title": "Inserted maps with ggplot2",
    "section": "Option 3",
    "text": "Option 3\nThe last option for inserting a secondary map is to use the inset_element() function of the patchwork package. The difference with the previous method is the relative position, which limits the use. In this case proportional symbols should not be represented as the relative insertion does not maintain the same dimensions as the main map.\n\n# provincial boundaries\nesp &lt;- esp_get_prov(epsg = 4326, moveCAN = F)\n\n# Canary Island map\ncan &lt;-  filter(esp, nuts2.name == \"Canarias\") |&gt;\n          ggplot() +\n            geom_vline(xintercept = -13.3, colour = \"grey80\") +\n            geom_hline(yintercept = 29.5, colour = \"grey80\") +\n            geom_sf(fill = \"red\", colour = \"white\") +\n            coord_sf(expand = F) +\n            theme_void() \n\n# main map\nm &lt;- filter(esp, nuts2.name != \"Canarias\") |&gt;\n  ggplot() +\n  geom_sf(colour = \"white\", linewidth = .2) +\n  theme_void()\n\n# insert with relative position \nm + inset_element(can, left = -.1, bottom = 0, \n                  right = .2, top = .2, \n                  align_to = \"full\")"
  },
  {
    "objectID": "blog/inserted-map/index.html#earth-globe-as-inset-map",
    "href": "blog/inserted-map/index.html#earth-globe-as-inset-map",
    "title": "Inserted maps with ggplot2",
    "section": "Earth globe as inset map",
    "text": "Earth globe as inset map\nThe only difficulty here is the orthogonal projection while preserving the visible geometry of the earth. The first step is the creation of the “ocean” using the radius of the earth from the point 0,0. Then we only have to cut out the visible part and reproject the boundaries. In the definition of the orthogonal projection it is possible to centre at different latitudes and longitudes by changing the +lat_0 and +lon_0 values. The ms_innerlines() functions of the rmapshaper package easily create the inner boundaries of polygons, which is recommended to avoid blurring small areas.\n\n# overall country boundaries\nwld &lt;- gisco_get_countries(resolution = \"20\")\n\n# definition of orthogonal projection\northo_crs &lt;-'+proj=ortho +lat_0=30 +lon_0=0.5 +x_0=0 +y_0=0 +R=6371000 +units=m +no_defs +type=crs'\n\n# creation of the ocean \nocean &lt;- st_point(x = c(0,0)) |&gt;\n            st_buffer(dist = 6371000) |&gt; # radio Tierra\n              st_sfc(crs = ortho_crs)\nplot(ocean)\n\n\n\n\n\n\n\n\n# cut out the visible land and reproject it\nworld &lt;-   st_intersection(wld, st_transform(ocean, 4326)) |&gt;\n            st_transform(crs = ortho_crs) |&gt; \n            mutate(dummy = ifelse(NAME_ENGL == \"Spain\", \"yes\", \"no\"))\n\nplot(world)\n\n\n\n\n\n\n\n\n# obtain only the inner limits\nworld_line &lt;- ms_innerlines(world)\nplot(world_line)\n\n\n\n\n\n\n\n\n# main map of Spain \nwld_map &lt;- ggplot(world) +\n            geom_sf(data = ocean, fill = \"#deebf7\", linewidth = .2) +\n            geom_sf(aes(fill = dummy), \n                    colour = NA,\n                    show.legend = F) +\n            geom_sf(data = world_line, linewidth = .05, colour = \"white\") +\n            scale_fill_manual(values = c(\"grey50\", \"red\")) + \n            theme_void()\n\n# insert the globe marking the location of Spain \nm + inset_element(wld_map, left = 0.65, bottom = 0.82, right = 1.1, top = 1, align_to = \"full\")"
  },
  {
    "objectID": "blog/night-day-world/index.html",
    "href": "blog/night-day-world/index.html",
    "title": "Visualize the day-night cycle on a world map",
    "section": "",
    "text": "In April of this year, I made an animation of the 24-hour average temperature of January 2020, also showing the day-night cycle.\nMy biggest problem was finding a way to project correctly the area at night without breaking the geometry. The easiest solution I found was rasterising the night polygon and then reprojecting it. Indeed, a vector approach could be used, but I have preferred to use raster data here."
  },
  {
    "objectID": "blog/night-day-world/index.html#external-functions",
    "href": "blog/night-day-world/index.html#external-functions",
    "title": "Visualize the day-night cycle on a world map",
    "section": "External functions",
    "text": "External functions\nThe functions to estimate the separator line between day and night are based on a javascript L.Terminator.js from the {Leaflet} package I found on stackoverflow. You can download the script with the functions here or access it on github.\n\nsource(\"terminator.R\") # import the functions"
  },
  {
    "objectID": "blog/night-day-world/index.html#custom-functions",
    "href": "blog/night-day-world/index.html#custom-functions",
    "title": "Visualize the day-night cycle on a world map",
    "section": "Custom functions",
    "text": "Custom functions\nThe primary function terminator() based on the javascript of {Leaflet} needs as arguments: the date-time, the minimum and maximum extension, as well as the resolution or the interval of longitude.\n\nt0 &lt;- Sys.time() # date and time of our operating system\nt0\n\n[1] \"2025-01-07 17:01:33 CET\"\n\ncoord_nightday &lt;- terminator(t0, -180, 180, 0.2) # estimate the day-night line\n\n# convert it into a spatial object of class sf\nline_nightday &lt;- st_linestring(as.matrix(coord_nightday)) |&gt; st_sfc(crs = 4326)\n\n# plot\nplot(line_nightday)\n\n\n\n\n\n\n\nIn the next step, we obtain the polygons corresponding to the day and the night that separates the previously estimated line. To do this, we create a rectangle covering the entire planet and use the st_split() function from the lwgeom package that divides the rectangle.\n\n# rectangle\nwld_bbx &lt;- st_bbox(\n  c(\n    xmin = -179.99, xmax = 179.99,\n    ymin = -90, ymax = 90\n  ),\n  crs = 4326\n) |&gt;\n  st_as_sfc() \n\n# division with the day-night line\npoly_nightday &lt;- st_split(wld_bbx, line_nightday) |&gt;\n  st_collection_extract(c(\"POLYGON\")) |&gt;\n  st_sf()\n\n# plot\nplot(poly_nightday)\n\n\n\n\n\n\n\nThe question now arises which of the two polygons corresponds to the night and which to the day. That will depend on what day of the year we are, given the changes in the Earth’s position concerning the Sun. Between the first summer equinox and the autumn equinox, it corresponds to the first polygon, when we can also observe the polar day at the north pole, and in the opposite case, it would be the second. The terra package only accepts its vector class called SpatVector, so we convert the vector object sf with the vect() function.\n\n# select the second polygon\npoly_nightday &lt;- slice(poly_nightday, 2) |&gt;\n  mutate(daynight = 1)\n\n# create the raster with a resolution of 0.5º and the extent of the world\nr &lt;- rast(vect(wld_bbx), resolution = .1)\n\n# rasterize the night polygon\nnight_rast &lt;- rasterize(vect(poly_nightday), r)\n\n# result in raster format\nplot(night_rast)\n\n\n\n\n\n\n\nIn the last step we reproject the raster to Mollweide.\n\n# define the raster projection (WGS84)\ncrs(night_rast) &lt;- \"EPSG:4326\"\n\n# reproject\nnight_rast_prj &lt;- project(night_rast, \"ESRI:54009\")\n# map\nplot(night_rast_prj)\n\n\n\n\n\n\n\nFinally we include the individual steps that we have done in a custom function.\n\nrast_determiner &lt;- function(x_min, date, res) {\n  # create date with time adding the number of minutes\n  t0 &lt;- as_date(date) + minutes(x_min)\n  # estimate the coordinates of the line that separates day and night\n  night_step &lt;- terminator(t0, -180, 180, 0.2) |&gt; as.matrix()\n  # pass the points to line\n  night_line &lt;- st_linestring(night_step) |&gt; st_sfc(crs = 4326)\n\n  # define the rectangle of the planet\n  wld_bbx &lt;- st_bbox(\n    c(\n    xmin = -179.99, xmax = 179.99,\n    ymin = -90, ymax = 90\n    ),\n    crs = 4326\n  ) |&gt;\n    st_as_sfc()\n\n  # divide the polygon with the day-night line\n  poly_nightday &lt;- st_split(wld_bbx, night_line) |&gt;\n    st_collection_extract(c(\"POLYGON\")) |&gt;\n    st_sf()\n\n  # select the polygon according to the date\n  if (date &lt;= make_date(year(date), 3, 20) | date &gt;= make_date(year(date), 9, 23)) {\n    poly_nightday &lt;- slice(poly_nightday, 2) |&gt;\n      mutate(daynight = 1)\n  } else {\n    poly_nightday &lt;- slice(poly_nightday, 1) |&gt;\n      mutate(daynight = 1)\n  }\n\n  # create the raster with the resolution given in the argument res\n  r &lt;- rast(vect(wld_bbx), resolution = res)\n\n  # rasterize the night polygon\n  night_rast &lt;- rasterize(vect(poly_nightday), r)\n\n  return(night_rast)\n}\n\nSince we want to obtain the area at night for different day hours, we construct a second function to apply the first one at different day intervals (in minutes).\n\nnight_determinator &lt;- function(time_seq, # minutes\n                               date = Sys.Date(), # date (system default)\n                               res = .5) { # raster resolution 0.5º\n\n  # apply the first function on a vector of day intervals\n  night_raster &lt;- map(time_seq,\n    rast_determiner,\n    date = date,\n    res = res\n  )\n\n  # convert the raster into an object with as many layers as day intervals\n  night_raster &lt;- rast(night_raster)\n\n  # define the WGS84 projection\n  crs(night_raster) &lt;- \"EPSG:4326\"\n\n  return(night_raster)\n}"
  },
  {
    "objectID": "blog/night-day-world/index.html#preparation-1",
    "href": "blog/night-day-world/index.html#preparation-1",
    "title": "Visualize the day-night cycle on a world map",
    "section": "Preparation",
    "text": "Preparation\nTo create a 24-hour animation showing the movement of the night on the Earth, we must do a few previous steps. First we get the world boundaries with the gisco_get_countries() function and reproject them to the new Winkel II projection. Then we convert the raster data into a data.frame indicating to keep missing values. We can see that each layer of the raster (of each 30-minute interval) is a column in the data.frame. We rename the columns and convert the table into a long format using the pivot_longer() function. What we do is to merge all the columns of the layers into a single one. As the last step, we exclude the missing values with the filter() function.\n\n# country boundaries\nwld &lt;- gisco_get_countries(resolution = \"10\") |&gt; st_transform(\"ESRI:54019\")\n\n# convert the raster to a data.frame with xyz\ndf_winkel &lt;- as.data.frame(night_raster_winkel, xy = TRUE, na.rm = FALSE)\n\n# rename all the columns corresponding to the day intervals\nnames(df_winkel)[3:length(df_winkel)] &lt;- str_c(\"H\", as_hms(seq(0, 1410, 30) * 60))\n\n# change to a long format\ndf_winkel &lt;- pivot_longer(df_winkel, 3:length(df_winkel), names_to = \"hour\", values_to = \"night\")\n\n# exclude missing values to reduce table size\ndf_winkel &lt;- filter(df_winkel, !is.na(night))\n\nIt only remains to create a graticule and obtain the extent of the world map.\n\n# graticule\ngrid &lt;- st_graticule() |&gt; st_transform(\"ESRI:54019\")\n\n# get the extension of the world\nbbx &lt;- st_bbox(wld)\n\nNow we will build a map at a single interval with ggplot2, adding the vector geometry using the geom_sf() function (the boundaries and the graticule) and the raster data using the geom_raster() function. In the title, we are using a unicode symbol as a clock. We also define the map’s extent in coord_sf() to keet it constant over all maps in the animation. Finally, we make use of { } from the {rlang} package within the filter()function to be able to filter our raster data in table form. So that our function can correctly evaluate the values that we pass in x (the intervals of the day) it is necessary to use this grammar of tidy evaluation due to data masking in tidyverse. Honestly, it is a topic for another post.\n\n# example 5 UTC\nx &lt;- \"H05:00:00\"\n# map\nggplot() +\n  # boundaries\n  geom_sf(\n    data = wld,\n    fill = \"#74a9cf\",\n    colour = \"white\",\n    linewidth = .1\n  ) +\n  # graticule\n  geom_sf(data = grid, linewidth = .1) +\n  # filtered raster data\n  geom_raster(\n    data = filter(df_winkel, hour == {{ x }}),\n    aes(x, y),\n    fill = \"grey90\",\n    alpha = .6\n  ) +\n  # title\n  labs(title = str_c(\"\\U1F551\", str_remove(x, \"H\"), \" UTC\")) +\n  # extension limits\n  coord_sf(\n    xlim = bbx[c(1, 3)],\n    ylim = bbx[c(2, 4)]\n  ) +\n  # map style\n  theme_void() +\n  theme(plot.title = element_text(hjust = .1, vjust = .9))"
  },
  {
    "objectID": "blog/night-day-world/index.html#animation",
    "href": "blog/night-day-world/index.html#animation",
    "title": "Visualize the day-night cycle on a world map",
    "section": "Animation",
    "text": "Animation\nWe create the animation by applying the walk() function, which in turn will go through the interval vector to filter our data and map each step using ggplot.\n\nwalk(str_c(\"H\", as_hms(seq(0, 1410, 30) * 60)), function(step) {\n  g &lt;- ggplot() +\n    geom_sf(\n      data = wld,\n      fill = \"#74a9cf\",\n      colour = \"white\",\n         linewidth = .1\n    ) +\n    geom_sf(\n      data = grid,\n      linewidth = .1\n    ) +\n    geom_raster(\n      data = filter(df_winkel, hour == {{ step }}), aes(x, y),\n      fill = \"grey90\",\n      alpha = .6\n    ) +\n    labs(title = str_c(\"\\U1F551\", str_remove(x, \"H\"), \" UTC\")) +\n    coord_sf(xlim = bbx[c(1, 3)], ylim = bbx[c(2, 4)]) +\n    theme_void() +\n    theme(plot.title = element_text(hjust = .1, vjust = .9))\n\n\n  ggsave(str_c(\"wld_night_\", str_remove_all(step, \":\"), \".png\"), g,\n    height = 4.3, width = 8.4, bg = \"white\", dpi = 300, units = \"in\"\n  )\n})\n\nThe creation of the final gif is done with gifski() passing it the names of the images in the order as they should appear in the animation.\n\nfiles &lt;- str_c(\"wld_night_H\", str_remove_all(as_hms(seq(0, 1410, 30) * 60), \":\"), \".png\")\n\ngifski(files, \"night_day.gif\", width = 807, height = 409, loop = TRUE, delay = 0.1)"
  },
  {
    "objectID": "blog/tidy-correlation-tests-in-r/index.html",
    "href": "blog/tidy-correlation-tests-in-r/index.html",
    "title": "Tidy correlation tests in R",
    "section": "",
    "text": "When we try to estimate the correlation coefficient between multiple variables, the task is more complicated in order to obtain a simple and tidy result. A simple solution is to use the tidy() function from the {broom} package. In this post we are going to estimate the correlation coefficients between the annual precipitation of several Spanish cities and climate teleconnections indices: download. The data of the teleconnections are preprocessed, but can be downloaded directly from crudata.uea.ac.uk. The daily precipitation data comes from ECA&D."
  },
  {
    "objectID": "blog/tidy-correlation-tests-in-r/index.html#packages",
    "href": "blog/tidy-correlation-tests-in-r/index.html#packages",
    "title": "Tidy correlation tests in R",
    "section": "Packages",
    "text": "Packages\nIn this post we will use the following packages:\n\n\n\n\n\n\n\n\nPackage\nDescription\n\n\n\ntidyverse\nCollection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.\n\n\nbroom\nConvert results of statistical functions (lm, t.test, cor.test, etc.) into tidy tables\n\n\nfs\nProvides a cross-platform, uniform interface to file system operations\n\n\n\n\n\n\n# install the packages if necessary\n\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"broom\")) install.packages(\"broom\")\nif (!require(\"fs\")) install.packages(\"fs\")\n\n\n# load packages\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(fs)"
  },
  {
    "objectID": "blog/tidy-correlation-tests-in-r/index.html#import-data",
    "href": "blog/tidy-correlation-tests-in-r/index.html#import-data",
    "title": "Tidy correlation tests in R",
    "section": "Import data",
    "text": "Import data\nFirst we have to import the daily precipitation of the selected weather stations.\n\nCreate a vector with all precipitation files using the function dir_ls() of the {fs} package.\nImport the data using the map() function of the {purrr} package that applies another function to a vector or list, and then we can join them together in a single data.frame with list_rbind().\n\nSelect the columns that interest us, b) Convert the date string into a date object using the ymd() function of the {lubridate} package, c) Create a new column yr with the years, d) Divide the precipitation values by 10 and reclassify absent values -9999 by NA, e) Finally, reclassify the ID of each weather station creating a factor with new labels.\n\n\nMore details about the use of the dir_ls() and list_rbind() functions can be found in this previous post.\n\n# precipitation files\nfiles &lt;- dir_ls(regexp = \"txt\")\nfiles\n\nRR_STAID001393.txt RR_STAID001394.txt RR_STAID002969.txt RR_STAID003946.txt \nRR_STAID003969.txt \n\n# import all files and join them together\npr &lt;- files |&gt; map(read_csv, skip = 20) |&gt; list_rbind()\n\nRows: 26329 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (5): STAID, SOUID, DATE, RR, Q_RR\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 27545 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (5): STAID, SOUID, DATE, RR, Q_RR\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 34729 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (5): STAID, SOUID, DATE, RR, Q_RR\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 24927 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (5): STAID, SOUID, DATE, RR, Q_RR\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 19813 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (5): STAID, SOUID, DATE, RR, Q_RR\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npr\n\n# A tibble: 133,343 × 5\n   STAID SOUID     DATE    RR  Q_RR\n   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  1393 20611 19470301     0     0\n 2  1393 20611 19470302     5     0\n 3  1393 20611 19470303     0     0\n 4  1393 20611 19470304    33     0\n 5  1393 20611 19470305    15     0\n 6  1393 20611 19470306     0     0\n 7  1393 20611 19470307    85     0\n 8  1393 20611 19470308     3     0\n 9  1393 20611 19470309     0     0\n10  1393 20611 19470310     0     0\n# ℹ 133,333 more rows\n\n# create levels for the factor\nid &lt;- unique(pr$STAID)\n\n# the corresponding labels\nlab &lt;- c(\"Bilbao\", \"Santiago\", \"Barcelona\", \"Madrid\", \"Valencia\")\n\n# first changes\npr &lt;- select(pr, STAID, DATE, RR) |&gt;\n  mutate(\n    DATE = ymd(DATE),\n    RR = ifelse(RR == -9999, NA, RR / 10),\n    STAID = factor(STAID, id, lab),\n    yr = year(DATE)\n  )\npr\n\n# A tibble: 133,343 × 4\n   STAID  DATE          RR    yr\n   &lt;fct&gt;  &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1 Bilbao 1947-03-01   0    1947\n 2 Bilbao 1947-03-02   0.5  1947\n 3 Bilbao 1947-03-03   0    1947\n 4 Bilbao 1947-03-04   3.3  1947\n 5 Bilbao 1947-03-05   1.5  1947\n 6 Bilbao 1947-03-06   0    1947\n 7 Bilbao 1947-03-07   8.5  1947\n 8 Bilbao 1947-03-08   0.3  1947\n 9 Bilbao 1947-03-09   0    1947\n10 Bilbao 1947-03-10   0    1947\n# ℹ 133,333 more rows\n\n\nWe still need to filter and calculate the annual amount of precipitation. Actually, it is not correct to sum up precipitation without taking into account that there are missing values, but it should be enough for this practice. Then, we change the table format with the spread() function, passing from a long to a wide table, that is, we want to obtain one column per weather station.\n\npr_yr &lt;- filter(pr, DATE &gt;= \"1950-01-01\", \n                DATE &lt; \"2018-01-01\") |&gt;\n          group_by(STAID, yr) |&gt;\n          summarise(pr = sum(RR, na.rm = TRUE))\n\n`summarise()` has grouped output by 'STAID'. You can override using the\n`.groups` argument.\n\npr_yr\n\n# A tibble: 324 × 3\n# Groups:   STAID [5]\n   STAID     yr    pr\n   &lt;fct&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 Bilbao  1950 1342 \n 2 Bilbao  1951 1306.\n 3 Bilbao  1952 1355.\n 4 Bilbao  1953 1372.\n 5 Bilbao  1954 1428.\n 6 Bilbao  1955 1062.\n 7 Bilbao  1956 1254.\n 8 Bilbao  1957  968.\n 9 Bilbao  1958 1272.\n10 Bilbao  1959 1450.\n# ℹ 314 more rows\n\npr_yr &lt;- spread(pr_yr, STAID, pr)\npr_yr\n\n# A tibble: 68 × 6\n      yr Bilbao Santiago Barcelona Madrid Valencia\n   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n 1  1950  1342     1800.      345     NA        NA\n 2  1951  1306.    2344.     1072.   798.       NA\n 3  1952  1355.    1973.      415.   524.       NA\n 4  1953  1372.     973.      683.   365.       NA\n 5  1954  1428.    1348.      581.   246.       NA\n 6  1955  1062.    1769.      530.   473.       NA\n 7  1956  1254.    1533.      695.   480.       NA\n 8  1957   968.    1599.      635.   424.       NA\n 9  1958  1272.    2658.      479.   482.       NA\n10  1959  1450.    2847.     1006    665.       NA\n# ℹ 58 more rows\n\n\nThe next step is to import the climate teleconnection indices.\n\n# teleconnections\ntelecon &lt;- read_csv(\"teleconnections_indices.csv\")\n\nRows: 68 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (9): yr, NAO, WeMO, EA, POL-EUAS, EATL/WRUS, MO, SCAND, AO\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntelecon\n\n# A tibble: 68 × 9\n      yr   NAO   WeMO     EA `POL-EUAS` `EATL/WRUS`    MO    SCAND        AO\n   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1  1950  0.49  0.555 -0.332     0.0217     -0.0567 0.335  0.301   -0.199   \n 2  1951 -0.07  0.379 -0.372     0.402      -0.419  0.149 -0.00667 -0.365   \n 3  1952 -0.37  0.693 -0.688    -0.0117     -0.711  0.282  0.0642  -0.675   \n 4  1953  0.4  -0.213 -0.727    -0.0567     -0.0508 0.216  0.0233  -0.0164  \n 5  1954  0.51  1.20  -0.912     0.142      -0.318  0.386  0.458   -0.000583\n 6  1955 -0.64  0.138 -0.824    -0.0267      0.154  0.134  0.0392  -0.362   \n 7  1956  0.17  0.617 -1.29     -0.197       0.0617 0.256  0.302   -0.163   \n 8  1957 -0.02  0.321 -0.952    -0.638      -0.167  0.322 -0.134   -0.342   \n 9  1958  0.12  0.941 -0.243     0.138       0.661  0.296  0.279   -0.868   \n10  1959  0.49 -0.055 -0.23     -0.0142      0.631  0.316  0.725   -0.0762  \n# ℹ 58 more rows\n\n\nFinally we need to join both tables by year.\n\ndata_all &lt;- left_join(pr_yr, telecon, by = \"yr\")\ndata_all\n\n# A tibble: 68 × 14\n      yr Bilbao Santiago Barcelona Madrid Valencia   NAO   WeMO     EA\n   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1  1950  1342     1800.      345     NA        NA  0.49  0.555 -0.332\n 2  1951  1306.    2344.     1072.   798.       NA -0.07  0.379 -0.372\n 3  1952  1355.    1973.      415.   524.       NA -0.37  0.693 -0.688\n 4  1953  1372.     973.      683.   365.       NA  0.4  -0.213 -0.727\n 5  1954  1428.    1348.      581.   246.       NA  0.51  1.20  -0.912\n 6  1955  1062.    1769.      530.   473.       NA -0.64  0.138 -0.824\n 7  1956  1254.    1533.      695.   480.       NA  0.17  0.617 -1.29 \n 8  1957   968.    1599.      635.   424.       NA -0.02  0.321 -0.952\n 9  1958  1272.    2658.      479.   482.       NA  0.12  0.941 -0.243\n10  1959  1450.    2847.     1006    665.       NA  0.49 -0.055 -0.23 \n# ℹ 58 more rows\n# ℹ 5 more variables: `POL-EUAS` &lt;dbl&gt;, `EATL/WRUS` &lt;dbl&gt;, MO &lt;dbl&gt;,\n#   SCAND &lt;dbl&gt;, AO &lt;dbl&gt;"
  },
  {
    "objectID": "blog/tidy-correlation-tests-in-r/index.html#correlation-test",
    "href": "blog/tidy-correlation-tests-in-r/index.html#correlation-test",
    "title": "Tidy correlation tests in R",
    "section": "Correlation test",
    "text": "Correlation test\nA correlation test between paired samples can be done with the cor.test() function of R Base. In this case between the annual precipitation of Bilbao and the NAO index.\n\ncor_nao_bil &lt;- cor.test(data_all$Bilbao, \n                        data_all$NAO,\n                         method = \"spearman\"\n                )\n\nWarning in cor.test.default(data_all$Bilbao, data_all$NAO, method =\n\"spearman\"): Cannot compute exact p-value with ties\n\ncor_nao_bil\n\n\n    Spearman's rank correlation rho\n\ndata:  data_all$Bilbao and data_all$NAO\nS = 44372, p-value = 0.2126\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.1531149 \n\nstr(cor_nao_bil)\n\nList of 8\n $ statistic  : Named num 44372\n  ..- attr(*, \"names\")= chr \"S\"\n $ parameter  : NULL\n $ p.value    : num 0.213\n $ estimate   : Named num 0.153\n  ..- attr(*, \"names\")= chr \"rho\"\n $ null.value : Named num 0\n  ..- attr(*, \"names\")= chr \"rho\"\n $ alternative: chr \"two.sided\"\n $ method     : chr \"Spearman's rank correlation rho\"\n $ data.name  : chr \"data_all$Bilbao and data_all$NAO\"\n - attr(*, \"class\")= chr \"htest\"\n\n\nWe see that the result is in an unmanageable and untidy format. It is a console summary of the correlation with all the statistical parameters necessary to get a conclusion about the relationship. The orginal structure is a list of vectors. However, the tidy() function of the {broom} package allows us to convert the result into a table format.\n\ntidy(cor_nao_bil)\n\n# A tibble: 1 × 5\n  estimate statistic p.value method                          alternative\n     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;                           &lt;chr&gt;      \n1    0.153    44372.   0.213 Spearman's rank correlation rho two.sided"
  },
  {
    "objectID": "blog/tidy-correlation-tests-in-r/index.html#apply-the-correlation-test-to-multiple-variables",
    "href": "blog/tidy-correlation-tests-in-r/index.html#apply-the-correlation-test-to-multiple-variables",
    "title": "Tidy correlation tests in R",
    "section": "Apply the correlation test to multiple variables",
    "text": "Apply the correlation test to multiple variables\nThe objective is to apply the correlation test to all weather stations and climate teleconnection indices.\nFirst, we must pass the table to the long format, that is, create a column/variable for the city and for the value of the corresponding precipitation. Then we repeat the same for the teleconnections indices.\n\ndata &lt;- pivot_longer(data_all, Bilbao:Valencia, names_to = \"city\", values_to = \"pr\") |&gt;\n             pivot_longer(NAO:AO, names_to = \"telecon\", values_to = \"index\")\ndata\n\n# A tibble: 2,720 × 5\n      yr city        pr telecon     index\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;\n 1  1950 Bilbao   1342  NAO        0.49  \n 2  1950 Bilbao   1342  WeMO       0.555 \n 3  1950 Bilbao   1342  EA        -0.332 \n 4  1950 Bilbao   1342  POL-EUAS   0.0217\n 5  1950 Bilbao   1342  EATL/WRUS -0.0567\n 6  1950 Bilbao   1342  MO         0.335 \n 7  1950 Bilbao   1342  SCAND      0.301 \n 8  1950 Bilbao   1342  AO        -0.199 \n 9  1950 Santiago 1800. NAO        0.49  \n10  1950 Santiago 1800. WeMO       0.555 \n# ℹ 2,710 more rows\n\n\nTo apply the test to all cities, we need the corresponding groupings. Therefore, we use the group_by() function for indicating the two groups: city and telecon. In addition, we apply the nest() function of the {tidyr} package ({tidyverse} collection) with the aim of creating lists of tables nested per row. In other words, in each row of each city and teleconnection index we will have a new table that contains the year, the precipitation value and the value of each teleconection, correspondingly.\n\ndata_nest &lt;- group_by(data, city, telecon) |&gt; nest()\nhead(data_nest)\n\n# A tibble: 6 × 3\n# Groups:   city, telecon [6]\n  city   telecon   data             \n  &lt;chr&gt;  &lt;chr&gt;     &lt;list&gt;           \n1 Bilbao NAO       &lt;tibble [68 × 3]&gt;\n2 Bilbao WeMO      &lt;tibble [68 × 3]&gt;\n3 Bilbao EA        &lt;tibble [68 × 3]&gt;\n4 Bilbao POL-EUAS  &lt;tibble [68 × 3]&gt;\n5 Bilbao EATL/WRUS &lt;tibble [68 × 3]&gt;\n6 Bilbao MO        &lt;tibble [68 × 3]&gt;\n\nstr(head(slice(data_nest, 1)))\n\ngropd_df [6 × 3] (S3: grouped_df/tbl_df/tbl/data.frame)\n $ city   : chr [1:6] \"Barcelona\" \"Barcelona\" \"Barcelona\" \"Barcelona\" ...\n $ telecon: chr [1:6] \"AO\" \"EA\" \"EATL/WRUS\" \"MO\" ...\n $ data   :List of 6\n  ..$ : tibble [68 × 3] (S3: tbl_df/tbl/data.frame)\n  .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...\n  .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...\n  .. ..$ index: num [1:68] -0.199333 -0.364667 -0.674917 -0.016417 -0.000583 ...\n  ..$ : tibble [68 × 3] (S3: tbl_df/tbl/data.frame)\n  .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...\n  .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...\n  .. ..$ index: num [1:68] -0.333 -0.372 -0.688 -0.727 -0.912 ...\n  ..$ : tibble [68 × 3] (S3: tbl_df/tbl/data.frame)\n  .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...\n  .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...\n  .. ..$ index: num [1:68] -0.0567 -0.4192 -0.7108 -0.0508 -0.3175 ...\n  ..$ : tibble [68 × 3] (S3: tbl_df/tbl/data.frame)\n  .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...\n  .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...\n  .. ..$ index: num [1:68] 0.335 0.149 0.282 0.216 0.386 ...\n  ..$ : tibble [68 × 3] (S3: tbl_df/tbl/data.frame)\n  .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...\n  .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...\n  .. ..$ index: num [1:68] 0.49 -0.07 -0.37 0.4 0.51 -0.64 0.17 -0.02 0.12 0.49 ...\n  ..$ : tibble [68 × 3] (S3: tbl_df/tbl/data.frame)\n  .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...\n  .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...\n  .. ..$ index: num [1:68] 0.0217 0.4025 -0.0117 -0.0567 0.1425 ...\n - attr(*, \"groups\")= tibble [6 × 3] (S3: tbl_df/tbl/data.frame)\n  ..$ city   : chr [1:6] \"Barcelona\" \"Barcelona\" \"Barcelona\" \"Barcelona\" ...\n  ..$ telecon: chr [1:6] \"AO\" \"EA\" \"EATL/WRUS\" \"MO\" ...\n  ..$ .rows  : list&lt;int&gt; [1:6] \n  .. ..$ : int 1\n  .. ..$ : int 2\n  .. ..$ : int 3\n  .. ..$ : int 4\n  .. ..$ : int 5\n  .. ..$ : int 6\n  .. ..@ ptype: int(0) \n  ..- attr(*, \".drop\")= logi TRUE\n\n\nThe next step is to create a function, in which we define the correlation test and pass it to the clean format using the tidy() function, which we apply to each groupings.\n\ncor_fun &lt;- function(df) cor.test(df$pr, df$index, method = \"spearman\") |&gt; tidy()\n\nNow we only have to apply our function to the column that contains the tables for each combination between city and teleconnection. To do this, we use the map() function that applies another function to a vector or list. What we do is create a new column that contains the result, a statistical summary table, for each combination.\n\ndata_nest &lt;- mutate(data_nest, model = map(data, cor_fun))\nhead(data_nest)\n\n# A tibble: 6 × 4\n# Groups:   city, telecon [6]\n  city   telecon   data              model           \n  &lt;chr&gt;  &lt;chr&gt;     &lt;list&gt;            &lt;list&gt;          \n1 Bilbao NAO       &lt;tibble [68 × 3]&gt; &lt;tibble [1 × 5]&gt;\n2 Bilbao WeMO      &lt;tibble [68 × 3]&gt; &lt;tibble [1 × 5]&gt;\n3 Bilbao EA        &lt;tibble [68 × 3]&gt; &lt;tibble [1 × 5]&gt;\n4 Bilbao POL-EUAS  &lt;tibble [68 × 3]&gt; &lt;tibble [1 × 5]&gt;\n5 Bilbao EATL/WRUS &lt;tibble [68 × 3]&gt; &lt;tibble [1 × 5]&gt;\n6 Bilbao MO        &lt;tibble [68 × 3]&gt; &lt;tibble [1 × 5]&gt;\n\nstr(head(slice(data_nest, 1)))\n\ngropd_df [6 × 4] (S3: grouped_df/tbl_df/tbl/data.frame)\n $ city   : chr [1:6] \"Barcelona\" \"Barcelona\" \"Barcelona\" \"Barcelona\" ...\n $ telecon: chr [1:6] \"AO\" \"EA\" \"EATL/WRUS\" \"MO\" ...\n $ data   :List of 6\n  ..$ : tibble [68 × 3] (S3: tbl_df/tbl/data.frame)\n  .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...\n  .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...\n  .. ..$ index: num [1:68] -0.199333 -0.364667 -0.674917 -0.016417 -0.000583 ...\n  ..$ : tibble [68 × 3] (S3: tbl_df/tbl/data.frame)\n  .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...\n  .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...\n  .. ..$ index: num [1:68] -0.333 -0.372 -0.688 -0.727 -0.912 ...\n  ..$ : tibble [68 × 3] (S3: tbl_df/tbl/data.frame)\n  .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...\n  .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...\n  .. ..$ index: num [1:68] -0.0567 -0.4192 -0.7108 -0.0508 -0.3175 ...\n  ..$ : tibble [68 × 3] (S3: tbl_df/tbl/data.frame)\n  .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...\n  .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...\n  .. ..$ index: num [1:68] 0.335 0.149 0.282 0.216 0.386 ...\n  ..$ : tibble [68 × 3] (S3: tbl_df/tbl/data.frame)\n  .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...\n  .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...\n  .. ..$ index: num [1:68] 0.49 -0.07 -0.37 0.4 0.51 -0.64 0.17 -0.02 0.12 0.49 ...\n  ..$ : tibble [68 × 3] (S3: tbl_df/tbl/data.frame)\n  .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...\n  .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...\n  .. ..$ index: num [1:68] 0.0217 0.4025 -0.0117 -0.0567 0.1425 ...\n $ model  :List of 6\n  ..$ : tibble [1 × 5] (S3: tbl_df/tbl/data.frame)\n  .. ..$ estimate   : Named num -0.00989\n  .. .. ..- attr(*, \"names\")= chr \"rho\"\n  .. ..$ statistic  : Named num 52912\n  .. .. ..- attr(*, \"names\")= chr \"S\"\n  .. ..$ p.value    : num 0.936\n  .. ..$ method     : chr \"Spearman's rank correlation rho\"\n  .. ..$ alternative: chr \"two.sided\"\n  ..$ : tibble [1 × 5] (S3: tbl_df/tbl/data.frame)\n  .. ..$ estimate   : Named num -0.295\n  .. .. ..- attr(*, \"names\")= chr \"rho\"\n  .. ..$ statistic  : Named num 67832\n  .. .. ..- attr(*, \"names\")= chr \"S\"\n  .. ..$ p.value    : num 0.0147\n  .. ..$ method     : chr \"Spearman's rank correlation rho\"\n  .. ..$ alternative: chr \"two.sided\"\n  ..$ : tibble [1 × 5] (S3: tbl_df/tbl/data.frame)\n  .. ..$ estimate   : Named num 0.161\n  .. .. ..- attr(*, \"names\")= chr \"rho\"\n  .. ..$ statistic  : Named num 43966\n  .. .. ..- attr(*, \"names\")= chr \"S\"\n  .. ..$ p.value    : num 0.19\n  .. ..$ method     : chr \"Spearman's rank correlation rho\"\n  .. ..$ alternative: chr \"two.sided\"\n  ..$ : tibble [1 × 5] (S3: tbl_df/tbl/data.frame)\n  .. ..$ estimate   : Named num -0.255\n  .. .. ..- attr(*, \"names\")= chr \"rho\"\n  .. ..$ statistic  : Named num 65754\n  .. .. ..- attr(*, \"names\")= chr \"S\"\n  .. ..$ p.value    : num 0.0361\n  .. ..$ method     : chr \"Spearman's rank correlation rho\"\n  .. ..$ alternative: chr \"two.sided\"\n  ..$ : tibble [1 × 5] (S3: tbl_df/tbl/data.frame)\n  .. ..$ estimate   : Named num -0.0203\n  .. .. ..- attr(*, \"names\")= chr \"rho\"\n  .. ..$ statistic  : Named num 53460\n  .. .. ..- attr(*, \"names\")= chr \"S\"\n  .. ..$ p.value    : num 0.869\n  .. ..$ method     : chr \"Spearman's rank correlation rho\"\n  .. ..$ alternative: chr \"two.sided\"\n  ..$ : tibble [1 × 5] (S3: tbl_df/tbl/data.frame)\n  .. ..$ estimate   : Named num 0.178\n  .. .. ..- attr(*, \"names\")= chr \"rho\"\n  .. ..$ statistic  : Named num 43082\n  .. .. ..- attr(*, \"names\")= chr \"S\"\n  .. ..$ p.value    : num 0.147\n  .. ..$ method     : chr \"Spearman's rank correlation rho\"\n  .. ..$ alternative: chr \"two.sided\"\n - attr(*, \"groups\")= tibble [6 × 3] (S3: tbl_df/tbl/data.frame)\n  ..$ city   : chr [1:6] \"Barcelona\" \"Barcelona\" \"Barcelona\" \"Barcelona\" ...\n  ..$ telecon: chr [1:6] \"AO\" \"EA\" \"EATL/WRUS\" \"MO\" ...\n  ..$ .rows  : list&lt;int&gt; [1:6] \n  .. ..$ : int 1\n  .. ..$ : int 2\n  .. ..$ : int 3\n  .. ..$ : int 4\n  .. ..$ : int 5\n  .. ..$ : int 6\n  .. ..@ ptype: int(0) \n  ..- attr(*, \".drop\")= logi TRUE\n\n\nHow can we undo the list of tables in each row of our table?\nFirst we eliminate the column with the data and then simply we can apply the unnest() function.\n\ncorr_pr &lt;- select(data_nest, -data) |&gt; unnest()\n\nWarning: `cols` is now required when using `unnest()`.\nℹ Please use `cols = c(model)`.\n\ncorr_pr\n\n# A tibble: 40 × 7\n# Groups:   city, telecon [40]\n   city     telecon   estimate statistic  p.value method             alternative\n   &lt;chr&gt;    &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;              &lt;chr&gt;      \n 1 Bilbao   NAO         0.153     44372. 0.213    Spearman's rank c… two.sided  \n 2 Bilbao   WeMO        0.404     31242  0.000706 Spearman's rank c… two.sided  \n 3 Bilbao   EA         -0.256     65825. 0.0348   Spearman's rank c… two.sided  \n 4 Bilbao   POL-EUAS    0.147     44670  0.230    Spearman's rank c… two.sided  \n 5 Bilbao   EATL/WRUS   0.0155    51584. 0.900    Spearman's rank c… two.sided  \n 6 Bilbao   MO         -0.0457    54788  0.711    Spearman's rank c… two.sided  \n 7 Bilbao   SCAND       0.357     33688  0.00296  Spearman's rank c… two.sided  \n 8 Bilbao   AO         -0.185     62070  0.131    Spearman's rank c… two.sided  \n 9 Santiago NAO        -0.181     61902. 0.139    Spearman's rank c… two.sided  \n10 Santiago WeMO        0.332     35014  0.00594  Spearman's rank c… two.sided  \n# ℹ 30 more rows\n\n\nThe result is a table in which we can see the correlations and their statistical significance for each city and teleconnection index."
  },
  {
    "objectID": "blog/tidy-correlation-tests-in-r/index.html#heatmap-of-the-results",
    "href": "blog/tidy-correlation-tests-in-r/index.html#heatmap-of-the-results",
    "title": "Tidy correlation tests in R",
    "section": "Heatmap of the results",
    "text": "Heatmap of the results\nFinally, we make a heatmap of the obtained result. But, previously we create a column that indicates whether the correlation is significant with p-value less than 0.05.\n\ncorr_pr &lt;- mutate(corr_pr, sig = ifelse(p.value &lt; 0.05, \"Sig.\", \"Non Sig.\"))\n\n\nggplot() +\n  geom_tile(\n    data = corr_pr,\n    aes(city, telecon, fill = estimate),\n    linewidth = 1,\n    colour = \"white\"\n  ) +\n  geom_tile(\n    data = filter(corr_pr, sig == \"Sig.\"),\n    aes(city, telecon),\n    linewidth = 1,\n    colour = \"black\",\n    fill = NA\n  ) +\n  geom_text(\n    data = corr_pr,\n    aes(city, telecon,\n      label = round(estimate, 2),\n      fontface = ifelse(sig == \"Sig.\", \"bold\", \"plain\")\n    )\n  ) +\n  scale_fill_gradient2(breaks = seq(-1, 1, 0.2)) +\n  labs(x = NULL, y = NULL, fill = NULL) +\n  coord_cartesian(expand = F) +\n  theme_void() +\n  theme(axis.text = element_text())"
  },
  {
    "objectID": "blog/visualize-anomalies-monthly-precipitation/index.html",
    "href": "blog/visualize-anomalies-monthly-precipitation/index.html",
    "title": "Visualize monthly precipitation anomalies",
    "section": "",
    "text": "Normally when we visualize monthly precipitation anomalies, we simply use a bar graph indicating negative and positive values with red and blue. However, it does not explain the general context of these anomalies. For example, what was the highest or lowest anomaly in each month? In principle, we could use a boxplot to visualize the distribution of the anomalies, but in this particular case they would not fit aesthetically, so we should look for an alternative. Here I present a very useful graphic form."
  },
  {
    "objectID": "blog/visualize-anomalies-monthly-precipitation/index.html#packages",
    "href": "blog/visualize-anomalies-monthly-precipitation/index.html#packages",
    "title": "Visualize monthly precipitation anomalies",
    "section": "Packages",
    "text": "Packages\nIn this post we will use the following packages:\n\n\n\n\n\n\n\n\n\nPackage\nDescription\n\n\n\n\ntidyverse\nCollection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.\n\n\nggthemes\nThemes for ggplot2\n\n\ncowplot\nEasy creation of multiple graphics with ggplot2\n\n\n\n\n\n\n# we install the packages if necessary\n\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"ggthemes\")) install.packages(\"broom\")\nif (!require(\"cowplot\")) install.packages(\"cowplot\")\n\n# packages\n\nlibrary(tidyverse) \nlibrary(ggthemes)\nlibrary(cowplot)"
  },
  {
    "objectID": "blog/visualize-anomalies-monthly-precipitation/index.html#preparing-the-data",
    "href": "blog/visualize-anomalies-monthly-precipitation/index.html#preparing-the-data",
    "title": "Visualize monthly precipitation anomalies",
    "section": "Preparing the data",
    "text": "Preparing the data\nFirst we import the daily precipitation of the selected weather station (download). We will use data from Santiago de Compostela (Spain) accessible through ECA&D.\n\nStep 1: import the data\nWe not only import the data in csv format, but we also make the first changes. We skip the first 21 rows that contain information about the weather station. In addition, we convert the date to the date class and replace missing values (-9999) with NA. The precipitation is given in 0.1 mm, therefore, we must divide the values by 10. Then we select the columns DATE and RR, and rename them.\n\ndata &lt;- read_csv(\"RR_STAID001394.txt\", skip = 21) |&gt;\n  mutate(DATE = ymd(DATE), \n         RR = ifelse(RR == -9999, NA, RR / 10)) |&gt;\n1  dplyr::select(date = DATE, pr = RR)\n\n\n1\n\nselect() causes many conflicts with other functions, hence the form of package::function\n\n\n\n\nRows: 27606 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (5): STAID, SOUID, DATE, RR, Q_RR\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndata\n\n# A tibble: 27,606 × 2\n   date          pr\n   &lt;date&gt;     &lt;dbl&gt;\n 1 1943-11-01   0.6\n 2 1943-11-02   0  \n 3 1943-11-03   0  \n 4 1943-11-04   0  \n 5 1943-11-05   0  \n 6 1943-11-06   0  \n 7 1943-11-07   0  \n 8 1943-11-08   0  \n 9 1943-11-09   0  \n10 1943-11-10   0  \n# ℹ 27,596 more rows\n\n\n\n\nStep 2: creating monthly values\nIn the second step we calculate the monthly amounts of precipitation. To do this, a) we limit the period to the years after 1950, b) we add the month with its labels and the year as variables.\n\ndata &lt;- mutate(data, mo = month(date, label = TRUE), \n                     yr = year(date)) |&gt;\n         filter(date &gt;= \"1950-01-01\") |&gt;\n          group_by(yr, mo) |&gt;\n            summarise(prs = sum(pr, na.rm = TRUE))\n\n`summarise()` has grouped output by 'yr'. You can override using the `.groups`\nargument.\n\ndata\n\n# A tibble: 833 × 3\n# Groups:   yr [70]\n      yr mo      prs\n   &lt;dbl&gt; &lt;ord&gt; &lt;dbl&gt;\n 1  1950 Jan    55.6\n 2  1950 Feb   349. \n 3  1950 Mar    85.8\n 4  1950 Apr    33.4\n 5  1950 May   272. \n 6  1950 Jun   111. \n 7  1950 Jul    35.4\n 8  1950 Aug    76.4\n 9  1950 Sep    85  \n10  1950 Oct    53  \n# ℹ 823 more rows\n\n\n\n\nStep 3: estimating anomalies\nNow we must estimate the normals of each month and join this table to our main data in order to calculate the monthly anomaly. We express the anomalies in percentage and subtract 100 to set the average to 0. In addition, we create a variable which indicates if the anomaly is negative or positive, and another with the date.\n\npr_ref &lt;- filter(data, yr &gt; 1981, yr &lt;= 2010) |&gt;\n            group_by(mo) |&gt;\n              summarise(pr_ref = mean(prs))\n\ndata &lt;- left_join(data, pr_ref, by = \"mo\")\n\ndata &lt;- mutate(data,\n  anom = (prs * 100 / pr_ref) - 100,\n  date = str_c(yr, mo, \"01\") |&gt; ymd(),\n  sign = ifelse(anom &gt; 0, \"pos\", \"neg\") |&gt; factor(c(\"pos\", \"neg\"))\n)\n\nWe can do a first test graph of anomalies (the classic one), for that we filter the year 2018. In this case we use a bar graph, remember that by default the function geom_bar() applies the counting of the variable. However, in this case we know y, hence we indicate with the argument stat = \"identity\" that it should use the given value in aes().\n\nfilter(data, yr == 2018) |&gt;\n  ggplot(aes(date, anom, fill = sign)) +\n    geom_col(show.legend = FALSE) +\n      scale_x_date(date_breaks = \"month\", date_labels = \"%b\") +\n      scale_y_continuous(breaks = seq(-100, 100, 20)) +\n      scale_fill_manual(values = c(\"#99000d\", \"#034e7b\")) +\n    labs(y = \"Precipitation anomaly (%)\", x = \"\") +\n   theme_hc()\n\n\n\n\n\n\n\n\n\n\nStep 4: calculating the statistical metrics\nIn this last step we estimate the maximum, minimum value, the 25%/75% quantiles and the interquartile range per month of the entire time series.\n\ndata_norm &lt;- group_by(data, mo) |&gt;\n                summarise(\n                  mx = max(anom),\n                  min = min(anom),\n                  q25 = quantile(anom, .25),\n                  q75 = quantile(anom, .75),\n                  iqr = q75 - q25\n                )\ndata_norm\n\n# A tibble: 12 × 6\n   mo       mx    min   q25   q75   iqr\n   &lt;ord&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Jan    193.  -89.6 -43.6 56.3   99.9\n 2 Feb    320.  -96.5 -51.2 77.7  129. \n 3 Mar    381. -100   -40.6 88.2  129. \n 4 Apr    198.  -93.6 -51.2 17.1   68.3\n 5 May    141.  -90.1 -45.2 17.0   62.2\n 6 Jun    419.  -99.3 -58.2 50.0  108. \n 7 Jul    311.  -98.2 -77.3 27.1  104. \n 8 Aug    264. -100   -68.2 39.8  108. \n 9 Sep    241.  -99.2 -64.9 48.6  113. \n10 Oct    220.  -99.0 -54.5  4.69  59.2\n11 Nov    137.  -98.8 -44.0 39.7   83.7\n12 Dec    245.  -91.8 -49.8 36.0   85.8"
  },
  {
    "objectID": "blog/visualize-anomalies-monthly-precipitation/index.html#creating-the-graph",
    "href": "blog/visualize-anomalies-monthly-precipitation/index.html#creating-the-graph",
    "title": "Visualize monthly precipitation anomalies",
    "section": "Creating the graph",
    "text": "Creating the graph\nTo create the anomaly graph with legend it is necessary to separate the main graph from the legends.\n\nPart 1\nIn this first part we are adding layer by layer the different elements: 1) the range of anomalies maximum-minimum 2) the interquartile range and 3) the anomalies of the year 2018.\n\n# range of anomalies maximum-minimum\ng1.1 &lt;- ggplot(data_norm) +\n  geom_crossbar(aes(x = mo, y = 0, ymin = min, ymax = mx),\n    fatten = 0, fill = \"grey90\", colour = \"NA\"\n  )\n\ng1.1\n\n\n\n\n\n\n\n\n\n# adding interquartile range\ng1.2 &lt;- g1.1 + geom_crossbar(aes(x = mo, y = 0, ymin = q25, ymax = q75),\n  fatten = 0, fill = \"grey70\"\n)\n\ng1.2\n\n\n\n\n\n\n\n\n\n# adding anomalies of the year 2018\n\ng1.3 &lt;- g1.2 + geom_crossbar(\n  data = filter(data, yr == 2018),\n  aes(x = mo, y = 0, ymin = 0, ymax = anom, fill = sign),\n  fatten = 0, width = 0.7, alpha = .7, colour = \"NA\",\n  show.legend = FALSE\n)\ng1.3\n\n\n\n\n\n\n\n\nFinally we change some last style settings.\n\ng1 &lt;- g1.3 + geom_hline(yintercept = 0) +\n  scale_fill_manual(values = c(\"#99000d\", \"#034e7b\")) +\n  scale_y_continuous(\"Precipitation anomaly (%)\",\n    breaks = seq(-100, 500, 50),\n    expand = c(0, 5)\n  ) +\n  labs(\n    x = \"\",\n    title = \"Precipitation anomaly in Santiago de Compostela 2018\",\n    caption = \"Data: eca.knmi.nl\"\n  ) +\n  theme_hc()\ng1\n\n\n\n\n\n\n\n\n\n\nPart 2\nWe still need a legend. First we create it for the normals.\n\n# legend data\nlegend &lt;- filter(data_norm, mo == \"Jan\")\n\nlegend_lab &lt;- gather(legend, stat, y, mx:q75) |&gt;\n  mutate(stat = factor(stat, stat, c(\n    \"maximum\",\n    \"minimum\",\n    \"Quantile 25%\",\n    \"Quantile 75%\"\n  )) |&gt;\n    as.character())\n\n# legend graph\ng2 &lt;- legend |&gt; ggplot() +\n  geom_crossbar(aes(x = mo, y = 0, ymin = min, ymax = mx),\n    fatten = 0, fill = \"grey90\", colour = \"NA\", width = 0.2\n  ) +\n  geom_crossbar(aes(x = mo, y = 0, ymin = q25, ymax = q75),\n    fatten = 0, fill = \"grey70\", width = 0.2\n  ) +\n  geom_text(\n    data = legend_lab,\n    aes(x = mo, y = y + c(12, -8, -10, 12), label = stat),\n    fontface = \"bold\", size = 2\n  ) +\n  annotate(\"text\",\n    x = 1.18, y = 40,\n    label = \"Period 1950-2018\", angle = 90, size = 3\n  ) +\n  theme_void() +\n  theme(plot.margin = unit(c(0, 0, 0, 0), \"cm\"))\n\ng2\n\n\n\n\n\n\n\n\nSecond, we create another legend for the current anomalies.\n\n# legend data\nlegend2 &lt;- filter(data, yr == 1950, mo %in% c(\"Jan\", \"Feb\")) |&gt;\n               ungroup() |&gt;\n                dplyr::select(mo, anom, sign)\n\nlegend2[2, 1] &lt;- \"Jan\"\n\nlegend_lab2 &lt;- data.frame(\n  mo = rep(\"Jan\", 3),\n  anom = c(110, 3, -70),\n  label = c(\"Positive anomaly\", \"Average\", \"Negative anomaly\")\n)\n\n# legend graph\ng3 &lt;- ggplot() +\n  geom_bar(\n    data = legend2,\n    aes(x = mo, y = anom, fill = sign),\n    alpha = .6, colour = \"NA\", stat = \"identity\", show.legend = FALSE, width = 0.2\n  ) +\n  geom_segment(aes(x = .85, y = 0, xend = 1.15, yend = 0), linetype = \"dashed\") +\n  geom_text(\n    data = legend_lab2,\n    aes(x = mo, y = anom + c(10, 5, -13), label = label),\n    fontface = \"bold\", size = 2\n  ) +\n  annotate(\"text\",\n    x = 1.25, y = 20,\n    label = \"Reference 1971-2010\", angle = 90, size = 3\n  ) +\n  scale_fill_manual(values = c(\"#99000d\", \"#034e7b\")) +\n  theme_void() +\n  theme(plot.margin = unit(c(0, 0, 0, 0), \"cm\"))\n\ng3\n\n\n\n\n\n\n\n\n\n\nPart 3\nFinally, we only have to join the graph and the legends with the help of the cowplot package. The main function of cowplot is plot_grid() which is used for combining different graphs. However, in this case it is necessary to use more flexible functions to create less common formats. The ggdraw() function configures the basic layer of the graph, and the functions that are intended to operate on this layer start with draw_*.\n\np &lt;- ggdraw() +\n  draw_plot(g1, x = 0, y = .3, width = 1, height = 0.6) +\n  draw_plot(g2, x = 0, y = .15, width = .2, height = .15) +\n  draw_plot(g3, x = 0.08, y = .15, width = .2, height = .15)\n\np\n\n\n\n\n\n\n\n\n\nsave_plot(\"pr_anomaly2016_scq.png\", p, dpi = 300, base_width = 12.43, base_height = 8.42)"
  },
  {
    "objectID": "blog/visualize-anomalies-monthly-precipitation/index.html#multiple-facets",
    "href": "blog/visualize-anomalies-monthly-precipitation/index.html#multiple-facets",
    "title": "Visualize monthly precipitation anomalies",
    "section": "Multiple facets",
    "text": "Multiple facets\nIn this section we will make the same graph as in the previous one, but for several years.\n\nPart 1\nFirst we need to filter again by set of years, in this case from 2016 to 2018, using the operator %in%, we also add the function facet_grid() to ggplot, which allows us to plot the graph according to a variable. The formula used for the facet function is similar to the use in models: variable_by_row ~ variable_by_column. When we do not have a variable in the column, we should use the ..\n\n# range of anomalies maximum-minimum\ng1.1 &lt;- ggplot(data_norm) +\n  geom_crossbar(aes(x = mo, y = 0, ymin = min, ymax = mx),\n    fatten = 0, fill = \"grey90\", colour = \"NA\"\n  )\n\n\n# adding the interquartile range\ng1.2 &lt;- g1.1 + geom_crossbar(aes(x = mo, y = 0, ymin = q25, ymax = q75),\n  fatten = 0, fill = \"grey70\"\n)\n\n\n# adding the anomalies of the year 2016-2018\n\ng1.3 &lt;- g1.2 + geom_crossbar(\n  data = filter(data, yr %in% 2016:2018),\n  aes(x = mo, y = 0, ymin = 0, ymax = anom, fill = sign),\n  fatten = 0, width = 0.7, alpha = .7, colour = \"NA\",\n  show.legend = FALSE\n) +\n  facet_grid(yr ~ .)\ng1.3\n\n\n\n\n\n\n\n\nFinally we change some last style settings.\n\ng1 &lt;- g1.3 + geom_hline(yintercept = 0) +\n  scale_fill_manual(values = c(\"#99000d\", \"#034e7b\")) +\n  scale_y_continuous(\"Anomalía de precipitación (%)\",\n    breaks = seq(-100, 500, 100),\n    expand = c(0, 5)\n  ) +\n  labs(\n    x = \"\",\n    title = \"Anomalía de precipitación en Santiago de Compostela\",\n    caption = \"Datos: eca.knmi.nl\"\n  ) +\n  theme_hc()\ng1\n\n\n\n\n\n\n\n\nWe use the same legend created for the previous graph.\n\n\nPart 2\nFinally, we join the graph and the legends with the help of the cowplot package. The only thing we must adjust here are the arguments in the draw_plot() function to correctly place the different parts.\n\np &lt;- ggdraw() +\n  draw_plot(g1, x = 0, y = .18, width = 1, height = 0.8) +\n  draw_plot(g2, x = 0, y = .08, width = .2, height = .15) +\n  draw_plot(g3, x = 0.08, y = .08, width = .2, height = .15)\n\np"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Send me a note ",
    "section": "",
    "text": "You can use this form to contact me about collaborations, questions or simply to say hello.\n   \n    \n\n\n\n\n\n\n Your email:    Your message:\n\n  Send\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "project/index.html",
    "href": "project/index.html",
    "title": "Data Vizualization",
    "section": "",
    "text": "CLIMATE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGEOGRAPHY\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nANIMATIONS\nSmoothed daily maximum temperature throughout the year in Europe. Data: ERA5-Land.\n\nHow cloudiness changes throughout the year in Europe. Data: METEOSAT.\n\nThe average temperature of 24 hours in August 2020 for Europe. Data: ERA5-Land.\n\nThe average temperature of 24 hours in January 2020. Data: ERA5-Land.\n\nSmoothed daily rainfall throughout the year in Australia. Data: SILO.\n\nSmoothed daily maximum temperature throughout the year in Australia. Data: SILO.\n\nSmoothed daily sea surface temperature throughout the year for the Northeast Atlantic, the Mediterranean, North and Black Sea. Data: NOAA/NODC.\n\nProbability of a summer day (maximum temperature greater than 25ºC/77ºF) through the year in Europe. Data: E-OBS.\n\nProbability of a frost day (minimum temperature less than 0ºC) through the year in Europe. Data: ERA5-Land.\n\nEvolution of 3G and 4G mobile telephony in the Iberian Peninsula from 2012 to 2022.Data: opencellid.org\n\n\n\n Back to top"
  }
]