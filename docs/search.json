[
  {
    "objectID": "publication/index.html#journal-articles",
    "href": "publication/index.html#journal-articles",
    "title": "Publications",
    "section": "Journal Articles",
    "text": "Journal Articles\n2026\n\n\nWagatsuma K, Feurer D, Yu W, Xu R, Riffe T, Kniffka MS, Acosta E, Armstrong B, Mistry M, Lowe R, Royé D, Hashizume M, Tobias A, Vicedo‑Cabrera AM, Madaniyazi L, Ng CFS, Íñiguez C, Ragettli MS, Lavigne E, Matus Correa P, Valdés Ortega N, Kyselý J, Urban A, Orru H, Indermitte E, Maasikmets M, Breitner‑Busch S, Schneider A, Honda Y, Alahmad B, Zanobetti A, Schwartz J, Carrasco G, Holobâca IH, Kim H, Lee W, Bell ML, Scovronick N, Acquaotta F, de Sousa Zanotti Stagliorio Coelho M, Hurtado Diaz M, Félix Arellano EE, Michelozzi P, Stafoggia M, de’Donato F, Rao S, Seposo X, Tong S, Klompmaker J, Guo Y, Masselot P, Gasparrini A, Sera F (2026). The joint impact of temperature, humidity, and air pollution on COVID-19 incidence: a multi-country time-series study in 439 cities. Environment International.  10.1016/j.envint.2026.110090 \n\n\nSeveral studies have explored the short-term effects of environmental stressors on coronavirus disease 2019 (COVID-19) transmission and severity. However, evidence on the interactive effects of meteorological conditions and air pollution remains limited and geographically variable. We therefore aimed to quantify the independent and interactive effects of short-term exposure to humidex, a composite index of temperature and relative humidity, and fine particulate matter 2.5 μm (PM2.5) on daily COVID-19 incidence across multiple cities and in multiple countries. Daily time-series data on confirmed COVID-19 cases, meteorological factors, and PM2.5 concentrations were collected from 439 cities in 22 countries during January 2020–August 2022 as part of the Multi-Country Multi-City Collaborative Research Network. A two-stage design was applied: first, city-specific quasi-Poisson models with distributed lag non-linear models estimated exposure–response associations; second, multilevel random-effects meta-analyses pooled city-specific estimates. Effect modification by PM2.5 was assessed using a product term between non-linear humidex function and linear PM2.5 function. Approximately 95.1 million confirmed COVID-19 cases were analyzed. Lower humidex values (0.1C versus 15.1C) were associated with increased daily cases (relative risk [RR]: 1.1192, 95% confidence interval [CI]: 1.0214–1.2262). A 10 μg/m3 increase in PM2.5 over the current and preceding 2 days was associated with a modest increase in daily cases (RR: 1.0079, 95% CI: 1.0001–1.0161). No statistically significant interaction between humidex and PM2.5 was observed. Short-term exposure to cold–dry conditions and elevated PM2.5 independently increased COVID-19 incidence, highlighting the need to consider both thermal environment and air quality when designing climate-resilient public health responses. These findings enhance understanding of how climate-related environmental stressors influence COVID-19 transmission.\n\n\nhumidexpm2.5covid‑19incidencemulti‑country analysis\n\n\n\n\n\nTorres‑Vázquez MÁ, Dalle Vaglie M, Kettridge N, Martellozzo F, Miguez‑Macho G, Provenzale A, Royé D, Randelli F, Turco M (2026). Assessing decadal changes in human exposure near wildfires in a Mediterranean region. Scientific Reports, vol. 208, art. no. 110090.  10.1038/s41598-026-35426-4 \n\n\nThis study examines the evolution of human exposure to wildfires in Catalonia, Spain, over the period 1992–2021, by integrating geospatial data on fire perimeters, population, satellite-derived nighttime light (NTL) imagery, and settlement records. Although the burned area shows a slight statistically non-significant decrease (-0.43 km2/year), human exposure per unit of burned area has risen by 42% (based on GlobPOP data within burned areas) to 138% (based on GlobPOP data within a 5 km static buffer around fire perimeters), depending on the buffer distance and dataset used. This alarming trend is mainly driven by rapid urban expansion and population redistribution, particularly in coastal regions, which highlights a growing intersection between human settlements and fire-prone areas. Our findings emphasize the critical role of urbanization in amplifying wildfire risks, underscoring the urgent need to integrate demographic dynamics into fire risk governance strategies. By employing innovative proxies such as nighttime light data alongside high-resolution population and building density datasets, this study provides a comprehensive framework to assess wildfire exposure in rapidly urbanizing Mediterranean environments.\n\n\nurbanizationhuman exposurewildfire riskcatalonia\n\n\n\n\n\nChua P L C, Madaniyazi L, Tobias A, Ng C F S, Phung V L H, Pan R, Hossain N, Abrutzky R, Carrasco Escobar G, Phung D T, Faruque A S G, Brown P, de Sousa Zanotti Stagliorio Coêlho M, Nascimento Saldiva P H, Lavigne E, Salazar M A, Royé D, Jung C‑R, Tantrakarnapa K, Kliengchuay W, Scovronick N, Lynch V, Park J, Kim Y, Huang C, Semenza J C, Hales S, Hashizume M (2026). Data Resource Profile: Climate and Enteric Diseases Research Project (ClimED). International Journal of Epidemiology, vol. 55(1).  10.1093/ije/dyaf215 \n\n\nThe Climate and Enteric Diseases Research Project (ClimED) is a multinational data resource developed to enable consistent assessment of the relationships between climate-related exposures and enteric diseases. ClimED compiles weekly time-series data on mortality and morbidity from intestinal infectious diseases, classified under ICD‑10 codes A00–A09, across 49 countries and 1,290 subnational units from 1993 to 2024. The dataset includes more than 664,000 deaths and over 407 million morbidity cases, encompassing hospital admissions, hospital visits, and surveillance records. Climate exposures comprise 2‑m air temperature, total precipitation, and tropical cyclone–related wind and rainfall, uniformly derived from ERA5‑Land and ISIMIP3a reanalysis datasets using standardized and reproducible processing procedures. By harmonizing exposure and outcome definitions across diverse settings, ClimED supports the generation of comparable region‑specific and pooled risk curves. This resource provides a robust foundation for quantifying historical and projected impacts of climate change on the global burden of enteric diseases and for informing adaptation and mitigation strategies in public health.\n\n\ndiarrhoeagastroenteritisclimateweatherdataset\n\n\n\n\n\nRoyé D, Janoš T, Paniello-Castillo B, Chen Z‑Y, Thompson A T, Ruiz-Cabrejos J, Quijal-Zamorano M, Tobias A, Shartova N, Antó J M, Ballester J (2026). Rethinking early warning systems for the health effects of extreme heat. Nature Health, vol. 1, pp. 6-8.  10.1038/s44360-025-00004-x \n\n\nExtreme heat is one of the most severe and rapidly intensifying threats to global health, yet current early warning systems remain insufficient to prevent its growing impacts. Despite two decades of adaptation efforts, recent European summers have recorded heat‑related mortality comparable to or exceeding that of the 2003 heatwave, underscoring persistent vulnerabilities. A major barrier to effective prevention is the absence of open, high‑quality health data and the lack of standardized methodologies for estimating and forecasting heat‑related health outcomes across countries. Existing systems largely focus on predicting hazardous meteorological events rather than their direct consequences for human health. This commentary argues for the urgent integration of advanced epidemiological modelling with weather forecasting to develop impact‑based early warning systems capable of providing reliable, real‑time predictions with lead times of one to two weeks. Such systems would enable targeted interventions, particularly for vulnerable groups, and support more efficient allocation of public health resources. We call on public health, meteorological, and statistical agencies to harmonize methods, improve data availability, and co‑design climate services for health, with priority for low‑resource settings where vulnerability is highest. Anticipating health impacts rather than merely tracking weather extremes is essential to prevent avoidable mortality in an era of accelerating climate change.\n\n\nextreme heatheat‑related mortalityimpact‑based early warning systemsepidemiological forecastingclimate services for health\n\n\n\n\n2025\n\n\nSánchez-Hernández G, Turco M, Repeto-Deudero I, Royé D, Baudena M, Montávez JP, Pietroiusti R, Provenzale A, Santin C, Torres-Vázquez MÁ, Pausas JG (2025). Record-Breaking 2025 European Wildfires Concentrated in Northwest Iberia. Global Change Biology, vol. 31(12), art. no. e70649.  10.1111/gcb.70649 \n\n\nIn August 2025, Europe experienced its largest wildfire season on record, with burned area exceeding 1 million hectares. Over half of this total (~541,000 ha) occurred within just 2% of EU territory in northwest Iberia during a 16-day heatwave. August 2025 registered the most extreme Fire Weather Index since 1985, strongly linked to climate change, which increased the likelihood of such conditions by ~40 times. Fires disproportionately affected shrublands, driven by fuel continuity and land-use changes, overwhelming suppression capacity. Despite rising fire-weather trends, burned area remains highly variable, highlighting the need for proactive adaptation, fuel management, and mitigation to prevent future crises.\n\n\nextreme wildfiresfire weather indexnorthwest iberian peninsulaheatwaveshrubland flammabilityadaptation strategies\n\n\n\n\n\nPan R, Chua PLC, Madaniyazi L, Ng CFS, Tobias A, Guo Q, Phung VLH, Hossain N, Lynch V, Jung CR, Salazar MA, Royé D, Phung D, Coêlho M, Nascimento Saldiva PH, Hales S, Huang C, Semenza JC, Hashizume M (2025). The association between total precipitation and diarrhea morbidity: A multicountry study across diverse climate zones. Environmental Epidemiology, vol. 9(6), art. no. e430.  10.1097/EE9.0000000000000430 \n\n\nBackground: Although substantial evidence has shown that precipitation is associated with diarrhea in low- and middle-income countries, few multicountry studies have focused on middle- and high-income countries to comprehensively explore the exposure–response curves between precipitation and diarrhea across different countries/regions and climate zones (tropical, arid, temperate, and cold). Methods: We collected weekly diarrhea morbidity data (primarily from hospital visits, hospital admissions, and surveillance systems) and corresponding exposure data (total precipitation and mean temperature) from 904 locations in 39 middle- and high-income countries/regions. To assess location-specific precipitation–diarrhea associations, we fitted time-stratified case-crossover analyses in distributed lag nonlinear models with 8 weeks of lag. Then, we pooled the estimates at the country/region level and by climate zone with multivariate meta-regression analysis. Results: A total of 160,266,691 diarrhea cases were included in the study. The exposure–response association curves between total precipitation and diarrhea varied substantially at the country/region level. For example, U-shaped, J-shaped, or V-shaped curves were observed in Taiwan, Hungary, Germany, Denmark, Mexico, Brazil, and Ecuador. We identified a generally increased trend of diarrhea morbidity risk in the Philippines, Czech Republic, Norway, and USA when total precipitation exceeded the minimum risk level, defined at the first percentile of total precipitation. In China, Japan, Bangladesh, and Vietnam, diarrhea morbidity risk tended to decrease with increasing total precipitation. The country-specific relative risks ranged from 1.02 (95% confidence interval [CI]: 0.88, 1.19) in Finland to 2.67 (95% CI: 2.28, 3.13) in Japan for low levels of total precipitation and from 1.02 (95% CI: 0.93, 1.11) in Ecuador to 2.03 (95% CI: 1.49, 2.76) in Austria for high levels of total precipitation. Overall, associations between precipitation and diarrhea morbidity were stronger in arid regions and weaker in cold regions. Conclusions: Associations between precipitation and diarrhea morbidity differed by country/region and climate zone. This study provides valuable evidence showing that location-specific prevention measures should be considered to mitigate the diarrhea burden associated with precipitation.\n\n\nprecipitationdiarrheamiddle- and high-income countriesclimate zones\n\n\n\n\n\nMonjo R, Essa YH, Prado-López C, Kaur M, Redolat D, Paradinas C, Royé D, Ahrens B, San José R (2025). High time-and spatial-resolution climate scenarios of the DISTENDER project according to statistical and dynamical downscaling. Climate Services, vol. 40, art. no. 100623.  10.1016/j.cliser.2025.100623 \n\n\nThis paper discusses statistical and dynamical methods used to produce local (grid-spacing &lt; 4 km) and European (10 km) climate scenarios that were used as input for multi-sectoral impact models in the DevelopIng STratEgies by integrating mitigatioN, aDaptation and participation to climate changE Risks (DISTENDER) project, and shares the main results with a special focus on temperature and precipitation. The statistical downscaling consisted of three stages: (1) a parametric quantile mapping at a daily scale; (2) an analogous-transference function of hourly curves for each day, and (3) a classical geostatistical downscaling. This three-stage technique was applied to three representative Earth System Models according to three different climate-change level (being EC-EARTH3-Veg the medium case) under four shared socioeconomic pathways (SSP1-2.6, SSP2-4.5, SSP3-7.0, SSP5-8.5). In addition, dynamical downscaling was also considered. Particularly, the ICOsahedral Nonhydrostatic model downscaled the EC-EARTH3-Veg model to computationally costly km-scale resolution under all four pathways. Both downscaling approaches show consistent behaviour for the downscaled model under the different pathways. Results indicate historical biases in precipitation about +-10 % in general, while temperature biases ranged from -2°C to +1°C across different regions and seasons. Under SSP5-8.5, summer precipitation in southern Europe is projected to decrease by up to 20 %, while northern Europe experiences increases of + 10 % to + 15 %. Temperature increases under the same scenario reach + 5°C in summer across southern Europe, with smaller increases of + 2°C to + 3°C in northern regions. These findings on management for uncertainty levels demonstrate the utility of combined downscaling approaches for local climate risk assessment and adaptation strategies.\n\n\nstatistical downscalingdynamical downscalingdlimate modelingclimate hazards\n\n\n\n\n\nTobías A, Íñiguez C, Royé D (2025). Mortalidad atribuible al calor en España durante el verano de 2025. Gaceta Sanitaria, vol. 39, art. no. 102530.  10.1016/j.gaceta.2025.102530 \n\n\nEl verano de 2025 fue el más cálido registrado en España, con junio histórico y una ola de calor en agosto (+4,6 °C). Se estimaron alrededor de 15.700 muertes atribuibles al calor, principalmente por exposiciones prolongadas a temperaturas moderadas. Urge reforzar estrategias de adaptación ante el aumento proyectado de extremos térmicos.\n\n\nola de calormortalidad atribuibletemperatura mínima de mortalidadcambio climáticoadaptación\n\n\n\n\n\nZhou L, Xiong Y, Sera F, Vicedo-Cabrera AM, Abrutzky R, Guo Y, Tong S, Coelho M, Nascimento Saldiva PH, Lavigne E, Matus Correa P, Valdés Ortega N, Osorio S, Royé D, Kyselý J, Orru H, Maasikmets M, Jaakkola JJK, Ryti N, Pascal M, Huber V, Breitner-Busch S, Schneider A, Katsouyanni K, Samoli E, Entezari A, Mayvaneh F, Goodman P, Zeka A, Raz R, Scortichini M, Stafoggia M, Honda Y, Hashizume M, Ng CFS, Alahmad B, Hurtado Diaz M, Félix Arellano EE, Overcenco A, Klompmaker J, Rao S, Carrasco G, Seposo X, Carlos Chua PL, das Neves Pereira da Silva S, Madureira J, Holobaca IH, Scovronick N, Garland RM, Kim H, Lee W, Tobias A, Íñiguez C, Forsberg B, Ragettli MS, Guo YL, Pan SC, Li S, Masselot P, Colistro V, Bell M, Zanobetti A, Schwartz J, Dang TN, Dung DV, Gasparrini A, Huang Y, Kan H (2025). Associations of ambient exposure to benzene, toluene, ethylbenzene, and xylene with daily mortality: a multicountry time-series study in 757 global locations. The Lancet Planetary Health, vol. 9(9), art. no. 101306.  10.1016/j.lanplh.2025.101306 \n\n\nBackground. The presence of benzene, toluene, ethylbenzene, and xylene isomers (BTEX) in the environment is of increasing concern due to their toxicity and ubiquity. Although the adverse health effects of BTEX exposure have been documented, robust epidemiological evidence from large-scale, multicountry studies using advanced exposure assessment methodologies remains scarce. We aimed to assess the association of short-term ambient exposure to individual BTEX components and their mixture with daily total, cardiovascular, and respiratory mortality on a global scale. Methods. Daily data on mortality, meteorological factors, and air pollution were collected from 757 locations across 46 countries or regions. Data on individual chemicals (ie, benzene, toluene, xylenes [summation of ethylbenzene, m-xylene, p-xylene, and o-xylene]) and the aggregate mixture (ie, BTEX) were estimated using a chemistry–climate model. We examined the short-term associations of each individual chemical as well as the BTEX mixture with daily total, cardiovascular, and respiratory mortality in a multicountry framework. Using a two-stage time-series design, we first applied generalised additive models with a quasi-Poisson distribution to obtain location-specific associations, which were subsequently pooled using random-effects meta-analysis. Two-pollutant models were used to assess the independent effects of BTEX after adjusting for co-pollutants (PM2.5, PM10, nitrogen dioxide, sulphur dioxide, ozone, and carbon monoxide). Additionally, we assessed the overall exposure–response curves with spline terms. Findings. An IQR increment of BTEX concentration on lag 0–2 days (3-day moving average of the present day and the previous 2 days) was associated with increases of 0.57% (95% CI 0.49–0.65), 0.42% (0.30–0.54), and 0.68% (0.50–0.86) in total, cardiovascular, and respiratory mortality, respectively. The corresponding effect estimates for an IQR increment in individual chemicals (benzene, toluene, and xylenes) were 0.38–0.61%, 0.44–0.70%, and 0.41–0.65%, respectively. The associations remained significant after adjusting for co-pollutants, with a general decline in magnitude, except for a slight increase after adjustment for ozone. The shape of the exposure–response curves for all pollutants and causes of death was almost linear, with steeper slopes at low concentrations and no discernible thresholds. Interpretation. This global study provides novel evidence linking short-term exposure to ambient BTEX, both individually and as a mixture, with increased daily total, cardiovascular, and respiratory mortality. Our findings underscore the need for comprehensive air pollution mitigation policies, including stringent controls on BTEX emissions, to protect public health.\n\n\nbtex exposureair pollutioncardiovascular and respiratory mortalityglobal epidemiological study\n\n\n\n\n\nTobías A, Íñiguez C, Royé D, Hashizume M, Madaniyazi L (2025). Comparing mortality burdens attributable to ambient temperature and seasonal variation across major causes of death in Spain. Environmental Epidemiology, vol. 9(5), art. no. e416.  10.1097/EE9.0000000000000416 \n\n\nBackground: Seasonal variation in mortality results from a combination of environmental, biological, and social factors, with ambient temperature recognized as a key contributor. However, comprehensive assessments disentangling temperature effects from other seasonal influences across a broad range of mortality causes remain limited. This study aimed to quantify and compare the mortality burden attributable to ambient temperature and broader seasonal variation across major causes of death in Spain. Methods: We analyzed daily mortality counts for major International Classification of Diseases, 10th Revision (ICD-10) chapters and daily mean ambient temperature in Spain from 1999 to 2018. For each cause of death, we used quasi-Poisson regression models with distributed lag nonlinear models to estimate the temperature-mortality association, and cyclic splines to assess residual seasonality. We then calculated the number of deaths attributable to nonoptimal temperatures and seasonal variation over the study period. Results: Annual deaths attributable to ambient temperature were estimated at 5,563 (95% empirical confidence interval: 4,720, 6,382), while those attributable to seasonal variation reached 12,400 (95% empirical confidence interval: 10,245, 14,491). Cold temperatures accounted for a higher fraction of mortality (2.8%) than heat (1.4%), with the greatest temperature-related burden observed for circulatory and respiratory diseases. Seasonal variation had a greater overall impact (9.5%) and was also most strongly associated with respiratory and circulatory causes. Across most mortality chapters, the number of deaths attributable to seasonal variation was nearly twice as high as that from ambient temperature. Conclusion: Seasonal factors beyond ambient temperature may play a substantial and under-recognized role in shaping mortality patterns across diverse causes of death. Identifying and evaluating these factors is critical for developing targeted public health strategies to mitigate seasonal mortality and its underlying determinants.\n\n\nseasonal mortalityambient temperaturecold and heat effectspublic health strategies\n\n\n\n\n\nLimoncella G, Feurer D, Royé D, de Hoogh K, de la Cruz A, Gasparrini A, Schneider R, Pirotti F, Catelan D, Stafoggia M, de’Donato F, Biscardi G, Marzi C, Baccini M, Sera F (2025). A Machine Learning Model Integrating Remote Sensing, Ground Station, and Geospatial Data to Predict Fine-Resolution Daily Air Temperature for Tuscany, Italy. remote sensing, vol. 17(17), art. no. 3052.  10.3390/rs17173052 \n\n\nHeat-related morbidity and mortality are increasing due to climate change, emphasizing the need to identify vulnerable areas and people exposed to extreme temperatures. To improve heat stress impact assessment, we developed a replicable machine learning model that integrates remote sensing, ground station, and geospatial data to estimate daily air temperature at a spatial resolution of 100 m x 100 m across the region of Tuscany, Italy. Using a two-stage approach, we first imputed missing land surface temperature data from MODIS using gradient-boosted trees and spatio-temporal predictors. Then, we modeled daily maximum and minimum air temperatures by incorporating monitoring station observations, satellite-derived data (MODIS, Landsat 8), topography, land cover, meteorological variables (ERA5-land), and vegetation indices (NDVI). The model achieved high predictive accuracy, with R2 values of 0.95 for Tmax and 0.92 for Tmin, and root mean square errors (RMSE) of 1.95C and 1.96C, respectively. It effectively captured both temporal (R2: 0.95; 0.94) and spatial (R2: 0.92; 0.72) temperature variations, allowing for the creation of high-resolution maps. These results highlight the potential of integrating Earth Observation and machine learning to generate high-resolution temperature maps, offering valuable insights for urban planning, climate adaptation, and epidemiological studies on heat-related health effects.\n\n\nair temperaturemodislandsat 8machine learningremote sensingurban heat island\n\n\n\n\n\nHundessa S, Huang W, Xu R, Yang Z, Zhao Q, Gasparrini A, Armstrong B, Bell ML, Huber V, Urban A, Coelho M, Sera F, Tong S, Royé D, Kyselý J, de’Donato F, Mistry M, Tobias A, Íñiguez C, Ragettli MS, Hales S, Achilleos S, Klompmaker J, Li S, Guo Y (2025). Global Excess Deaths Associated with Heatwaves in 2023 and the Contribution of Human-Induced Climate Change. The Innovation, vol. 6(10), art. no. 101110.  10.1016/j.xinn.2025.101110 \n\n\nAn unprecedented heatwave swept the globe in 2023, marking it one of the hottest years on record and raising concerns about its health impacts. However, a comprehensive assessment of the heatwave-related mortality and its attribution to human-induced climate change remains lacking. We aim to address this gap by analyzing high-resolution climate and mortality data from 2,013 locations across 67 countries/territories using a three-stage modeling approach. First, we estimated historical heatwave-mortality associations using a quasi-Poisson regression model with distributed lag structures, considering lag effects, seasonality, and within-week variations. Second, we pooled the estimates in meta-regression, accounting for spatial heterogeneity and potential changes in heatwave-mortality associations over time. Third, we predicted grid-specific (0.5 x 0.5) association in 2023 and calculated the heatwave-related excess deaths, death ratio, and death rate per million people. Attribution analysis was conducted by comparing heatwave-related mortality under factual and counterfactual climate scenarios. We estimated 178,486 excess deaths (95% empirical confidence interval [eCI], 159,892;204,147) related to the 2023 heatwave, accounting for 0.73% of global deaths, corresponding to 23 deaths per million people. The highest mortality rates occurred in Southern (120, 95% eCI, 116;126), Eastern (107, 95% eCI, 100;114), and Western Europe (66, 95% eCI, 62;70), where the excess death ratio was also higher. Notably, 54.29% (95% eCI, 45.71%;61.36%) of the global heatwave-related deaths were attributable to human-induced climate change. These results underscore the urgent need for adaptive public health interventions and climate mitigation strategies to reduce future mortality burdens in the context of increasing global warming\n\n\nall-cause mortalityheatwavesglobal burden of diseaseexcess deathdeath ratehuman-induced climate change\n\n\n\n\n\nRoyé D, Sera F, Tobías A, Hashizume M, Honda Y, Kim H, Vicedo-Cabrera AM, Tong S, Lavigne E, Kyselý J, Pascal M, de’Donato F, das Neves Pereira da Silva S, Madureira J, Huber V, Urban A, Schwartz J, Bell ML, Armstrong B, Iñiguez C, Abrutzky R, de Sousa Zanotti Stagliorio Coelho M, Nascimento Saldiva PH, Matus Correa P, Valdés Ortega N, Kan H, Osorio S, Gasparrini A, Achilleos S, Orru H, Indermitte E, Ryti N, Schneider A, Katsouyanni K, Analitis A, Mayvaneh F, Enteyari A, Raz R, Michelozzi P, Kim Y, Alahmad B, Cauchi JP, Hurtado Diaz M, Félix Arellano EE, Overcenco A, Klompmaker JO, Carrasco G, Seposo X, Carlos Chua PL, Holobaca IH, Guo Y, Jaakkola JJK, Scovronick N, Acquaotta F, Lee W, Forsberg B, Ragettli MS, Li S, Zanobetti A, Colistro V, Dang TN, Dung DV (2025). Short-term association between hot nights and mortality: a multicountry analysis in 178 locations considering hourly ambient temperature. Environment International, vol. 203, art. no. 109719.  10.1016/j.envint.2025.109719 \n\n\nBackground. The rise in hot nights over recent decades and projections of further increases due to climate change underscores the critical need to understand their impact. This knowledge is essential for shaping public health strategies and guiding adaptation efforts. Despite their significance, research on the implications of hot nights remains limited. Objective. This study estimated the association between hot-night excess (the sum of excess heat during the nighttime above a threshold) and duration (the percent of nighttime with a positive excess) based on hourly ambient temperatures and daily mortality in the warm season over multiple locations worldwide. Methods. We fitted time series regression models to mortality in 178 locations across 44 countries using a distributed lag non-linear model over lags of 0–3 days, controlling for daily maximum temperature and daily mean absolute humidity. Next, we used a multivariate meta-regression model to pool results and estimated attributable burdens. Results. We found a positive, increasing mortality risk with hot-night excess and duration. Assuming 0 as a reference, the pooled relative risks of death associated with extreme excess and duration, defined as the 90th percentile in each index, were both similar at 1.026 (95 % CI, 1.017; 1.036) and 1.026 (95 % CI, 1.013; 1.040). The overall estimated attributable fractions were also observed to be closely similar at 0.60 % (95 % CI, 0.09; 1.10 %) and 0.62 % (95 % CI, 0.00; 1.23 %), respectively. Discussion. This study provides new evidence that hot nights have a specific contribution to heat-related mortality risk. Modeling thermal characteristics’ sub-hourly impact on mortality during the night could improve decision-making for long-term adaptions and preventive public health strategies.\n\n\nextreme heat exposurenighttime temperaturepublic health riskclimate change adaptation\n\n\n\n\n\nYu W, Li C, Royé D, Sera F, Ryti N, Bell ML, Ebi KL, Woodward A, Saldiva P, Coeho M (2025). Anthropogenic climate change contributed to excess dengue risk related to hydrometeorological conditions in Brazil and China. One Earth, vol. 8(10), art. no. 101388.  10.1016/j.oneear.2025.101388 \n\n\nHydrometeorological conditions are substantially linked to the dengue epidemic. Although human activity is considered a major driver of climate change, its contribution to hydrometeorology-related dengue burden remains unclear. Clarifying this question is essential for developing climate actions to mitigate dengue risk. Here, we compared the contribution of anthropogenic climate change to dengue incidence related to hydrometeorological conditions, measured by the Palmer drought severity index (PDSI), in Brazil and China—two typical countries in each hemisphere—and investigated the modification effects of urban characteristics. We found that during 1981–2020, 73.6% of PDSI-related dengue excess risk in Brazil and 26.5% in China could be attributed to anthropogenic climate change. Higher urbanization was linked with a lower attributable impact of anthropogenic climate change. These findings underscore the substantial role of human-induced climate change in shaping dengue risk and the importance of integrating climate action with urban planning to prevent and control dengue epidemics.\n\n\nanthropogenic climate changehydrometeorological conditionsdengue riskurbanization effects\n\n\n\n\n\nWu Y, Wen B, Ye T, Huang W, Liu Y, Gasparrini A, Sera F, Tong S, Lavigne E, Royé D, Achilleos S, Ryti N, Pascal M, Zeka A, deDonato F, Pereira da Silva S, Madureira J, Mistry M, Armstrong B, Bell M, Schwartz J, Guo Y, Li S (2025). Estimating the urban heat-related mortality burden due to greenness: a global modelling study. The Lancet Planetary Health.  10.1016/S2542-5196(25)00062-2 \n\n\nBackground: Heat exposure poses a substantial public health threat. Increasing greenness has been suggested as a mitigation strategy due to its cooling effect and potential to modify the heat–mortality association. This study aimed to comprehensively estimate the effects of increased greenness on heat-related deaths. Methods: We applied a multistage meta-analytical approach to estimate the potential reduction in global heat-related deaths by increasing greenness in the warm season in 2000–19 in 11 534 urban areas. We used the enhanced vegetation index (EVI) to indicate greenness and a random forest model to predict daily temperatures in counterfactual EVI scenarios. In the factual EVI scenarios, daily mortality and weather variables from 830 locations in 53 countries were extracted from the Multi-Country Multi-City Collaborative Research Network and used to assess heat–mortality associations. These associations were then extrapolated to each urban area under both factual and counterfactual EVI scenarios based on meta-regression models. Findings: We estimated that EVI increased by 10% would decrease the global population-weighted warm-season mean temperature by 0·08°C, EVI increased by 20% would decrease temperature by 0.14C, and EVI increased by 30% would decrease temperature by 0.19C. In the factual scenario, 3 153 225 (2,48%) of 127 179 341 total deaths could be attributed to heat exposure. The attributable fraction of heat-related deaths (as a fraction of total deaths) in 2000–19 would decrease by 0.67 (95% empirical CI 0.53–0.82) percentage points in the 10% scenario, 0.80 (0.63–0.97) percentage points in the 20% scenario, and 0.91 (0.72–1.10) percentage points in the 30% scenario, compared with the factual scenario. South Europe was modelled to have the largest decrease in attributable fraction of heat-related mortality. Interpretation: This modelling study suggests that increased greenness could substantially reduce the heat-related mortality burden. Preserving and expanding greenness might be potential strategies to lower ambient temperature and reduce the health impacts of heat exposure. greenness heat mortality exposure modification\n\n\ngreennessheatmortalityexposuremodification\n\n\n\n\n\nDíaz-Poso A, Lorenzo N, Martí A, Royé D (2025). Heat and cold wave intensity and spatial extent on the Iberian Peninsula: future climate projections (2050–2095). Climate Dynamics, vol. 63(222).  10.1007/s00382-025-07699-4 \n\n\nIn the current context of global warming, heat waves are extreme climate events that have captured the focused attention of the scientific community due to their increasing impact on public health, energy consumption, fire risk, and agriculture livestock. Although less studied, cold waves remain an extreme climate event to be reckoned with, with implications for transport systems, energy consumption, crops, and human health. This paper presents an analysis of the representative concentration pathway (RCP) 4.5 and RCP 8.5 scenarios under European Coordinated Regional Downscaling Experiment simulations using the excess heat factor (EHF) and excess cold factor indices for the Iberian Peninsula and the Balearic Islands (IPB). The study period is the second half of the 21st Century (2050–2095) with respect to the historical reference period (1971–2000), and the dimensions analysed are intensity and spatial extent. The projected EHF results show a very significant increase on these dimensions. The average change in maximum heat wave intensity for the IPB is projected to be 144%, which is 40% more than in the 2021–2050 period. The largest changes are expected in the east and southeast and will reach 300%. The average spatial extent of heat waves is projected to increase by 1–2.7% per decade, significantly amplifying fire risk, energy demand, and human exposure. For cold waves, both dimensions will decrease. The average change in maximum cold wave intensity will be − 16%, and the maximum extent will decrease much more than the average, with decreases between − 0.7%/decade and − 3.2%/decade, which will imply lower exposure. Despite this, the RCP 8.5 scenario will record a higher maximum intensity of cold waves in the IPB than the RCP 4.5 scenario, demonstrating that such events will continue to exist in the second half of the century, even with high radiative forcing. climate change ecf ehf extreme temperatures future projections\n\n\nclimate changeecfehfextreme temperaturesfuture projections\n\n\n\n\n\nGaliano L, Monjo R, Royé D, Martin-Vide J (2025). Will the world experience more fractal droughts?. Atmospheric Research, vol. 316(1), art. no. 107941.  10.1016/j.atmosres.2025.107941 \n\n\nMeteorological droughts will become the principal factor driving compound hot-dry events and analysis thereof is therefore fundamental with regard to understanding future climate patterns. The average citizen knows little of geometry, but it plays an essential role in the characteristics of the droughts, by means of “fractional lengths”. We analyzed the fractality of the meteorological droughts under the most recent climate change scenarios. A temporal fractality measure based upon the Cantor set reveals consensual changes in the behavior of droughts worldwide. Most regions will undergo a slight increase in fractality (up to +10 % on average), particularly associated with an acceleration of the hydrological cycle and the Hadley cell expansion, with a shift towards the higher latitudes of the tropical edge in both hemispheres. Geometrical measures were applied to the dry spells (1 mm) at a daily scale simulated by the SSP2–4.5 and SSP5–8.5 scenarios from 10 different Earth System Models of the Coupled Model Intercomparison Project Phase 6 (CMIP6). The historical experiment was used as a baseline (1981–2010) and also compared to the ERA5 reanalysis. The results show an increasingly concentrated or uneven distribution of droughts in mid-latitudes towards the end of the century, becoming more intense the more pessimistic the scenario selected. Simultaneously, the polar regions might benefit from more regular precipitation patterns. Other inequality measures, such as the indices of Gini and Monjo, showed similar results. In general terms, the earth’s climate will be more fractal in the rainfall-related patterns, which likely means that the consequences will be more catastrophic for the human population. fractal droughts climate change precipitation patterns global dry spells\n\n\nfractal droughtsclimate changeprecipitation patternsglobaldry spells\n\n\n\n\n\nBatibeniz F, Seneviratne SI, Jha S, Ribeiro A, Suarez Gutierrez L, Raible CC, Malhotra A, Armstrong B, Bell ML, Lavigne E, Gasparrini A, Guo Y, Hashizume M, Masselot P, da Silva S, Royé D, Sera F, Tong S, Urban A, Vicedo-Cabrera AM (2025). Rapid climate action is needed: comparing heat vs. COVID-19-related mortality. Scientific Reports, vol. 15, art. no. 1002.  10.1038/s41598-024-82788-8 \n\n\nThe impacts of climate change on human health are often underestimated or perceived to be in a distant future. Here, we present the projected impacts of climate change in the context of COVID-19, a recent human health catastrophe. We compared projected heat mortality with COVID-19 deaths in 38 cities worldwide and found that in half of these cities, heat-related deaths could exceed annual COVID-19 deaths in less than ten years (at + 3.0 °C increase in global warming relative to preindustrial). In seven of these cities, heat mortality could exceed COVID-19 deaths in less than five years. Our results underscore the crucial need for climate action and for the integration of climate change into public health discourse and policy. climate action heat mortality covid-19 public health global warming\n\n\nclimate actionheat mortalitycovid-19public healthglobal warming\n\n\n\n\n2024\n\n\nXu R, Ye T, Huang W, Yue X, Morawska L, Abramson M, Chen G, Yu P, Liu Y, Yang Z, Zhang Y, Wu Y, Yu W, Wen B, Zhang Y, Hales S, Lavigne E, Saldiva P, Coelho M, Matus P, Royé D, Klompmaker J, Mistry M, Breitner S, Zeka A, Raz R, Tong S, Johnston F, Schwartz J, Gasparrini A, Guo Y, Li S (2024). Global, regional, and national mortality burden attributable to air pollution from landscape fires: a health impact assessment study. The Lancet, vol. 404, art. no. 10470, pp. 2447-2459.  10.1016/S0140-6736(24)02251-7 \n\n\nBackground: Landscape fire-sourced (LFS) air pollution is an increasing public health concern in the context of climate change. However, little is known about the attributable global, regional, and national mortality burden related to LFS air pollution. Methods: We calculated country-specific population-weighted average daily and annual LFS fine particulate matter (PM2·5) and surface ozone (O3) during 2000-19 from a validated dataset. We obtained the relative risks (RRs) for both short-term and long-term impact of LFS PM2·5 and O3 on all-cause, cardiovascular, and respiratory mortality. The short-term RRs were pooled from community-specific standard time-series regressions in 2267 communities across 59 countries or territories. The long-term RRs were obtained from published meta-analyses of cohort studies on all-source PM2·5 and O3. Annual mortality, population, and socio-demographic data for each country or territory were extracted from the Global Burden of Diseases Study 2019. These data were used to estimate country-specific annual deaths attributable to LFS air pollution using standard algorithms. Findings: Globally, 1·53 million all-cause deaths per year (95% empirical confidence interval [eCI] 1·24-1·82) were attributable to LFS air pollution during 2000-19, including 0·45 million (0·32-0·57) cardiovascular deaths and 0·22 million respiratory deaths (0·08-0·35). LFS PM2·5 and O3 contributed to 77·6% and 22·4% of the total attributable deaths, respectively. Over 90% of all attributable deaths were in low-income and middle-income countries, particularly in sub-Saharan Africa (606 769 deaths per year), southeast Asia (206 817 deaths), south Asia (170 762 deaths), and east Asia (147 291 deaths). The global cardiovascular attributable deaths saw an average 1·67% increase per year (ptrend 0·001), although the trends for all-cause and respiratory attributable deaths were not statistically significant. The five countries with the largest all-cause attributable deaths were China, the Democratic Republic of the Congo, India, Indonesia, and Nigeria, although the order changed in the second decade. The leading countries with the greatest attributable mortality rates (AMRs) were all in sub-Saharan Africa, despite decreasing trends from 2000 to 2019. North and central America, and countries surrounding the Mediterranean, showed increasing trends of all-cause, cardiovascular, and respiratory AMRs. Increasing cardiovascular AMR was also observed in southeast Asia, south Asia, and east Asia. In 2019, the AMRs in low-income countries remained four times those in high-income countries, though this had reduced from nine times in 2000. AMRs negatively correlated with a country-specific socio-demographic index (Spearman correlation coefficients r around -0·60). Interpretation: LFS air pollution induced a substantial global mortality burden, with notable geographical and socioeconomic disparities. Urgent actions are required to address such substantial health impact and the associated environmental injustice in a warming climate. air pollution landscape fires mortality burden health impact global assessment\n\n\nair pollutionlandscape firesmortality burdenhealth impactglobal assessment\n\n\n\n\n\nCarbone J, Sanchez B, Román-Cascón C, Martilli A, Royé D, Yagüe C (2024). Effects of the urban development on the nearsurface air temperature and surface energy balance: The case study of Madrid from 1970 to 2020. Urban Climate, vol. 58, art. no. 102198.  10.1016/j.uclim.2024.102198 \n\n\nThe aim of the present study is to examine the impact of Madrid’s urban growth over the last 50 years (1970–2020). We conduct a modelling study using WRF-ARW with the multilayer urban parameterization BEP-BEM, in which different urban parameters have been incorporated at each point within the model’s inner domain according to urban expansion from 1970 to 2020. Two scenarios of important societal interest with different meteorological conditions are selected for this study: a period of intense heatwave during the summer season and a short period of strongly stable atmospheric conditions in winter, both in 2020. The results show that in areas where the urban fraction becomes greater an increase in near-surface air temperature is found for both simulated periods, especially during the night. The urbanization modifies the surface energy balance and turbulent transport in Madrid and its surroundings. It leads to a decrease in latent heat flux due to the high impermeability and reduced vegetation in urban areas. Additionally, the urban areas with a higher density of buildings have a high heat capacity, increasing heat flux storage during the day through solar radiation absorption. This stored energy is released at night, exacerbating the increase in nighttime near-surface air temperature in both periods. urban climate urban growth near-surface air temperatures surface energy balance turbulence heatwave stable atmospheric conditions madrid\n\n\nurban climateurban growthnear-surface air temperaturessurface energy balanceturbulenceheatwavestable atmospheric conditionsmadrid\n\n\n\n\n\nFeurer D, Riffe T, Kniffka M, Acosta E, Armstrong B, Mistry M, Lowe R, Royé D, Hashizume M, Madaniyazi L, Ng C, Tobias A, Íñiguez C, Vicedo-Cabrera A, Ragettli M, Lavigne E, Correa P, Ortega N, Kyselý J, Urban A, Orru H, Indermitte E, Maasikmets M, Dallavalle M, Schneider A, Honda Y, Alahmad B, Zanobetti A, Schwartz J, Carrasco G, Holobâca I, Kim H, Lee W, Bell M, Scovronick N, Acquaotta F, Coélho M, Diaz M, Arellano E, Michelozzi P, Stafoggia M, de’Donato F, Rao S, Di Ruscio F, Seposo X, Guo Y, Tong S, Masselot P, Gasparrini A, Sera F (2024). Meteorological factors, population immunity, and COVID19 incidence: A global multicity analysis. Environmental Epidemiology, vol. 8(6), art. no. e338.  10.1097/ee9.0000000000000338 \n\n\nObjectives: While COVID-19 continues to challenge the world, meteorological variables are thought to impact COVID-19 transmission. Previous studies showed evidence of negative associations between high temperature and absolute humidity on COVID-19 transmission. Our research aims to fill the knowledge gap on the modifying effect of vaccination rates and strains on the weather-COVID-19 association. Methods: Our study included COVID-19 data from 439 cities in 22 countries spanning 3 February 2020 - 31 August 2022 and meteorological variables (temperature, relative humidity, absolute humidity, solar radiation, and precipitation). We used a two-stage time-series design to assess the association between meteorological factors and COVID-19 incidence. For the exposure modeling, we used distributed lag nonlinear models with a lag of up to 14 days. Finally, we pooled the estimates using a random effect meta-analytic model and tested vaccination rates and dominant strains as possible effect modifiers. Results: Our results showed an association between temperature and absolute humidity on COVID-19 transmission. At 5 °C, the relative risk of COVID-19 incidence is 1.22-fold higher compared to a reference level at 17 °C. Correlated with temperature, we observed an inverse association for absolute humidity. We observed a tendency of increased risk on days without precipitation, but no association for relative humidity and solar radiation. No interaction between vaccination rates or strains on the weather-COVID-19 association was observed. Conclusions: This study strengthens previous evidence of a relationship of temperature and absolute humidity with COVID-19 incidence. Furthermore, no evidence was found that vaccinations and strains significantly modify the relationship between environmental factors and COVID-19 transmission. covid-19 distributed lag nonlinear models humidity multi-country multi-city collaborative research network precipitation solar radiation temperature time-series design\n\n\ncovid-19distributed lag nonlinear modelshumiditymulti-country multi-city collaborative research networkprecipitationsolar radiationtemperaturetime-series design\n\n\n\n\n\nLee W, Kang C, Park C, Bell M, Armstrong B, Royé D, Hashizume M, Gasparrini A, Tobias A, Sera F, Honda Y, Urban A, Kyselý J, Íñiguez C, Ryti N, Guo Y, Tong S, de Sousa Zanotti Stagliorio Coelho M, Lavigne E, de’Donato F, Guo Y, Schwartz J, Schneider A, Breitner S, Chung Y, Kim S, Ha E, Kim H, Kim Y (2024). Association of holidays and the day of the week with suicide risk: multicountry, two stage, time series study. BMJ, vol. 387, art. no. e077262.  10.1136/bmj-2024-077262 \n\n\nObjectives To assess the short term temporal variations in suicide risk related to the day of the week and national holidays in multiple countries. Design Multicountry, two stage, time series design. Setting Data from 740 locations in 26 countries and territories, with overlapping periods between 1971 and 2019, collected from the Multi-city Multi-country Collaborative Research Network database. Participants All suicides were registered in these locations during the study period (overall 1 701  286 cases). Main outcome measures Daily suicide mortality. Results Mondays had peak suicide risk during weekdays (Monday-Friday) across all countries, with relative risks (reference: Wednesday) ranging from 1.02 (95% confidence interval (CI) 0.95 to 1.10) in Costa Rica to 1.17 (1.09 to 1.25) in Chile. Suicide risks were lowest on Saturdays or Sundays in many countries in North America, Asia, and Europe. However, the risk increased during weekends in South and Central American countries, Finland, and South Africa. Additionally, evidence suggested strong increases in suicide risk on New Year’s day in most countries with relative risks ranging from 0.93 (95% CI 0.75 to 1.14) in Japan to 1.93 (1.31 to 2.85) in Chile, whereas the evidence on Christmas day was weak. Suicide risk was associated with a weak decrease on other national holidays, except for Central and South American countries, where the risk generally increased one or two days after these holidays. Conclusions Suicide risk was highest on Mondays and increased on New Year’s day in most countries. However, the risk of suicide on weekends and Christmas varied by country and territory. The results of this study can help to better understand the short term variations in suicide risks and define suicide prevention action plans and awareness campaigns. suicide risk holidays day of the week time series analysis multicountry study\n\n\nsuicide riskholidaysday of the weektime series analysismulticountry study\n\n\n\n\n\nOrlov A, De Hertog S, Havermann F, Guo S, Manola I, Lejeune Q, Schleussner C, Thiery W, Pongratz J, Humpenöder F, Popp A, Aunan K, Armstrong B, Royé D, Cvijanovic I, Lavigne E, Achilleos S, Bell M, Masselot P, Sera F, Vicedo-Cabrera A, Gasparrini A, Mistry M (2024). Impacts of landuse and landcover changes on temperature related mortality. Environmental Epidemiology, vol. 8(6), art. no. e337.  10.1097/ee9.0000000000000337 \n\n\nBackground: Land-use and land-cover change (LULCC) can substantially affect climate through biogeochemical and biogeophysical effects. Here, we examine the future temperature–mortality impact for two contrasting LULCC scenarios in a background climate of low greenhouse gas concentrations. The first LULCC scenario implies a globally sustainable land use and socioeconomic development (sustainability). In the second LULCC scenario, sustainability is implemented only in the Organisation for Economic Cooperation and Development countries (inequality). Methods: Using the Multi-Country Multi-City (MCC) dataset on mortality from 823 locations in 52 countries and territories, we estimated the temperature–mortality exposure–response functions (ERFs). The LULCC and noLULCC scenarios were implemented in three fully coupled Earth system models (ESMs): Community Earth System Model, Max Planck Institute Earth System Model, and European Consortium Earth System Model. Next, using temperature from the ESMs’ simulations and the estimated location-specific ERFs, we assessed the temperature-related impact on mortality for the LULCC and noLULCC scenarios around the mid and end century. Results: Under sustainability, the multimodel mean changes in excess mortality range from −1.1 to +0.6 percentage points by 2050–2059 across all locations and from −1.4 to +0.5 percentage points by 2090–2099. Under inequality, these vary from −0.7 to +0.9 percentage points by 2050–2059 and from −1.3 to +2 percentage points by 2090–2099. Conclusions: While an unequal socioeconomic development and unsustainable land use could increase the burden of heat-related mortality in most regions, globally sustainable land use has the potential to reduce it in some locations. However, the total (cold and heat) impact on mortality is very location specific and strongly depends on the underlying climate change scenario due to nonlinearity in the temperature–mortality relationship. land-use change temperature-related mortality climate impact biogeophysical effects health assessment\n\n\nland-use changetemperature-related mortalityclimate impactbiogeophysical effectshealth assessment\n\n\n\n\n\nTobías A, Íñiguez C, Hurtado Díaz M, Riojas H, Cifuentes L, Royé D, Abrutzky R, Coelho M, Saldiva P, Valdés Ortega N, Matus Correa P, Osorio S, Carrasco G, Colistro V, Pascal M, Chanel O, Madaniyazi L, Gasparrini A (2024). Mortality burden and economic loss attributable to cold and heat in Central and South America. Environmental Epidemiology, vol. 8(6), art. no. e335.  10.1097/ee9.0000000000000335 \n\n\nBackground: We quantify the mortality burden and economic loss attributable to nonoptimal temperatures for cold and heat in the Central and South American countries in the Multi-City Multi-Country (MCC) Collaborative Research Network. Methods: We collected data for 66 locations from 13 countries in Central and South America to estimate location-specific temperature–mortality associations using time-series regression with distributed lag nonlinear models. We calculated the attributable deaths for cold and heat as the 2.5th and 97.5th temperature percentiles, above and below the minimum mortality temperature, and used the value of a life year to estimate the economic loss of delayed deaths. Results: The mortality impact of cold varied widely by country, from 9.64% in Uruguay to 0.22% in Costa Rica. The heat-attributable fraction for mortality ranged from 1.41% in Paraguay to 0.01% in Ecuador. Locations in arid and temperate climatic zones showed higher cold-related mortality (5.10% and 5.29%, respectively) than those in tropical climates (1.71%). Arid and temperate climatic zones saw lower heat-attributable fractions (0.69% and 0.58%) than arid climatic zones (0.92%). Exposure to cold led to an annual economic loss of 0.6 million in Costa Rica to 472.2 million in Argentina. In comparison, heat resulted in economic losses of 0.05 million in Ecuador to 90.6 million in Brazil. Conclusion: Most of the mortality burden for Central and South American countries is caused by cold compared to heat, generating annual economic losses of 2.1 billion and 290.7 million, respectively. Public health policies and adaptation measures in the region should account for the health effects associated with nonoptimal temperatures. mortality burden economic loss cold and heat central and south america nonoptimal temperatures\n\n\nmortality burdeneconomic losscold and heatcentral and south americanonoptimal temperatures\n\n\n\n\n\nHe C, Breitner-Busch S, Huber V, Chen K, Zhang S, Gasparrini A, Bell M, Kan H, Royé D, Armstrong B, Schwartz J, Sera F, Vicedo-Cabrera A, Honda Y, Jaakkola J, Ryti N, Kyselý J, Guo Y, Tong S, de’Donato F, Michelozzi P, Coelho M, Saldiva P, Lavigne E, Orru H, Indermitte E, Pascal M, Goodman P, Zeka A, Kim Y, Diaz M, Arellano E, Overcenco A, Klompmaker J, Rao S, Palomares A, Carrasco G, Seposo X, Pereira da Silva S, Madureira J, Holobaca I, Scovronick N, Acquaotta F, Kim H, Lee W, Hashizume M, Tobias A, Íñiguez C, Forsberg B, Ragettli M, Guo Y, Pan S, Osorio S, Li S, Zanobetti A, Dang T, Van Dung D, Schneider A (2024). Rainfall events and daily mortality across 645 global locations: two stage time series analysis. BMJ, vol. 387, art. no. e080944.  10.1136/bmj2024080944 \n\n\nObjective To examine the associations between characteristics of daily rainfall (intensity, duration, and frequency) and all cause, cardiovascular, and respiratory mortality. Design Two stage time series analysis.Setting 645 locations across 34 countries or regions. Population Daily mortality data, comprising a total of 109954744 all cause, 31164161 cardiovascular, and 11817278 respiratory deaths from 1980 to 2020. Main outcome measure Association between daily mortality and rainfall events with return periods (the expected average time between occurrences of an extreme event of a certain magnitude) of one year, two years, and five years, with a 14 day lag period. A continuous relative intensity index was used to generate intensity-response curves to estimate mortality risks at a global scale. Results During the study period, a total of 50 913 rainfall events with a one year return period, 8362 events with a two year return period, and 3301 events with a five year return period were identified. A day of extreme rainfall with a five year return period was significantly associated with increased daily all cause, cardiovascular, and respiratory mortality, with cumulative relative risks across 0-14 lag days of 1.08 (95% confidence interval 1.05 to 1.11), 1.05 (1.02 to 1.08), and 1.29 (1.19 to 1.39), respectively. Rainfall events with a two year return period were associated with respiratory mortality only, whereas no significant associations were found for events with a one year return period. Non-linear analysis revealed protective effects (relative risk 1) with moderate-heavy rainfall events, shifting to adverse effects (relative risk 1) with extreme intensities. Additionally, mortality risks from extreme rainfall events appeared to be modified by climate type, baseline variability in rainfall, and vegetation coverage, whereas the moderating effects of population density and income level were not significant. Locations with lower variability of baseline rainfall or scarce vegetation coverage showed higher risks. Conclusion Daily rainfall intensity is associated with varying health effects, with extreme events linked to an increasing relative risk for all cause, cardiovascular, and respiratory mortality. The observed associations varied with local climate and urban infrastructure. rainfall events daily mortality time series analysis global study cardiovascular and respiratory mortality\n\n\nrainfall eventsdaily mortalitytime series analysisglobal studycardiovascular and respiratory mortality\n\n\n\n\n\nAlvarez I, Diaz-Poso A, Lorenzo MN, Royé D (2024). Heat index historical trends and projections due to climate change in the Mediterranean basin based on CMIP6. Atmospheric Research, vol. 308, art. no. 107512.  10.1016/j.atmosres.2024.107512 \n\n\nAir temperature and relative humidity can be considered as two essential meteorological parameters in the determination of heat stress. The heat index (HI) includes both of them and it is appropriate for determining the thermal conditions of different climates. We investigated potential changes in the HI for the Mediterranean basin using simulations from the Coupled Model Intercomparison Project Phase 6 (CMIP6) climate models under two future scenarios (Shared Socio-economic Pathways: SSP2-4.5 and SSP5-8.5) over the period 2020–2099. Results reveal an important increase of HI at the end of the 21st century for both scenarios, with greater changes for the SSP5-8.5 scenario all over the basin. Strong significant upwards trends (around 1 °C per decade; significance level computed at 5%) are expected in the entire area and for all months at the end of the century, with greatest values during the summer months (close to 1.5 °C per decade) along the coastal areas of the basin. Many areas of the Southern Mediterranean basin (Africa and Arabian Peninsula) will be strongly affected with dangerously high heat index values (higher than 41 °C) during summer months by the end of the 21st century. A northward extension of these dangerous conditions is also expected including several areas of southern Europe. heat index heat risk mediterranean arabian peninsula africa cmip6\n\n\nheat indexheat riskmediterraneanarabian peninsulaafricacmip6\n\n\n\n\n\nYang D, Hashizume M, Tobías A, Honda Y, Royé D, Oh J, Dang T, Kim Y, Abrutzky R, Guo Y, Tong S, Coelho M, Saldiva P, Lavigne E, Correa P, Ortega N, Osorio S, Kyselý J, Urban A, Orru H, Indermitte E, Jaakkola J, Ryti N, Pascal M, Huber V, Schneider A, Katsouyanni K, Analitis A, Entezari A, Mayvaneh F, Goodman P, Zeka A, Michelozzi P, de’Donato F, Alahmad B, Diaz M, la Cruz Valencia C, Overcenco A, Houthuijs D, Ameling C, Rao S, Nunes B, Madureira J, Holo-bâc I, Scovronick N, Acquaotta F, Kim H, Lee W, Íñiguez C, Forsberg B, Vicedo-Cabrera A, Ragettli M, Guo Y, Pan S, Li S, Sera F, Zanobetti A, Schwartz J, Armstrong B, Gasparrini A, Chung Y (2024). Temporal change in minimum mortality temperature under changing climate: A multicountry multicommunity observational study spanning 1986–2015. Environmental Epidemiology, vol. 8(5), art. no. e334.  10.1097/ee9.0000000000000334 \n\n\nBackground: The minimum mortality temperature (MMT) or MMT percentile (MMTP) is an indicator of population susceptibility to nonoptimum temperatures. MMT and MMTP change over time; however, the changing directions show region-wide heterogeneity. We examined the heterogeneity of temporal changes in MMT and MMTP across multiple communities and in multiple countries. Methods: Daily time-series data for mortality and ambient mean temperature for 699 communities in 34 countries spanning 1986–2015 were analyzed using a two-stage meta-analysis. First, a quasi-Poisson regression was employed to estimate MMT and MMTP for each community during the designated subperiods. Second, we pooled the community-specific temporally varying estimates using mixed-effects meta-regressions to examine temporal changes in MMT and MMTP in the entire study population, as well as by climate zone, geographical region, and country. Results: Temporal increases in MMT and MMTP from 19.5C (17.9, 21.1) to 20.3C (18.5, 22.0) and from the 74.5 (68.3, 80.6) to 75.0 (71.0, 78.9) percentiles in the entire population were found, respectively. Temporal change was significantly heterogeneous across geographical regions (P 0.001). Temporal increases in MMT were observed in East Asia (linear slope [LS] = 0.91, P = 0.02) and South-East Asia (LS = 0.62, P = 0.05), whereas a temporal decrease in MMT was observed in South Europe (LS = −0.46, P = 0.05). MMTP decreased temporally in North Europe (LS = −3.45, P = 0.02) and South Europe (LS = −2.86, P = 0.05). Conclusions: The temporal change in MMT or MMTP was largely heterogeneous. Population susceptibility in terms of optimum temperature may have changed under a warming climate, albeit with large region-dependent variations. minimum mortality temperature climate change temporal change multicountry study observational analysis\n\n\nminimum mortality temperatureclimate changetemporal changemulticountry studyobservational analysis\n\n\n\n\n\nScovronick N, Sera F, Vu B, Vicedo-Cabrera A, Royé D, Tobias A, Seposo X, Forsberg B, Guo Y, Li S, Honda Y, Abrutzky R, de Sousa Zanotti Stagliorio Coelho M, Nascimento Saldiva P, Lavigne E, Kan H, Osorio S, Kyselý J, Urban A, Orru H, Indermitte E, Jaakkola J, Ryti N, Pascal M, Katsouyanni K, Mayvaneh F, Entezari A, Goodman P, Zeka A, Michelozzi P, de’Donato F, Hashizume M, Alahmad B, Zanobetti A, Schwartz J, Hurtado Diaz M, De La Cruz Valencia C, Rao S, Madureira J, Acquaotta F, Kim H, Lee W, Iniguez C, Ragettli M, Guo Y, Dang T, Dung D, Armstrong B, Gasparrini A (2024). Temperature mortality associations by age and cause: a multicountry multicity study. Environmental Epidemiology, vol. 8(5), art. no. e336.  10.1097/ee9.0000000000000336 \n\n\nBackground: Heterogeneity in temperature-mortality relationships across locations may partly result from differences in the demographic structure of populations and their cause-specific vulnerabilities. Here we conduct the largest epidemiological study to date on the association between ambient temperature and mortality by age and cause using data from 532 cities in 33 countries. Methods: We collected daily temperature and mortality data from each country. Mortality data was provided as daily death counts within age groups from all, cardiovascular, respiratory, or noncardiorespiratory causes. We first fit quasi-Poisson regression models to estimate location-specific associations for each age-by-cause group. For each cause, we then pooled location-specific results in a dose-response multivariate meta-regression model that enabled us to estimate overall temperature-mortality curves at any age. The age analysis was limited to adults. Results: We observed high temperature effects on mortality from both cardiovascular and respiratory causes compared to noncardiorespiratory causes, with the highest cold-related risks from cardiovascular causes and the highest heat-related risks from respiratory causes. Risks generally increased with age, a pattern most consistent for cold and for nonrespiratory causes. For every cause group, risks at both temperature extremes were strongest at the oldest age (age 85 years). Excess mortality fractions were highest for cold at the oldest ages. Conclusions: There is a differential pattern of risk associated with heat and cold by cause and age; cardiorespiratory causes show stronger effects than noncardiorespiratory causes, and older adults have higher risks than younger adults. temperature-mortality associations age-specific mortality cause-specific mortality multi-country study multi-city analysis\n\n\ntemperature-mortality associationsage-specific mortalitycause-specific mortalitymulti-country studymulti-city analysis\n\n\n\n\n\nGuo Q, Mistry M, Zhou X, Zhao G, Kino K, Wen B, Yoshimura K, Satoh Y, Cvijanovic I, Kim Y, Ng C, Vicedo-Cabrera A, Armstrong B, Urban A, Katsouyanni K, Masselot P, Tong S, Sera F, Huber V, Bell M, Kyselý J, Gasparrini A, Hashizume M, Oki T, Abrutzky R, Guo Y, de Sousa Zanotti Stagliorio Coelho M, Nascimento Saldiva P, Lavigne E, Ortega N, Correa P, Kan H, Osorio S, Royé D, Indermitte E, Orru H, Jaakkola J, Ryti N, Pascal M, Schneider A, Analitis A, Entezari A, Mayvaneh F, Zeka A, Goodman P, de’Donato F, Michelozzi P, Alahmad B, De la Cruz Valencia C, Hurtado Diaz M, Overcenco A, Ameling C, Houthuijs D, Rao S, Carrasco G, Seposo X, Madureira J, das Neves Pereira da Silva S, Holobaca I, Acquaotta F, Scovronick N, Kim H, Lee W, Tobias A, Íñiguez C, Forsberg B, Ragettli M, Pan S, Guo Y, Li S, Schneider R, Colistro V, Zanobetti A, Schwartz J, Van Dung D, Ngoc Dang T, Honda Y (2024). Regional variation in the role of humidity on citylevel heatrelated mortality. PNAS Nexus, vol. 3(8), art. no. pgae290.  10.1093/pnasnexus/pgae290 \n\n\nThe rising humid heat is regarded as a severe threat to human survivability, but the proper integration of humid heat into heat-health alerts is still being explored. Using state-of-the-art epidemiological and climatological datasets, we examined the association between multiple heat stress indicators (HSIs) and daily human mortality in 739 cities worldwide. Notable differences were observed in the long-term trends and timing of heat events detected by HSIs. Air temperature (Tair) predicts heat-related mortality well in cities with a robust negative Tair-relative humidity correlation (CT-RH). However, in cities with near-zero or weak positive CT-RH, HSIs considering humidity provide enhanced predictive power compared to Tair. Furthermore, the magnitude and timing of heat-related mortality measured by HSIs could differ largely from those associated with Tair in many cities. Our findings provide important insights into specific regions where humans are vulnerable to humid heat and can facilitate the further enhancement of heat-health alert systems. humidity heat-related mortality city-level analysis regional variation heat stress indicators\n\n\nhumidityheat-related mortalitycity-level analysisregional variationheat stress indicators\n\n\n\n\n\nChua P, Tobias A, Madaniyazi L, Ng C, Phung V, Fu S, Rodriguez P, Brown P, Coelho M, Saldiva P, Scovronick N, Deshpande A, Salazar M, Dorotan M, Tantrakarnapa K, Kliengchuay W, Abrutzky R, Carrasco-Escobar G, Royé D, Hales S, Hashizume M (2024). Association between precipitation and mortality due to diarrheal diseases by climate zone: A multicountry modeling study. Environmental Epidemiology, vol. 8(4), art. no. e320.  10.1097/ee9.0000000000000320 \n\n\nBackground: Precipitation could affect the transmission of diarrheal diseases. The diverse precipitation patterns across different climates might influence the degree of diarrheal risk from precipitation. This study determined the associations between precipitation and diarrheal mortality in tropical, temperate, and arid climate regions. Methods: Daily counts of diarrheal mortality and 28-day cumulative precipitation from 1997 to 2019 were analyzed across 29 locations in eight middle-income countries (Argentina, Brazil, Costa Rica, India, Peru, the Philippines, South Africa, and Thailand). A two-stage approach was employed: the first stage is conditional Poisson regression models for each location, and the second stage is meta-analysis for pooling location-specific coefficients by climate zone. Results: In tropical climates, higher precipitation increases the risk of diarrheal mortality. Under extremely wet conditions (95th percentile of 28-day cumulative precipitation), diarrheal mortality increased by 17.8% (95% confidence interval [CI] = 10.4%, 25.7%) compared with minimum-risk precipitation. For temperate and arid climates, diarrheal mortality increases in both dry and wet conditions. In extremely dry conditions (fifth percentile of 28-day cumulative precipitation), diarrheal mortality risk increases by 3.8% (95% CI = 1.2%, 6.5%) for temperate and 5.5% (95% CI = 1.0%, 10.2%) for arid climates. Similarly, under extremely wet conditions, diarrheal mortality risk increases by 2.5% (95% CI = −0.1%, 5.1%) for temperate and 4.1% (95% CI = 1.1%, 7.3%) for arid climates. Conclusions: Associations between precipitation and diarrheal mortality exhibit variations across different climate zones. It is crucial to consider climate-specific variations when generating global projections of future precipitation-related diarrheal mortality. precipitation diarrheal diseases climate zones mortality multi-country modeling\n\n\nprecipitationdiarrheal diseasesclimate zonesmortalitymulti-country modeling\n\n\n\n\n\nChen G, Guo Y, Yue X, Xu R, Yu W, Ye T, Tong S, Gasparrini A, Bell M, Armstrong B, Schwartz J, Jaakkola J, Lavigne E, Saldiva P, Kan H, Royé D, Urban A, Vicedo-Cabrera A, Tobias A, Forsberg B, Sera F, Lei Y, Abramson M, Li S, Abrutzky R, Alahmad B, Ameling C, Åström C, Breitner S, Carrasco-Escobar G, Coêlho M, Colistro V, Correa P, Dang T, de’Donato F, Dung D, Entezari A, Garcia S, Garland R, Goodman P, Guo Y, Hashizume M, Holobaca I, Honda Y, Houthuijs D, Hurtado-Díaz M, Íñiguez C, Katsouyanni K, Kim H, Kyselý J, Lee W, Maasikmets M, Madureira J, Mayvaneh F, Nunes B, Orru H, Ortega N, Overcenco A, Pan S, Pascal M, Ragettli M, Rao S, Ryti N, Samoli E, Schneider A, Scovronick N, Seposo X, Stafoggia M, Valencia C, Zanobetti A, Zeka A (2024). Allcause, cardiovascular, and respiratory mortality and wildfirerelated ozone: a multicountry twostage time series analysis. The Lancet Planetary Health, vol. 8(7), pp. e452-e462.  10.1016/S2542-5196(24)00117-7 \n\n\nBackground. Wildfire activity is an important source of tropospheric ozone (O3) pollution. However, no study to date has systematically examined the associations of wildfire-related O3 exposure with mortality globally. Methods. We did a multicountry two-stage time series analysis. From the Multi-City Multi-Country (MCC) Collaborative Research Network, data on daily all-cause, cardiovascular, and respiratory deaths were obtained from 749 locations in 43 countries or areas, representing overlapping periods from Jan 1, 2000, to Dec 31, 2016. We estimated the daily concentration of wildfire-related O3 in study locations using a chemical transport model, and then calibrated and downscaled O3 estimates to a resolution of 0·25° × 0·25° (approximately 28 km2 at the equator). Using a random-effects meta-analysis, we examined the associations of short-term wildfire-related O3 exposure (lag period of 0–2 days) with daily mortality, first at the location level and then pooled at the country, regional, and global levels. Annual excess mortality fraction in each location attributable to wildfire-related O3 was calculated with pooled effect estimates and used to obtain excess mortality fractions at country, regional, and global levels. Findings. Between 2000 and 2016, the highest maximum daily wildfire-related O3 concentrations (≥30 μg/m3) were observed in locations in South America, central America, and southeastern Asia, and the country of South Africa. Across all locations, an increase of 1 μg/m3 in the mean daily concentration of wildfire-related O3 during lag 0–2 days was associated with increases of 0·55% (95% CI 0·29 to 0·80) in daily all-cause mortality, 0·44% (–0·10 to 0·99) in daily cardiovascular mortality, and 0·82% (0·18 to 1·47) in daily respiratory mortality. The associations of daily mortality rates with wildfire-related O3 exposure showed substantial geographical heterogeneity at the country and regional levels. Across all locations, estimated annual excess mortality fractions of 0·58% (95% CI 0·31 to 0·85; 31 606 deaths [95% CI 17 038 to 46 027]) for all-cause mortality, 0·41% (–0·10 to 0·91; 5249 [–1244 to 11 620]) for cardiovascular mortality, and 0·86% (0·18 to 1·51; 4657 [999 to 8206]) for respiratory mortality were attributable to short-term exposure to wildfire-related O3. Interpretation. In this study, we observed an increase in all-cause and respiratory mortality associated with short-term wildfire-related O3 exposure. Effective risk and smoke management strategies should be implemented to protect the public from the impacts of wildfires. wildfire-related ozone all-cause mortality cardiovascular mortality respiratory mortality two-stage time series\n\n\nwildfire-related ozoneall-cause mortalitycardiovascular mortalityrespiratory mortalitytwo-stage time series\n\n\n\n\n\nLemus-Canovas M, Montesinos-Ciuró E, Cearreta-Innocenti T, Serrano-Notivoli R, Royé D (2024). Attribution of the unprecedented heat event of August 2023 in Barcelona (Spain) to observed and projected global warming. Urban Climate, vol. 56, art. no. 102019.  10.1016/j.uclim.2024.102019 \n\n\nThe study analyses observed and numerical simulations of daily maximum and minimum temperature from 1920 onwards and to investigate the unprecedented heat event that occurred in 21–23 August 2023 in Barcelona. The historical changes in the intensity of such events, their expected future changes under scenarios of +1.5 °C, +2 °C, and + 3 °C, and the future exposure of populations to such kind of events are examined using the flow analogues approach. The findings indicate a significant increase in observed temperatures for similar heatwaves to those occurred in August 2023. The study also emphasises the impact of global warming on the intensification of heat events over the impact of urbanization. Additionally, after examining the role of natural variability in temperature changes, we concluded that global warming is the primary factor driving the increase in heatwave intensity. In terms of the frequency of such events, we found that extreme heat events, such as the August 2023 heatwave, will become 2 and 5 times more likely with a global summer warming of 2 °C and 3 °C, respectively. This will expose a large portion of the population to dangerous heat levels highlighting the importance of limiting global warming to 1.5 °C to mitigate the impacts on urban populations. extreme event attribution heatwave urban climate global warming barcelona\n\n\nextreme event attributionheatwaveurban climateglobal warmingbarcelona\n\n\n\n\n\nAlahmad B, Khraishah H, Kamineni M, Royé D, Papatheodorou S, Vicedo-Cabrera A, Guo Y, Lavigne E, Armstrong B, Sera F, Bernstein A, Zanobetti A, Garshick E, Schwartz J, Bell M, Al-Mulla F, Koutrakis P, Gasparrini A, Souzana A, Acquaotta F, Pan S, Sousa Zanotti Stagliorio Coelho M, Colistro V, Ngoc Dang T, Van Dung D, De’ Donato F, Entezari A, Leon Guo Y, Hashizume M, Honda Y, Indermitte E, Íñiguez C, Jaakkola J, Kim H, Lee W, Li S, Madureira J, Mayvaneh F, Orru H, Overcenco A, Ragettli M, Ryti N, Hilario Nascimento Saldiva P, Scovronick N, Seposo X, Pereira Silva S, Stafoggia M, Tobias A (2024). Extreme Temperatures and Stroke Mortality: Evidence From a MultiCountry Analysis. Stroke, vol. 55(7), pp. 1847-1856.  10.1161/strokeaha.123.045751 \n\n\nBackground: Extreme temperatures contribute significantly to global mortality. While previous studies on temperature and stroke-specific outcomes presented conflicting results, these studies were predominantly limited to single-city or single-country analyses. Their findings are difficult to synthesize due to variations in methodologies and exposure definitions. Methods: Within the Multi-Country Multi-City Network, we built a new mortality database for ischemic and hemorrhagic stroke. Applying a unified analysis protocol, we conducted a multinational case-crossover study on the relationship between extreme temperatures and stroke. In the first stage, we fitted a conditional quasi-Poisson regression for daily mortality counts with distributed lag nonlinear models for temperature exposure separately for each city. In the second stage, the cumulative risk from each city was pooled using mixed-effect meta-analyses, accounting for clustering of cities with similar features. We compared temperature-stroke associations across country-level gross domestic product per capita. We computed excess deaths in each city that are attributable to the 2.5% hottest and coldest of days based on each city’s temperature distribution. Results: We collected data for a total of 3 443 969 ischemic strokes and 2 454 267 hemorrhagic stroke deaths from 522 cities in 25 countries. For every 1000 ischemic stroke deaths, we found that extreme cold and hot days contributed 9.1 (95% empirical CI, 8.6–9.4) and 2.2 (95% empirical CI, 1.9–2.4) excess deaths, respectively. For every 1000 hemorrhagic stroke deaths, extreme cold and hot days contributed 11.2 (95% empirical CI, 10.9–11.4) and 0.7 (95% empirical CI, 0.5–0.8) excess deaths, respectively. We found that countries with low gross domestic product per capita were at higher risk of heat-related hemorrhagic stroke mortality than countries with high gross domestic product per capita (P=0.02). Conclusions: Both extreme cold and hot temperatures are associated with an increased risk of dying from ischemic and hemorrhagic strokes. As climate change continues to exacerbate these extreme temperatures, interventional strategies are needed to mitigate impacts on stroke mortality, particularly in low-income countries. extreme temperatures stroke mortality ischemic and hemorrhagic stroke multi-country analysis climate impact\n\n\nextreme temperaturesstroke mortalityischemic and hemorrhagic strokemulti-country analysisclimate impact\n\n\n\n\n\nHundessa S, Huang W, Zhao Q, Wu Y, Wen B, Alahmad B, Armstrong B, Gasparrini A, Sera F, Tong S, Madureira J, Kyselý J, Schwartz J, Vicedo-Cabrera A, Hales S, Johnson A, Li S, Guo Y, Jaakkola J, Ryti N, Urban A, Tobias A, Royé D, Lavigne E, Ragettli M, Åström C, Raz R, Pascal M, Kan H, Goodman P, Zeka A, Hashizume M, Diaz M, Seposo X, Nunes B, Kim H, Lee W, Íñiguez C, Guo Y, Pan S, Zanobetti A, Dang T, Van Dung D, Schneider A, Entezari A, Analitis A, Forsberg B, Ameling C, Houthuijs D, Indermitte E, Mayvaneh F, Acquaotta F, de’Donato F, Carrasco-Escobar G, Orru H, Katsouyanni K, de Sousa Zanotti Stagliorio Coelho M, Ortega N, Scovronick N, Michelozzi P, Correa P, Nascimento Saldiva P, Abrutzky R, Osorio S, Colistro V, Huber V, Honda Y, Kim Y, Bell M, Xu R, Yang Z, Roradeh H, Félix Arellano E, Rao S, Carlos Chua P, da Silva S, da Silva S, De la Cruz Valencia C (2024). Global and Regional Cardiovascular Mortality Attributable to Nonoptimal Temperatures Over Time. Journal of the American College of Cardiology, vol. 83(23), pp. 2276-2287.  10.1016/j.jacc.2024.03.425 \n\n\nBackground. The association between nonoptimal temperatures and cardiovascular mortality risk is recognized. However, a comprehensive global assessment of this burden is lacking. Objectives. The goal of this study was to assess global cardiovascular mortality burden attributable to nonoptimal temperatures and investigate spatiotemporal trends. Methods. Using daily cardiovascular deaths and temperature data from 32 countries, a 3-stage analytical approach was applied. First, location-specific temperature–mortality associations were estimated, considering nonlinearity and delayed effects. Second, a multivariate meta-regression model was developed between location-specific effect estimates and 5 meta-predictors. Third, cardiovascular deaths associated with nonoptimal, cold, and hot temperatures for each global grid (55 km × 55 km resolution) were estimated, and temporal trends from 2000 to 2019 were explored. Results. Globally, 1,801,513 (95% empirical CI: 1,526,632-2,202,831) annual cardiovascular deaths were associated with nonoptimal temperatures, constituting 8.86% (95% empirical CI: 7.51%-12.32%) of total cardiovascular mortality corresponding to 26 deaths per 100,000 population. Cold-related deaths accounted for 8.20% (95% empirical CI: 6.74%-11.57%), whereas heat-related deaths accounted for 0.66% (95% empirical CI: 0.49%-0.98%). The mortality burden varied significantly across regions, with the highest excess mortality rates observed in Central Asia and Eastern Europe. From 2000 to 2019, cold-related excess death ratios decreased, while heat-related ratios increased, resulting in an overall decline in temperature-related deaths. Southeastern Asia, Sub-Saharan Africa, and Oceania observed the greatest reduction, while Southern Asia experienced an increase. The Americas and several regions in Asia and Europe displayed fluctuating temporal patterns. Conclusions. Nonoptimal temperatures substantially contribute to cardiovascular mortality, with heterogeneous spatiotemporal patterns. Effective mitigation and adaptation strategies are crucial, especially given the increasing heat-related cardiovascular deaths amid climate change. cardiovascular mortality nonoptimal temperatures global assessment spatiotemporal trends climate impact\n\n\ncardiovascular mortalitynonoptimal temperaturesglobal assessmentspatiotemporal trendsclimate impact\n\n\n\n\n\nZhao Q, Li S, Ye T, Wu Y, Gasparrini A, Tong S, Urban A, Vicedo-Cabrera A, Tobias A, Armstrong B, Royé D, Lavigne E, de’Donato F, Sera F, Kan H, Schwartz J, Pascal M, Ryti N, Goodman P, Saldiva P, Bell M, Guo Y (2024). Global, regional, and national burden of heatwave related mortality from 1990 to 2019: A three stage modelling study. PLOS Medicine, vol. 21(5), art. no. e1004364.  10.1371/journal.pmed.1004364 \n\n\nBackground. The regional disparity of heatwave-related mortality over a long period has not been sufficiently assessed across the globe, impeding the localisation of adaptation planning and risk management towards climate change. We quantified the global mortality burden associated with heatwaves at a spatial resolution of 0.5°×0.5° and the temporal change from 1990 to 2019. Methods and findings. We collected data on daily deaths and temperature from 750 locations of 43 countries or regions, and 5 meta-predictors in 0.5°×0.5° resolution across the world. Heatwaves were defined as location-specific daily mean temperature ≥95th percentiles of year-round temperature range with duration ≥2 days. We first estimated the location-specific heatwave-mortality association. Secondly, a multivariate meta-regression was fitted between location-specific associations and 5 meta-predictors, which was in the third stage used with grid cell-specific meta-predictors to predict grid cell-specific association. Heatwave-related excess deaths were calculated for each grid and aggregated. During 1990 to 2019, 0.94% (95% CI: 0.68–1.19) of deaths [i.e., 153,078 cases (95% eCI: 109,950–194,227)] per warm season were estimated to be from heatwaves, accounting for 236 (95% eCI: 170–300) deaths per 10 million residents. The ratio between heatwave-related excess deaths and all premature deaths per warm season remained relatively unchanged over the 30 years, while the number of heatwave-related excess deaths per 10 million residents per warm season declined by 7.2% per decade in comparison to the 30-year average. Locations with the highest heatwave-related death ratio and rate were in Southern and Eastern Europe or areas had polar and alpine climates, and/or their residents had high incomes. The temporal change of heatwave-related mortality burden showed geographic disparities, such that locations with tropical climate or low incomes were observed with the greatest decline. The main limitation of this study was the lack of data from certain regions, e.g., Arabian Peninsula and South Asia. Conclusions. Heatwaves were associated with substantial mortality burden that varied spatiotemporally over the globe in the past 30 years. The findings indicate the potential benefit of governmental actions to enhance health sector adaptation and resilience, accounting for inequalities across communities. heatwave-related mortality global burden temporal change spatiotemporal analysis\n\n\nheatwave-related mortalityglobal burdentemporal changespatiotemporal analysis\n\n\n\n\n\nWu Y, Wen B, Gasparrini A, Armstrong B, Sera F, Lavigne E, Li S, Guo Y, Overcenco A, Urban A, Schneider A, Entezari A, Vicedo-Cabrera A, Zanobetti A, Analitis A, Zeka A, Tobias A, Nunes B, Alahmad B, Forsberg B, Íñiguez C, Ameling C, la Cruz Valencia C, Houthuijs D, Van Dung D, Royé D, Indermitte E, Mayvaneh F, Acquaotta F, de’Donato F, Carrasco-Escobar G, Kan H, Carlsen H, Orru H, Kim H, Holobaca I, Kyselý J, Madureira J, Schwartz J, Jaakkola J, Katsouyanni K, Diaz M, Ragettli M, Hashizume M, Pascal M, de Sousa Zanotti Stagliorio Coelho M, Ortega N, Ryti N, Scovronick N, Michelozzi P, Correa P, Goodman P, Nascimento Saldiva P, Raz R, Abrutzky R, Osorio S, Pan S, Rao S, Tong S, Achilleos S, Dang T, Colistro V, Huber V, Lee W, Seposo X, Honda Y, Kim Y, Guo Y, Li S, Guo Y (2024). Temperature frequency and mortality: Assessing adaptation to local temperature. Environment International, vol. 187, art. no. 108691.  10.1016/j.envint.2024.108691 \n\n\nAssessing the association between temperature frequency and mortality can provide insights into human adaptation to local ambient temperatures. We collected daily time-series data on mortality and temperature from 757 locations in 47 countries/regions during 1979–2020. We used a two-stage time series design to assess the association between temperature frequency and all-cause mortality. The results were pooled at the national, regional, and global levels. We observed a consistent decrease in the risk of mortality as the normalized frequency of temperature increases across the globe. The average increase in mortality risk comparing the 10th to 100th percentile of normalized frequency was 13.03% (95% CI: 12.17–13.91), with substantial regional differences (from 4.56% in Australia and New Zealand to 33.06% in South Europe). The highest increase in mortality was observed for high-income countries (13.58%, 95% CI: 12.56–14.61), followed by lower-middle-income countries (12.34%, 95% CI: 9.27–15.51). This study observed a declining risk of mortality associated with higher temperature frequency. Our findings suggest that populations can adapt to their local climate with frequent exposure, with the adapting ability varying geographically due to differences in climatic and socioeconomic characteristics. temperature adaptation frequency mortality climate change\n\n\ntemperatureadaptationfrequencymortalityclimate change\n\n\n\n\n\nMadaniyazi L, Alpízar J, Cifuentes L, Riojas-Rodríguez H, Hurtado Díaz M, de Sousa Zanotti Stagliorio Coelho M, Abrutzky R, Osorio S, Carrasco Escobar G, Valdés Ortega N, Colistro V, Royé D, Tobías A (2024). Health and Economic Benefits of Complying With the World Health Organization Air Quality Guidelines for Particulate Matter in Nine Major Latin American Cities. International Journal of Public Health, vol. 69, art. no. 1606909.  10.3389/ijph.2024.1606909 \n\n\nObjectives: This study aims to estimate the short-term preventable mortality and associated economic costs of complying with the World Health Organization (WHO) air quality guidelines (AQGs) limit values for PM10 and PM2.5 in nine major Latin American cities. Methods: We estimated city-specific PM-mortality associations using time-series regression models and calculated the attributable mortality fraction. Next, we used the value of statistical life to calculate the economic benefits of complying with the WHO AQGs limit values. Results: In most cities, PM concentrations exceeded the WHO AQGs limit values more than 90% of the days. PM10 was found to be associated with an average excess mortality of 1.88% with concentrations above WHO AQGs limit values, while for PM2.5 it was 1.05%. The associated annual economic costs varied widely, between US$ 19.5 million to 3,386.9 million for PM10, and US$ 196.3 million to 2,209.6 million for PM2.5. Conclusion: Our findings suggest that there is an urgent need for policymakers to develop interventions to achieve sustainable air quality improvements in Latin America. Complying with the WHO AQGs limit values for PM10 and PM2.5 in Latin American cities would substantially benefits for urban populations. air quality guidelines particulate matter health benefits economic benefits latin american cities\n\n\nair quality guidelinesparticulate matterhealth benefitseconomic benefitslatin american cities\n\n\n\n\n\nWen B, Wu Y, Guo Y, Gasparrini A, Tong S, Overcenco A, Urban A, Schneider A, Entezari A, Vicedo-Cabrera A, Zanobetti A, Analitis A, Zeka A, Tobias A, Nunes B, Alahmad B, Armstrong B, Forsberg B, Pan S, Íñiguez C, Ameling C, Valencia C, Åström C, Houthuijs D, Van Dung D, Royé D, Indermitte E, Lavigne E, Mayvaneh F, Acquaotta F, de’Donato F, Rao S, Sera F, Carrasco-Escobar G, Kan H, Orru H, Kim H, Holobaca I, Kyselý J, Madureira J, Schwartz J, Jaakkola J, Katsouyanni K, Diaz M, Ragettli M, Hashizume M, Pascal M, Coélho M, Ortega N, Ryti N, Scovronick N, Michelozzi P, Matus Correa P, Goodman P, Saldiva P, Raz R, Abrutzky R, Osorio S, Dang T, Colistro V, Huber V, Lee W, Seposo X, Honda Y, Kim Y, Guo Y, Bell M, Li S (2024). Comparison for the effects of different components of temperature variability on mortality: A multicountry timeseries study. Environment International, vol. 187, art. no. 108712.  10.1016/j.envint.2024.108712 \n\n\nBackground. Temperature variability (TV) is associated with increased mortality risk. However, it is still unknown whether intra-day or inter-day TV has different effects. Objectives. We aimed to assess the association of intra-day TV and inter-day TV with all-cause, cardiovascular, and respiratory mortality. Methods. We collected data on total, cardiovascular, and respiratory mortality and meteorology from 758 locations in 47 countries or regions from 1972 to 2020. We defined inter-day TV as the standard deviation (SD) of daily mean temperatures across the lag interval, and intra-day TV as the average SD of minimum and maximum temperatures on each day. In the first stage, inter-day and intra-day TVs were modelled simultaneously in the quasi-Poisson time-series model for each location. In the second stage, a multi-level analysis was used to pool the location-specific estimates. Results. Overall, the mortality risk due to each interquartile range [IQR] increase was higher for intra-day TV than for inter-day TV. The risk increased by 0.59% (95% confidence interval [CI]: 0.53, 0.65) for all-cause mortality, 0.64% (95% CI: 0.56, 0.73) for cardiovascular mortality, and 0.65% (95% CI: 0.49, 0.80) for respiratory mortality per IQR increase in intra-day TV0–7 (0.9 °C). An IQR increase in inter-day TV0–7 (1.6 °C) was associated with 0.22% (95% CI: 0.18, 0.26) increase in all-cause mortality, 0.44% (95% CI: 0.37, 0.50) increase in cardiovascular mortality, and 0.31% (95% CI: 0.21, 0.41) increase in respiratory mortality. The proportion of all-cause deaths attributable to intra-day TV0–7 and inter-day TV0–7 was 1.45% and 0.35%, respectively. The mortality risks varied by lag interval, climate area, season, and climate type. Conclusions. Our results indicated that intra-day TV may explain the main part of the mortality risk related to TV and suggested that comprehensive evaluations should be proposed in more countries to help protect human health. temperature variability mortality inter-day intra-day\n\n\ntemperature variabilitymortalityinter-dayintra-day\n\n\n\n\n\nGincheva A, Pausas J, Edwards A, Provenzale A, Cerdà A, Hanes C, Royé D, Chuvieco E, Mouillot F, Vissio G, Rodrigo J, Bedía J, Abatzoglou J, Senciales González J, Short K, Baudena M, Llasat M, Magnani M, Boer M, González M, Torres-Vázquez M, Fiorucci P, Jacklyn P, Libonati R, Trigo R, Herrera S, Jerez S, Wang X, Turco M (2024). A monthly gridded burned area database of national wildland fire data. Scientific Data, vol. 11(352).  10.1038/s41597-024-03141-2 \n\n\nWe assembled the first gridded burned area (BA) database of national wildfire data (ONFIRE), a comprehensive and integrated resource for researchers, non-government organisations, and government agencies analysing wildfires in various regions of the Earth. We extracted and harmonised records from different regions and sources using open and reproducible methods, providing data in a common framework for the whole period available (starting from 1950 in Australia, 1959 in Canada, 1985 in Chile, 1980 in Europe, and 1984 in the United States) up to 2021 on a common 1° × 1° grid. The data originate from national agencies (often, ground mapping), thus representing the best local expert knowledge. Key opportunities and limits in using this dataset are discussed as well as possible future expansions of this open-source approach that should be explored. This dataset complements existing gridded BA data based on remote sensing and offers a valuable opportunity to better understand and assess fire regime changes, and their drivers, in these regions. The ONFIRE database can be freely accessed at https://zenodo.org/record/8289245. urned area database wildland fire gridded data national fire data onfire database\n\n\nurned area databasewildland firegridded datanational fire dataonfire database\n\n\n\n\n\nChen K, de Schrijver E, Sivaraj S, Sera F, Scovronick N, Jiang L, Royé D, Lavigne E, Kyselý J, Urban A, Schneider A, Huber V, Madureira J, Mistry M, Cvijanovic I, Armstrong B, Schneider R, Tobias A, Astrom C, Guo Y, Honda Y, Abrutzky R, Tong S, de Sousa Zanotti Stagliorio Coelho M, Saldiva P, Correa P, Ortega N, Kan H, Osorio S, Orru H, Indermitte E, Jaakkola J, Ryti N, Pascal M, Katsouyanni K, Analitis A, Mayvaneh F, Entezari A, Goodman P, Zeka A, Michelozzi P, de’Donato F, Hashizume M, Alahmad B, Diaz M, De la Cruz Valencia C, Overcenco A, Houthuijs D, Ameling C, Rao S, Carrasco-Escobar G, Seposo X, da Silva S, Holobaca I, Acquaotta F, Kim H, Lee W, Íñiguez C, Forsberg B, Ragettli M, Guo Y, Pan S, Li S, Colistro V, Zanobetti A, Schwartz J, Dang T, Van Dung D, Carlsen H, Cauchi J, Achilleos S, Raz R, Gasparrini A, Vicedo-Cabrera A (2024). Impact of population aging on future temperature related mortality at different global warming levels. Nature Communications, vol. 15, art. no. 1796.  10.1038/s41467-024-45901-z \n\n\nOlder adults are generally amongst the most vulnerable to heat and cold. While temperature-related health impacts are projected to increase with global warming, the influence of population aging on these trends remains unclear. Here we show that at 1.5 °C, 2 °C, and 3 °C of global warming, heat-related mortality in 800 locations across 50 countries/areas will increase by 0.5%, 1.0%, and 2.5%, respectively; among which 1 in 5 to 1 in 4 heat-related deaths can be attributed to population aging. Despite a projected decrease in cold-related mortality due to progressive warming alone, population aging will mostly counteract this trend, leading to a net increase in cold-related mortality by 0.1%–0.4% at 1.5–3 °C global warming. Our findings indicate that population aging constitutes a crucial driver for future heat- and cold-related deaths, with increasing mortality burden for both heat and cold due to the aging population. population aging temperature-related mortality global warming levels heat and cold mortality future projections\n\n\npopulation agingtemperature-related mortalityglobal warming levelsheat and cold mortalityfuture projections\n\n\n\n\n\nGao Y, Huang W, Zhao Q, Ryti N, Armstrong B, Gasparrini A, Tong S, Pascal M, Urban A, Zeka A, Lavigne E, Madureira J, Goodman P, Huber V, Forsberg B, Kyselý J, Sera F, Guo Y, Li S, Gao Y, Huang W, Zhao Q, Ryti N, Armstrong B, Gasparrini A, Tong S, Pascal M, Urban A, Zeka A, Lavigne E, Madureira J, Goodman P, Huber V, Forsberg B, Kyselý J, Sera F, Bell M, Hales S, Honda Y, Jaakkola J, Tobias A, Vicedo-Cabrera A, Abrutzky R, Coelho M, Saldiva P, Correa P, Ortega N, Kan H, Osorio S, Royé D, Orru H, Indermitte E, Schneider A, Katsouyanni K, Analitis A, Carlsen H, Mayvaneh F, Roradeh H, Raz R, Michelozzi P, de’Donato F, Hashizume M, Kim Y, Alahmad B, Cauchy J, Diaz M, Arellano E, Valencia C, Overcenco A, Houthuijs D, Ameling C, Rao S, Carrasco G, Seposo X, Chua P, Silva S, Nunes B, Holobaca I, Cvijanovic I, Mistry M, Scovronick N, Acquaotta F, Kim H, Lee W, Íñiguez C, Åström C, Ragettli M, Guo Y, Pan S, Colistro V, Zanobetti A, Schwartz J, Dang T, Dung D, Guo Y, Li S (2024). Global, regional, and national burden of mortality associated with cold spells during 2000–19: a three stage modelling study. The Lancet Planetary Health, vol. 8(2), pp.  e108-e116.  10.1016/S2542-5196(23)00277-2 \n\n\nBackground. Exposure to cold spells is associated with mortality. However, little is known about the global mortality burden of cold spells. Methods. A three-stage meta-analytical method was used to estimate the global mortality burden associated with cold spells by means of a time series dataset of 1960 locations across 59 countries (or regions). First, we fitted the location-specific, cold spell-related mortality associations using a quasi-Poisson regression with a distributed lag non-linear model with a lag period of up to 21 days. Second, we built a multivariate meta-regression model between location-specific associations and seven predictors. Finally, we predicted the global grid-specific cold spell-related mortality associations during 2000–19 using the fitted meta-regression model and the yearly grid-specific meta-predictors. We calculated the annual excess deaths, excess death ratio (excess deaths per 1000 deaths), and excess death rate (excess deaths per 100 000 population) due to cold spells for each grid across the world. Findings.Globally, 205 932 (95% empirical CI [eCI] 162 692–250 337) excess deaths, representing 3·81 (95% eCI 2·93–4·71) excess deaths per 1000 deaths (excess death ratio), and 3·03 (2·33–3·75) excess deaths per 100 000 population (excess death rate) were associated with cold spells per year between 2000 and 2019. The annual average global excess death ratio in 2016–19 increased by 0·12 percentage points and the excess death rate in 2016–19 increased by 0·18 percentage points, compared with those in 2000–03. The mortality burden varied geographically. The excess death ratio and rate were highest in Europe, whereas these indicators were lowest in Africa. Temperate climates had higher excess death ratio and rate associated with cold spells than other climate zones. Interpretation. Cold spells are associated with substantial mortality burden around the world with geographically varying patterns. Although the number of cold spells has on average been decreasing since year 2000, the public health threat of cold spells remains substantial. The findings indicate an urgency of taking local and regional measures to protect the public from the mortality burdens of cold spells. Funding.Australian Research Council, Australian National Health and Medical Research Council, EU’s Horizon 2020 Project Exhaustion. cold spells mortality burden three-stage modelling global assessment climate impact\n\n\ncold spellsmortality burdenthree-stage modellingglobal assessmentclimate impact\n\n\n\n\n\nMadaniyazi L, Armstrong B, Tobias A, Mistry M, Bell M, Urban A, Kyselý J, Ryti N, Cvijanovic I, Ng C, Royé D, Vicedo-Cabrera A, Tong S, Lavigne E, Íñiguez C, da Silva S, Madureira J, Jaakkola J, Sera F, Honda Y, Gasparrini A, Hashizume M, Abrutzky R, Acquaotta F, Alahmad B, Analitis A, Carlsen H, Carrasco-Escobar G, de Sousa Zanotti Stagliorio Coelho M, Colistro V, Matus Correa P, Dang T, de’Donato F, Hurtado Diaz M, Dung D, Entezari A, Forsberg B, Goodman P, Guo Y, Guo Y, Holobaca I, Houthuijs D, Huber V, Indermitte E, Kan H, Katsouyanni K, Kim Y, Kim H, Lee W, Li S, Mayvaneh F, Michelozzi P, Orru H, Valdés Ortega N, Osorio S, Overcenco A, Pan S, Pascal M, Ragettli M, Rao S, Raz R, Saldiva P, Schneider A, Schwartz J, Scovronick N, Seposo X, De la Cruz Valencia C, Zanobetti A, Zeka A (2024). Seasonality of mortality under climate change: a multicountry projection study. The Lancet Planetary Health, vol. 8(2), pp.  e86-e94.  10.1016/s25425196(23)00269-3 \n\n\nBackground. Climate change can directly impact temperature-related excess deaths and might subsequently change the seasonal variation in mortality. In this study, we aimed to provide a systematic and comprehensive assessment of potential future changes in the seasonal variation, or seasonality, of mortality across different climate zones. Methods. In this modelling study, we collected daily time series of mean temperature and mortality (all causes or non-external causes only) via the Multi-Country Multi-City Collaborative (MCC) Research Network. These data were collected during overlapping periods, spanning from Jan 1, 1969 to Dec 31, 2020. We projected daily mortality from Jan 1, 2000 to Dec 31, 2099, under four climate change scenarios corresponding to increasing emissions (Shared Socioeconomic Pathways [SSP] scenarios SSP1-2.6, SSP2-4.5, SSP3-7.0, and SSP5-8.5). We compared the seasonality in projected mortality between decades by its shape, timings (the day-of-year) of minimum (trough) and maximum (peak) mortality, and sizes (peak-to-trough ratio and attributable fraction). Attributable fraction was used to measure the burden of seasonality of mortality. The results were summarised by climate zones. Findings. The MCC dataset included 126 809 537 deaths from 707 locations within 43 countries or areas. After excluding the only two polar locations (both high-altitude locations in Peru) from climatic zone assessments, we analysed 126 766 164 deaths in 705 locations aggregated in four climate zones (tropical, arid, temperate, and continental). From the 2000s to the 2090s, our projections showed an increase in mortality during the warm seasons and a decrease in mortality during the cold seasons, albeit with mortality remaining high during the cold seasons, under all four SSP scenarios in the arid, temperate, and continental zones. The magnitude of this changing pattern was more pronounced under the high-emission scenarios (SSP3-7.0 and SSP5-8.5), substantially altering the shape of seasonality of mortality and, under the highest emission scenario (SSP5-8.5), shifting the mortality peak from cold seasons to warm seasons in arid, temperate, and continental zones, and increasing the size of seasonality in all zones except the arid zone by the end of the century. In the 2090s compared with the 2000s, the change in peak-to-trough ratio (relative scale) ranged from 0·96 to 1·11, and the change in attributable fraction ranged from 0·002% to 0·06% under the SSP5-8.5 (highest emission) scenario. Interpretation. A warming climate can substantially change the seasonality of mortality in the future. Our projections suggest that health-care systems should consider preparing for a potentially increased demand during warm seasons and sustained high demand during cold seasons, particularly in regions characterised by arid, temperate, and continental climates. seasonality of mortality climate change multicountry projection temperature-related deaths future climate scenarios\n\n\nseasonality of mortalityclimate changemulticountry projectiontemperature-related deathsfuture climate scenarios\n\n\n\n\n\nRoyé D, Íñiguez C, Tobías A (2024). Comparison of Air Pollution–Mortality Associations Using Observed Particulate Matter Concentrations and Reanalysis Data in 33 Spanish Cities. Environment & Health, vol. 2(3), pp. 161-169.  10.1021/envhealth.3c00128 \n\n\nAir pollution poses a health hazard in all countries. However, complete data on ambient particulate matter (PM) concentrations are not available in all world regions. Reanalysis data is already a valuable source of exposure data in epidemiological studies examining the relationship between temperature and health. Nevertheless, the performance of reanalysis data in assessing the short-term health effects of particulate air pollution remains unclear. We assessed the performance of CAMS reanalysis (EAC4) data from the European Centre for Medium-Range Weather Forecasts, compared with daily PM concentrations from field monitoring stations, to estimate short-term exposure to PM with an aerodynamic diameter less than 10 μm (PM10) on daily mortality in 33 Spanish provincial capital cities using a two-stage time series regression design. The shape of the PM10 distribution varied substantially between PM observations and CAMS global reanalysis of atmospheric composition (EAC4) reanalysis data, with correlation ranging from 0.21 to 0.58. The pooled mortality risk for a 10 μg/m3 increase in PM10 showed similar estimates using PM concentrations {relative risks (RR) = 1.007, 95% confidence intervals (95% CI) = [1.002, 1.011]} and EAC4 reanalysis data (RR = 1.011, 95% CI = [1.006, 1.015]). However, the city-specific PM10 beta coefficients estimated using PM concentrations and EAC4 reanalysis data showed a low correlation (r = 0.22). The use of reanalysis data should be approached with caution when assessing the association between particulate matter air pollution and health outcomes, particularly in cities with small populations. air pollution particulate matter pm10 reanalysis eac4 mortality spain time series regression\n\n\nair pollutionparticulate matterpm10reanalysiseac4mortalityspaintime series regression\n\n\n\n\n2023\n\n\nStafoggia M, Michelozzi P, Schneider A, Armstrong B, Scortichini M, Rai M, Achilleos S, Alahmad B, Analitis A, Åström C, Bell M, Calleja N, Krage Carlsen H, Carrasco G, Paul Cauchi J, DSZS Coelho M, Correa P, Diaz M, Entezari A, Forsberg B, Garland R, Leon Guo Y, Guo Y, Hashizume M, Holobaca I, Íñiguez C, Jaakkola J, Kan H, Katsouyanni K, Kim H, Kyselý J, Lavigne E, Lee W, Li S, Maasikmets M, Madureira J, Mayvaneh F, Fook Sheng Ng C, Nunes B, Orru H, V Ortega N, Osorio S, Palomares A, Pan S, Pascal M, Ragettli M, Rao S, Raz R, Royé D, Ryti N, HN Saldiva P, Samoli E, Schwartz J, Scovronick N, Sera F, Tobias A, Tong S, DLC Valencia C, Maria Vicedo-Cabrera A, Urban A, Gasparrini A, Breitner S, de’ Donato F (2023). Joint effect of heat and air pollution on mortality in 620 cities of 36 countries. Environment International, vol. 181, art. no. 108258.  10.1016/j.envint.2023.108258 \n\n\nBackground. The epidemiological evidence on the interaction between heat and ambient air pollution on mortality is still inconsistent. Objectives. To investigate the interaction between heat and ambient air pollution on daily mortality in a large dataset of 620 cities from 36 countries. Methods. We used daily data on all-cause mortality, air temperature, particulate matter ≤ 10 μm (PM10), PM ≤ 2.5 μm (PM2.5), nitrogen dioxide (NO2), and ozone (O3) from 620 cities in 36 countries in the period 1995–2020. We restricted the analysis to the six consecutive warmest months in each city. City-specific data were analysed with over-dispersed Poisson regression models, followed by a multilevel random-effects meta-analysis. The joint association between air temperature and air pollutants was modelled with product terms between non-linear functions for air temperature and linear functions for air pollutants. Results. We analyzed 22,630,598 deaths. An increase in mean temperature from the 75th to the 99th percentile of city-specific distributions was associated with an average 8.9 % (95 % confidence interval: 7.1 %, 10.7 %) mortality increment, ranging between 5.3 % (3.8 %, 6.9 %) and 12.8 % (8.7 %, 17.0 %), when daily PM10 was equal to 10 or 90 μg/m3, respectively. Corresponding estimates when daily O3 concentrations were 40 or 160 μg/m3 were 2.9 % (1.1 %, 4.7 %) and 12.5 % (6.9 %, 18.5 %), respectively. Similarly, a 10 μg/m3 increment in PM10 was associated with a 0.54 % (0.10 %, 0.98 %) and 1.21 % (0.69 %, 1.72 %) increase in mortality when daily air temperature was set to the 1st and 99th city-specific percentiles, respectively. Corresponding mortality estimate for O3 across these temperature percentiles were 0.00 % (-0.44 %, 0.44 %) and 0.53 % (0.38 %, 0.68 %). Similar effect modification results, although slightly weaker, were found for PM2.5 and NO2. Conclusions. Suggestive evidence of effect modification between air temperature and air pollutants on mortality during the warm period was found in a global dataset of 620 cities. air temperature air pollution effect modification epidemiology mortality\n\n\nair temperatureair pollutioneffect modificationepidemiologymortality\n\n\n\n\n\nDíaz-Poso A, Lorenzo N, Martí A, Royé D (2023). Cold wave intensity on the Iberian Peninsula: Future climate projections. Atmospheric Research, vol. 295, art. no. 107011.  10.1016/j.atmosres.2023.107011 \n\n\nIn the context of global warming, cold waves have generated less interest in the scientific community than heat waves, despite their impacts on public health, transport infrastructures and energy consumption. The present study analyses climate change scenarios with simulations of the EURO-CORDEX project, using the Excess Cold Factor (ECF) index for the Iberian Peninsula and Balearic Islands (IPB). The dimensions of intensity, frequency, duration and spatial extent are evaluated for the near future (2021–2050) with respect to the historical period of reference (1971–2000). The projections show a significant overall decrease in all dimensions. The mean change in maximum cold wave intensity is −50% over most of the IPB as a whole in the near future (2021–2050). The largest changes occur in the interior of the Peninsula, where the decrease is around −100%. The annual mean number of cold wave days decreases for the IPB as a whole by −50% compared to 1971–2000, with the maximum extent decreasing by more than the mean, with decreases of between −2.4%/decade and − 5.5%/decade. Although a smaller number of cold waves suggests less human exposure, the acclimatisation of the population to higher temperatures will imply that cold waves will continue to pose a serious local threat. ecf cold wave intensity spatial extent climate change future projections\n\n\necfcold waveintensityspatial extentclimate changefuture projections\n\n\n\n\n\nUhl J, Royé D, Burghardt K, Aldrey Vázquez J, Borobio Sanchiz M, Leyk S (2023). HISDACES: historical settlement data compilation for Spain (1900–2020). Earth System Science Data, vol. 15(10), pp. 4713-4747.  10.5194/essd-15-4713-2023 \n\n\nMulti-temporal measurements quantifying the changes to the Earth’s surface are critical for understanding many natural, anthropogenic, and social processes. Researchers typically use remotely sensed Earth observation data to quantify and characterize such changes in land use and land cover (LULC). However, such data sources are limited in their availability prior to the 1980s. While an observational window of 40 to 50 years is sufficient to study most recent LULC changes, processes such as urbanization, land development, and the evolution of urban and coupled nature–human systems often operate over longer time periods covering several decades or even centuries. Thus, to quantify and better understand such processes, alternative historical–geospatial data sources are required that extend farther back in time. However, such data are rare, and processing is labor-intensive, often involving manual work. To overcome the resulting lack in quantitative knowledge of urban systems and the built environment prior to the 1980s, we leverage cadastral data with rich thematic property attribution, such as building usage and construction year. We scraped, harmonized, and processed over 12 000 000 building footprints including construction years to create a multi-faceted series of gridded surfaces, describing the evolution of human settlements in Spain from 1900 to 2020, at 100 m spatial and 5-year temporal resolution. These surfaces include measures of building density, built-up intensity, and built-up land use. We evaluated our data against a variety of data sources including remotely sensed human settlement data and land cover data, model-based historical land use depictions, and historical maps and historical aerial imagery and find high levels of agreement. This new data product, the Historical Settlement Data Compilation for Spain (HISDAC-ES), is publicly available (https://doi.org/10.6084/m9.figshare.22009643, Uhl et al., 2023a) and represents a rich source for quantitative, long-term analyses of the built environment and related processes over large spatial and temporal extents and at fine resolutions. historical settlement data spain land use and land cover urbanization geospatial analysis\n\n\nhistorical settlement dataspainland use and land coverurbanizationgeospatial analysis\n\n\n\n\n\nTobías A, Íñiguez C, Royé D (2023). From Research to the Development of an Innovative Application for Monitoring HeatRelated Mortality in Spain. Environment & Health, vol. 1(6). https://doi.org/10.1021/envhealth.3c00134 \n\n\nExposure to heat poses a major threat to high-risk populations by substantially contributing to increased mortality and morbidity. Heat-related mortality has been a significant concern since the summer of 2003, when Europe experienced a heatwave, leading to an excess of more than 70,000 deaths during the summer months, with 3,166 of those occurring in Spain. Heat-health early warning systems can reduce the burden of high ambient temperatures. However, the evidence of their effectiveness is limited. Therefore, developing innovative tools for real-time monitoring and forecast of health impacts from heat becomes essential for effective public health interventions and resource allocation strategies. We developed a user-friendly and accessible tool for monitoring heat-attributable mortality in Spain during the summer season between June and August. https://ficlima.shinyapps.io/mace/ heat-related mortality innovative application real-time monitoring public health spain\n\n\nheat-related mortalityinnovative applicationreal-time monitoringpublic healthspain\n\n\n\n\n\nLiu C, Chen R, Sera F, Vicedo-Cabrera A, Guo Y, Tong S, Lavigne E, Correa P, Ortega N, Achilleos S, Royé D, Jaakkola J, Ryti N, Pascal M, Schneider A, Breitner S, Entezari A, Mayvaneh F, Raz R, Honda Y, Hashizume M, Ng C, Gaio V, Madureira J, Holobaca I, Tobias A, Íñiguez C, Guo Y, Pan S, Masselot P, Bell M, Zanobetti A, Schwartz J, Gasparrini A, Kan H (2023). Interactive effects of ambient fine particulate matter and ozone on daily mortality in 372 cities: two stage time series analysis. BMJ, vol. 383, art. no. e075203.  10.1136/bmj-2023-075203 \n\n\nObjective: To investigate potential interactive effects of fine particulate matter (PM2.5) and ozone (O3) on daily mortality at global level. Design: Two stage time series analysis. Setting: 372 cities across 19 countries and regions. Population: Daily counts of deaths from all causes, cardiovascular disease, and respiratory disease. Main outcome measure: Daily mortality data during 1994-2020. Stratified analyses by co-pollutant exposures and synergy index (1 denotes the combined effect of pollutants is greater than individual effects) were applied to explore the interaction between PM2.5 and O3 in association with mortality. Results: During the study period across the 372 cities, 19.3 million deaths were attributable to all causes, 5.3 million to cardiovascular disease, and 1.9 million to respiratory disease. The risk of total mortality for a 10 μg/m3 increment in PM2.5 (lag 0-1 days) ranged from 0.47% (95% confidence interval 0.26% to 0.67%) to 1.25% (1.02% to 1.48%) from the lowest to highest fourths of O3 concentration; and for a 10 μg/m3 increase in O3 ranged from 0.04% (-0.09% to 0.16%) to 0.29% (0.18% to 0.39%) from the lowest to highest fourths of PM2.5 concentration, with significant differences between strata (P for interaction 0.001). A significant synergistic interaction was also identified between PM2.5 and O3 for total mortality, with a synergy index of 1.93 (95% confidence interval 1.47 to 3.34). Subgroup analyses showed that interactions between PM2.5 and O3 on all three mortality endpoints were more prominent in high latitude regions and during cold seasons. Conclusion: The findings of this study suggest a synergistic effect of PM2.5 and O3 on total, cardiovascular, and respiratory mortality, indicating the benefit of coordinated control strategies for both pollutants. fine particulate matter (pm2.5) ozone (o3) daily mortality two-stage time series synergistic effects\n\n\nfine particulate matter (pm2.5)ozone (o3)daily mortalitytwo-stage time seriessynergistic effects\n\n\n\n\n\nLüthi S, Fairless C, Fischer EM, Scovronick N, Armstrong B, De Sousa Zanotti Stagliorio Coelho M, Guo YL, Guo Y, Honda Y, Huber V, Kyselý J, Lavigne E, Royé D, Ryti N, Silva S, Urban A, Gasparrini A, Bresch DN, Vicedo-Cabrera AM (2023). Rapid increase in the risk of heatrelated mortality. Nature Communications, vol. 14, art. no. 4894.  10.1038/s41467-023-40599-x \n\n\nHeat-related mortality has been identified as one of the key climate extremes posing a risk to human health. Current research focuses largely on how heat mortality increases with mean global temperature rise, but it is unclear how much climate change will increase the frequency and severity of extreme summer seasons with high impact on human health. In this probabilistic analysis, we combined empirical heat-mortality relationships for 748 locations from 47 countries with climate model large ensemble data to identify probable past and future highly impactful summer seasons. Across most locations, heat mortality counts of a 1-in-100 year season in the climate of 2000 would be expected once every ten to twenty years in the climate of 2020. These return periods are projected to further shorten under warming levels of 1.5 °C and 2 °C, where heat-mortality extremes of the past climate will eventually become commonplace if no adaptation occurs. Our findings highlight the urgent need for strong mitigation and adaptation to reduce impacts on human lives. extreme heat climate change heatwaves public health risk assessment\n\n\nextreme heatclimate changeheatwavespublic healthrisk assessment\n\n\n\n\n\nHuang W, Li S, Vogt T, Xu R, Tong S, Molina T, Masselot P, Gasparrini A, Armstrong B, Pascal M, Royé D, Sheng Ng C, Vicedo-Cabrera A, Schwartz J, Lavigne E, Kan H, Goodman P, Zeka A, Hashizume M, Diaz M, De la Cruz Valencia C, Seposo X, Nunes B, Madureira J, Kim H, Lee W, Tobias A, Íñiguez C, Guo Y, Pan S, Zanobetti A, Dang T, Van Dung D, Geiger T, Otto C, Johnson A, Hales S, Yu P, Yang Z, Ritchie E, Guo Y (2023). Global shortterm mortality risk and burden associated with tropical cyclones from 1980 to 2019: a multicountry timeseries study. The Lancet Planetary Health, vol. 7(8), pp. e694-e705.  10.1016/S2542-5196(23)00143-2 \n\n\nBackground. The global spatiotemporal pattern of mortality risk and burden attributable to tropical cyclones is unclear. We aimed to evaluate the global short-term mortality risk and burden associated with tropical cyclones from 1980 to 2019. Methods. The wind speed associated with cyclones from 1980 to 2019 was estimated globally through a parametric wind field model at a grid resolution of 0·5° × 0·5°. A total of 341 locations with daily mortality and temperature data from 14 countries that experienced at least one tropical cyclone day (a day with maximum sustained wind speed associated with cyclones ≥17·5 m/s) during the study period were included. A conditional quasi-Poisson regression with distributed lag non-linear model was applied to assess the tropical cyclone–mortality association. A meta-regression model was fitted to evaluate potential contributing factors and estimate grid cell-specific tropical cyclone effects. Findings. Tropical cyclone exposure was associated with an overall 6% (95% CI 4–8) increase in mortality in the first 2 weeks following exposure. Globally, an estimate of 97 430 excess deaths (95% empirical CI [eCI] 71 651–126 438) per decade were observed over the 2 weeks following exposure to tropical cyclones, accounting for 20·7 (95% eCI 15·2–26·9) excess deaths per 100 000 residents (excess death rate) and 3·3 (95% eCI 2·4–4·3) excess deaths per 1000 deaths (excess death ratio) over 1980–2019. The mortality burden exhibited substantial temporal and spatial variation. East Asia and south Asia had the highest number of excess deaths during 1980–2019: 28 744 (95% eCI 16 863–42 188) and 27 267 (21 157–34 058) excess deaths per decade, respectively. In contrast, the regions with the highest excess death ratios and rates were southeast Asia and Latin America and the Caribbean. From 1980–99 to 2000–19, marked increases in tropical cyclone-related excess death numbers were observed globally, especially for Latin America and the Caribbean and south Asia. Grid cell-level and country-level results revealed further heterogeneous spatiotemporal patterns such as the high and increasing tropical cyclone-related mortality burden in Caribbean countries or regions. Interpretation. Globally, short-term exposure to tropical cyclones was associated with a significant mortality burden, with highly heterogeneous spatiotemporal patterns. In-depth exploration of tropical cyclone epidemiology for those countries and regions estimated to have the highest and increasing tropical cyclone-related mortality burdens is urgently needed to help inform the development of targeted actions against the increasing adverse health impacts of tropical cyclones under a changing climate. tropical cyclones short-term mortality global burden,time-series analysis spatiotemporal patterns\n\n\ntropical cyclonesshort-term mortalityglobal burden,time-series analysisspatiotemporal patterns\n\n\n\n\n\nDíaz-Poso A, Royé D, Martínez-Ibarra E (2023). Turismo y Cambio Climático: Aplicación del Holiday Climate Index (HCI:Urban) en España en los meses de verano para mediados y finales de siglo. Investigaciones Turísticas, vol. 26.  10.14198/inturi.23493 \n\n\nEn las últimas décadas el turismo ha adquirido una importancia cada vez mayor en la economía española. Con 83,5 millones de turistas en 2019, el 11.7% del PIB nacional proviene del sector turístico. El clima es uno de los principales aspectos a tener en cuenta por las personas para elegir un destino turístico. El índice Holiday Climate Index (HCI) es un indicador bioclimático que tiene en cuenta diferentes variables climáticas (temperatura, precipitación, humedad, viento y nubosidad), con el fin de determinar si las condiciones climáticas son adecuadas para las actividades turísticas de carácter urbano. Utilizando el HCI:Urban, se ha analizado la evolución de los niveles de confortabilidad climática para la Península y Baleares (PB) en verano (junio, julio y agosto) para mediados (2041-2060) y finales de siglo (2081-2100) bajo los escenarios climáticos RCP 4.5 y 8.5. Tomando como referencia el periodo 1986-2005, los resultados indican un aumento considerable del confort climático especialmente a finales de siglo en las comunidades autónomas del norte y noroeste del país, donde los valores, alcanzan la calificación de “excelente” (HCI 80-90). Paralelamente, la progresiva pérdida de confort a consecuencia del cambio climático en comunidades autónomas meridionales como Extremadura, Murcia, Andalucía e Islas Baleares, dará lugar a cambios en la distribución espacio-temporal de los flujos turísticos. Pese a que su formulación es susceptible de mejora, los datos proporcionados por el índice HCI:Urban pueden ser útiles en el desarrollo de instrumentos de planificación urbana, facilitando a las autoridades la toma de decisiones en un nuevo contexto turístico. hci (holiday climate index) cambio climático confort climático turismo españa.\n\n\nhci (holiday climate index)cambio climáticoconfort climáticoturismoespaña.\n\n\n\n\n\nLo Y, Mitchell D, Buzan J, Zscheischler J, Schneider R, Mistry M, Kyselý J, Lavigne É, da Silva S, Royé D, Urban A, Armstrong B, Gasparrini A, Vicedo‐Cabrera A (2023). Optimal heat stress metric for modelling heat‐related mortality varies from country to country. International Journal of Climatology, vol. 43(12), pp. 5553-5568.  10.1002/joc.8160 \n\n\nCombined heat and humidity is frequently described as the main driver of human heat-related mortality, more so than dry-bulb temperature alone. While based on physiological thinking, this assumption has not been robustly supported by epidemiological evidence. By performing the first systematic comparison of eight heat stress metrics (i.e., temperature combined with humidity and other climate variables) with warm-season mortality, in 604 locations over 39 countries, we find that the optimal metric for modelling mortality varies from country to country. Temperature metrics with no or little humidity modification associates best with mortality in ~40% of the studied countries. Apparent temperature (combined temperature, humidity and wind speed) dominates in another 40% of countries. There is no obvious climate grouping in these results. We recommend, where possible, that researchers use the optimal metric for each country. However, dry-bulb temperature performs similarly to humidity-based heat stress metrics in estimating heat-related mortality in present-day climate. heat stress metrics heat-related mortality country-specific analysis climate variables epidemiological evidence\n\n\nheat stress metricsheat-related mortalitycountry-specific analysisclimate variablesepidemiological evidence\n\n\n\n\n\nGestal Romaní S, Figueiras A, Royé D (2023). Effect of Temperature on Emergency Ambulance Call Outs for Cardiovascular Causes: A Scoping Review. Environment & Health, vol. 1(1). https://doi.org/10.1021/envhealth.3c00003 \n\n\nClimate change has increased interest in the effects of the thermal environment on cardiovascular health. Most studies have focused on mortality data. However, pre-hospital care data are better able to evaluate these effects, as they can register the full spectrum of the disease in real time. This scoping review aims to synthesize the epidemiological evidence regarding the effects of the thermal environment on cardiovascular morbidity in the pre-hospital setting, evaluated through ambulance calls. A staged literature search was performed using the PubMed database for the period between 1st January 2000 and 30th March 2023, using the MeSH terms “Weather” AND “Emergency Medical Services”. A total of 987 publications were identified that examined the correlation between the thermal environment and ambulance call-outs for cardiovascular causes. The studies were mostly ecological time series, with significant variability in the methodological aspects employed. An increase in the number of ambulance call-outs has been observed in association with low temperatures, both for overall cardiovascular pathologies and for certain pathological subtypes. For high temperatures, no effect has been observed in overall call-outs, although an increase has been observed during heat waves. The demand for ambulances for cardiac arrests is increased by both low and high temperatures and during heat waves. Ambulance call-outs for cardiovascular causes increase with low temperatures and heat waves, with no significant increase in the overall demand associated with high temperatures. Ambulance call-outs for cardiac arrests are the only subtype that is increased by high temperatures. cardiovascular diseases weather cold exposure heat exposure ambulance call-out emergency medical services\n\n\ncardiovascular diseasesweathercold exposureheat exposureambulance call-outemergency medical services\n\n\n\n\n\nO’Brien E, Masselot P, Sera F, Royé D, Breitner S, Ng C, de Sousa Zanotti Stagliorio Coelho M, Madureira J, Tobias A, Vicedo-Cabrera A, Bell M, Lavigne E, Kan H, Gasparrini (2023). ShortTerm Association between Sulfur Dioxide and Mortality: A Multicountry Analysis in 399 Cities. Environmental Health Perspectives, vol. 131. https://doi.org/10.1289/ehp11112 \n\n\nBackground: Epidemiological evidence on the health risks of sulfur dioxide (SO2) is more limited compared with other pollutants, and doubts remain on several aspects, such as the form of the exposure–response relationship, the potential role of copollutants, as well as the actual risk at low concentrations and possible temporal variation in risks. Objectives: Our aim was to assess the short-term association between exposure to SO2 and daily mortality in a large multilocation data set, using advanced study designs and statistical techniques. Methods: The analysis included 43,729,018 deaths that occurred in 399 cities within 23 countries between 1980 and 2018. A two-stage design was applied to assess the association between the daily concentration of SO2 and mortality counts, including first-stage time-series regressions and second-stage multilevel random-effect meta-analyses. Secondary analyses assessed the exposure–response shape and the lag structure using spline terms and distributed lag models, respectively, and temporal variations in risk using a longitudinal meta-regression. Bi-pollutant models were applied to examine confounding effects of particulate matter with an aerodynamic diameter of ≤10μ\n\n\nsulfur dioxide (so2)daily mortalitymulticountry analysisair pollutiontime-series study\n\n\n\n\n\nde Schrijver E, Royé D, Gasparrini A, Franco O, Vicedo-Cabrera A (2023). Exploring vulnerability to heat and cold across urban and rural populations in Switzerland. Environmental Research: Health, vol. 1(2), art. no. 25003.  10.1088/2752-5309/acab78 \n\n\nHeat- and cold-related mortality risks are highly variable across different geographies, suggesting a differential distribution of vulnerability factors between and within countries, which could partly be driven by urban-to-rural disparities. Identifying these drivers of risk is crucial to characterize local vulnerability and design tailored public health interventions to improve adaptation of populations to climate change. We aimed to assess how heat- and cold-mortality risks change across urban, peri-urban and rural areas in Switzerland and to identify and compare the factors associated with increased vulnerability within and between different area typologies. We estimated the heat- and cold-related mortality association using the case time-series design and distributed lag non-linear models over daily mean temperature and all-cause mortality series between 1990-2017 in each municipality in Switzerland. Then, through multivariate meta-regression, we derived pooled heat and cold-mortality associations by typology (i.e. urban/rural/peri-urban) and assessed potential vulnerability factors among a wealth of demographic, socioeconomic, topographic, climatic, land use and other environmental data. Urban clusters reported larger pooled heat-related mortality risk (at 99th percentile, vs. temperature of minimum mortality (MMT)) (relative risk=1.17(95%CI:1.10;1.24, vs peri-urban 1.03(1.00;1.06), and rural 1.03 (0.99;1.08)), but similar cold-mortality risk (at 1st percentile, vs. MMT) (1.35(1.28;1.43), vs rural 1.28(1.14;1.44) and peri-urban 1.39 (1.27-1.53)) clusters. We found different sets of vulnerability factors explaining the differential risk patterns across typologies. In urban clusters, mainly environmental factors (i.e. PM2.5) drove differences in heat-mortality association, while for peri-urban/rural clusters socio-economic variables were also important. For cold, socio-economic variables drove changes in vulnerability across all typologies, while environmental factors and ageing were other important drivers of larger vulnerability in peri-urban/rural clusters, with heterogeneity in the direction of the association. Our findings suggest that urban populations in Switzerland may be more vulnerable to heat, compared to rural locations, and different sets of vulnerability factors may drive these associations in each typology. Thus, future public health adaptation strategies should consider local and more tailored interventions rather than a one-size fits all approach. size fits all approach. vulnerability heat cold urban-rural differences switzerland\n\n\nvulnerabilityheatcoldurban-rural differencesswitzerland\n\n\n\n\n\nDíaz-Poso A, Lorenzo N, Royé D (2023). Spatiotemporal evolution of heat waves severity and expansion across the Iberian Peninsula and Balearic islands. Environmental Research, vol. 217, art. no. 114864.  10.1016/j.envres.2022.114864 \n\n\nIn the current climate change scenario, heat waves have become one of the most concerning extreme climatic events, both because of their implications for human health and the economy, and because of their increase in intensity and frequency in recent decades. This work presents for the first time a climatological analysis of heat waves in the Iberian Peninsula and Balearic Archipelago (IPB) using the Excess Heat Factor index (EHF). This index considers the factor of intensity and the acclimatization process of human body in the study of heat waves. We focused on the intensity (also called severity), duration, frequency and spatial extension of heat waves in the IPB in the 1950–2020 period. The exceptional heat wave of August 2018 was approached in a similar way to further explore the usefulness of the EHF index. We found that the EHF index identified heat wave conditions 2 days earlier than indices that used only maximum temperatures. Results showed a significant increase in intensity, duration, frequency and spatial extension of heat waves for the whole IPB for 1950–2020 period. The average extent of heat waves increased by 4.0% per decade and the maximum extent by 4.1% per decade. This trend suggested a significant increase in human exposure, droughts, fire risk and energy demand in this region in the last decades. ehf intensity severity heat wave extent duration\n\n\nehfintensityseverityheat waveextentduration\n\n\n\n\n\nAlahmad B, Khraishah H, Royé D, Vicedo-Cabrera A, Guo Y, Papatheodorou S, Achilleos S, Acquaotta F, Armstrong B, Bell M, Pan S, de Sousa Zanotti Stagliorio Coelho M, Colistro V, Dang T, Van Dung D, De’ Donato F, Entezari A, Guo Y, Hashizume M, Honda Y, Indermitte E, Íñiguez C, Jaakkola J, Kim H, Lavigne E, Lee W, Li S, Madureira J, Mayvaneh F, Orru H, Overcenco A, Ragettli M, Ryti N, Saldiva P, Scovronick N, Seposo X, Sera F, Silva S, Stafoggia M, Tobias A, Garshick E, Bernstein A, Zanobetti A, Schwartz J, Gasparrini A, Koutrakis P (2023). Associations Between Extreme Temperatures and Cardiovascular Cause Specific Mortality: Results From 27 Countries. Circulation, vol. 147(1). https://doi.org/10.1161/circulationaha.122.061832 \n\n\nBackground: Cardiovascular disease is the leading cause of death worldwide. Existing studies on the association between temperatures and cardiovascular deaths have been limited in geographic zones and have generally considered associations with total cardiovascular deaths rather than cause-specific cardiovascular deaths. Methods: We used unified data collection protocols within the Multi-Country Multi-City Collaborative Network to assemble a database of daily counts of specific cardiovascular causes of death from 567 cities in 27 countries across 5 continents in overlapping periods ranging from 1979 to 2019. City-specific daily ambient temperatures were obtained from weather stations and climate reanalysis models. To investigate cardiovascular mortality associations with extreme hot and cold temperatures, we fit case-crossover models in each city and then used a mixed-effects meta-analytic framework to pool individual city estimates. Extreme temperature percentiles were compared with the minimum mortality temperature in each location. Excess deaths were calculated for a range of extreme temperature days. Results: The analyses included deaths from any cardiovascular cause (32 154  935), ischemic heart disease (11 745 880), stroke (9 351 312), heart failure (3 673 723), and arrhythmia (670 859). At extreme temperature percentiles, heat (99th percentile) and cold (1st percentile) were associated with higher risk of dying from any cardiovascular cause, ischemic heart disease, stroke, and heart failure as compared to the minimum mortality temperature, which is the temperature associated with least mortality. Across a range of extreme temperatures, hot days (above 97.5th percentile) and cold days (below 2.5th percentile) accounted for 2.2 (95% empirical CI [eCI], 2.1–2.3) and 9.1 (95% eCI, 8.9–9.2) excess deaths for every 1000 cardiovascular deaths, respectively. Heart failure was associated with the highest excess deaths proportion from extreme hot and cold days with 2.6 (95% eCI, 2.4–2.8) and 12.8 (95% eCI, 12.2–13.1) for every 1000 heart failure deaths, respectively. Conclusions: Across a large, multinational sample, exposure to extreme hot and cold temperatures was associated with a greater risk of mortality from multiple common cardiovascular conditions. The intersections between extreme temperatures and cardiovascular health need to be thoroughly characterized in the present day—and especially under a changing climate. cardiovascular mortality extreme temperatures heat cold multi-country analysis\n\n\ncardiovascular mortalityextreme temperaturesheatcoldmulti-country analysis\n\n\n\n\n\nNottmeyer L, Armstrong B, Lowe R, Abbott S, Meakin S, O’Reilly K, von Borries R, Schneider R, Royé D, Hashizume M, Pascal M, Tobias A, Vicedo-Cabrera A, Lavigne E, Correa P, Ortega N, Kynčl J, Urban A, Orru H, Ryti N, Jaakkola J, Dallavalle M, Schneider A, Honda Y, Ng C, Alahmad B, Carrasco-Escobar G, Holobâc I, Kim H, Lee W, Íñiguez C, Bell M, Zanobetti A, Schwartz J, Scovronick N, Coélho M, Saldiva P, Diaz M, Gasparrini A, Sera F (2023). The association of COVID19 incidence with temperature, humidity, and UV radiation – A global multicity analysis. Science of The Total Environment, vol. 854, art. no. 158636.  10.1016/j.scitotenv.2022.158636 \n\n\nBackground and aim. The associations between COVID-19 transmission and meteorological factors are scientifically debated. Several studies have been conducted worldwide, with inconsistent findings. However, often these studies had methodological issues, e.g., did not exclude important confounding factors, or had limited geographic or temporal resolution. Our aim was to quantify associations between temporal variations in COVID-19 incidence and meteorological variables globally. Methods. We analysed data from 455 cities across 20 countries from 3 February to 31 October 2020. We used a time-series analysis that assumes a quasi-Poisson distribution of the cases and incorporates distributed lag non-linear modelling for the exposure associations at the city-level while considering effects of autocorrelation, long-term trends, and day of the week. The confounding by governmental measures was accounted for by incorporating the Oxford Governmental Stringency Index. The effects of daily mean air temperature, relative and absolute humidity, and UV radiation were estimated by applying a meta-regression of local estimates with multi-level random effects for location, country, and climatic zone. Results. We found that air temperature and absolute humidity influenced the spread of COVID-19 over a lag period of 15 days. Pooling the estimates globally showed that overall low temperatures (7.5 °C compared to 17.0 °C) and low absolute humidity (6.0 g/m3 compared to 11.0 g/m3) were associated with higher COVID-19 incidence (RR temp =1.33 with 95%CI: 1.08; 1.64 and RR AH =1.33 with 95%CI: 1.12; 1.57). RH revealed no significant trend and for UV some evidence of a positive association was found. These results were robust to sensitivity analysis. However, the study results also emphasise the heterogeneity of these associations in different countries. Conclusion. Globally, our results suggest that comparatively low temperatures and low absolute humidity were associated with increased risks of COVID-19 incidence. However, this study underlines regional heterogeneity of weather-related effects on COVID-19 transmission. temperature humidity uv radiation covid-19 distributed lag non-linear modelling global analysis\n\n\ntemperaturehumidityuv radiationcovid-19distributed lag non-linear modellingglobal analysis\n\n\n\n\n2022\n\n\nTobías A, Royé D, Iñiguez C (2022). Heatattributable Mortality in the Summer of 2022 in Spain. Epidemiology, vol. 34(2), pp. e5-e6.  10.1097/ede.0000000000001583 \n\n\nThe article examines heat-attributable mortality during the summer of 2022 in Spain, a period marked by exceptionally high temperatures. Using Poisson regression models with non-linear distributions, deaths attributable to moderate and extreme heat were estimated. In June, July, and August, temperatures exceeded extreme heat thresholds multiple times, resulting in a significant increase in mortality. The study highlights the importance of clearly defining reference scenarios to assess the impact of heat on health and underscores the need for adaptation measures to mitigate the effects of climate change. mortality extreme heat summer 2022 spain temperature\n\n\nmortalityextreme heatsummer 2022spaintemperature\n\n\n\n\n\nChoi H, Lee W, Royé D, Heo S, Urban A, Entezari A, Vicedo-Cabrera A, Zanobetti A, Gasparrini A, Analitis A, Tobias A, Armstrong B, Forsberg B, Íñiguez C, Åström C, Indermitte E, Lavigne E, Mayvaneh F, Acquaotta F, Sera F, Orru H, Kim H, Kyselý J, Madueira J, Schwartz J, Jaakkola J, Katsouyanni K, Diaz M, Ragettli M, Pascal M, Ryti N, Scovronick N, Osorio S, Tong S, Seposo X, Guo Y, Guo Y, Bell M (2022). Effect modification of greenness on the association between heat and mortality: A multicity multicountry study. eBioMedicine, vol. 84, art. no. 104251.  10.1016/j.ebiom.2022.104251 \n\n\nBackground. Identifying how greenspace impacts the temperature-mortality relationship in urban environments is crucial, especially given climate change and rapid urbanization. However, the effect modification of greenspace on heat-related mortality has been typically focused on a localized area or single country. This study examined the heat-mortality relationship among different greenspace levels in a global setting. Methods. We collected daily ambient temperature and mortality data for 452 locations in 24 countries and used Enhanced Vegetation Index (EVI) as the greenspace measurement. We used distributed lag non-linear model to estimate the heat-mortality relationship in each city and the estimates were pooled adjusting for city-specific average temperature, city-specific temperature range, city-specific population density, and gross domestic product (GDP). The effect modification of greenspace was evaluated by comparing the heat-related mortality risk for different greenspace groups (low, medium, and high), which were divided into terciles among 452 locations. Findings. Cities with high greenspace value had the lowest heat-mortality relative risk of 1·19 (95% CI: 1·13, 1·25), while the heat-related relative risk was 1·46 (95% CI: 1·31, 1·62) for cities with low greenspace when comparing the 99th temperature and the minimum mortality temperature. A 20% increase of greenspace is associated with a 9·02% (95% CI: 8·88, 9·16) decrease in the heat-related attributable fraction, and if this association is causal (which is not within the scope of this study to assess), such a reduction could save approximately 933 excess deaths per year in 24 countries. Interpretation. Our findings can inform communities on the potential health benefits of greenspaces in the urban environment and mitigation measures regarding the impacts of climate change. green spaces heat mortality urbanization climate change public health\n\n\ngreen spacesheat mortalityurbanizationclimate changepublic health\n\n\n\n\n\nWu Y, Li S, Zhao Q, Wen B, Gasparrini A, Tong S, Overcenco A, Urban A, Schneider A, Entezari A, Vicedo-Cabrera A, Zanobetti A, Analitis A, Zeka A, Tobias A, Nunes B, Alahmad B, Armstrong B, Forsberg B, Pan S, Íñiguez C, Ameling C, De la Cruz Valencia C, Åström C, Houthuijs D, Van Dung D, Royé D, Indermitte E, Lavigne E, Mayvaneh F, Acquaotta F, de’Donato F, Rao S, Sera F, Carrasco-Escobar G, Kan H, Orru H, Kim H, Holobaca I, Kyselý J, Madureira J, Schwartz J, Jaakkola J, Katsouyanni K, Hurtado Diaz M, Ragettli M, Hashizume M, Pascal M, de Sousa Zanotti Stagliorio Coélho M, Ortega N, Ryti N, Scovronick N, Michelozzi P, Correa P, Goodman P, Nascimento Saldiva P, Abrutzky R, Osorio S, Dang T, Colistro V, Huber V, Lee W, Seposo X, Honda Y, Guo Y, Bell M, Guo Y (2022). Global, regional, and national burden of mortality associated with shortterm temperature variability from 2000–19: a threestage modelling study. The Lancet Planetary Health, vol. 6(5), pp. e410-e421.  10.1016/S2542-5196(22)00073-0 \n\n\nBackground. Increased mortality risk is associated with short-term temperature variability. However, to our knowledge, there has been no comprehensive assessment of the temperature variability-related mortality burden worldwide. In this study, using data from the MCC Collaborative Research Network, we first explored the association between temperature variability and mortality across 43 countries or regions. Then, to provide a more comprehensive picture of the global burden of mortality associated with temperature variability, global gridded temperature data with a resolution of 0·5° × 0·5° were used to assess the temperature variability-related mortality burden at the global, regional, and national levels. Furthermore, temporal trends in temperature variability-related mortality burden were also explored from 2000–19. Methods. In this modelling study, we applied a three-stage meta-analytical approach to assess the global temperature variability-related mortality burden at a spatial resolution of 0·5° × 0·5° from 2000–19. Temperature variability was calculated as the SD of the average of the same and previous days’ minimum and maximum temperatures. We first obtained location-specific temperature variability related-mortality associations based on a daily time series of 750 locations from the Multi-country Multi-city Collaborative Research Network. We subsequently constructed a multivariable meta-regression model with five predictors to estimate grid-specific temperature variability related-mortality associations across the globe. Finally, percentage excess in mortality and excess mortality rate were calculated to quantify the temperature variability-related mortality burden and to further explore its temporal trend over two decades. Findings. An increasing trend in temperature variability was identified at the global level from 2000 to 2019. Globally, 1 753 392 deaths (95% CI 1 159 901–2 357 718) were associated with temperature variability per year, accounting for 3·4% (2·2–4·6) of all deaths. Most of Asia, Australia, and New Zealand were observed to have a higher percentage excess in mortality than the global mean. Globally, the percentage excess in mortality increased by about 4·6% (3·7–5·3) per decade. The largest increase occurred in Australia and New Zealand (7·3%, 95% CI 4·3–10·4), followed by Europe (4·4%, 2·2–5·6) and Africa (3·3, 1·9–4·6). Interpretation. Globally, a substantial mortality burden was associated with temperature variability, showing geographical heterogeneity and a slightly increasing temporal trend. Our findings could assist in raising public awareness and improving the understanding of the health impacts of temperature variability. mortality burden temperature variability climate change global analysis public health\n\n\nmortality burdentemperature variabilityclimate changeglobal analysispublic health\n\n\n\n\n\nTedim F, Leone V, Lovreglio R, Xanthopoulos G, Chas-Amil M, Ganteaume A, Efe R, Royé D, Fuerst-Bjeliš B, Nikolov N, Musa S, Milenković M, Correia F, Conedera M, Boris Pezzatti G (2022). Forest Fire Causes and Motivations in the Southern and South Eastern Europe through Experts’ Perception and Applications to Current Policies. Forests, vol. 13(4), art. no. 562.  10.3390/f13040562 \n\n\nForest fires causes and motivations are poorly understood in southern and south-eastern Europe. This research aims to identify how experts perceive the different causes of forest fires as defined in the classification proposed by the European Commission in 2013. A panel of experts (N = 271) was gathered from the EU Southern Member States (France, Greece, Italy, Portugal, and Spain) and from Central (Switzerland) and south-eastern Europe (Croatia, Serbia, Bosnia and Herzegovina, Republic of North Macedonia, and Turkey). Experts were asked to answer a questionnaire to score the importance of the 29 fire causes using a five point (1–5) Likert Scale. Agricultural burnings received the highest score, followed by Deliberate fire for profit, and Vegetation management. Most of the events stem from Negligence, whereas malicious fire setting is arguably overestimated although there are differences among the countries. This research demonstrates the importance of different techniques to enhance the knowledge of the causes of the complex anthropogenic phenomenon of forest fire occurrence. delphi method effis forest fire causes forest fire motivations likert scale anthropogenic causes\n\n\ndelphi methodeffisforest fire causesforest fire motivationslikert scaleanthropogenic causes\n\n\n\n\n\nMistry M, Schneider R, Masselot P, Royé D, Armstrong B, Kyselý J, Orru H, Sera F, Tong S, Lavigne É, Urban A, Madureira J, García-León D, Ibarreta D, Ciscar J, Feyen L, de Schrijver E, de Sousa Zanotti Stagliorio Coelho M, Pascal M, Tobias A, Alahmad B, Abrutzky R, Saldiva P, Correa P, Orteg N, Kan H, Osorio S, Indermitte E, Jaakkola J, Ryti N, Schneider A, Huber V, Katsouyanni K, Analitis A, Entezari A, Mayvaneh F, Michelozzi P, de’Donato F, Hashizume M, Kim Y, Diaz M, De la Cruz Valencia C, Overcenco A, Houthuijs D, Ameling C, Rao S, Seposo X, Nunes B, Holobaca I, Kim H, Lee W, Íñiguez C, Forsberg B, Åström C, Ragettli M, Guo Y, Chen B, Colistro V, Zanobetti A, Schwartz J, Dang T, Van Dung D, Guo Y, Vicedo-Cabrera A, Gasparrini A (2022). Comparison of weather station and climate reanalysis data for modelling temperaturerelated mortality. Scientific Reports, vol. 12, art. no. 5178.  10.1038/s41598-022-09049-4 \n\n\nEpidemiological analyses of health risks associated with non-optimal temperature are traditionally based on ground observations from weather stations that offer limited spatial and temporal coverage. Climate reanalysis represents an alternative option that provide complete spatio-temporal exposure coverage, and yet are to be systematically explored for their suitability in assessing temperature-related health risks at a global scale. Here we provide the first comprehensive analysis over multiple regions to assess the suitability of the most recent generation of reanalysis datasets for health impact assessments and evaluate their comparative performance against traditional station-based data. Our findings show that reanalysis temperature from the last ERA5 products generally compare well to station observations, with similar non-optimal temperature-related risk estimates. However, the analysis offers some indication of lower performance in tropical regions, with a likely underestimation of heat-related excess mortality. Reanalysis data represent a valid alternative source of exposure variables in epidemiological analyses of temperature-related risk. temperature-related mortality weather stations climate reanalysis health impact assessment data comparison\n\n\ntemperature-related mortalityweather stationsclimate reanalysishealth impact assessmentdata comparison\n\n\n\n\n\nWu Y, Wen B, Li S, Gasparrini A, Tong S, Overcenco A, Urban A, Schneider A, Entezari A, Vicedo-Cabrera A, Zanobetti A, Analitis A, Zeka A, Tobias A, Alahmad B, Armstrong B, Forsberg B, Íñiguez C, Ameling C, De la Cruz Valencia C, Åström C, Houthuijs D, Van Dung D, Royé D, Indermitte E, Lavigne E, Mayvaneh F, Acquaotta F, de’Donato F, Sera F, Carrasco-Escobar G, Kan H, Orru H, Kim H, Holobaca I, Kyselý J, Madureira J, Schwartz J, Katsouyanni K, Hurtado-Diaz M, Ragettli M, Hashizume M, Pascal M, de Sousa Zanotti Stagliorio Coélho M, Scovronick N, Michelozzi P, Goodman P, Nascimento Saldiva P, Abrutzky R, Osorio S, Dang T, Colistro V, Huber V, Lee W, Seposo X, Honda Y, Bell M, Guo Y (2022). Fluctuating temperature modifies heatmortality association around the globe. The Innovation, vol. 3(2), art. no. 100225.  10.1016/j.xinn.2022.100225 \n\n\nStudies have investigated the effects of heat and temperature variability (TV) on mortality. However, few assessed whether TV modifies the heat-mortality association. Data on daily temperature and mortality in the warm season were collected from 717 locations across 36 countries. TV was calculated as the standard deviation of the average of the same and previous days’ minimum and maximum temperatures. We used location-specific quasi-Poisson regression models with an interaction term between the cross-basis term for mean temperature and quartiles of TV to obtain heat-mortality associations under each quartile of TV, and then pooled estimates at the country, regional, and global levels. Results show the increased risk in heat-related mortality with increments in TV, accounting for 0.70% (95% confidence interval [CI]: −0.33 to 1.69), 1.34% (95% CI: −0.14 to 2.73), 1.99% (95% CI: 0.29–3.57), and 2.73% (95% CI: 0.76–4.50) of total deaths for Q1–Q4 (first quartile–fourth quartile) of TV. The modification effects of TV varied geographically. Central Europe had the highest attributable fractions (AFs), corresponding to 7.68% (95% CI: 5.25–9.89) of total deaths for Q4 of TV, while the lowest AFs were observed in North America, with the values for Q4 of 1.74% (95% CI: −0.09 to 3.39). TV had a significant modification effect on the heat-mortality association, causing a higher heat-related mortality burden with increments of TV. Implementing targeted strategies against heat exposure and fluctuant temperatures simultaneously would benefit public health. temperature variability heat modification effect mortality\n\n\ntemperature variabilityheatmodification effectmortality\n\n\n\n\n2021\n\n\nRoyé D, Tobías A, Figueiras A, Gestal S, Taracido M, Santurtun A, Iñiguez C (2021). Temperature related effects on respiratory medical prescriptions in Spain. Environmental Research, vol. 202, art. no. 111695.  10.1016/j.envres.2021.111695 \n\n\nBackground. The increased risk of mortality during periods of high and low temperatures has been well established. However, most of the studies used daily counts of deaths or hospitalisations as health outcomes, although they are the ones at the top of the health impact pyramid reflecting only a limited proportion of patients with the most severe cases. Objectives. This study evaluates the relationship between short-term exposure to the daily mean temperature and medication prescribed for the respiratory system in five Spanish cities. Methods. We fitted time series regression models to cause-specific medical prescriptions, including different respiratory subgroups and age groups. We included a distributed lag non-linear model with lags up to 14 days for daily mean temperature. City-specific associations were summarised as overall-cumulative exposure-response curves. Results. We found a positive association between cause-specific medical prescriptions and daily mean temperature with a non-linear inverted J- or V-shaped relationship in most cities. Between 0.3% and 0.6% of all respiratory prescriptions were attributed to cold for Madrid, Zaragoza and Pamplona, while in cities with only cold effects the attributable fractions were estimated as 19.2% for Murcia and 13.5% for Santander. Heat effects in Madrid, Zaragoza and Pamplona showed higher fractions between 8.7% and 17.2%. The estimated costs are in general higher for heat effects, showing annual values ranging between €191,905 and €311,076 for heat per 100,000 persons. Conclusions. This study provides novel evidence of the effects of the thermal environment on the prescription of medication for respiratory disorders in Spain, showing that low and high temperatures lead to an increase in the number of such prescriptions. The consumption of medication can reflect exposure to the environment with a lesser degree of severity in terms of morbidity. medical prescriptions temperature respiratory exposure spain drugs\n\n\nmedical prescriptionstemperaturerespiratoryexposurespaindrugs\n\n\n\n\n\nSera F, Armstrong B, Abbott S, Meakin S, O’Reilly K, von Borries R, Schneider R, Royé D, Hashizume M, Pascal M, Tobias A, Vicedo-Cabrera A, Hu W, Tong S, Lavigne E, Correa P, Meng X, Kan H, Kynčl J, Urban A, Orru H, Ryti N, Jaakkola J, Cauchemez S, Dallavalle M, Schneider A, Zeka A, Honda Y, Ng C, Alahmad B, Rao S, Di Ruscio F, Carrasco-Escobar G, Seposo X, Holobâcă I, Kim H, Lee W, Íñiguez C, Ragettli M, Aleman A, Colistro V, Bell M, Zanobetti A, Schwartz J, Dang T, Scovronick N, de Sousa Zanotti Stagliorio Coélho M, Diaz M, Zhang Y, Russell T, Koltai M, Kucharski A, Barnard R, Quaife M, Jarvis C, Lei J, Munday J, Chan Y, Quilty B, Eggo R, Flasche S, Foss A, Clifford S, Tully D, Edmunds W, Klepac P, Brady O, Krauer F, Procter S, Jombart T, Rosello A, Showering A, Funk S, Hellewell J, Sun F, Endo A, Williams J, Gimma A, Waterlow N, Prem K, Bosse N, Gibbs H, Atkins K, Pearson C, Jafari Y, Villabona-Arenas C, Jit M, Nightingale E, Davies N, van Zandvoort K, Liu Y, Sandmann F, Waites W, Abbas K, Medley G, Knight G, Gasparrini A, Lowe R (2021). A crosssectional analysis of meteorological factors and SARSCoV2 transmission in 409 cities across 26 countries. Nature Communications, vol. 12, art. no. 5968.  10.1038/s41467-021-25914-8 \n\n\nThere is conflicting evidence on the influence of weather on COVID-19 transmission. Our aim is to estimate weather-dependent signatures in the early phase of the pandemic, while controlling for socio-economic factors and non-pharmaceutical interventions. We identify a modest non-linear association between mean temperature and the effective reproduction number (Re) in 409 cities in 26 countries, with a decrease of 0.087 (95% CI: 0.025; 0.148) for a 10 °C increase. Early interventions have a greater effect on Re with a decrease of 0.285 (95% CI 0.223; 0.347) for a 5th - 95th percentile increase in the government response index. The variation in the effective reproduction number explained by government interventions is 6 times greater than for mean temperature. We find little evidence of meteorological conditions having influenced the early stages of local epidemics and conclude that population behaviour and government interventions are more important drivers of transmission. sars-cov-2 transmission meteorological factors temperature non-pharmaceutical interventions global analysis\n\n\nsars-cov-2 transmissionmeteorological factorstemperaturenon-pharmaceutical interventionsglobal analysis\n\n\n\n\n\nTobías A, Hashizume M, Honda Y, Sera F, Ng C, Kim Y, Royé D, Chung Y, Dang T, Kim H, Lee W, Íñiguez C, Vicedo-Cabrera A, Abrutzky R, Guo Y, Tong S, Coelho M, Saldiva P, Lavigne E, Correa P, Ortega N, Kan H, Osorio S, Kyselý J, Urban A, Orru H, Indermitte E, Jaakkola J, Ryti N, Pascal M, Huber V, Schneider A, Katsouyanni K, Analitis A, Entezari A, Mayvaneh F, Goodman P, Zeka A, Michelozzi P, de’Donato F, Alahmad B, Diaz M, De la Cruz Valencia C, Overcenco A, Houthuijs D, Ameling C, Rao S, Di Ruscio F, Carrasco G, Seposo X, Nunes B, Madureira J, Holobaca I, Scovronick N, Acquaotta F, Forsberg B, Åström C, Ragettli M, Guo Y, Chen B, Li S, Colistro V, Zanobetti A, Schwartz J, Dung D, Armstrong B, Gasparrini A (2021). Geographical Variations of the Minimum Mortality Temperature at a Global Scale. Environmental Epidemiology, vol. 5(5), art. no. e169.  10.1097/EE9.0000000000000169 \n\n\nBackground: Minimum mortality temperature (MMT) is an important indicator to assess the temperature-mortality association, indicating long-term adaptation to local climate. Limited evidence about the geographical variability of the MMT is available at a global scale. Methods: We collected data from 658 communities in 43 countries under different climates. We estimated temperature-mortality associations to derive the MMT for each community using Poisson regression with distributed lag nonlinear models. We investigated the variation in MMT by climatic zone using a mixed-effects meta-analysis and explored the association with climatic and socioeconomic indicators. Results: The geographical distribution of MMTs varied considerably by country between 14.2 and 31.1 °C decreasing by latitude. For climatic zones, the MMTs increased from alpine (13.0 °C) to continental (19.3 °C), temperate (21.7 °C), arid (24.5 °C), and tropical (26.5 °C). The MMT percentiles (MMTPs) corresponding to the MMTs decreased from temperate (79.5th) to continental (75.4th), arid (68.0th), tropical (58.5th), and alpine (41.4th). The MMTs indreased by 0.8 °C for a 1 °C rise in a community’s annual mean temperature, and by 1 °C for a 1 °C rise in its SD. While the MMTP decreased by 0.3 centile points for a 1 °C rise in a community’s annual mean temperature and by 1.3 for a 1 °C rise in its SD. Conclusions: The geographical distribution of the MMTs and MMTPs is driven mainly by the mean annual temperature, which seems to be a valuable indicator of overall adaptation across populations. Our results suggest that populations have adapted to the average temperature, although there is still more room for adaptation. adaptation climate distributed lag nonlinear models minimum mortality temperature multi-city multi-country time-series\n\n\nadaptationclimatedistributed lag nonlinear modelsminimum mortality temperaturemulti-citymulti-countrytime-series\n\n\n\n\n\nChen G, Guo Y, Yue X, Tong S, Gasparrini A, Bell M, Armstrong B, Schwartz J, Jaakkola J, Zanobetti A, Lavigne E, Nascimento Saldiva P, Kan H, Royé D, Milojevic A, Overcenco A, Urban A, Schneider A, Entezari A, Vicedo-Cabrera A, Zeka A, Tobias A, Nunes B, Alahmad B, Forsberg B, Pan S, Íñiguez C, Ameling C, De la Cruz Valencia C, Åström C, Houthuijs D, Van Dung D, Samoli E, Mayvaneh F, Sera F, Carrasco-Escobar G, Lei Y, Orru H, Kim H, Holobaca I, Kyselý J, Teixeira J, Madureira J, Katsouyanni K, Hurtado-Díaz M, Maasikmets M, Ragettli M, Hashizume M, Stafoggia M, Pascal M, Scortichini M, de Sousa Zanotti Stagliorio Coêlho M, Valdés Ortega N, Ryti N, Scovronick N, Matus P, Goodman P, Garland R, Abrutzky R, Garcia S, Rao S, Fratianni S, Dang T, Colistro V, Huber V, Lee W, Seposo X, Honda Y, Guo Y, Ye T, Yu W, Abramson M, Samet J, Li S (2021). Mortality risk attributable to wildfire related PM2·5 pollution: a global time series study in 749 locations. The Lancet Planetary Health, vol. 5(9), pp. e579-e587.  10.1016/S2542-5196(21)00200-X \n\n\nackground. Many regions of the world are now facing more frequent and unprecedentedly large wildfires. However, the association between wildfire-related PM2·5 and mortality has not been well characterised. We aimed to comprehensively assess the association between short-term exposure to wildfire-related PM2·5 and mortality across various regions of the world. Methods. For this time series study, data on daily counts of deaths for all causes, cardiovascular causes, and respiratory causes were collected from 749 cities in 43 countries and regions during 2000–16. Daily concentrations of wildfire-related PM2·5 were estimated using the three-dimensional chemical transport model GEOS-Chem at a 0·25° × 0·25° resolution. The association between wildfire-related PM2·5 exposure and mortality was examined using a quasi-Poisson time series model in each city considering both the current-day and lag effects, and the effect estimates were then pooled using a random-effects meta-analysis. Based on these pooled effect estimates, the population attributable fraction and relative risk (RR) of annual mortality due to acute wildfire-related PM2·5 exposure was calculated. Findings. 65·6 million all-cause deaths, 15·1 million cardiovascular deaths, and 6·8 million respiratory deaths were included in our analyses. The pooled RRs of mortality associated with each 10 μg/m3 increase in the 3-day moving average (lag 0–2 days) of wildfire-related PM2·5 exposure were 1·019 (95% CI 1·016–1·022) for all-cause mortality, 1·017 (1·012–1·021) for cardiovascular mortality, and 1·019 (1·013–1·025) for respiratory mortality. Overall, 0·62% (95% CI 0·48–0·75) of all-cause deaths, 0·55% (0·43–0·67) of cardiovascular deaths, and 0·64% (0·50–0·78) of respiratory deaths were annually attributable to the acute impacts of wildfire-related PM2·5 exposure during the study period. Interpretation. Short-term exposure to wildfire-related PM2·5 was associated with increased risk of mortality. Urgent action is needed to reduce health risks from the increasing wildfires. wildfire-related pm2.5 mortality risk global analysis cardiovascular mortality respiratory mortality\n\n\nwildfire-related pm2.5mortality riskglobal analysiscardiovascular mortalityrespiratory mortality\n\n\n\n\n\nLorenzo N, Díaz-Poso A, Royé D (2021). Heatwave intensity on the Iberian Peninsula: Future climate projections. Atmospheric Research, vol. 258(15), art. no. 105655.  10.1016/j.atmosres.2021.105655 \n\n\nHeatwaves are the most relevant extreme climatic events, particularly in the context of global warming and the related increasing impacts on society and the natural environment. This work presents an analysis of climate change scenarios with simulations from the EURO-CORDEX project using the excess heat factor over the Iberian Peninsula. We focus on climate change projections of the heatwave intensity and spatial distribution, which are evaluated for the near future (2021–2050) relative to a reference past climate (1971–2000). Heatwave projections show a general significant increase in intensity, frequency, duration and spatial extent for the whole region. The average change in heatwave intensity is 104% for the whole Iberian Peninsula for the near future 2021–2050. The largest changes occur in the eastern-central region, rising to 150% for the Mediterranean coast and the Pyrenees. The greater spatial extent of heatwaves strongly suggests increased human exposure, increased energy demand, and implications for fire risk. This spatial trend is predicted to continue in the near future with increases in the maximum spatial heatwave extent ranging from 6% to 8% per decade. heatwaves climate change iberian peninsula temperature projections extreme weather\n\n\nheatwavesclimate changeiberian peninsulatemperature projectionsextreme weather\n\n\n\n\n\nMathbout S, Lopez-Bustins J, Royé D, Martin-Vide J (2021). Mediterranean Scale Drought: Regional Datasets for Exceptional Meteorological Drought Events during 1975–2019. Atmosphere, vol. 12(8), art. no. 941.  10.3390/atmos12080941 \n\n\nDrought is one of the most complex climate-related phenomena and is expected to progressively affect our lives by causing very serious environmental and socioeconomic damage by the end of the 21st century. In this study, we have extracted a dataset of exceptional meteorological drought events between 1975 and 2019 at the country and subregional scales. Each drought event was described by its start and end date, intensity, severity, duration, areal extent, peak month and peak area. To define such drought events and their characteristics, separate analyses based on three drought indices were performed at 12-month timescale: the Standardized Precipitation Index (SPI), the Standardized Precipitation Evapotranspiration Index (SPEI), and the Reconnaissance Drought Index (RDI). A multivariate combined drought index (DXI) was developed by merging the previous three indices for more understanding of droughts’ features at the country and subregional levels. Principal component analysis (PCA) was used to identify five different drought subregions based on DXI-12 values for 312 Mediterranean stations and a new special score was defined to classify the multi-subregional exceptional drought events across the Mediterranean Basin (MED). The results indicated that extensive drought events occurred more frequently since the late 1990s, showing several drought hotspots in the last decades in the southeastern Mediterranean and northwest Africa. In addition, the results showed that the most severe events were more detected when more than single drought index was used. The highest percentage area under drought was also observed through combining the variations of three drought indices. Furthermore, the drought area in both dry and humid areas in the MED has also experienced a remarkable increase since the late 1990s. Based on a comparison of the drought events during the two periods—1975–1996 and 1997–2019—we find that the current dry conditions in the MED are more severe, intense, and frequent than the earlier period; moreover, the strongest dry conditions occurred in last two decades. The SPEI-12 and RDI-12 have a higher capacity in providing a more comprehensive description of the dry conditions because of the inclusion of temperature or atmospheric evaporative demand in their scheme. A complex range of atmospheric circulation patterns, particularly the Western Mediterranean Oscillation (WeMO) and East Atlantic/West Russia (EATL/WRUS), appear to play an important role in severe, intense and region-wide droughts, including the two most severe droughts, 1999–2001 and 2007–2012, with lesser influence of the NAO, ULMO and SCAND. climate change drought event mediterranean basin meteorological drought spei spi rdi dxi\n\n\nclimate changedrought eventmediterranean basinmeteorological droughtspeispirdidxi\n\n\n\n\n\nMartí Ezpeleta A, Royé D (2021). Intensidad y duración del estrés térmico en verano en el área urbana de Madrid. Geographicalia, vol. 73.  10.26754/ojs_geoph/geoph.2021735202 \n\n\nEn este trabajo se aplica una metodología nueva al estudio de las noches calurosas, también denominadas “tropicales”, en el área metropolitana de Madrid, de cara a evaluar desde una perspectiva temporal y espacial aquellas noches en las que la población pueda verse afectada por estrés térmico. La utilización de dos indicadores obtenidos a través de datos horarios, junto a la información climática suministrada por el modelo UrbClim, ha permitido conocer a una escala de detalle las características térmicas de las noches del mes de julio entre 2008 y 2017, pudiendo así evaluar con más precisión el riesgo para el bienestar y la salud de la población. Los resultados muestran una gran variabilidad interurbana en cuanto a intensidad y duración del estrés térmico, así como una correlación significativa entre las intensidades de la isla de calor y los índices de exceso de calor. Asimismo se ha comprobado la existencia de una estrecha relación entre las tipologías de usos del suelo y estructuras urbanas definidas en el Urban Atlas, y los índices de exceso de calor nocturno. noche calurosa estrés térmico isla de calor urbclim madrid\n\n\nnoche calurosaestrés térmicoisla de calorurbclimmadrid\n\n\n\n\n\nZhao Q, Guo Y, Ye T, Gasparrini A, Tong S, Overcenco A, Urban A, Schneider A, Entezari A, Vicedo-Cabrera A, Zanobetti A, Analitis A, Zeka A, Tobias A, Nunes B, Alahmad B, Armstrong B, Forsberg B, Pan S, Íñiguez C, Ameling C, De la Cruz Valencia C, Åström C, Houthuijs D, Dung D, Royé D, Indermitte E, Lavigne E, Mayvaneh F, Acquaotta F, de’Donato F, Di Ruscio F, Sera F, Carrasco-Escobar G, Kan H, Orru H, Kim H, Holobaca I, Kyselý J, Madureira J, Schwartz J, Jaakkola J, Katsouyanni K, Hurtado Diaz M, Ragettli M, Hashizume M, Pascal M, de Sousa Zanotti Stagliorio Coélho M, Valdés Ortega N, Ryti N, Scovronick N, Michelozzi P, Matus Correa P, Goodman P, Nascimento Saldiva P, Abrutzky R, Osorio S, Rao S, Fratianni S, Dang T, Colistro V, Huber V, Lee W, Seposo X, Honda Y, Guo Y, Bell M, Li S (2021). Global, regional, and national burden of mortality associated with nonoptimal ambient temperatures from 2000 to 2019: a threestage modelling study. The Lancet Planetary Health, vol. 5(7), pp. e415-e425.  10.1016/S2542-5196(21)00081-4 \n\n\nBackground. Exposure to cold or hot temperatures is associated with premature deaths. We aimed to evaluate the global, regional, and national mortality burden associated with non-optimal ambient temperatures. Methods. In this modelling study, we collected time-series data on mortality and ambient temperatures from 750 locations in 43 countries and five meta-predictors at a grid size of 0·5° × 0·5° across the globe. A three-stage analysis strategy was used. First, the temperature–mortality association was fitted for each location by use of a time-series regression. Second, a multivariate meta-regression model was built between location-specific estimates and meta-predictors. Finally, the grid-specific temperature–mortality association between 2000 and 2019 was predicted by use of the fitted meta-regression and the grid-specific meta-predictors. Excess deaths due to non-optimal temperatures, the ratio between annual excess deaths and all deaths of a year (the excess death ratio), and the death rate per 100 000 residents were then calculated for each grid across the world. Grids were divided according to regional groupings of the UN Statistics Division. Findings. Globally, 5 083 173 deaths (95% empirical CI [eCI] 4 087 967–5 965 520) were associated with non-optimal temperatures per year, accounting for 9·43% (95% eCI 7·58–11·07) of all deaths (8·52% [6·19–10·47] were cold-related and 0·91% [0·56–1·36] were heat-related). There were 74 temperature-related excess deaths per 100 000 residents (95% eCI 60–87). The mortality burden varied geographically. Of all excess deaths, 2 617 322 (51·49%) occurred in Asia. Eastern Europe had the highest heat-related excess death rate and Sub-Saharan Africa had the highest cold-related excess death rate. From 2000–03 to 2016–19, the global cold-related excess death ratio changed by −0·51 percentage points (95% eCI −0·61 to −0·42) and the global heat-related excess death ratio increased by 0·21 percentage points (0·13–0·31), leading to a net reduction in the overall ratio. The largest decline in overall excess death ratio occurred in South-eastern Asia, whereas excess death ratio fluctuated in Southern Asia and Europe. Interpretation. Non-optimal temperatures are associated with a substantial mortality burden, which varies spatiotemporally. Our findings will benefit international, national, and local communities in developing preparedness and prevention strategies to reduce weather-related impacts immediately and under climate change scenarios. mortality burden non-optimal temperatures climate change global analysis public health\n\n\nmortality burdennon-optimal temperaturesclimate changeglobal analysispublic health\n\n\n\n\n\nWright B, Laffineur B, Royé D, Armstrong G, Fensham R (2021). Rainfall Linked Megafires as Innate Fire Regime Elements in Arid Australian Spinifex (Triodia spp.) Grasslands. Frontiers in Ecology and Evolution, vol. 9.  10.3389/fevo.2021.666241 \n\n\nLarge, high-severity wildfires, or “megafires,” occur periodically in arid Australian spinifex (Triodia spp.) grasslands after high rainfall periods that trigger fuel accumulation. Proponents of the patch-burn mosaic (PBM) hypothesis suggest that these fires are unprecedented in the modern era and were formerly constrained by Aboriginal patch burning that kept landscape fuel levels low. This assumption deserves scrutiny, as evidence from fire-prone systems globally indicates that weather factors are the primary determinant behind megafire incidence, and that fuel management does not mitigate such fires during periods of climatic extreme. We reviewed explorer’s diaries, anthropologist’s reports, and remotely sensed data from the Australian Western Desert for evidence of large rainfall-linked fires during the pre-contact period when traditional Aboriginal patch burning was still being practiced. We used only observations that contained empiric estimates of fire sizes. Concurrently, we employed remote rainfall data and the Oceanic Niño Index to relate fire size to likely seasonal conditions at the time the observations were made. Numerous records were found of small fires during periods of average and below-average rainfall conditions, but no evidence of large-scale fires during these times. By contrast, there was strong evidence of large-scale wildfires during a high-rainfall period in the early 1870s, some of which are estimated to have burnt areas up to 700,000 ha. Our literature review also identified several Western Desert Aboriginal mythologies that refer to large-scale conflagrations. As oral traditions sometimes corroborate historic events, these myths may add further evidence that large fires are an inherent feature of spinifex grassland fire regimes. Overall, the results suggest that, contrary to predictions of the PBM hypothesis, traditional Aboriginal burning did not modulate spinifex fire size during periods of extreme-high arid zone rainfall. The mechanism behind this is that plant assemblages in seral spinifex vegetation comprise highly flammable non-spinifex tussock grasses that rapidly accumulate high fuel loads under favorable precipitation conditions. Our finding that fuel management does not prevent megafires under extreme conditions in arid Australia has parallels with the primacy of climatic factors as drivers of megafires in the forests of temperate Australia. megafires rainfall spinifex grasslands fire regimes aboriginal burning\n\n\nmegafiresrainfallspinifex grasslandsfire regimesaboriginal burning\n\n\n\n\n\nVicedo-Cabrera A M, Scovronick N, Sera F, Royé D, Schneider R, Tobias A, Astrom C, Guo Y, Honda Y, Hondula D M, Abrutzky R, Tong S, Coelho M de Sousa Zanotti Stagliorio, Saldiva P H Nascimento, Lavigne E, Correa P Matus, Ortega N Valdes, Kan H, Osorio S, Kyselý J, Urban A, Orru H, Indermitte E, Jaakkola J J K, Ryti N, Pascal M, Schneider A, Katsouyanni K, Samoli E, Mayvaneh F, Entezari A, Goodman P, Zeka A, Michelozzi P, de’Donato F, Hashizume M, Alahmad B, Diaz M Hurtado, Valencia C De La Cruz, Overcenco A, Houthuijs D, Ameling C, Rao S, Di Ruscio F, Carrasco-Escobar G, Seposo X, Silva S, Madureira J, Holobaca I H, Fratianni S, Acquaotta F, Kim H, Lee W, Iniguez C, Forsberg B, Ragettli M S, Guo Y L L, Chen B Y, Li S, Armstrong B, Aleman A, Zanobetti A, Schwartz J, Dang T N, Dung D V, Gillett N, Haines A, Mengel M, Huber V, Gasparrini A (2021). The burden of heatrelated mortality attributable to recent humaninduced climate change. Nature Climate Change, vol. 11, pp. 492-500.  10.1038/s41558-021-01058-x \n\n\nClimate change affects human health; however, there have been no large-scale, systematic efforts to quantify the heat-related human health impacts that have already occurred due to climate change. Here, we use empirical data from 732 locations in 43 countries to estimate the mortality burdens associated with the additional heat exposure that has resulted from recent human-induced warming, during the period 1991–2018. Across all study countries, we find that 37.0% (range 20.5–76.3%) of warm-season heat-related deaths can be attributed to anthropogenic climate change and that increased mortality is evident on every continent. Burdens varied geographically but were of the order of dozens to hundreds of deaths per year in many locations. Our findings support the urgent need for more ambitious mitigation and adaptation strategies to minimize the public health impacts of climate change. heat-related mortality climate change anthropogenic warming global analysis public health\n\n\nheat-related mortalityclimate changeanthropogenic warmingglobal analysispublic health\n\n\n\n\n\nde Schrijver E, Folly C, Schneider R, Royé D, Franco O, Gasparrini A, Vicedo‐Cabrera A (2021). A Comparative Analysis of the Temperature‐Mortality Risks Using Different Weather Datasets Across Heterogeneous Regions. GeoHealth, vol. 5(5). https://doi.org/10.1029/2020GH000363 \n\n\nNew gridded climate datasets (GCDs) on spatially resolved modeled weather data have recently been released to explore the impacts of climate change. GCDs have been suggested as potential alternatives to weather station data in epidemiological assessments on health impacts of temperature and climate change. These can be particularly useful for assessment in regions that have remained understudied due to limited or low quality weather station data. However to date, no study has critically evaluated the application of GCDs of variable spatial resolution in temperature-mortality assessments across regions of different orography, climate, and size. Here we explored the performance of population-weighted daily mean temperature data from the global ERA5 reanalysis dataset in the 10 regions in the United Kingdom and the 26 cantons in Switzerland, combined with two local high-resolution GCDs (HadUK-grid UKPOC-9 and MeteoSwiss-grid-product, respectively) and compared these to weather station data and unweighted homologous series. We applied quasi-Poisson time series regression with distributed lag nonlinear models to obtain the GCD- and region-specific temperature-mortality associations and calculated the corresponding cold- and heat-related excess mortality. Although the five exposure datasets yielded different average area-level temperature estimates, these deviations did not result in substantial variations in the temperature-mortality association or impacts. Moreover, local population-weighted GCDs showed better overall performance, suggesting that they could be excellent alternatives to help advance knowledge on climate change impacts in remote regions with large climate and population distribution variability, which has remained largely unexplored in present literature due to the lack of reliable exposure data. temperature-related mortality weather datasets heterogeneous regions climate data health impact assessment\n\n\ntemperature-related mortalityweather datasetsheterogeneous regionsclimate datahealth impact assessment\n\n\n\n\n\nRoyé D, Sera F, Tobías A, Lowe R, Gasparrini A, Pascal M, de’Donato F, Nunes B, Teixeira J (2021). Effects of Hot Nights on Mortality in Southern Europe. Epidemiology, vol. 32(4), pp. 487-498.  10.1097/ede.0000000000001359 \n\n\nBackground: There is strong evidence concerning the impact of heat stress on mortality, particularly from high temperatures. However, few studies to our knowledge emphasize the importance of hot nights, which may prevent necessary nocturnal rest. Objectives: In this study, we use hot-night duration and excess to predict daily cause-specific mortality in summer, using multiple cities across Southern Europe. Methods: We fitted time series regression models to summer cause-specific mortality, including natural, respiratory, and cardiovascular causes, in 11 cities across four countries. We included a distributed lag nonlinear model with lags up to 7 days for hot night duration and excess adjusted by daily mean temperature. We summarized city-specific associations as overall-cumulative exposure–response curves at the country level using meta-analysis. Results: We found positive but generally nonlinear associations between relative risk (RR) of cause-specific mortality and duration and excess of hot nights. RR of duration associated with nonaccidental mortality in Portugal was 1.29 (95% confidence interval [CI] = 1.07, 1.54); other associations were imprecise, but we also found positive city-specific estimates for Rome and Madrid. Risk of hot-night excess ranged from 1.12 (95% CI = 1.05, 1.20) for France to 1.37 (95% CI = 1.26, 1.48) for Portugal. Risk estimates for excess were consistently higher than for duration. Conclusions: This study provides new evidence that, over a wider range of locations, hot night indices are strongly associated with cause-specific deaths. Modeling the impact of thermal characteristics during summer nights on mortality could improve decisionmaking for preventive public health strategies. hot nights mortality southern europe heat stress public health\n\n\nhot nightsmortalitysouthern europeheat stresspublic health\n\n\n\n\n\nFdez-Arróyabe P, Marti-Ezpeleta A, Royé D, Zarrabeitia A (2021). Effects of circulation weather types on influenza hospital admissions in Spain. International Journal of Biometeorology, vol. 65.  10.1007/s00484-021-02107-y \n\n\nIn this study, we use a statistical approach based on generalized additive models, linking atmospheric circulation and the number of influenza-related hospital admissions in the Spanish Iberian Peninsula during 2003–2013. The relative risks are estimated for administrative units in the Spanish territory, which is politically structured into 15 regions called autonomous communities. A catalog of atmospheric circulation types is defined for this purpose. The relationship between the exposure and response variables is modeled using a distributed lag nonlinear model (DLNM). Types from southwest and anticyclonic are significant in terms of the probability of having more influenza-related hospital admissions for all of Spain. The heterogeneity of the results is very high. The relative risk is also estimated for each autonomous community and weather type, with the maximum number of influenza-related hospital admissions associated with circulation types from the southwest and the south. We identify six specific situations where relative risk is considered extreme and twelve with a high risk of increasing influenza-related hospital admissions. The rest of the situations present a moderate risk. Atmospheric local conditions become a key factor for understanding influenza spread in each spatial unit of the Peninsula. Further research is needed to understand how different weather variables (temperature, humidity, and sun radiation) interact and promote the spread of influenza. influenza atmospheric circulation hospital admissions spain weather types\n\n\ninfluenzaatmospheric circulationhospital admissionsspainweather types\n\n\n\n\n\nIñiguez C, Royé D, Tobías A (2021). Contrasting patterns of temperature related mortality and hospitalization by cardiovascular and respiratory diseases in 52 Spanish cities. Environmental Research, vol. 192, art. no. 110191.  10.1016/j.envres.2020.110191 \n\n\nBackground. Climate change is a severe public health challenge. Understanding to what extent fatal and non-fatal consequences of specific diseases are associated with temperature may help to improve the effectiveness of preventive public health efforts. This study examines the effects of temperature on deaths and hospital admissions by cardiovascular and respiratory diseases, empathizing the difference between mortality and morbidity. Methods. Daily counts for mortality and hospital admissions by cardiovascular and respiratory diseases were collected for the 52 provincial capital cities in Spain, between 1990 and 2014. The association with temperature in each city was investigated by means of distributed lag non-linear models using quasi-Poisson regression. City-specific exposure-response curves were pooled by multivariate random-effects meta-analysis to obtain countrywide risk estimates of mortality and hospitalizations due to heat and cold, and attributable fractions were computed. Results. Heat and cold exposure were identified to be associated with increased risk of cardiovascular and respiratory mortality. Heat was not found to have an impact on hospital admissions. The estimated fraction of mortality attributable to cold was of greater magnitude in hospitalizations (17.5% for cardiovascular and 12.5% for respiratory diseases) compared to deaths (9% and 2.7%, respectively). Conclusions. There were noteworthy differences between temperature-related mortality and hospital admissions regarding cardiovascular and respiratory diseases, hence reinforcing the convenience of cause-specific measures to prevent temperature-related deaths. temperature-related mortality hospital admissions cardiovascular diseases, respiratory diseases spain\n\n\ntemperature-related mortalityhospital admissionscardiovascular diseasesrespiratory diseasesspain\n\n\n\n\n2020\n\n\nRomani S, Royé D, Sánchez Santos L, Figueiras A (2020). Impact of Extreme Temperatures on Ambulance Dispatches Due to Cardiovascular Causes in NorthWest Spain. International Journal of Environmental Research and Public Health, vol. 17(23), art. no. 9001.  10.3390/ijerph17239001 \n\n\nIntroduction and objectives. The increase in mortality and hospital admissions associated with high and low temperatures is well established. However, less is known about the influence of extreme ambient temperature conditions on cardiovascular ambulance dispatches. This study seeks to evaluate the effects of minimum and maximum daily temperatures on cardiovascular morbidity in the cities of Vigo and A Coruña in North-West Spain, using emergency medical calls during the period 2005–2017. Methods. For the purposes of analysis, we employed a quasi-Poisson time series regression model, within a distributed non-linear lag model by exposure variable and city. The relative risks of cold- and heat-related calls were estimated for each city and temperature model. Results. A total of 70,537 calls were evaluated, most of which were associated with low maximum and minimum temperatures on cold days in both cities. At maximum temperatures, significant cold-related effects were observed at lags of 3–6 days in Vigo and 5–11 days in A Coruña. At minimum temperatures, cold-related effects registered a similar pattern in both cities, with significant relative risks at lags of 4 to 12 days in A Coruña. Heat-related effects did not display a clearly significant pattern. Conclusions. An increase in cardiovascular morbidity is observed with moderately low temperatures without extremes being required to establish an effect. Public health prevention plans and warning systems should consider including moderate temperature range in the prevention of cardiovascular morbidity. ambulance dispatches extreme temperature galicia cardiovascular diseases quasi-poisson regression model\n\n\nambulance dispatchesextreme temperaturegaliciacardiovascular diseasesquasi-poisson regression model\n\n\n\n\n\nFdez-Arroyabe P, Kourtidis K, Haldoupis C, Savoska S, Matthews J, Mir L, Kassomenos P, Cifra M, Barbosa S, Chen X, Dragovic S, Consoulas C, Hunting E, Robert D, van der Velde O, Apollonio F, Odzimek A, Chilingarian A, Royé D, Mkrtchyan H, Price C, Bór J, Oikonomou C, Birsan M, Crespo-Facorro B, Djordjevic M, Salcines C, López-Jiménez A, Donner R, Vana M, Pedersen J, Vorenhout M, Rycroft M (2020). Glossary on atmospheric electricity and its effects on biology. International Journal of Biometeorology, vol. 65, pp. 5-29.  10.1007/s00484-020-02013-9 \n\n\nThere is an increasing interest to study the interactions between atmospheric electrical parameters and living organisms at multiple scales. So far, relatively few studies have been published that focus on possible biological effects of atmospheric electric and magnetic fields. To foster future work in this area of multidisciplinary research, here we present a glossary of relevant terms. Its main purpose is to facilitate the process of learning and communication among the different scientific disciplines working on this topic. While some definitions come from existing sources, other concepts have been re-defined to better reflect the existing and emerging scientific needs of this multidisciplinary and transdisciplinary area of research. atmospheric electric field (aef) schumann resonances biological processes electromagnetic interference multidisciplinary research\n\n\natmospheric electric field (aef)schumann resonancesbiological processeselectromagnetic interferencemultidisciplinary research\n\n\n\n\n\nSanturtún A, Almendra R, Fdez-Arroyabe P, Sanchez-Lorenzo A, Royé D, Zarrabeitia M, Santana P (2020). Predictive value of three thermal comfort indices in low temperatures on cardiovascular morbidity in the Iberian peninsula. Science of The Total Environment, vol. 729, art. no. 138969.  10.1016/j.scitotenv.2020.138969 \n\n\nThe natural environment has been considered an important determinant of cardiovascular morbidity. This work seeks to assess the impact of the winter thermal environment on hospital admissions from diseases of the circulatory system by using three biometeorological indices in five regions of the Iberian Peninsula. A theoretical index based on a thermophysiological model (Universal Thermal Climate Index [UTCI]) and two experimental biometeorological ones (Net Effective Temperature [NET] and Apparent Temperature [AT]) were estimated in two metropolitan areas of Portugal (Porto and Lisbon) and in three provinces of Spain (Madrid, Barcelona and Valencia). Subsequently, their relationship with hospital admissions, adjusted by NO2 concentration, time, and day of the week, was analyzed using a Generalized Additive Model. As the estimation method, a semi-parametric quasi-Poisson regression was used. Around 53% of the hospitalizations occurred during the cold periods. The admissions rate followed an upward trend over the 9-year period in both capitals (Madrid and Lisbon) as well as in Barcelona. An inverse and statistically significant relationship was found between thermal comfort and hospital admissions in the five regions (p  0.001). The highest relative risk (RR) was found after a cumulative 7-day exposure in Lisbon, where there was a 1.4% increase in hospital admissions for each NET and AT degree Celsius, and 1.0% for each UTCI degree Celsius. In conclusion, low air temperatures are a significant risk factor for hospital admissions from diseases of the circulatory system in the Iberian Peninsula, regardless of the index calculated. thermal comfort indices low temperatures cardiovascular morbidity iberian peninsula health impacts\n\n\nthermal comfort indiceslow temperaturescardiovascular morbidityiberian peninsulahealth impacts\n\n\n\n\n\nRoyé D, Íñiguez C, Tobías A (2020). Comparison of temperature–mortality associations using observed weather station and reanalysis data in 52 Spanish cities. Environmental Research, vol. 183, art. no. 109237.  10.1016/j.envres.2020.109237 \n\n\nBackground. Most studies use temperature observation data from weather stations near the analyzed region or city as the reference point for the exposure-response association. Climatic reanalysis data sets have already been used for climate studies, but are not yet used routinely in environmental epidemiology. Methods. We compared the mortality-temperature association using weather station temperature and ERA-5 reanalysis data for the 52 provincial capital cities in Spain, using time-series regression with distributed lag non-linear models. Results. The shape of temperature distribution is very close between the weather station and ERA-5 reanalysis data (correlation from 0.90 to 0.99). The overall cumulative exposure-response curves are very similar in their shape and risks estimates for cold and heat effects, although risk estimates for ERA-5 were slightly lower than for weather station temperature. Conclusions. Reanalysis data allow the estimation of the health effects of temperature, even in areas located far from weather stations or without any available. temperature-mortality weather stations reanalysis data time-series regression distributed lag non-linear models\n\n\ntemperature-mortalityweather stationsreanalysis datatime-seriesregression distributed lag non-linear models\n\n\n\n\n\nRoyé D, Codesido R, Tobías A, Taracido M (2020). Heat wave intensity and daily mortality in four of the largest cities of Spain. Environmental Research, vol. 182, art. no. 109027.  10.1016/j.envres.2019.109027 \n\n\nIn the current context of climate change, heat waves have become a significant problem for human health. This study assesses the effects of heat wave intensity on mortality (natural, respiratory and cardiovascular causes) in four of the largest cities of Spain (Barcelona, Bilbao, Madrid and Seville) during the period between 1990 and 2014. To model the heat wave severity the Excess Heat Factor (EHF) was used. The EHF is a two-component index. The first is the comparison of the three-day average daily mean temperature with the 95th percentile. The second component is a measure of the temperatures reached during the three-day period compared with the recent past (the previous 30 days). The city-specific exposure-response curves showed a non-linear J-shaped relationship between mortality and the EHF. Overall city-specific mortality risk estimates in natural causes for 1st vs. 99th percentile increases range from the highest mortality risk with 2.73 (95% CI: 2.34-3.18) in Seville to a risk of 1.78 (95% CI: 1.62-1.97) and 1.78 (95% CI: 1.45-2.19) in Barcelona and Bilbao, respectively. When we compare our results with risk estimates for the analyzed Spanish cities in other studies, the heat wave related mortality risks seem to be clearly higher. Furthermore, it has been demonstrated that different heat wave days of the same event do not present the same degree of severity/intensity. Thus, the intensity of a heat wave is an important mortality risk indicator during heat wave days. Due to the low number of studies on the EHF as a heat wave intensity indicator and heat-related mortality and morbidity, further research is required to validate its application in other geographic areas and focus populations. apparent temperature excess heat factor heat effects intensity mortality spain\n\n\napparent temperatureexcess heat factorheat effectsintensitymortalityspain\n\n\n\n\n\nMonjo R, Royé D, Martin-Vide J (2020). Meteorological drought lacunarity around the world and its classification. Earth System Science Data, vol. 12(1), pp. 741-752.  10.5194/essd-12-741-2020 \n\n\nThe measure of drought duration strongly depends on the definition considered. In meteorology, dryness is habitually measured by means of fixed thresholds (e.g. 0.1 or 1 mm usually define dry spells) or climatic mean values (as is the case of the standardised precipitation index), but this also depends on the aggregation time interval considered. However, robust measurements of drought duration are required for analysing the statistical significance of possible changes. Herein we climatically classified the drought duration around the world according to its similarity to the voids of the Cantor set. Dryness time structure can be concisely measured by the n index (from the regular or irregular alternation of dry or wet spells), which is closely related to the Gini index and to a Cantor-based exponent. This enables the world’s climates to be classified into six large types based on a new measure of drought duration. To conclude, outcomes provide the ability to determine when droughts start and finish. We performed the dry-spell analysis using the full global gridded daily Multi-Source Weighted-Ensemble Precipitation (MSWEP) dataset. The MSWEP combines gauge-, satellite-, and reanalysis-based data to provide reliable precipitation estimates. The study period comprises the years 1979–2016 (total of 45 165 d), and a spatial resolution of 0.5∘, with a total of 259 197 grid points. The dataset is publicly available at https://doi.org/10.5281/zenodo.3247041 (Monjo et al., 2019). lacunarity drought duration cantor set dry spells global classification\n\n\nlacunaritydrought durationcantor setdry spellsglobal classification\n\n\n\n\n\nMori-Gamarra F, Moure-Rodríguez L, Sureda X, Carbia C, Royé D, Montes-Martínez A, Cadaveira F, Caamaño-Isorna F (2020). Alcohol outlet density and alcohol consumption in Galician youth. Gaceta Sanitaria, vol. 34(1), pp. 15-20.  10.1016/j.gaceta.2018.09.005 \n\n\nObjective. To assess the influence that alcohol outlet density, off- and on-alcohol premises, and alcohol consumption wield on the consumption patterns of young pre-university students in Galicia (Spain). Method. A cross-sectional analysis of a cohort of students of the University of Santiago de Compostela (Compostela Cohort 2016) was carried out. Consumption prevalence were calculated for each of the municipalities from the first-cycle students’ home residence during the year prior to admission. The association with risky alcohol consumption (RC) and binge-drinking (BD) was assessed with a logistic model considering as independent variables the municipality population, alcohol outlet density of off- premises, density of off- and on- premises and total density of both types of premises in the municipality. Results. The prevalence of RC was 60.5% (95% confidence interval [95%CI]: 58.4-62.5) and the BD was 28.5% (95%CI: 26.7-30.2). A great variability was observed according to the municipality of provenance. The multivariate logistic model showed municipalities with a density of 8.42-9.34 of both types of premises per thousand inhabitants presented a higher risk of RC (odds ratio [OR]: 1,39; 95%CI: 1.09-1.78) and BD (OR: 1.29; 95%CI: 1.01-1.66). Conclusion. These data suggest the importance of including environmental information when studying alcohol consumption. Knowing our environment better could help plan policies that encourage healthier behaviour in the population. alcohol outlet density alcohol underage drinking adolescents\n\n\nalcohol outlet densityalcoholunderage drinkingadolescents\n\n\n\n\n2019\n\n\nRoyé D, Tedim F, Martin‐Vide J, Salis M, Vendrell J, Lovreglio R, Bouillon C, Leone V (2019). Wildfire burnt area patterns and trends in Western Mediterranean Europe via the application of a concentration index. Land Degradation & Development, vol. 31(3), pp. 311-324.  10.1002/ldr.3450 \n\n\nThe most widely used metrics to characterize wildfire regime and estimate the impact of wildfires are total burnt area (BA) and the number of fire events (FE). However, these are insufficient to analyse the threat to society of a new fire regime characterized by a higher occurrence of very large events. To overcome this weakness, we propose the use of a Concentration Index (CIB) which makes it possible to identify spatio-temporal patterns. The frequency distribution of BA follows a negative exponential distribution almost everywhere, in which a small minority of FE is responsible of the majority of BA. In this article, the spatio-temporal behaviour of BA is analysed in Western Mediterranean Europe, with particular focus on Portugal, Spain, France and Italy, using data from the European Forest Fire Information System and national wildfire databases. This is the first time that the CI has been applied to wildfire events. This research shows that, in most Mediterranean European countries, the amount of BA is increasingly related with a lower number of fires. The spatio-temporal distribution of CIB shows high variability in all of the countries analysed in Europe. Portugal and Spain show increasing significant trends of CIB + 7.6% (p-value = 0.001) and + 1.3% per decade (p-value = 0.003). Statistically significant correlations for Portugal, Spain and Italy are also found between the annual CIB and several teleconnection indices. The application of the CIB demonstrates its discriminatory ability, which is a key point in detecting vulnerable areas and temporal trends under climate change. burnt area concentration index spatial patterns temporal trends fire regimes\n\n\nburnt areaconcentration indexspatial patternstemporal trendsfire regimes\n\n\n\n\n\nMathbout S, Lopez‐Bustins J, Royé D, Martin‐Vide J, Benhamrouche A (2019). Spatiotemporal variability of daily precipitation concentration and its relationship to teleconnection patterns over the Mediterranean during 1975–2015. International Journal of Climatology, vol. 40(3), pp. 1435-1455.  10.1002/joc.6278 \n\n\nThis study has addressed the spatiotemporal distribution of the daily rainfall concentration and its relation to the teleconnection patterns across the Mediterranean (MR). Daily concentration index (CI) and the ordered n index ( nor) are used at annual time scale to reveal the statistical structure of precipitation across the MR based on 233 daily rainfall series for the period 1975–2015. Eight teleconnection patterns, North Atlantic Oscillation (NAO), Mediterranean Oscillation (MO), Western Mediterranean Oscillation (WeMO), Upper-Level Mediterranean Oscillation index (ULMO), East Atlantic (EA) pattern, East Atlantic/West Russia (EATL/WRUS) pattern, Scandinavia (SCAND) pattern and Southern Oscillation (SO) at annual time scale are selected. The spatiotemporal patterns in precipitation concentration indices, annual precipitation and their teleconnections with previous large-scale circulations are investigated. Results show a strong connection between the CI and the nor (r = 0.70, p  .05) which present the same relative areas of high and low concentration. The annual values range from 0.57 to 0.70 for CI and 0.49 to 0.71 for nor index which show a high daily precipitation concentration across the MR. Trend analysis demonstrated mostly significant increasing trends for both indices. This increase is mainly found in south France, northern coastlands of the Iberian Peninsula (IP), Greece and Tunisia. An inverse relationship between the number of rainy days and concentration indices is evident. Both of WeMO and MO can play an important role in modulating rainfall in the northwest Mediterranean. The positive EATL/WRUS phase is mainly connected with positive precipitation mean anomalies in the eastern Mediterranean and vice versa in the west. The high daily precipitation concentration values over south France, northeast Spain, Croatia and Tunisia are linked to the low values of WeMO and high values of EA. These results could pave the way for new possibilities regarding the projection of precipitation concentration and precipitation irregularity in downscaling techniques. precipitation concentration teleconnection patterns spatiotemporal variability mediterranean climate indices\n\n\nprecipitation concentrationteleconnection patternsspatiotemporal variabilitymediterraneanclimate indices\n\n\n\n\n\nLemus-Canovas M, Lopez-Bustins J, Martin-Vide J, Royé D (2019). synoptReg: An R package for computing a synoptic climate classification and a spatial regionalization of environmental data. Environmental Modelling & Software, vol. 118, pp. 114-119.  10.1016/j.envsoft.2019.04.006 \n\n\nSpatial knowledge of the climatic or environmental variables associated with the most frequent circulation types is essential with regard to developing strategies to address the risk of avalanches, floods, soil erosion, air pollution or other natural hazards. In order to derive an environmental regionalization, we present an Open Source R package known as synoptReg, which combines the spatialization of environmental variables based on the atmospheric circulation types. The synoptReg package contains a set of functions which we will employ (1) to perform a PCA-based synoptic classification using an atmospheric variable; (2) to map the spatial distribution of the selected environmental variable based upon the circulation types; (3) to develop a spatial environmental regionalization based on the previous results. We illustrate the usefulness of the package for a case study in the Alps area. synoptic classification clustering environmental data regionalization circulation types\n\n\nsynoptic classificationclusteringenvironmental dataregionalizationcirculation types\n\n\n\n\n\nRoyé D, Zarrabeitia M, Fdez-Arroyabe P, Álvarez Gutiérrez A, Santurtún A (2019). Role of Apparent Temperature and Air Pollutants in Hospital Admissions for Acute Myocardial Infarction in the North of Spain. Revista Española de Cardiología, vol. 72(8), pp. 634-640.  10.1016/j.recesp.2018.05.032 \n\n\nIntroduction and objectives. The role of the environment on cardiovascular health is becoming more prominent in the context of global change. The aim of this study was to analyze the relationship between apparent temperature (AT) and air pollutants and acute myocardial infarction (AMI) and to study the temporal pattern of this disease and its associated mortality. Methods. We performed a time-series study of admissions for AMI in Cantabria between 2001 and 2015. The association between environmental variables (including a biometeorological index, AT) and AMI was analyzed using a quasi-Poisson regression model. To assess potential delayed and non-linear effects of these variables on AMI, a lag non-linear model was fitted in a generalized additive model. Results. The incidence rate and the mortality followed a downward trend during the study period (CC = –0.714; P = .0002). An annual pattern was found in hospital admissions (P = .005), with the highest values being registered in winter; a weekly trend was also identified, reaching a minimum during the weekends (P = .000005). There was an inverse association between AT and the number of hospital admissions due to AMI and a direct association with particulate matter with a diameter smaller than 10 μm. Conclusions. Hospital admissions for AMI followed a downward trend between 2007 and 2015. Mortality associated with admissions due to this diagnosis has decreased. Predictive factors for this disease were AT and particulate matter with a diameter smaller than 10 μm. apparent temperature air pollutants acute myocardial infarction hospital admissions particulate matter\n\n\napparent temperatureair pollutantsacute myocardial infarctionhospital admissionsparticulate matter\n\n\n\n\n\nRoyé D, Zarrabeitia M, Riancho J, Santurtún A (2019). A time series analysis of the relationship between apparent temperature, air pollutants and ischemic stroke in Madrid, Spain. Environmental Research, vol. 173, pp. 349-358.  10.1016/j.envres.2019.03.065 \n\n\nThe understanding of the role of environment on the pathogenesis of stroke is gaining importance in the context of climate change. This study analyzes the temporal pattern of ischemic stroke (IS) in Madrid, Spain, during a 13-year period (2001-2013), and the relationship between ischemic stroke (admissions and deaths) incidence and environmental factors on a daily scale by using a quasi-Poisson regression model. To assess potential delayed and non-linear effects of air pollutants and Apparent Temperature (AT), a biometeorological index which represents human thermal comfort on IS, a lag non-linear model was fitted in a generalized additive model. The mortality rate followed a downward trend over the studied period, however admission rates progressively increased. Our results show that both increases and decreases in AT had a marked relationship with IS deaths, while hospital admissions were only associated with low AT. When analyzing the cumulative effects (for lag 0-14 days), with an AT of 1.7 °C (percentile 5%) a RR of 1.20 (95% CI, 1.05-1.37) for IS mortality and a RR of 1.09 (95% CI, 0.91-1.29) for morbidity is estimated. Concerning gender differences, men show higher risks of mortality in low temperatures and women in high temperatures. No significant relationship was found between air pollutant concentrations and IS morbi-mortality, but this result must be interpreted with caution, since there are strong spatial fluctuations of the former between nearby geographical areas that make it difficult to perform correlation analyses. admissions air pollutants apparent temperature ischemic stroke mortality\n\n\nadmissionsair pollutantsapparent temperatureischemic strokemortality\n\n\n\n\n2018\n\n\nRoyé D, Lorenzo N, Rasilla D, Martí A (2018). Spatio‐temporal variations of cloud fraction based on circulation types in the Iberian Peninsula. International Journal of Climatology, vol. 39(3), pp. 1716-1732.  10.1002/joc.5914 \n\n\nThis paper presents the first systematic study of the relationships between atmospheric circulation types (CT) and cloud fraction (CF) over the whole Iberian Peninsula, using satellite data from the MODIS (MOD09GA and MYD09GA) cloud mask for the period 2001–2017. The high level of detail, in combination with a classification for circulation patterns, provides us with relevant information about the spatio-temporal variability of cloudiness and the main mechanisms affecting the genesis of clouds. The results show that westerly CTs are the most influential, followed by cyclonic types, in cloudiness in the west of the Iberian Peninsula. Westerly flows, however, do not affect the Mediterranean coastline, which is dominated by easterly CTs, suggesting that local factors such as convective processes, orography and proximity to a body of warm water could play a major role in cloudiness processes. The Cantabrian Coast also has a particularly characteristic cloudiness dominated by northerly CTs. In general, the results found in this study are in line with the few studies that exist on cloudiness in the Iberian Peninsula. Furthermore, the results are geographically consistent, showing links to synoptic forcing in terms of atmospheric circulation patterns and the impact of the Iberian Peninsula’s complex orography upon this element of the climate system. cloudiness circulation types variability orography synoptic forcing\n\n\ncloudinesscirculation typesvariabilityorographysynoptic forcing\n\n\n\n\n\nVélez A, Martin-Vide J, Royé D, Santaella O (2018). Spatial analysis of daily precipitation concentration in Puerto Rico. Theoretical and Applied Climatology, vol. 136, pp. 1347-1355.  10.1007/s0070401825501 \n\n\nThe present study analyzes spatial patterns of precipitation Concentration Index (CI) in Puerto Rico considering the daily precipitation data of 20 precipitation-gauging stations during 1971–2010. The South and East interior parts of Puerto Rico are characterized by higher CI and the West and North-West parts show lower CI. The annual CI and the rainy season CI show a gradient from South-East to North-West and the dry season CI shows a gradient from South to North. Another difference between the rainy season CI and dry season CI is that the former shows the lowest values of CI while the latter shows the highest values of CI. The different types of seasonal precipitation seem to play a major role on the spatial CI distribution. However, the local relief plays a major role in the spatial patterns due to the effect of the air circulation by the mountains. These findings can contribute to basin-scale water resource management (flooding, soil erosion, etc.) and conservation of the ecological environment. precipitation concentration spatial patterns concentration index (ci) seasonal variability climate change\n\n\nprecipitation concentrationspatial patternsconcentration index (ci)seasonal variabilityclimate change\n\n\n\n\n\nRiancho-Zarrabeitia L, Rasilla D, Royé D, Fdez-Arroyabe P, Santurtún A (2018). Kawasaki disease in Spanish paediatric population and synoptic weather types: an observational study. Rheumatology International, vol. 38(7), pp. 1259-1266.  10.1007/s00296-018-4066-5 \n\n\nKawasaki disease (KD) is a vasculitis of unelucidated pathogenesis that usually occurs in paediatric patients. In this study we analyse the temporal pattern and geographical distribution of the disease in Spain, and its relationship with atmospheric circulation patterns. We performed a retrospective study in which we collected all hospital admissions due to KD in the country between 2005 and 2015 and explored their relationship with demographic and geographical characteristics. Moreover, we calculated daily surface atmospheric patterns over Spain to study the relationship between weather types (WT) and KD Admissions. The average admission rate for KD in the paediatric population was 3.90 per 100,000, with a male to female ratio of 1.56:1. The highest rate of admissions was found in the 0-4-year-old group, with an incidence of 11.7 cases per 100,000. Admissions followed an annual cyclic pattern with a peak of incidence in January (p = 0.022) and a nadir in September. There was an upwards trend in the number of KD admissions in male sex during the study period (p = 0.004). However, there were marked geographical differences in the incidence rate. Finally, the analysis of the relationship between the WT and the number of admissions by KD revealed no statistically significant association. KD admissions follow a peculiar seasonal and spatial distribution, that suggest the involvement of environmental factors in the disease; however, the absence of an association with WT should be interpreted with caution and regional studies should be done to explore this relationship. kawasaki disease season trend weather types\n\n\nkawasaki diseaseseasontrendweather types\n\n\n\n\n\nRoyé D, Figueiras A, Taracido M (2018). Short‐term effects of heat and cold on respiratory drug use: A time‐series epidemiological study in A Coruña, Spain. Pharmacoepidemiology and Drug Safety, vol. 27(6), pp. 638-644.  10.1002/pds.4427. \n\n\nThe consumption of medication, especially over-the-counter drugs, can reflect environmental exposure with a lesser degree of severity in terms of morbidity. The non-linear effects of maximum and minimum apparent temperature on respiratory drug sales in A Coruña from 2006 to 2010 were examined using a distributed lag nonlinear model. In particular, low apparent temperatures proved to be associated with increased sales of respiratory drugs. The strongest consistent risk estimates were found for minimum apparent temperatures in respiratory drug sales with an increase of 33.4% (95% CI, 12.5%-58.0%) when the temperature changed from 2.8°C to −1.4 °C. These findings may serve to guide the planning of public health interventions to predict and manage the health effects of exposure to the thermal environment for lower degrees of morbidity. More precisely, significant increases in the use of measured over-the-counter medication could be used to identify and anticipate influenza outbreaks due to a more sensitive degree of the data source. respiratory drug use heat cold time-series analysis a coruña\n\n\nrespiratory drug useheatcoldtime-series analysisa coruña\n\n\n\n\n\nRoyé D, Lorenzo N, Martin-Vide J (2018). Spatial–temporal patterns of cloudtoground lightning over the northwest Iberian Peninsula during the period 2010–2015. Natural Hazards, vol. 92, pp. 857-884.  10.1007/s11069-018-3228-9 \n\n\nThe spatial–temporal patterns of cloud-to-ground (CG) lightning covering the period 2010–2015 over the northwest Iberian Peninsula were investigated. The analysis conducted employed three main methods: the circulation weather types developed by Jenkinson and Collison, the fit of a generalized additive model (GAM) for geographic variables, and the use of a concentration index for the ratio of lightning strikes and thunderstorm days. The main activity in the summer months can be attributed to situations with eastern or anticyclonic flow due to convection by insolation. In winter, lightning proves to have a frontal origin and is mainly associated with western or cyclonic flow situations which occur with advections of air masses of maritime origin. The largest number of CG discharges occurs under eastern flow and their hybrids with anticyclonic situations. Thunderstorms with greater CG lightning activity, highlighted by a higher concentration index, are located in areas with a higher density of lightning strikes, above all in mountainous areas away from the sea. The modeling of lightning density with geographic variables shows the positive influence of altitude and, particularly, distance to the sea, with nonlinear relationships due to the complex orography of the region. Likewise, areas with convex topography receive more lightning strikes than concave ones, a relation which has been demonstrated for the first time from a GAM. cloud-to-ground lightning spatial-temporal patterns northwest iberian peninsula circulation weather types generalized additive model (gam)\n\n\ncloud-to-ground lightningspatial-temporal patternsnorthwest iberian peninsulacirculation weather typesgeneralized additive model (gam)\n\n\n\n\n2017\n\n\nRoyé D, Martin-Vide J (2017). Concentration of daily precipitation in the contiguous United States. Atmospheric Research, vol. 196(1), pp. 237-247.  10.1016/j.atmosres.2017.06.011 \n\n\nThe contiguous US exhibits a wide variety of precipitation regimes, first, because of the wide range of latitudes and altitudes. The physiographic units with a basic meridional configuration contribute to the differentiation between east and west in the country while generating some large interior continental spaces. The frequency distribution of daily precipitation amounts almost anywhere conforms to a negative exponential distribution, reflecting the fact that there are many small daily totals and few large ones. Positive exponential curves, which plot the cumulative percentages of days with precipitation against the cumulative percentage of the rainfall amounts that they contribute, can be evaluated through the Concentration Index. The Concentration Index has been applied to the contiguous United States using a gridded climate dataset of daily precipitation data, at a resolution of 0.25°, provided by CPC/NOAA/OAR/Earth System Research Laboratory, for the period between 1956 and 2006. At the same time, other rainfall indices and variables such as the annual coefficient of variation, seasonal rainfall regimes and the probabilities of a day with precipitation have been presented with a view to explaining spatial CI patterns. The spatial distribution of the CI in the contiguous United States is geographically consistent, reflecting the principal physiographic and climatic units of the country. Likewise, linear correlations have been established between the CI and geographical factors such as latitude, longitude and altitude. In the latter case the Pearson correlation coefficient (r) between this factor and the CI is −0.51 (p-value 0.001). For annual probability of days with precipitation and the CI there is also a significant and negative correlation, r = −0.25 (p-value 0.001). daily precipitation climate variability contiguous united states rainfall patterns hydrology\n\n\ndaily precipitationclimate variabilitycontiguous united statesrainfall patternshydrology\n\n\n\n\n\nMathbout S, Lopez-Bustins J A, Royé D, Martin-Vide J, Bech J, Rodrigo F S (2017). Observed Changes in Daily Precipitation Extremes at Annual Timescale Over the Eastern Mediterranean During 1961–2012. Pure and Applied Geophysics, vol. 175, pp. 3875-3890.  10.1007/s00024-017-1695-7 \n\n\nThe Eastern Mediterranean is one of the most prominent hot spots of climate change in the world and extreme climatic phenomena in this region such as drought or extreme rainfall events are expected to become more frequent and intense. In this study climate extreme indices recommended by the joint World Meteorological Organization Expert Team on Climate Change Detection and Indices are calculated for daily precipitation data in 70 weather stations during 1961–2012. Observed trends and changes in daily precipitation extremes over the EM basin were analysed using the RClimDex package, which was developed by the Climate Research Branch of the Meteorological Service of Canada. Extreme and heavy precipitation events showed globally a statistically significant decrease in the Eastern Mediterranean and, in the southern parts, a significant decrease in total precipitation. The overall analysis of extreme precipitation indices reveals that decreasing trends are generally more frequent than increasing trends. We found statistically significant decreasing trends (reaching 74% of stations for extremely wet days) and increasing trends (reaching 36% of stations for number of very heavy precipitation days). Finally, most of the extreme precipitation indices have a statistically significant positive correlation with annual precipitation, particularly the number of heavy and very heavy precipitation days. precipitation extremes eastern mediterranean climate change hydrological cycle trend analysis\n\n\nprecipitation extremeseastern mediterraneanclimate changehydrological cycletrend analysis\n\n\n\n\n\nRoyé D (2017). The effects of hot nights on mortality in Barcelona, Spain. International Journal of Biometeorology, vol. 61, pp. 2127-2140.  10.1007/s00484-017-1416-z \n\n\nHeat-related effects on mortality have been widely analyzed using maximum and minimum temperatures as exposure variables. Nevertheless, the main focus is usually on the former with the minimum temperature being limited in use as far as human health effects are concerned. Therefore, new thermal indices were used in this research to describe the duration of night hours with air temperatures higher than the 95% percentile of the minimum temperature (hot night hours) and intensity as the summation of these air temperatures in degrees (hot night degrees). An exposure-response relationship between mortality due to natural, respiratory, and cardiovascular causes and summer night temperatures was assessed using data from the Barcelona region between 2003 and 2013. The non-linear relationship between the exposure and response variables was modeled using a distributed lag non-linear model. The estimated associations for both exposure variables and mortality shows a relationship with high and medium values that persist significantly up to a lag of 1–2 days. In mortality due to natural causes, an increase of 1.1% per 10% (CI95% 0.6–1.5) for hot night hours and 5.8% per each 10° (CI95% 3.5–8.2%) for hot night degrees is observed. The effects of hot night hours reach their maximum with 100% and lead to an increase by 9.2% (CI95% 5.3–13.1%). The hourly description of night heat effects reduced to a single indicator in duration and intensity is a new approach and shows a different perspective and significant heat-related effects on human health. hot nights mortality barcelona heat stress public health\n\n\nhot nightsmortalitybarcelonaheat stresspublic health\n\n\n\n\n2015\n\n\nRoyé D (2015). The use of climate databases netCDF with array structure in the environment of R. Sémata: Ciencias Sociais e Humanidades, vol. 27, pp. 11-37. https://revistas.usc.gal/index.php/semata/article/view/2690 . \n\n\nA practical introduction in the use of netCDF in the environment of R Spatio-temporal data is currently key to many disciplines, especially to climatology and meteorology. A widespread format is netCDF allowing a multidimensional structure and an exchange of data machine independently. In this article, we introduce the use of these databases with the free software environment R. To do this, we will work with a grid of the maximum temperature of the Iberian Peninsula for the period 1971-2007. The goal is to read and visualize the netCDF format, and make some fist overall and specifi calculations. Finally the applicability is shown in a case study: the diurnal temperature variation in the Iberian Peninsula for January and August 2006. (Spanish) ncdf data cube climate programming array\n\n\nncdfdata cubeclimateprogrammingarray\n\n\n\n\n\nRoyé D, Martí (2015). Analysis of tropical nights on the atlantic coast of the Iberian Peninsula: A proposed methodology. Boletín de la Asociación de Geógrafos Españoles, vol. 69, pp. 351-368.  10.21138/bage.1900 \n\n\nAnalysis of tropical nights on the Atlantic coast of the Iberian peninsula. A proposed methodology. This paper presents a new methodology for the study of warm nights, also called «tropical», in Galicia and Portugal in order to identify those nights where people can be affected by heat stress. The use of two indicators obtained through half-hourly data has allowed us to define in more detail the thermal characteristics of the nights between May and October, thereby being able to more accurately assess the risk to the health and well-being of the population. There is a significant increase in the frequency of tropical nights and warm nights on the Atlantic coast, from the north of Galicia to the south of Portugal. The lower latitude and proximity to the coastline are associated with greater persistence of heat and thermal stress during these nights. In inland areas the persistence is less. The warmest nights are more frequent and intense in centres of the cities, due to the effect of the urban heat island. tropical nights atlantic coast iberian peninsula heat stress climate change\n\n\ntropical nightsatlantic coastiberian peninsulaheat stressclimate change\n\n\n\n\n\nRoyé D, Taboada J J, Martí A, Lorenzo M N (2015). Winter circulation weather types and hospital admissions for respiratory diseases in Galicia, Spain. International Journal of Biometeorology, vol. 60.  10.1007/s00484-015-1047-1 \n\n\nThe link between various pathologies and atmospheric conditions has been a constant topic of study over recent decades in many places across the world; knowing more about it enables us to pre-empt the worsening of certain diseases, thereby optimizing medical resources. This study looked specifically at the connections in winter between respiratory diseases and types of atmospheric weather conditions (Circulation Weather Types, CWT) in Galicia, a region in the north-western corner of the Iberian Peninsula. To do this, the study used hospital admission data associated with these pathologies as well as an automatic classification of weather types. The main result obtained was that weather types giving rise to an increase in admissions due to these diseases are those associated with cold, dry weather, such as those in the east and south-east, or anticyclonic types. A second peak was associated with humid, hotter weather, generally linked to south-west weather types. In the future, this result may help to forecast the increase in respiratory pathologies in the region some days in advance. circulation weather types (cwt) respiratory diseases hospital admissions galicia winter\n\n\ncirculation weather types (cwt)respiratory diseaseshospital admissionsgaliciawinter"
  },
  {
    "objectID": "publication/index.html#books",
    "href": "publication/index.html#books",
    "title": "Publications",
    "section": "Books",
    "text": "Books\n2019\n\n\nRoyé D, Serrano-Notivoli R (2019). Introducción a los SIG con R. Publicaciones de la Universidad de Zaragoza. https://puz.unizar.es/2133-introduccion-a-los-sig-con-r.html . \n\n\nR tiene, como lenguaje de programación enfocado al análisis estadístico, todos los ingredientes para ser usado como herramienta de análisis espacial y representación cartográﬁca: es gratuito, permite personalizar, replicar y compartir los análisis de cualquier nivel de diﬁcultad y no tiene ninguna limitación en cuanto a cantidad de información a procesar o tipos de formato diferentes para gestionar. Esto le sitúa en una situación de ventaja que mejora día a día, gracias a su amplia comunidad de usuarios, respecto a un SIG (Sistema de Información Geográﬁca) convencional. Este manual explica, sin necesidad de conocimientos previos, cómo desarrollar con R todos los análisis disponibles en un SIG, con ejemplos sencillos y multitud de casos prácticos. Además, se muestran las enormes posibilidades de representación cartográﬁca, que van mucho más allá de la simple creación de mapas. R permite, desde exportar a cualquier formato de archivo, hasta crear mapas dinámicos para supublicación en Internet.\n\n\n,\n\n\n\n\n\nMartí A, Taboada J, Royé D, Fonseca X (2019). Os tempos e o clima de Galicia. Vigo: Xerais. https://www.xerais.gal/libro/basicos-ciencia/os-tempos-e-o-clima-de-galicia-alberto-marti-ezpeleta-9788491215066/ . \n\n\nQue récords climáticos se alcanzaron en Galicia? Cales son os lugares máis calorosos? E os máis fríos? Onde chove máis? Onde se rexistran máis días de precipitación? Que zonas gozan dun maior número de horas de sol? Cales teñen maior nebulosidade? Que lugares son os máis ventosos? Como está a afectar o cambio climático a Galicia? Neste libro atoparás as respostas a estas e a outras preguntas relacionadas co clima de Galicia e os diversos tipos de tempo que o caracterizan. Nas súas páxinas explícase como se producen os fenómenos meteorolóxicos máis habituais no noso territorio: as inversións térmicas, as néboas costeiras e orográficas, as illas de calor urbanas, os tipos de precipitación, o efecto foehn, as brisas mariñas, o arco da vella etc. A través de exemplos concretos, analízanse tamén os riscos climáticos que afectan regularmente a Galicia, como vagas de calor, temporais de neve, cicloxéneses explosivas e temporais de choiva e vento, tormentas, secas, tornados… Tamén poderás coñecer como está a cambiar o clima da nosa comunidade debido ao quecemento global e cales son os escenarios de futuro.\n\n\n,"
  },
  {
    "objectID": "publication/index.html#book-chapters",
    "href": "publication/index.html#book-chapters",
    "title": "Publications",
    "section": "Book chapters",
    "text": "Book chapters\n2025\n\n\nRoyé D, De Gregorio Hurtado S, López-Díez A, Franco M, Vicedo A, Lowe R, Monjo R (2025). Ciudades, salud, bienestar y vulnerabilidades sociales. Cambio Climático y Territorio en el Mediterráneo Iberico.  Tirant Humanidades \n\n\nEl cambio climático constituye una crisis global que amenaza la salud y el bienestar humano, especialmente en regiones vulnerables como el Mediterráneo. El aumento de la temperatura, la intensificación de olas de calor, sequías, inundaciones y la degradación de la calidad del aire y del agua generan riesgos directos e indirectos para la salud, incluyendo enfermedades cardiovasculares, respiratorias, vectoriales, desnutrición y problemas de salud mental. Estos impactos se ven amplificados por desigualdades sociales preexistentes, lo que convierte al cambio climático en un multiplicador de riesgos que afecta de manera desproporcionada a poblaciones vulnerables. En entornos urbanos mediterráneos, el efecto isla de calor, la contaminación y la falta de espacios verdes incrementan la exposición y reducen la capacidad de adaptación. Las proyecciones indican que entre 2030 y 2050 se producirán 250.000 muertes adicionales anuales relacionadas con el clima, lo que exige respuestas urgentes. Las estrategias de mitigación y adaptación deben ser integrales y equitativas. Reducir emisiones ofrece co-beneficios para la salud, como la mejora de la calidad del aire. La adaptación requiere políticas que prioricen la justicia climática, la regeneración urbana, la protección social y la creación de sistemas sanitarios resilientes. Es esencial implementar planes locales de adaptación, infraestructuras verdes y azules, refugios climáticos y medidas para garantizar agua segura y controlar vectores. Además, se recomienda fortalecer la educación, la cultura del riesgo y la transferencia del conocimiento científico a la sociedad y a los marcos de decisión política. En definitiva, actuar con rapidez y equidad es clave para proteger la salud frente a los impactos del cambio climático en el Mediterráneo.\n\n\n\n\n\n\n\n2024\n\n\nRoyé D, Tobías A (2024). Cambio climático: un riesgo para nuestro bienestar y salud. Cambio climático en España Tirant Lo Blanch. https://editorial.tirant.com/es/libro/cambio-climatico-en-espana-luis-efren-rios-vega-9788411837279?busqueda=Cambio+clim%3Ftico+& . \n\n\nEl ambiente influye de forma directa e indirecta en nuestra salud, por tanto, una relación directa con el dinamismo antropogenético de las sociedades, en el sentido social, cultural, económico y político. El organismo humano y la atmósfera se encuentran en un equilibrio físico y químico en constante intercambio. Todos los seres humanos se ven forzados a reaccionar ante los elementos atmosféricos para poder garantizar su correcto y óptimo funcionamiento orgánico. En este contexto, el cambio climático es uno de los mayores desafíos que enfrenta la humanidad en el siglo XXI, porque implica consecuencias muy graves para la salud y el bienestar de las personas en todo el planeta. Se ha convertido en una inaplazable emergencia climática afectando especialmente a nuestro bienestar con hasta 3,6 millones de personas en áreas altamente susceptibles y vulnerables (IPCC, 2022). El cambio climático es un multiplicador de riesgos existentes, aumentando la frecuencia, intensidad y la duración de eventos extremos, así como de olas de calor o redistribuyendo enfermedades transmitidas por vectores. Dado que no es posible separar los impactos actuales del clima de aquellos provocados por el cambio climático antropogénico, aquí se resumen en dos los principales impactos del calentamiento global sobre la salud en España: las temperaturas extremas y la contaminación del aire, y se analizan las posibles medidas de adaptación y mitigación.\n\n\n,\n\n\n\n\n\nRoyé D (2024). Geoprocesamiento en nube. Fundamentos de ciencia de datos con R Publisher: Mc Graw Hill Editors: G Fernández-Avilés, JM Montero. https://cdr-book.github.io/geoproces.html . \n\n\nEl planteamiento de un problema basado en datos de diversos proveedores habitualmente implica la descarga de grandes volúmenes de datos. La actual proliferación de servicios de Open Data, despliegues de sensores y diversas fuentes, incluyendo los satélites, dificulta su procesamiento en equipos personales. El gran crecimiento en grandes volúmenes de datos espaciotemporales de tipo vectorial o raster lleva a la necesidad en trabajar con servicios en nube para ahorrar tiempo computacional y espacio de almacenamiento. En la actualidad existen diferentes servicios de geoprocesamiento en nube que ayudan a hacer análisis online sin necesidad de descargar los datos ni preocuparse por el rendimiento computacional. Uno de estos servicios es Google Earth Engine (GEE), donde se combina un catálogo de varios petabytes de imágenes satelitales y conjuntos de datos geoespaciales multidimensionales (vectorial y raster) de alta resolución con capacidades de análisis a escala planetaria. Este servicio gratuito para uso no comercial incluye incluso la posibilidad de crear aplicaciones.\n\n\n,\n\n\n\n\n\nRoyé D (2024). Una nota sobre el cambio climático. Fundamentos de ciencia de datos con R Publisher: Mc Graw Hill Editors: G Fernández-Avilés, JM Montero. https://cdr-book.github.io/cambioclimatico.html . \n\n\nLa temperatura media global en la superficie terrestre ha aumentado en 1,1 C desde la era preindustrial (1880-1900). A pesar de parecer un leve incremento en la temperatura, implica un aumento significativo en el calor acumulado del sistema Tierra. Cuando se combina el aumento de la temperatura en la superficie terrestre y en la superficie oceánica, la tasa de incremento promedio es de 0,08 C por década desde 1880. Sin embargo, la tasa promedio de aumento desde 1981 ha sido más del doble: 0,18 C por año. Los océanos se caracterizan por una menor tasa de calentamiento debido a su capacidad calorífica. No obstante, son los océanos los que absorben la mayoría del calor adicional del planeta debido al cambio climático…\n\n\n,\n\n\n\n\n2020\n\n\nTedim F, Leone V, Coughlan M, Bouillon C, Xanthopoulos G, Royé D, Correia FJM, Ferreira C (2020). Extreme wildfire events: the definition. Extreme Wildfire Events and Disasters Publisher: Elsevier Editors: F Tedim, V Leone, TK McGee.  10.1016/B978-0-12-815721-3.00001-1 \n\n\nExtreme wildfires events (EWEs) represent a minority among all wildfires but are a true challenge for societies as they exceed the current control capacity even in the best prepared regions of the world and they create destruction and a disproportionately number of fatalities. Recent events in Portugal, Chile, Greece, Australia, Canada, and the USA provide evidence that EWEs are an escalating worldwide problem, exceeding all previous records. Despite the challenges put by climate change, the occurrence of EWEs and disasters is not an ecological inevitability. In this chapter the rationale of the definition of EWEs and the integration of potential consequences on people and assets in a novel wildfire classification scheme are proposed and discussed. They are excellent instruments to enhance wildfire risk and crisis communication programs and to define appropriate prevention, mitigation, and response measures which are crucial to build up citizens’ safety. extreme wildfire events (ewes) climate change risk communication mitigation measures wildfire classification\n\n\nextreme wildfire events (ewes)climate changerisk communicationmitigation measureswildfire classification\n\n\n\n\n2017\n\n\nFdez-Arroyabe P, Royé D (2017). Co-creation and Participatory Design of Big Data Infrastructures on the Field of Human Health Related Climate Services. Internet of Things and Big Data Technologies for Next Generation HealthcareEdition: Studies in Big Data, Vol.  23 Publisher: Springer International PublishingEditors: C. Bhatt, N. Dey, A.S. Ashour. \n\n\nCo-creation of scientific knowledge based on new technologies and big data sources is one of the main challenges for the digital society in the XXI century. Data management and the analysis of patterns among datasets based on machine learning and artificial intelligence has become essential for many sectors nowadays. The development of real time health-related climate services represents an example where abundant structured and unstructured information and transdisciplinary research are needed. The study of the interactions between atmospheric processes and human health through a big data approach can reveal the hidden value of data. The Oxyalert technological platform is presented as an example of a digital biometeorological infrastructure able to forecast, at an individual level, oxygen changes impacts on human health. co-creation interdisciplinarity transdisciplinarity morbidity climate services digital divide big data health\n\n\nco-creationinterdisciplinaritytransdisciplinaritymorbidityclimate servicesdigital dividebig datahealth"
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "License",
    "section": "",
    "text": "My blog posts are released under a Creative Commons Attribution-ShareAlike 4.0 International License.\n\n  \n\n\n\n\n Back to top"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Send me a note ",
    "section": "",
    "text": "You can use this form to contact me about speaking engagements, collaborations, or simply to say hello.\n     \n\n\n\n\n\n\n\n\nYour email: \nYour message:\n\n\nSend\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "blog/visualize-anomalies-monthly-precipitation/index.html",
    "href": "blog/visualize-anomalies-monthly-precipitation/index.html",
    "title": "Visualize monthly precipitation anomalies",
    "section": "",
    "text": "Normally when we visualize monthly precipitation anomalies, we simply use a bar graph indicating negative and positive values with red and blue. However, it does not explain the general context of these anomalies. For example, what was the highest or lowest anomaly in each month? In principle, we could use a boxplot to visualize the distribution of the anomalies, but in this particular case they would not fit aesthetically, so we should look for an alternative. Here I present a very useful graphic form."
  },
  {
    "objectID": "blog/visualize-anomalies-monthly-precipitation/index.html#packages",
    "href": "blog/visualize-anomalies-monthly-precipitation/index.html#packages",
    "title": "Visualize monthly precipitation anomalies",
    "section": "Packages",
    "text": "Packages\nIn this post we will use the following packages:\n\n\n\n\n\n\n\nPackage\nDescription\n\n\n\n\ntidyverse\nCollection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.\n\n\nggthemes\nThemes for ggplot2\n\n\ncowplot\nEasy creation of multiple graphics with ggplot2\n\n\n\n\n# we install the packages if necessary\n\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"ggthemes\")) install.packages(\"broom\")\nif (!require(\"cowplot\")) install.packages(\"cowplot\")\n\n# packages\n\nlibrary(tidyverse) \nlibrary(ggthemes)\nlibrary(cowplot)"
  },
  {
    "objectID": "blog/visualize-anomalies-monthly-precipitation/index.html#preparing-the-data",
    "href": "blog/visualize-anomalies-monthly-precipitation/index.html#preparing-the-data",
    "title": "Visualize monthly precipitation anomalies",
    "section": "Preparing the data",
    "text": "Preparing the data\nFirst we import the daily precipitation of the selected weather station (download). We will use data from Santiago de Compostela (Spain) accessible through ECA&D.\n\nStep 1: import the data\nWe not only import the data in csv format, but we also make the first changes. We skip the first 21 rows that contain information about the weather station. In addition, we convert the date to the date class and replace missing values (-9999) with NA. The precipitation is given in 0.1 mm, therefore, we must divide the values by 10. Then we select the columns DATE and RR, and rename them.\n\ndata &lt;- read_csv(\"RR_STAID001394.txt\", skip = 21) |&gt;\n  mutate(DATE = ymd(DATE), \n          RR = ifelse(RR == -9999, NA, RR / 10)) |&gt;\n1  dplyr::select(date = DATE, pr = RR)\n\ndata\n\n\n1\n\nselect() causes many conflicts with other functions, hence the form of package::function\n\n\n\n\n\n\nStep 2: creating monthly values\nIn the second step we calculate the monthly amounts of precipitation. To do this, a) we limit the period to the years after 1950, b) we add the month with its labels and the year as variables.\n\ndata &lt;- mutate(data, mo = month(date, label = TRUE), \n                      yr = year(date)) |&gt;\n          filter(date &gt;= \"1950-01-01\") |&gt;\n          group_by(yr, mo) |&gt;\n            summarise(prs = sum(pr, na.rm = TRUE))\n\ndata\n\n\n\nStep 3: estimating anomalies\nNow we must estimate the normals of each month and join this table to our main data in order to calculate the monthly anomaly. We express the anomalies in percentage and subtract 100 to set the average to 0. In addition, we create a variable which indicates if the anomaly is negative or positive, and another with the date.\n\npr_ref &lt;- filter(data, yr &gt; 1981, yr &lt;= 2010) |&gt;\n            group_by(mo) |&gt;\n              summarise(pr_ref = mean(prs))\n\ndata &lt;- left_join(data, pr_ref, by = \"mo\")\n\ndata &lt;- mutate(data,\n  anom = (prs * 100 / pr_ref) - 100,\n  date = str_c(yr, mo, \"01\") |&gt; ymd(),\n  sign = ifelse(anom &gt; 0, \"pos\", \"neg\") |&gt; factor(c(\"pos\", \"neg\"))\n)\n\nWe can do a first test graph of anomalies (the classic one), for that we filter the year 2018. In this case we use a bar graph, remember that by default the function geom_bar() applies the counting of the variable. However, in this case we know y, hence we indicate with the argument stat = \"identity\" that it should use the given value in aes().\n\nfilter(data, yr == 2018) |&gt;\n  ggplot(aes(date, anom, fill = sign)) +\n    geom_col(show.legend = FALSE) +\n      scale_x_date(date_breaks = \"month\", date_labels = \"%b\") +\n      scale_y_continuous(breaks = seq(-100, 100, 20)) +\n      scale_fill_manual(values = c(\"#99000d\", \"#034e7b\")) +\n    labs(y = \"Precipitation anomaly (%)\", x = \"\") +\n    theme_hc()\n\n\n\n\nStep 4: calculating the statistical metrics\nIn this last step we estimate the maximum, minimum value, the 25%/75% quantiles and the interquartile range per month of the entire time series.\n\ndata_norm &lt;- group_by(data, mo) |&gt;\n                summarise(\n                  mx = max(anom),\n                  min = min(anom),\n                  q25 = quantile(anom, .25),\n                  q75 = quantile(anom, .75),\n                  iqr = q75 - q25\n                )\ndata_norm"
  },
  {
    "objectID": "blog/visualize-anomalies-monthly-precipitation/index.html#creating-the-graph",
    "href": "blog/visualize-anomalies-monthly-precipitation/index.html#creating-the-graph",
    "title": "Visualize monthly precipitation anomalies",
    "section": "Creating the graph",
    "text": "Creating the graph\nTo create the anomaly graph with legend it is necessary to separate the main graph from the legends.\n\nPart 1\nIn this first part we are adding layer by layer the different elements: 1) the range of anomalies maximum-minimum 2) the interquartile range and 3) the anomalies of the year 2018.\n\n# range of anomalies maximum-minimum\ng1.1 &lt;- ggplot(data_norm) +\n  geom_crossbar(aes(x = mo, y = 0, ymin = min, ymax = mx),\n    fatten = 0, fill = \"grey90\", colour = \"NA\"\n  )\n\ng1.1\n\n\n\n\n\n# adding interquartile range\ng1.2 &lt;- g1.1 + geom_crossbar(aes(x = mo, y = 0, ymin = q25, ymax = q75),\n  fatten = 0, fill = \"grey70\"\n)\n\ng1.2\n\n\n\n\n\n# adding anomalies of the year 2018\n\ng1.3 &lt;- g1.2 + geom_crossbar(\n  data = filter(data, yr == 2018),\n  aes(x = mo, y = 0, ymin = 0, ymax = anom, fill = sign),\n  fatten = 0, width = 0.7, alpha = .7, colour = \"NA\",\n  show.legend = FALSE\n)\ng1.3\n\n\n\n\nFinally we change some last style settings.\n\ng1 &lt;- g1.3 + geom_hline(yintercept = 0) +\n  scale_fill_manual(values = c(\"#99000d\", \"#034e7b\")) +\n  scale_y_continuous(\"Precipitation anomaly (%)\",\n    breaks = seq(-100, 500, 50),\n    expand = c(0, 5)\n  ) +\n  labs(\n    x = \"\",\n    title = \"Precipitation anomaly in Santiago de Compostela 2018\",\n    caption = \"Data: eca.knmi.nl\"\n  ) +\n  theme_hc()\ng1\n\n\n\n\n\n\nPart 2\nWe still need a legend. First we create it for the normals.\n\n# legend data\nlegend &lt;- filter(data_norm, mo == \"Jan\")\n\nlegend_lab &lt;- gather(legend, stat, y, mx:q75) |&gt;\n  mutate(stat = factor(stat, stat, c(\n    \"maximum\",\n    \"minimum\",\n    \"Quantile 25%\",\n    \"Quantile 75%\"\n  )) |&gt;\n    as.character())\n\n# legend graph\ng2 &lt;- legend |&gt; ggplot() +\n  geom_crossbar(aes(x = mo, y = 0, ymin = min, ymax = mx),\n    fatten = 0, fill = \"grey90\", colour = \"NA\", width = 0.2\n  ) +\n  geom_crossbar(aes(x = mo, y = 0, ymin = q25, ymax = q75),\n    fatten = 0, fill = \"grey70\", width = 0.2\n  ) +\n  geom_text(\n    data = legend_lab,\n    aes(x = mo, y = y + c(12, -8, -10, 12), label = stat),\n    fontface = \"bold\", size = 2\n  ) +\n  annotate(\"text\",\n    x = 1.18, y = 40,\n    label = \"Period 1950-2018\", angle = 90, size = 3\n  ) +\n  theme_void() +\n  theme(plot.margin = unit(c(0, 0, 0, 0), \"cm\"))\n\ng2\n\n\n\n\nSecond, we create another legend for the current anomalies.\n\n# legend data\nlegend2 &lt;- filter(data, yr == 1950, mo %in% c(\"Jan\", \"Feb\")) |&gt;\n                ungroup() |&gt;\n                dplyr::select(mo, anom, sign)\n\nlegend2[2, 1] &lt;- \"Jan\"\n\nlegend_lab2 &lt;- data.frame(\n  mo = rep(\"Jan\", 3),\n  anom = c(110, 3, -70),\n  label = c(\"Positive anomaly\", \"Average\", \"Negative anomaly\")\n)\n\n# legend graph\ng3 &lt;- ggplot() +\n  geom_bar(\n    data = legend2,\n    aes(x = mo, y = anom, fill = sign),\n    alpha = .6, colour = \"NA\", stat = \"identity\", show.legend = FALSE, width = 0.2\n  ) +\n  geom_segment(aes(x = .85, y = 0, xend = 1.15, yend = 0), linetype = \"dashed\") +\n  geom_text(\n    data = legend_lab2,\n    aes(x = mo, y = anom + c(10, 5, -13), label = label),\n    fontface = \"bold\", size = 2\n  ) +\n  annotate(\"text\",\n    x = 1.25, y = 20,\n    label = \"Reference 1971-2010\", angle = 90, size = 3\n  ) +\n  scale_fill_manual(values = c(\"#99000d\", \"#034e7b\")) +\n  theme_void() +\n  theme(plot.margin = unit(c(0, 0, 0, 0), \"cm\"))\n\ng3\n\n\n\n\n\n\nPart 3\nFinally, we only have to join the graph and the legends with the help of the cowplot package. The main function of cowplot is plot_grid() which is used for combining different graphs. However, in this case it is necessary to use more flexible functions to create less common formats. The ggdraw() function configures the basic layer of the graph, and the functions that are intended to operate on this layer start with draw_*.\n\np &lt;- ggdraw() +\n  draw_plot(g1, x = 0, y = .3, width = 1, height = 0.6) +\n  draw_plot(g2, x = 0, y = .15, width = .2, height = .15) +\n  draw_plot(g3, x = 0.08, y = .15, width = .2, height = .15)\n\np\n\n\n\nsave_plot(\"pr_anomaly2016_scq.png\", p, dpi = 300, base_width = 12.43, base_height = 8.42)"
  },
  {
    "objectID": "blog/visualize-anomalies-monthly-precipitation/index.html#multiple-facets",
    "href": "blog/visualize-anomalies-monthly-precipitation/index.html#multiple-facets",
    "title": "Visualize monthly precipitation anomalies",
    "section": "Multiple facets",
    "text": "Multiple facets\nIn this section we will make the same graph as in the previous one, but for several years.\n\nPart 1\nFirst we need to filter again by set of years, in this case from 2016 to 2018, using the operator %in%, we also add the function facet_grid() to ggplot, which allows us to plot the graph according to a variable. The formula used for the facet function is similar to the use in models: variable_by_row ~ variable_by_column. When we do not have a variable in the column, we should use the ..\n\n# range of anomalies maximum-minimum\ng1.1 &lt;- ggplot(data_norm) +\n  geom_crossbar(aes(x = mo, y = 0, ymin = min, ymax = mx),\n    fatten = 0, fill = \"grey90\", colour = \"NA\"\n  )\n\n\n# adding the interquartile range\ng1.2 &lt;- g1.1 + geom_crossbar(aes(x = mo, y = 0, ymin = q25, ymax = q75),\n  fatten = 0, fill = \"grey70\"\n)\n\n\n# adding the anomalies of the year 2016-2018\n\ng1.3 &lt;- g1.2 + geom_crossbar(\n  data = filter(data, yr %in% 2016:2018),\n  aes(x = mo, y = 0, ymin = 0, ymax = anom, fill = sign),\n  fatten = 0, width = 0.7, alpha = .7, colour = \"NA\",\n  show.legend = FALSE\n) +\n  facet_grid(yr ~ .)\ng1.3\n\n\n\n\nFinally we change some last style settings.\n\ng1 &lt;- g1.3 + geom_hline(yintercept = 0) +\n  scale_fill_manual(values = c(\"#99000d\", \"#034e7b\")) +\n  scale_y_continuous(\"Anomalía de precipitación (%)\",\n    breaks = seq(-100, 500, 100),\n    expand = c(0, 5)\n  ) +\n  labs(\n    x = \"\",\n    title = \"Anomalía de precipitación en Santiago de Compostela\",\n    caption = \"Datos: eca.knmi.nl\"\n  ) +\n  theme_hc()\ng1\n\n\n\n\nWe use the same legend created for the previous graph.\n\n\nPart 2\nFinally, we join the graph and the legends with the help of the cowplot package. The only thing we must adjust here are the arguments in the draw_plot() function to correctly place the different parts.\n\np &lt;- ggdraw() +\n  draw_plot(g1, x = 0, y = .18, width = 1, height = 0.8) +\n  draw_plot(g2, x = 0, y = .08, width = .2, height = .15) +\n  draw_plot(g3, x = 0.08, y = .08, width = .2, height = .15)\n\np"
  },
  {
    "objectID": "blog/tomorrows-weather/index.html",
    "href": "blog/tomorrows-weather/index.html",
    "title": "Tomorrow’s weather",
    "section": "",
    "text": "Part II. Orthographic map\n\n\nA while back I saw Chris Campbell’s global maps from the Financial Times like in this Tweet and I thought I needed to do it in R. In this first post of 2023 well see how we can access the GFS (Global Forecast System) data and visualize it with {ggplot2}, even though there are several ways, in this case we use the Google Earth Engine API via the {rgee} package for accessing the GFS data. We will select the most recent run and calculate the maximum temperature for the next few days.\n\nPackages\n\n\n\n\n\n\n\nPackage\nDescription\n\n\n\n\ntidyverse\nCollection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.\n\n\nlubridate\nEasy manipulation of dates and times\n\n\nsf\nSimple Feature: import, export and manipulate vector data\n\n\nterra\nImport, export and manipulate raster ({raster} successor package)\n\n\nrgee\nAccess to Google Earth Engine API\n\n\ngiscoR\nAdministrative boundaries of the world\n\n\nggshadow\nExtension to ggplot2 for shaded and glow geometries\n\n\nfs\nProvides a cross-platform, uniform interface to file system operations\n\n\nggforce\nProvides missing functionality to ggplot2\n\n\n\n\n#  install the packages if necessary\nif(!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif(!require(\"sf\")) install.packages(\"sf\")\nif(!require(\"terra\")) install.packages(\"terra\")\nif(!require(\"fs\")) install.packages(\"fs\")\nif(!require(\"rgee\")) install.packages(\"rgee\")\nif(!require(\"giscoR\")) install.packages(\"giscoR\")\n1if(!require(\"ggshadow\")) install.packages(\"ggshadow\")\nif(!require(\"ggforce\")) install.packages(\"ggforce\")\nif(!require(\"googledrive\")) install.packages(\"googledrive\")\n\n#  packages\nlibrary(rgee)\nlibrary(terra)\nlibrary(sf)\nlibrary(giscoR)\n\nlibrary(fs)\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(ggshadow)\nlibrary(ggforce)\nlibrary(googledrive)\n\n\n1\n\nToday the newest version 0.0.5 is not working correctly. Here I used the 0.0.4 version.\n\n\n\n\n\n\nPart I. Geoprocessing with Google Earth Engine (GEE)\n\nBefore using GEE in R\nThe first step is to sign up at earthengine.google.com. In addition, it is necessary to install CLI of gcloud (https://cloud.google.com/sdk/docs/install?hl=es-419), you just have to follow the instructions in Google. Regarding the GEE language, many functions that are applied are similar to what is known from {tidyverse}. More help can be found at https://r-spatial.github.io/rgee/reference/rgee-package.html and on the GEE page itself.\nThe most essential of GEE’s native Javascript language is that it is characterized by the way of combining functions and variables using the dot, which is replaced by the $ in R. All GEE functions start with the prefix ee_* (ee_print( ), ee_image_to_drive()).\nOnce we have gcloud and the {rgee} package installed we can proceed to create the Python virtual environment. The ee_install() function takes care of installing Anaconda 3 and all necessary packages. To check the correct installation of Python, and particularly of the numpy and earthengine-api packages, we can use ee_check().\n\nee_install() # create python virtual environment\nee_check() # check if everything is correct\n\nBefore programming with GEE’s own syntax, GEE must be authenticated and initialized using the ee_Initialize() function. Not working! See issue https://github.com/r-spatial/rgee/issues/355\n\nee_Initialize(drive = TRUE) \n\nInstead you should do:\n\nee$Authenticate(auth_mode='notebook')\n\n\nee$Initialize(project='ee-dominicroye')\n\n\n\nAccess the Global Forecast System\nA time series of images or multidimensional data is called an ImageCollection in GEE. Each dataset is assigned an ID and we can access it by making the following call ee$ImageCollection('ID_IMAGECOLLECTION'). There are helper functions that allow conversion of purely R classes to Javascript, e.g. for dates rdate_to_eedate(). The first thing we do is to filter to the most recent date with the last run of the GFS model.\nWe have to know that, unlike R, only when GEE tasks are sent, the calculation are executed on the servers using all the created GEE objects. Most steps create only EarthEngine objects what you will see soon in this post.\n\n## GFS forecast\ndataset &lt;- ee$ImageCollection('NOAA/GFS0P25')$filter(ee$Filter$date(rdate_to_eedate(today()-days(1)),\n\nrdate_to_eedate(today()+days(1))))\ndataset\n\nThe model runs every 6 hours (0, 6, 12, 18), so the ee_get_date_ic() function extracts the dates to choose the most recent one. This is the first time that calculations are run.\n\n# vector of unique run dates\nlast_run &lt;- ee_get_date_ic(dataset)$time_start |&gt; unique()\nlast_run\n\n\n# select the last one\nlast_run &lt;- max(last_run)\n\nNext we filter the date of the last run and select the band of the air temperature at 2m. Forecast dates are attributes of each model run up to 336 hours (14 days) from the day of execution. When we want to make changes to each image in an ImageCollection we must make use of the map() function, similar to the one we know from the {purrr} package. In this case we redefine the date of each image (system:time_start: run date) by that of the forecast (forecast_time). It is important that the R function to apply is inside ee_utils_pyfunc(), which translates it into Python. Then we extract the dates from the 14 day forecast.\n\n# last run and variable selection\ntemp &lt;- dataset$filter(ee$Filter$date(rdate_to_eedate(last_run)))$select('temperature_2m_above_ground')\n\n# define the forecast dates for each hour\nforcast_time &lt;- temp$map(ee_utils_pyfunc(function(img)  {\n  \n  return(ee$Image(img)$set('system:time_start',ee$Image(img)$get(\"forecast_time\")))\n\n  })\n)\n\n# get the forecast dates\ndate_forcast &lt;- ee_get_date_ic(forcast_time)\nhead(date_forcast)\n\nHere we could export the hourly temperature data, but it would also be possible to estimate the maximum or minimum daily temperature for the next 14 days. To achieve this we define the beginning and end of the period, and calculate the number of days. What we do in simple terms is map over the number of days to filter on each day and apply the max() function or any other similar function.\n\n# define start end of the period\nendDate &lt;- rdate_to_eedate(round_date(max(date_forcast$time_start)-days(1), \"day\"))\nstartDate &lt;- rdate_to_eedate(round_date(min(date_forcast$time_start), \"day\"))\n\n# number of days\nnumberOfDays &lt;- endDate$difference(startDate, 'days')\n\n# calculate the daily maximum\ndaily &lt;- ee$ImageCollection(\n  ee$List$sequence(0, numberOfDays$subtract(1))$\n  map(ee_utils_pyfunc(function (dayOffset) {\n    start = startDate$advance(dayOffset, 'days')\n    end = start$advance(1, 'days')\n    return(forcast_time$\n    filterDate(start, end)$\n    max()$ # alternativa: min(), mean()\n    set('system:time_start', start$millis()))\n  }))\n)\n\n# dates of the daily maximum\nhead(ee_get_date_ic(daily))\n\n\n\nDynamic map via GEE\nSince there is the possibility of adding images to a dynamic map in the GEE code editor, we can also do it from R using the GEE function Map.addLayer(). We simply select the first day with first(). In the other argument we define the range of the temperature values and the color ramp.\n\nMap$addLayer(\n        eeObject = daily$first(),\n        visParams = list(min = -45, max = 45,\n                        palette = rev(RColorBrewer::brewer.pal(11, \"RdBu\"))),\n        name = \"GFS\") + \nMap$addLegend(\n  list(min = -45, max = 45, \n        palette = rev(RColorBrewer::brewer.pal(11, \"RdBu\"))), \n        name = \"Maximum temperature\", \n        position = \"bottomright\", \n        bins = 10)\n\n\n\nExport multiple images\nThe {rgee} package has a very useful function for exporting an ImageCollection: ee_imagecollection_to_local(). Before using it, we need to set a region, the one that is intended to be exported. In this case, we export the entire globe with a rectangle covering the whole Earth.\n\n# earth extension\ngeom &lt;- ee$Geometry$Polygon(coords = list(\n  c(-180, -90), \n  c(180, -90),\n  c(180, 90),\n  c(-180, 90),\n  c(-180, -90)\n),\nproj = \"EPSG:4326\",\ngeodesic = FALSE)\n\ngeom # EarthEngine object of type geometry\n\n# temporary download folder\n\ndata_export &lt;- daily$filter(ee$Filter$date(rdate_to_eedate(today()), rdate_to_eedate(today()+days(3))))\n\n# Obtener la lista de imÃ¡genes\nimage_list &lt;- data_export$toList(data_export$size())\n\n# FunciÃ³n para exportar cada imagen\nexport_image &lt;- function(image, index) {\n  image &lt;- ee$Image(image_list$get(index))\n  task &lt;- ee$batch$Export$image$toDrive(\n    image = image$clip(geom),\n    description = paste0(\"Image_\", index),\n    scale = 20000,\n    region = geom,\n    folder = \"tomorrow\", # create folder on your drive before submitting\n    maxPixels = 1e13\n  )\n  task$start()\n}\n\n# Iterar sobre la lista de imÃ¡genes y exportarlas\nfor (i in 0:(data_export$size()$getInfo() - 1)) {\n  export_image(image_list, i)\n}\n\nee_monitoring(eeTaskList = TRUE)\n\n\ngee_files &lt;- drive_ls(path = \"tomorrow\") \n\n\nwalk(gee_files$id, drive_download, overwrite = T)\n\n\n\n\nPart II. Orthographic map\n\nData\nOf course, the first step is to import the data with the help of rast(). We also define the name of each layer according to its temporal dimension correctly.\n\n# paths to downloaded data\nforecast_world &lt;- dir_ls(regexp = \"tif\")\n\n# guarantee the file order \nfile_ord &lt;- str_extract(forecast_world, \"_[0-9]{1,2}\") |&gt; parse_number()\n\nforecast_rast &lt;- rast(forecast_world[order(file_ord)]) # import\nforecast_rast\n\n# define the temporal dimension as the name of each layer\nnames(forecast_rast) &lt;- seq(today(), today() + days(2), \"day\")\ntime(forecast_rast) &lt;- seq(today(), today() + days(2), \"day\")\nforecast_rast\n\n# plot\nplot(forecast_rast)\n\nNow we can define the orthographic projection indicating with +lat_0 and +lon_0 the center of the projection. We then reproject and convert the raster to a data.frame.\n\n# projection definition\northo_crs &lt;-'+proj=ortho +lat_0=51 +lon_0=0.5 +x_0=0 +y_0=0 +R=6371000 +units=m +no_defs +type=crs'\n\n# reproject the raster\nras_ortho &lt;- project(forecast_rast, ortho_crs)\n\n# convert the raster to a data.frame of xyz\nforecast_df &lt;- as.data.frame(ras_ortho, xy = TRUE)\n\n# transform to a long format\nforecast_df &lt;- pivot_longer(forecast_df, 3:length(forecast_df), names_to = \"date\", values_to = \"ta\")\n\n\n\nAdministrative boundaries and graticules\nWe import the administrative boundaries with gisco_get_countries() which we need prepare for the orthographic projection. In the same way we create the graticule using st_graticule(). In order to preserve the geometry, it will be necessary to cut to only the visible part. The ocean is created starting from a point at 0.0 with the radius of the earth. Using the st_intersection() function we reduce to the visible part and reproject the boundaries.\n\n# obtain the administrative limits\nworld_poly &lt;- gisco_get_countries(year = \"2016\", epsg = \"4326\", resolution = \"10\") \n\n# get the global graticule\ngrid &lt;- st_graticule()\n\n# define what would be ocean\nocean &lt;- st_point(x = c(0,0)) |&gt;\n            st_buffer(dist = 6371000) |&gt; # earth radius\n              st_sfc(crs = ortho_crs)\nplot(ocean)\n\n\n# select only visible from the boundaries and reproject\nworld &lt;- world_poly |&gt;\n            st_intersection(st_transform(ocean, 4326)) |&gt;\n            st_transform(crs = ortho_crs) # \nplot(world)\n\nFor the graticules we must repeat the same selection, although we previously limit the grid of lines to the ocean. The ocean boundary is used to create the globeâs shadow, but to use it in geom_glowpath() you need to convert it to a data.frame.\n\n# eliminate the lines that pass over the continents\ngrid_crp &lt;- st_difference(grid, st_union(world_poly))\n\n# select the visible part\ngrid_crp &lt;- st_intersection(grid_crp, st_transform(ocean, 4326)) |&gt;\n                  st_transform(crs = ortho_crs)\n\nplot(grid_crp)\n\n# convert the boundary of the globe into a data.frame\nocean_df &lt;- st_cast(ocean, \"LINESTRING\") |&gt; st_coordinates() |&gt; as.data.frame()\n\n\n\nMap construction\n\nSelect tomorrow\nFirst we select the day of tomorrow, in my case when I write this post it is February 22, 2023. In addition, we limit the temperature range to -45ÂºC and +45ÂºC.\n\nforecast_tomorrow &lt;- filter(forecast_df, date == today() + days(1)) |&gt;\n                        mutate(ta_limit = case_when(ta &gt; 45 ~ 45,\n                                              ta &lt; -45 ~ -45,\n                                              TRUE ~ ta))\n\n\n\nThe shadow of the globe\nWe create the shadow effect using the geom_glowpath() function from the {ggshadow} package. Aiming for a more smooth transition I duplicate this layer with different transparency and shadow settings.\n\n# build a simple shadow\nggplot() + \n   geom_glowpath(data = ocean_df, \n                aes(X, Y, group = \"L1\"),\n                shadowcolor='grey90',\n                     colour = \"white\",\n                alpha = .01,\n                shadowalpha=0.05,\n                shadowsize = 1.5) +\n    geom_glowpath(data = ocean_df, \n                aes(X, Y, group = \"L1\"),\n                shadowcolor='grey90',\n                       colour = \"white\",\n                alpha = .01,\n                shadowalpha=0.01,\n                shadowsize = 1) +\n   coord_sf() +\n   theme_void()\n\n\n# combining several layers of shadow\ng &lt;- ggplot() +\n   geom_glowpath(data = ocean_df, \n                aes(X, Y, group = \"L1\"),\n                shadowcolor='grey90',\n                     colour = \"white\",\n                alpha = .01,\n                shadowalpha=0.05,\n                shadowsize = 1.8) +\n   geom_glowpath(data = ocean_df, \n                aes(X, Y, group = \"L1\"),\n                shadowcolor='grey90',\n                       colour = \"white\",\n                alpha = .01,\n                shadowalpha=0.02,\n                shadowsize = 1) +\n   geom_glowpath(data = ocean_df, \n                aes(X, Y, group = \"L1\"),\n                shadowcolor='grey90',\n                       colour = \"white\",\n                alpha = .01,\n                shadowalpha=0.01,\n                shadowsize = .5) \n\n\n\nAdding other layers\nIn the next step we add the temperature layer and both vector layers.\n\ng2 &lt;- g + geom_raster(data = forecast_tomorrow, aes(x, y, fill = ta_limit)) +\n          geom_sf(data = grid_crp, \n                  colour = \"white\", \n                  linewidth = .2) +\n          geom_sf(data = world, \n                   fill = NA,\n                   colour = \"grey10\",\n                   linewidth = .2) \n\nWhat we need to add are the last definitions of the color, the legend and the general style of the map.\n\ng2 + scale_fill_distiller(palette = \"RdBu\", \n                          limits = c(-45, 45),\n                          breaks = c(-45, -25, 0, 25, 45)) +\n     guides(fill = guide_colourbar(barwidth = 15, \n                                   barheight = .5, \n                                   title.position = \"top\",\n                                   title.hjust = .5)) +\n  coord_sf() +\n  labs(fill = str_wrap(\"Maximum temperature at 2 meters for February 14\", 35)) +\n  theme_void() +\n  theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 7),\n        plot.margin = margin(10, 10, 10, 10)) \n\nIf we wanted to add labels for the points with the lowest and highest temperatures, we would need to filter the extremes from our table.\n\nlabeling &lt;- slice(forecast_tomorrow, which.min(ta), which.max(ta))\nlabeling\n\nThe geom_mark_circle() function allows you to include a circle label at any position. We create the label using str_glue() where the variable will be replaced by each temperature of both extremes, at the same time we can define the format of the number with number() from the {scales} package.\n\ng2 +  geom_mark_circle(data = labeling, \n                       aes(x, y, \n                          description = str_glue('{scales::number(ta, accuracy = .1, decimal.mark = \".\", style_positive = \"plus\", suffix = \"ÂºC\")}')\n                          ), \n                   expand = unit(1, \"mm\"), \n                   label.buffer = unit(4, \"mm\"),\n                   label.margin = margin(1, 1, 1, 1, \"mm\"),\n                   con.size = 0.3,\n                   label.fontsize = 8,\n                   label.fontface = \"bold\",\n                   con.type = \"straight\",\n                  label.fill = alpha(\"white\", .5)) +\n     scale_fill_distiller(palette = \"RdBu\", \n                          limits = c(-45, 45),\n                          breaks = c(-45, -25, 0, 25, 45)) +\n     guides(fill = guide_colourbar(barwidth = 15, \n                                   barheight = .5, \n                                   title.position = \"top\",\n                                   title.hjust = .5)) +\n  coord_sf(crs = ortho_crs) +\n  labs(fill = str_wrap(\"Maximum temperature at 2 meters for February 14\", 35)) +\n  theme_void() +\n  theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 7),\n        plot.margin = margin(10, 10, 10, 10)) \n\n\n\n\n\n\n\n Back to topReuseCC BY-SA 4.0CitationFor attribution, please cite this work as:\nRoyé, Dominic. 2023. “Tomorrow’s Weather.” February 20,\n2023. https://dominicroye.github.io/blog/tomorrows-weather/."
  },
  {
    "objectID": "blog/river-flow-directions/index.html",
    "href": "blog/river-flow-directions/index.html",
    "title": "River flow directions",
    "section": "",
    "text": "I recently created a visualization of the distribution of river flow directions and also of coastal orientations. Following its publication in social networks, I was asked to make a post about how I did it. Well, here we go to start with an example of rivers, coastal orientation is somewhat more complex. I did the same for a selection of European rivers here in this. However, originally I started with the orientation of the European coasts."
  },
  {
    "objectID": "blog/river-flow-directions/index.html#data",
    "href": "blog/river-flow-directions/index.html#data",
    "title": "River flow directions",
    "section": "Data",
    "text": "Data\nWe download the central lines of the largest rivers in the world (here), also accessible in Zeenatul Basher et al. 2018."
  },
  {
    "objectID": "blog/river-flow-directions/index.html#import-and-project",
    "href": "blog/river-flow-directions/index.html#import-and-project",
    "title": "River flow directions",
    "section": "Import and project",
    "text": "Import and project\nThe first thing we do is to import, project the spatial lines and delete the third dimension Z, chaining the following functions: st_read() helps us import any vector format, st_zm() delete the dimension Z or M of a geometry and st_transform() projects the vector data to the new projection in proj4 format. We combine the functions with the famous pipe (|&gt;) that facilitates the application of a sequence of functions on a data set. All functions in the sf package start with st_* with reference to the spatial character, similar to PostGIS. In the same style as PostGIS, verbs are used as function names.\n\nproj_rob &lt;- \"ESRI:54030\"\n\nriver_line &lt;- st_read(\"RiverHRCenterlinesCombo.shp\") |&gt;\n  st_zm() |&gt;\n  st_transform(proj_rob)"
  },
  {
    "objectID": "blog/river-flow-directions/index.html#extract-the-angles",
    "href": "blog/river-flow-directions/index.html#extract-the-angles",
    "title": "River flow directions",
    "section": "Extract the angles",
    "text": "Extract the angles\nIn the next step we have to extract the vertice angles. Unfortunately, as far as I know, it is not possible to extract the attributes with some function from the sf package. Although the function st_coordinates() returns the coordinates, it does not include other attributes. Therefore, we must use another way, and that is the open software Quantum GIS in which we can find a tool to extract all the vertice attributes. We could import the vector data into QGIS Desktop and export the vertices from there, but it is also possible to access the QGIS tools from R directly.\nFor this, we need to have QGIS installed. The qgisprocess package allows us to use very easily all the tools of the software in R. First we use the qgis_configure() function to define all the necessary QGIS paths.\n\n# paths to QGIS\nqgis_configure()\n\nThe qgis_algorithms() function helps us to search for different QGIS tools. In addition the qgis_show_help() function specifies the way of usage with all the required parameters.\n\n# search tools\nqgis_algorithms()\n\n\n# usage of tool\nqgis_show_help(\"native:extractvertices\")\n\nIn our case the tool to extract the vertices is simple and only has one input and one output. The function qgis_run_algorithm() executes a QGIS tool indicating the algorithm and its arguments. The advantage of using the algorithm directly from R is that we can pass objects of class sf (or sp) and raster that we have imported or created in R. As output we create a geojson, it could also be of another vector format, and we save it in a temporary folder. To obtain the QGIS output we need to use qgis_extract_output() function.\n\nriver_vertices &lt;- qgis_run_algorithm(\n  alg = \"native:extractvertices\",\n  INPUT = river_line,\n  OUTPUT = file.path(tempdir(), \"rivers_world_vertices.geojson\")\n)\n\nriver_vertices &lt;- st_read(qgis_extract_output(river_vertices, \"OUTPUT\"))"
  },
  {
    "objectID": "blog/river-flow-directions/index.html#selection",
    "href": "blog/river-flow-directions/index.html#selection",
    "title": "River flow directions",
    "section": "Selection",
    "text": "Selection\nBefore continuing with the distribution estimation of the angles, we filter some rivers of interest. The functions of the tidyverse collection are compatible with the sf package.\n\nriver_vertices &lt;- filter(\n  river_vertices,\n  NAME %in% c(\n    \"Mississippi\", \"Colorado\",\n    \"Amazon\", \"Nile\", \"Orange\",\n    \"Ganges\", \"Yangtze\", \"Danube\",\n    \"Mackenzie\", \"Lena\", \"Murray\",\n    \"Niger\"\n  )\n)\n\nriver_vertices"
  },
  {
    "objectID": "blog/map-circle-packing/index.html",
    "href": "blog/map-circle-packing/index.html",
    "title": "Map of circles grouped in multiple locations",
    "section": "",
    "text": "In my first post of 2024, which unfortunately has not been possible before April, I will explain how we can group in the same location several proportional circles. In 2022 I was looking for how to represent the number of heat wave days according to the degree of severity in Spain. I found the solution using the circle packing which is also used in the Dorling cartogram."
  },
  {
    "objectID": "blog/map-circle-packing/index.html#data",
    "href": "blog/map-circle-packing/index.html#data",
    "title": "Map of circles grouped in multiple locations",
    "section": "Data",
    "text": "Data\nIn this post we will use a dataset of heat waves registered in the year 2022 (download). At the time I calculated the Excess Heat Factor index for different locations in Spain. You can find the formulas of the index in Díaz-Poso et al. (2023). It is a geojson with the number of heat wave days according to severity (low, severe, extreme) for 51 weather stations. The data needs to be projected, in this case it is ETRS89 UTM 30 (EPSG:25830). In addition, we import and modify the provincial and global boundaries to use them as a basis for the map.\n\n# import EHF heat wave 2022 data\nehf &lt;- st_read(\"ehf_2022_spain.geojson\")\nehf\n\n\n# basic plot\nplot(ehf)\n\n\n\n# provincial boundaries Spain\nesp &lt;- esp_get_prov(moveCAN = FALSE, epsg = \"4326\")\nplot(esp)\n\n\n\nesp_pen &lt;- filter(esp, nuts2.name != \"Canarias\")\n\n# interior boundaries of Spain\nesp_inline &lt;- rmapshaper::ms_innerlines(esp_pen)\n\n# global boundaries\neu &lt;- gisco_get_countries(res = 10) |&gt;\n  st_cast(\"MULTILINESTRING\") |&gt;\n  st_crop(\n    xmin = -10, ymin = 34.7,\n    xmax = 4.4, ymax = 43.8\n  )\nplot(eu)\n\n\n\n## Canary Islands\ncanlim &lt;- esp_get_ccaa(\"Canarias\", moveCAN = FALSE)\nbx &lt;- st_bbox(canlim)"
  },
  {
    "objectID": "blog/map-circle-packing/index.html#dorling-diagram",
    "href": "blog/map-circle-packing/index.html#dorling-diagram",
    "title": "Map of circles grouped in multiple locations",
    "section": "Dorling diagram",
    "text": "Dorling diagram\nWhen I started investigating possibilities to achieve circles in a grouped position without overlapping, I thought directly of the cartogram_dorling() function from the {cartogram} package. The problem I faced was that it is designed for only one category or level, however, as we can see we have up to three levels of severity. If we use the function for low severity we get the following result.\n\n# Dorling low gravity map\ndor &lt;- cartogram_dorling(filter(ehf, levels == \"low\"), \"n\", k = .3)\n\n# map\nggplot(\n  dor,\n  aes(fill = n)\n) +\n  geom_sf(\n    data = esp,\n    fill = \"grey80\",\n    colour = \"white\",\n    linewidth = .3\n  ) +\n  geom_sf() +\n  scale_fill_distiller(palette = \"YlOrRd\", direction = 1) +\n  labs(fill = NULL, title = \"Number of heat weave days with low severity\") +\n  theme_void() +\n  theme(\n    legend.position = \"top\",\n    legend.key.height = unit(.5, \"lines\"),\n    legend.key.width = unit(3, \"lines\"),\n    plot.title = element_text(margin = margin(t = 5, b = 10), hjust = .5)\n  )\n\n\nSo, what can we do? We should take a closer look at the function, which facilitates the creation of the Dorling map (link). First we could create a map of small multiples, but one problem we encounter is that we cannot set a maximum value of a variable. So, we add and modify it slightly to the line where the area is calculated (dat.init$v).\n\ncartogram_dorling2.sf &lt;- function(x, weight,\n                                  limit_mx = NULL, # new argument\n                                  k = 5,\n                                  m_weight = 1,\n                                  itermax = 1000) {\n  # proj or unproj\n  if (sf::st_is_longlat(x)) {\n    stop('Using an unprojected map. This function does not give correct centroids and distances for longitude/latitude data:\\nUse \"st_transform()\" to transform coordinates to another projection.', call. = F)\n  }\n  # no 0 values\n  x &lt;- x[x[[weight]] &gt; 0, ]\n  # data prep\n  dat.init &lt;- data.frame(sf::st_coordinates(sf::st_centroid(sf::st_geometry(x))),\n    v = x[[weight]]\n  )\n  surf &lt;- (max(dat.init[, 1]) - min(dat.init[, 1])) * (max(dat.init[, 2]) - min(dat.init[, 2]))\n  # dat.init$v &lt;- dat.init$v * (surf * k / 100) / max(dat.init$v) # old\n\n  dat.init$v &lt;- dat.init$v * (surf * k / 100) / ifelse(is_null(limit_mx),\n    max(dat.init$v),\n    limit_mx\n  ) # new argument\n\n  # circles layout and radiuses\n  res &lt;- packcircles::circleRepelLayout(\n    x = dat.init, xysizecols = 1:3,\n    wrap = FALSE, sizetype = \"area\",\n    maxiter = itermax, weights = m_weight\n  )\n  # sf object creation\n  . &lt;- sf::st_buffer(\n    sf::st_as_sf(res$layout,\n      coords = c(\"x\", \"y\"),\n      crs = sf::st_crs(x)\n    ),\n    dist = res$layout$radius\n  )\n  sf::st_geometry(x) &lt;- sf::st_geometry(.)\n  return(x)\n}\n\nIf we now use the modified function, we will achieve multiple small Dorling’s. We simply map the new function on each category.\n\n# estimate the maximum value\nmax_value &lt;- max(ehf$n)\n\n# map over each category\ndor2 &lt;- split(ehf, ~levels) |&gt;\n  map(cartogram_dorling2.sf,\n    weight = \"n\",\n    k = .3,\n    limit_mx = max_value\n  )\n\n# rejoin the tables and set the order\ndor2 &lt;- bind_rows(dor2) |&gt;\n  mutate(levels = factor(levels, c(\"low\", \"severe\", \"extreme\")))\n\n# map of small multiples\nggplot(\n  dor2,\n  aes(fill = n)\n) +\n  geom_sf(\n    data = esp,\n    fill = \"grey80\",\n    colour = \"white\",\n    linewidth = .3\n  ) +\n  geom_sf() +\n  facet_grid(~levels) +\n  scale_fill_distiller(palette = \"YlOrRd\", direction = 1) +\n  labs(fill = NULL, title = \"Number of heat weave days with low severity\") +\n  theme_void() +\n  theme(\n    legend.position = \"top\",\n    legend.key.height = unit(.5, \"lines\"),\n    legend.key.width = unit(3, \"lines\"),\n    plot.title = element_text(margin = margin(t = 5, b = 10), hjust = .5)\n  )\n\n\nI found it interesting, but it was not what I was looking for. I also considered making a proportional symbol map with circles in the same location, using color mixing and transparency in the style of this map (link). Finally I decided to modify the function to achieve a grouped position with circle packing. I introduced another argument surf = null for the extension of the data set, also kept the change of introducing the possibility of the maximum value with the same aim, and I changed the circleRepelLayout() function to the circleProgressiveLayout() one. The second one arranges a set of circles, denoted by their sizes, placing consecutively each circle externally tangent to two previously placed circles avoiding overlaps. Unlike the original layout in which the circles are ordered by iterative pairwise repulsion within a bounding rectangle. Another potential alternative could be the use of networks or graphs with {ggraph}, but I have not yet gotten around to testing it.\n\npackedcircle_dodge_position.sf &lt;- function(x,\n                                            weight,\n                                            surf = NULL,\n                                            limit_mx = NULL, # new argument\n                                            k = .5) {\n  # proj or unproj\n  if (sf::st_is_longlat(x)) {\n    stop('Using an unprojected map. This function does not give correct centroids and distances for longitude/latitude data:\\nUse \"st_transform()\" to transform coordinates to another projection.', call. = F)\n  }\n  # no 0 values\n  x &lt;- x[x[[weight]] &gt; 0, ]\n  # data prep\n  dat.init &lt;- data.frame(sf::st_coordinates(sf::st_centroid(sf::st_geometry(x))),\n    v = x[[weight]]\n  )\n\n  if (is_null(surf)) surf &lt;- (max(dat.init[, 1]) - min(dat.init[, 1])) * (max(dat.init[, 2]) - min(dat.init[, 2]))\n\n  dat.init$v &lt;- dat.init$v * (surf * k / 100) / ifelse(is_null(limit_mx),\n    max(dat.init$v),\n    limit_mx\n  ) # new argument\n  # circles layout and radiuses\n  res &lt;- packcircles::circleProgressiveLayout(\n    x = dat.init,\n    sizecol = \"v\"\n  ) # other layout\n\n  res &lt;- mutate(res, x = dat.init$X + x, y = dat.init$Y + y) # reconvert to lon, lat\n\n  # sf object creation\n  . &lt;- sf::st_buffer(\n    sf::st_as_sf(res,\n      coords = c(\"x\", \"y\"),\n      crs = sf::st_crs(x)\n    ),\n    dist = res$radius\n  )\n  sf::st_geometry(x) &lt;- sf::st_geometry(.)\n\n  return(x)\n}"
  },
  {
    "objectID": "blog/map-circle-packing/index.html#creation-of-grouped-circles",
    "href": "blog/map-circle-packing/index.html#creation-of-grouped-circles",
    "title": "Map of circles grouped in multiple locations",
    "section": "Creation of grouped circles",
    "text": "Creation of grouped circles\nFirst, we must define global variables for all locations. Among others, the spatial extent of the data, the maximum value, the scale factor for the size, and the variable of interest.\n\nlimit_mx &lt;- max(ehf$n) # maximum value\nlonglat &lt;- st_coordinates(ehf) # UTM coordinates\nsurf &lt;- (max(longlat[, 1]) - min(longlat[, 1])) * (max(longlat[, 2]) - min(longlat[, 2])) # extension\nweight &lt;- \"n\" # variable\nk &lt;- .1 # size factor\n\nIn the next step, we split our data into as many subsets as locations using the split() function. Then we apply the circle packing function to each one individually with map() passing all the previously defined global arguments. After that, we would only have to gather all the spatial tables.\n\n# map over all locations\ncircle_dodge &lt;- split(ehf, ~stat_name) |&gt;\n  map(packedcircle_dodge_position.sf,\n    surf = surf, k = k,\n    weight = weight,\n    limit_mx = limit_mx\n  )\n\n# rejoin\ncircle_dodge &lt;- bind_rows(circle_dodge) |&gt;\n  mutate(levels = factor(\n    levels,\n    c(\"low\", \"severe\", \"extreme\")\n  )) # fijamos orden\n\nplot(circle_dodge[\"n\"]) # resultado"
  },
  {
    "objectID": "blog/map-circle-packing/index.html#map-construction",
    "href": "blog/map-circle-packing/index.html#map-construction",
    "title": "Map of circles grouped in multiple locations",
    "section": "Map construction",
    "text": "Map construction"
  },
  {
    "objectID": "blog/map-circle-packing/index.html#legend",
    "href": "blog/map-circle-packing/index.html#legend",
    "title": "Map of circles grouped in multiple locations",
    "section": "Legend",
    "text": "Legend\nIn the map construction the first thing we should make is the legend. We must create it manually by defining different magnitudes, in our case, number of days. Then we estimate the area and construct the circles artificially on a constant line of latitude at +45º, position where we will insert the legend as if it were a spatial object.\n\n# areas\nlegend_area &lt;- c(5, 10, 15, 30, 50) * (surf * k / 100) / limit_mx\n\n# circles construction at artificial coordinates\nlegend_dat &lt;- tibble(\n  area = legend_area, r = sqrt(area / pi),\n  n = c(5, 10, 15, 30, 50), y = 45\n) |&gt;\n  arrange(area) |&gt;\n  mutate(x = -4:0) |&gt;\n  st_as_sf(coords = c(\"x\", \"y\"), crs = st_crs(esp)) |&gt;\n  st_transform(25830) %&gt;% # switch to the other pipe for nested placehodler .\n  st_buffer(dist = .$r) |&gt;\n  st_cast(\"LINESTRING\")\n\nplot(legend_dat[\"n\"])\n\n\nA more compact alternative legend would be collapsed circles, which can be achieved by changing the position with respect to the largest circle. However, the legend in this case remains small because of the maximum size of the circles. An increase in the size of the circles would lead to overlapping between different locations.\n\n# circles construction at artificial coordinates\nlegend_dat2 &lt;- tibble(\n  area = legend_area, r = sqrt(area / pi),\n  n = c(5, 10, 15, 30, 50), y = 45\n) |&gt;\n  arrange(area) |&gt;\n  mutate(x = -3) |&gt;\n  st_as_sf(coords = c(\"x\", \"y\"), crs = st_crs(esp)) |&gt;\n  st_transform(25830)\n\nlegend_dat2 &lt;- cbind(legend_dat2, st_coordinates(legend_dat2)) |&gt;\n  mutate(Y = Y - (max(r) - r)) |&gt;\n  st_drop_geometry() |&gt;\n  st_as_sf(coords = c(\"X\", \"Y\"), crs = 25830) %&gt;%\n  st_buffer(dist = .$r) |&gt;\n  st_cast(\"LINESTRING\")\n\nplot(legend_dat2[\"n\"])"
  },
  {
    "objectID": "blog/map-circle-packing/index.html#canary-islands",
    "href": "blog/map-circle-packing/index.html#canary-islands",
    "title": "Map of circles grouped in multiple locations",
    "section": "Canary Islands",
    "text": "Canary Islands\nThe first map would correspond to the Canary Islands, which is added to the main map in a false position. In ggplot2 any simple feature geometry can be added with geom_sf() by adjusting the own characteristics of points, lines or polygons.\n\ncan &lt;- ggplot() +\n  geom_sf(data = esp, fill = \"grey20\", colour = NA) +\n  geom_sf(\n    data = esp_inline, colour = \"white\",\n    size = .2\n  ) +\n  geom_sf(\n    data = circle_dodge,\n    aes(fill = levels),\n    alpha = .8,\n    colour = \"white\",\n    stroke = .025,\n    show.legend = FALSE\n  ) +\n  scale_fill_manual(\n    values = c(\"#feb24c\", \"#fc4e2a\", \"#b10026\"),\n    guide = \"none\"\n  ) +\n  theme_void(base_family = \"Lato\") +\n  labs(title = \"Canary Islands\") +\n  theme(\n    plot.background = element_rect(fill = NA, colour = \"black\"),\n    plot.title = element_text(vjust = 8, margin = margin(b = 4, l = 3))\n  ) +\n  coord_sf(\n    xlim = bx[c(1, 3)],\n    ylim = bx[c(2, 4)],\n    crs = 4326\n  )\n\ncan"
  },
  {
    "objectID": "blog/map-circle-packing/index.html#spain",
    "href": "blog/map-circle-packing/index.html#spain",
    "title": "Map of circles grouped in multiple locations",
    "section": "Spain",
    "text": "Spain\nTo build the main map, we will exclude the locations of the Canary Islands. In addition, we need to have the new position of the Canary Islands in the southwest of the Peninsula. The main difference with the previous map is that we include the legend as a spatial object using the geom_text_sf() function. It is a variant of the {geomtextpath} package to add a label following any geometry path. Unfortunately, not all possible arguments of the package (issue) can be used. It is important that the geometry must be of type LINESTRING. Therefore, we changed the type with st_cast() above. Finally, we insert the map of the Canary Islands using the annotation_custom() function. More details about inserted maps can be found here.\n\n# filter out locations in mainland Spain and the Balearic Islands\nesp_data &lt;- st_filter(circle_dodge, st_transform(esp_pen, 25830))\n\n# coordinates of the Canary Islands moved position\ncan_ext &lt;- c(xmin = -11.74, ymin = 34.92, xmax = -7, ymax = 36.70)\nclass(can_ext) &lt;- \"bbox\"\n\ncan_bbx &lt;- st_as_sfc(can_ext) |&gt;\n  st_set_crs(4326) |&gt;\n  st_transform(25830) |&gt;\n  st_bbox()\n\n# part one adding the base map limits\ng1 &lt;- ggplot() +\n  geom_sf(data = eu, colour = \"grey80\", size = .3) +\n  geom_sf(data = esp_pen, fill = \"grey20\", colour = NA) +\n  geom_sf(\n    data = esp_inline, colour = \"white\",\n    size = .2\n  )\n\n# add the grouped proportional circles\ng2 &lt;- g1 + geom_sf(\n  data = esp_data,\n  aes(fill = levels),\n  alpha = .7,\n  colour = \"white\",\n  stroke = .02,\n  show.legend = \"point\"\n) +\n  geom_sf(data = legend_dat, aes(label = n)) + \n  geom_text(\n    data = st_centroid(legend_dat), # legend in artifical\n    aes(label = n, geometry = geometry),\n    stat = \"sf_coordinates\",\n    size = 2.5, vjust = 0.5\n  ) +\n1\n  # geom_textsf(data = legend_dat,  # position lat 45º.  not working due to bug \n  #          aes(label = n),\n  #          size = 2.5, hjust = .21) +\n  annotation_custom(ggplotGrob(can), # Canary Islands\n    xmin = can_bbx[1], xmax = can_bbx[3],\n    ymin = can_bbx[2], ymax = can_bbx[4]\n  )\n\n# final adjustments of legend and style\ng2 + scale_fill_manual(values = c(\"#feb24c\", \"#fc4e2a\", \"#b10026\")) +\n  guides(fill = guide_legend(override.aes = list(size = 5, shape = 21))) +\n  labs(fill = \"severity\", title = \"HEAT WAVE DAYS 2022\") +\n  theme_void() +\n  theme(\n    legend.position = \"top\",\n    legend.text.position = \"bottom\",\n    legend.title.position = \"top\",\n    legend.text = element_text(vjust = 3),\n    legend.title = element_text(\n      hjust = .5,\n      size = 14\n    ),\n    legend.margin = margin(t = 5),\n    plot.title = element_text(\n      hjust = .5,\n      face = \"bold\",\n      size = 25,\n      margin = margin(b = 5, t = 20)\n    ),\n    plot.margin = margin(15, 2, 2, 5)\n  ) +\n  coord_sf(crs = 25830, clip = \"off\")\n\n\n1\n\nThere seems to be a bug for the geom_text_sf() function from the {geomtextpath} package. Therefore I use here an alternative way. (30/12/2024)"
  },
  {
    "objectID": "blog/map-circle-packing/index.html#interactive-version",
    "href": "blog/map-circle-packing/index.html#interactive-version",
    "title": "Map of circles grouped in multiple locations",
    "section": "Interactive version",
    "text": "Interactive version\nAs an extra of this post, I show you how we can make the same map interactively using the {ggiraph} package. We only change the geom_sf() function for its geom_sf_interactive() variant. In addition, we indicate what we want to show in the tooltip. We put the result in an object to finish building the interactive version using giraph() and including style settings.\n\nif (!require(\"ggiraph\")) install.packages(\"ggiraph\")\nlibrary(ggiraph) # versión interactiva de geometrias ggplot\n\ng1 &lt;- ggplot() +\n  geom_sf(data = eu, colour = \"grey80\", size = .3) +\n  geom_sf(data = esp_pen, fill = \"grey20\", colour = NA) +\n  geom_sf(\n    data = esp_inline, colour = \"white\",\n    size = .2\n  )\n\ng2 &lt;- g1 + geom_sf_interactive(\n  data = esp_data,\n  aes(fill = levels, tooltip = n), # interactive version with tooltip\n  alpha = .7,\n  colour = \"white\",\n  stroke = .02,\n  show.legend = \"point\"\n) +\n  geom_sf(data = legend_dat, aes(label = n)) +\n    geom_text(\n    data = st_centroid(legend_dat), # legend in artifical\n    aes(label = n, geometry = geometry),\n    stat = \"sf_coordinates\",\n    size = 2.5, vjust = 0.5\n  )\n\ng_final &lt;- g2 + scale_fill_manual(values = c(\"#feb24c\", \"#fc4e2a\", \"#b10026\")) +\n  guides(fill = guide_legend(override.aes = list(size = 5, shape = 21))) +\n  labs(fill = \"severity\", title = \"HEAT WAVE DAYS 2022\") +\n  theme_void() +\n  theme(\n    legend.position = \"top\",\n    legend.text.position = \"bottom\",\n    legend.title.position = \"top\",\n    legend.text = element_text(vjust = 3),\n    legend.title = element_text(\n      hjust = .5,\n      size = 14\n    ),\n    legend.margin = margin(t = 5),\n    plot.title = element_text(\n      hjust = .5,\n      face = \"bold\",\n      size = 25,\n      margin = margin(b = 5, t = 20)\n    ),\n    plot.margin = margin(15, 2, 2, 5)\n  ) +\n  coord_sf(crs = 25830, clip = \"off\")\n\n# creation of the final interactive map\ngirafe(\n  ggobj = g_final,\n  width_svg = 14.69,\n  height_svg = 12,\n  options = list(\n    opts_tooltip(opacity = 0.7, use_fill = T)\n  )\n)"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Meeting People Where They R",
    "section": "",
    "text": "Mapping building use with a hexagonal grid\n\n\n\nSpatial analysis\n\nCartography\n\nGIS\n\nR\n\nR:Elementary\n\nraster\n\nhexagonal grid\n\n\n\n\n\n\n\n\n\nFeb 1, 2026\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nBroken Chart: discover 9 visualization alternatives\n\n\n\nR\n\nR:Intermediate\n\nVisualization\n\nCharts\n\nRemake\n\nBad practice\n\nDistribution\n\nTemperature\n\n\n\n\n\n\n\n\n\nDec 14, 2025\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nAlways normalize your data\n\n\n\nGIS\n\nR\n\nR:Elementary\n\nVisualization\n\nMap\n\nProportional symbol\n\nNormalize\n\n\n\n\n\n\n\n\n\nJan 5, 2025\n\n\nDominic Roye\n\n\n\n\n\n\n\n\n\n\n\n\nMap of circles grouped in multiple locations\n\n\n\nGIS\n\nR\n\nR:Advanced\n\nVisualization\n\nMap\n\nProportional symbol\n\nCircles\n\n\n\n\n\n\n\n\n\nApr 20, 2024\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nInserted maps with ggplot2\n\n\n\nGIS\n\nR\n\nR:Elementary\n\nVisualization\n\n\n\n\n\n\n\n\n\nOct 8, 2023\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nTomorrow’s weather\n\n\n\nGIS\n\nR\n\nR:Advanced\n\nVisualization\n\n\n\n\n\n\n\n\n\nFeb 20, 2023\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nHillshade effects\n\n\n\nGIS\n\nR\n\nR:Intermediate\n\nVisualization\n\nHillshade\n\nDEM\n\nElevation\n\n\n\n\n\n\n\n\n\nJul 20, 2022\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nUse of multidimensional spatial data\n\n\n\nGIS\n\nR\n\nR:Advanced\n\nVisualization\n\nNCDF\n\nDrought\n\nSpain\n\nRaster\n\n\n\n\n\n\n\n\n\nMar 8, 2022\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nVisualize the day-night cycle on a world map\n\n\n\nGIS\n\nR\n\nR:Intermediate\n\nVisualization\n\nWorld map\n\nDay-night\n\nAnimation\n\n\n\n\n\n\n\n\n\nDec 20, 2021\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nClimate circles\n\n\n\nR\n\nR:Elementary\n\nVisualization\n\nClimate\n\nPolar\n\nTemperature\n\n\n\n\n\n\n\n\n\nSep 4, 2021\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nFirefly cartography\n\n\n\nGIS\n\nR\n\nR:Intermediate\n\nVisualization\n\nFirefly\n\nMap\n\nCartography\n\n\n\n\n\n\n\n\n\nJun 1, 2021\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nBivariate dasymetric map\n\n\n\nGIS\n\nR\n\nR:Advanced\n\nVisualization\n\nBivariate\n\nMap\n\nIncome\n\nUrban\n\n\n\n\n\n\n\n\n\nMar 1, 2021\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nA heatmap as calendar\n\n\n\nVisualization\n\nR\n\nR:Intermediate\n\nCalendar\n\nHeatmap\n\nClimate\n\n\n\n\n\n\n\n\n\nDec 20, 2020\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nClimate animation of maximum temperatures\n\n\n\nVisualization\n\nR\n\nR:Advanced\n\nAnimation\n\nTemperature\n\nClimate\n\nGIS\n\n\n\n\n\n\n\n\n\nOct 11, 2020\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nRiver flow directions\n\n\n\nGIS\n\nR\n\nR:Advanced\n\nRiver\n\nDirections\n\nDistribution\n\n\n\n\n\n\n\n\n\nJul 24, 2020\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nVisualize climate anomalies\n\n\n\nVisualization\n\nR\n\nR:Intermediate\n\nClimate\n\nAnomaly\n\nTemperature\n\n\n\n\n\n\n\n\n\nMar 29, 2020\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nGeographic distance\n\n\n\nSpatial analysis\n\nR\n\nR:Elementary\n\nGIS\n\nDistance\n\nCities\n\n\n\n\n\n\n\n\n\nJan 19, 2020\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nVisualize urban growth\n\n\n\nVisualization\n\nR\n\nR:Elementary\n\nGIS\n\nCity\n\nGeography\n\n\n\n\n\n\n\n\n\nNov 1, 2019\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nVisualize monthly precipitation anomalies\n\n\n\nVisualization\n\nR\n\nR:Intermediate\n\nAnomaly\n\nClimate\n\nPrecipitation\n\nBoxplot\n\n\n\n\n\n\n\n\n\nJul 7, 2019\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nTidy correlation tests in R\n\n\n\nStatistics\n\nR\n\nR:Advanced\n\nCorrelation\n\nTests\n\n\n\n\n\n\n\n\n\nApr 17, 2019\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nImport Excel sheets with R\n\n\n\nManagement\n\nR\n\nR:Intermediate\n\nExcel\n\nSheets\n\n\n\n\n\n\n\n\n\nMar 10, 2019\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nCalculating the distance to the sea in R\n\n\n\nGIS\n\nR\n\nR:Elementary\n\nDistance\n\nRaster\n\n\n\n\n\n\n\n\n\nJan 8, 2019\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nHow to create ‘Warming Stripes’ in R\n\n\n\nVisualization\n\nR\n\nR:Elementary\n\nWarming stripes\n\nGlobal warming\n\n\n\n\n\n\n\n\n\nDec 5, 2018\n\n\nDominic Royé\n\n\n\n\n\n\n\n\n\n\n\n\nAccessing OpenStreetMap data with R\n\n\n\nVisualization\n\nR\n\nR:Elementary\n\nMap\n\nOSM\n\nPoint of interest\n\n\n\n\n\n\n\n\n\nNov 3, 2018\n\n\nDominic Royé\n\n\n\n\n\nNo matching items\n\n  \n\n Back to topReuseCC BY-SA 4.0"
  },
  {
    "objectID": "blog/how-to-create-warming-stripes-in-r/index.html",
    "href": "blog/how-to-create-warming-stripes-in-r/index.html",
    "title": "How to create ‘Warming Stripes’ in R",
    "section": "",
    "text": "This year, the so-called warming stripes, which were created by the scientist Ed Hawkins of the University of Reading, became very famous all over the world. These graphs represent and communicate climate change in a very illustrative and effective way.\nIn this post I will show how you can create these strips in R with the ggplot2 library. Although I must say that there are many ways in R that can lead us to the same result or to a similar one, even within ggplot2."
  },
  {
    "objectID": "blog/how-to-create-warming-stripes-in-r/index.html#data",
    "href": "blog/how-to-create-warming-stripes-in-r/index.html#data",
    "title": "How to create ‘Warming Stripes’ in R",
    "section": "Data",
    "text": "Data\nIn this case we will use the annual temperatures of Lisbon GISS Surface Temperature Analysis, homogenized time series, comprising the period from 1880 to 2018. Monthly temperatures or other time series could also be used. The file can be downloaded here. First, we should, as long as we have not done it, install the collection of tidyverse packages that also include ggplot2. Then, we import the data of Lisbon in csv format.\n\n# install the lubridate and tidyverse libraries\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\n\n# packages\nlibrary(tidyverse)\nlibrary(RColorBrewer)\n\n# import the annual temperatures\ntemp_lisboa &lt;- read_csv(\"temp_lisboa.csv\")\n\nstr(temp_lisboa)\n\nWe see in the columns that we have monthly and seasonal values, and the annual temperature value. But before proceeding to visualize the annual temperature, we must replace the missing values 999.9 with NA, using the ifelse() function that evaluates a condition and perform the given argument corresponding to true and false.\n\n# select only the annual temperature and year column\ntemp_lisboa_yr &lt;- select(temp_lisboa, YEAR, ta = metANN)\n\n# missing values 999.9\nsummary(temp_lisboa_yr)\n\n\ntemp_lisboa_yr &lt;- mutate(temp_lisboa_yr, ta = ifelse(ta == 999.9, NA, ta))\n\nWhen we use the year as a variable, we do not usually convert it into a date object, however it is advisable. This allows us to use the date functions of the lubridate package and the support functions inside of ggplot2. The str_c() function of the library stringr, part of the collection of tidyverse, is similar to paste() of R Base that allows us to combine characters by specifying a separator (sep = “-”). The ymd() (year month day) function of the lubridate package converts a date character into a Date object. It is possible to combine several functions using the pipe operator %&gt;% or |&gt; that helps to chain without assigning the result to a new object. The first pipe in R was %&gt;% very extended especially within the tidyverse package collection. If you want to know more about its use, you can find here a tutorial or some details on differences between both here.\n\ntemp_lisboa_yr &lt;- mutate(temp_lisboa_yr, date = make_date(YEAR))"
  },
  {
    "objectID": "blog/how-to-create-warming-stripes-in-r/index.html#creating-the-strips",
    "href": "blog/how-to-create-warming-stripes-in-r/index.html#creating-the-strips",
    "title": "How to create ‘Warming Stripes’ in R",
    "section": "Creating the strips",
    "text": "Creating the strips\nFirst, we create the style of the graph, specifying all the arguments of the theme we want to adjust. We start with the default style of theme_minimal(). In addition, we assign the colors from RColorBrewer to an object col_srip. More information about the colors used here.\n\ntheme_strip &lt;- function(){ \n  \n  theme_minimal() %+replace%\n  theme(\n    axis.text.y = element_blank(),\n    axis.line.y = element_blank(),\n    axis.title = element_blank(),\n    panel.grid.major = element_blank(),\n    legend.title = element_blank(),\n    axis.text.x = element_text(vjust = 3),\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(size = 14, face = \"bold\"),\n    legend.key.width = unit(.5, \"lines\")\n  )\n}\n\ncol_strip &lt;- brewer.pal(11, \"RdBu\")\n\n# all \nbrewer.pal.info\n\nFor the final graphic we use the geometry geom_tile(). Since the data does not have a specific value for the Y axis, we need a dummy value, here I used 1. Also, I adjust the width of the color bar in the legend.\n\nmaxmin &lt;- range(temp_lisboa_yr$ta, na.rm = T)\nmd &lt;- mean(temp_lisboa_yr$ta, na.rm = T)\n\nggplot(\n  temp_lisboa_yr,\n  aes(date, y = 1, fill = ta)\n) +\n  geom_tile() +\n  scale_x_date(\n    date_breaks = \"6 years\",\n    date_labels = \"%Y\",\n    expand = c(0, 0)\n  ) +\n  scale_fill_gradientn(colors = rev(col_strip), values = scales::rescale(c(maxmin[1], md, maxmin[2])),\n                        na.value = \"gray80\") +\n  labs(\n    title = \"LISBOA 1880-2018\",\n    caption = \"Datos: GISS Surface Temperature Analysis\"\n  ) +\n  coord_cartesian(expand = FALSE) +\n  theme_strip()\n\n\nIn case we want to get only the strips, we can use theme_void() and the argument show.legend = FALSE in geom_tile() to remove all style elements. We can also change the color for the NA values, including the argument na.value = “gray70” in the scale_fill_gradientn() function.\n\nggplot(\n  temp_lisboa_yr,\n  aes(x = date, y = 1, fill = ta)\n) +\n  geom_tile(show.legend = FALSE) +\n  scale_fill_gradientn(colors = rev(col_strip), values = scales::rescale(c(maxmin[1], md, maxmin[2])),\n                        na.value = \"gray80\") +\n  coord_cartesian(expand = FALSE) +\n  theme_void()"
  },
  {
    "objectID": "blog/hex-map-buuse/index.html",
    "href": "blog/hex-map-buuse/index.html",
    "title": "Mapping building use with a hexagonal grid",
    "section": "",
    "text": "I needed a compact way to show the composition of building uses across Spain without pixel‑level clutter. We will aggregate 100 m building‑use rasters to a 20 km hexagonal grid and visualize the mix of agricultural, industrial, and commercial uses with overlapping proportional symbols blended by multiplication. The Canary Islands are shown as an inset."
  },
  {
    "objectID": "blog/hex-map-buuse/index.html#packages",
    "href": "blog/hex-map-buuse/index.html#packages",
    "title": "Mapping building use with a hexagonal grid",
    "section": "Packages",
    "text": "Packages\n\npkgs &lt;- c(\"terra\",\"sf\",\"tidyverse\",\"fs\",\"mapSpain\",\"ggforce\",\n          \"patchwork\",\"scales\",\"ggblend\",\"rmapshaper\",\"classInt\")\nfor(p in pkgs) if(!require(p, character.only = TRUE)) install.packages(p)\n\nlibrary(terra)\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(fs)\nlibrary(mapSpain)\nlibrary(ggforce)\nlibrary(patchwork)\nlibrary(scales)\nlibrary(ggblend)\nlibrary(rmapshaper)\nlibrary(classInt)"
  },
  {
    "objectID": "blog/hex-map-buuse/index.html#data-preparation",
    "href": "blog/hex-map-buuse/index.html#data-preparation",
    "title": "Mapping building use with a hexagonal grid",
    "section": "Data preparation",
    "text": "Data preparation\nStudy area\nWe obtain autonomous community boundaries, project to EPSG:25830, and exclude the Canary Islands for the main map.\n\nprov &lt;- esp_get_ccaa(moveCAN = FALSE) |&gt;\n  st_transform(25830) |&gt;\n  filter(ccaa.shortname.ga != \"Canarias\")\n\nInput rasters and reclassification\nWe read the building use rasters from 2020, treat zeros as missing, and aggregate layers to build the comercial category (commerce + services + offices). The data come from our 2023 paper; see 10.5194/essd-2023-53 for details. Download data here, and for Canary Island here.\n\n# import raster layers  with regexp if all years are downloaded\nlanduse &lt;- dir_ls(\"spain\", regexp = \"2020.tif$\") |&gt; rast()\n\nlanduse[landuse == 0] &lt;- NA\n\n# subset and aggregate uses\ncomercial &lt;- sum(subset(landuse, c(2, 4, 5)), na.rm = TRUE)\n\n# joint raster layers new aggregate use with agriculture and industrial\nlanduse &lt;- c(subset(landuse, c(1, 2)), comercial)\nnames(landuse) &lt;- c(\"agriculture\", \"industrial\", \"comercial\")\n\nlanduse \n\nclass       : SpatRaster \nsize        : 9998, 11927, 3  (nrow, ncol, nlyr)\nresolution  : 100, 100  (x, y)\nextent      : -40877.9, 1151822, 3880869, 4880669  (xmin, xmax, ymin, ymax)\ncoord. ref. : ETRS89 / UTM zone 30N (EPSG:25830) \nsources     : spat_397864b84d08_14712_zxzxx9jyyx6UnnI.tif  (2 layers) \n              memory  \nnames       : agriculture, industrial, comercial \nmin values  :           1,          1,         1 \nmax values  :          58,         44,        64"
  },
  {
    "objectID": "blog/hex-map-buuse/index.html#hexagonal-grid",
    "href": "blog/hex-map-buuse/index.html#hexagonal-grid",
    "title": "Mapping building use with a hexagonal grid",
    "section": "Hexagonal grid",
    "text": "Hexagonal grid\nWe create a 20 km hex grid that covers the study area and add an id. To build the spatial units used for aggregation, we rely on st_make_grid(), a very flexible function from the sf package that allows us to generate regular grids directly from any input geometry. By default, the function creates square cells, but by setting square = FALSE we instead request hexagonal polygons, which are often preferred in spatial aggregation because they reduce directional bias and provide a more uniform neighborhood structure. The argument cellsize = units::set_units(20, km) specifies the diameter (edge‑to‑edge distance) of each hexagon, ensuring all cells have comparable area across the entire extent. We then assign each hexagon a unique identifier, which is later used to join aggregated raster values back to the grid.\n\ngrid &lt;- st_make_grid(prov, cellsize = units::set_units(20, km), \n                     square = FALSE) |&gt;\n  st_as_sf() |&gt;\n  mutate(poly_id = row_number())"
  },
  {
    "objectID": "blog/hex-map-buuse/index.html#extract-raster-values-by-hexagon",
    "href": "blog/hex-map-buuse/index.html#extract-raster-values-by-hexagon",
    "title": "Mapping building use with a hexagonal grid",
    "section": "Extract raster values by hexagon",
    "text": "Extract raster values by hexagon\nWe extract raster values for each hexagon and compute category totals.\n\nextr_pixels &lt;- terra::extract(landuse, vect(grid))\n\nabudf &lt;- extr_pixels |&gt;\n  pivot_longer(2:4, names_to = \"use\", values_to = \"nbu\") |&gt;\n  group_by(ID, use) |&gt;\n  summarise(nbu = sum(nbu, na.rm = TRUE), .groups = \"drop\")"
  },
  {
    "objectID": "blog/hex-map-buuse/index.html#compute-withinhexagon-proportions",
    "href": "blog/hex-map-buuse/index.html#compute-withinhexagon-proportions",
    "title": "Mapping building use with a hexagonal grid",
    "section": "Compute within‑hexagon proportions",
    "text": "Compute within‑hexagon proportions\nIn this step we rejoin the extracted raster data to the grid. To make the map speak about composition rather than sheer magnitude, we convert absolute counts to relative shares.\n\ngrid &lt;- left_join(grid, abudf, by = join_by(poly_id == ID)) |&gt;\n           filter(nbu != 0) |&gt;\n            group_by(poly_id) |&gt;\n             mutate(nbu_rel = nbu * 100 / sum(nbu, na.rm = TRUE)) |&gt;\n              ungroup()\n\nWe define discrete classes for proportional symbol sizes.\n\ncl &lt;- c(0, 15, 30, 60, 80, 100)"
  },
  {
    "objectID": "blog/hex-map-buuse/index.html#administrative-context",
    "href": "blog/hex-map-buuse/index.html#administrative-context",
    "title": "Mapping building use with a hexagonal grid",
    "section": "Administrative context",
    "text": "Administrative context\nWe get internal borders from the grid by assigning each hexagon to the community with the largest overlap.\n\n# regional boundaries\nccaa &lt;- esp_get_ccaa() |&gt;\n  st_transform(25830)\n\n# intersection between grid and boundaries\nlim &lt;- st_intersection(grid, ccaa)\ninter &lt;- lim |&gt; mutate(area = as.numeric(st_area(lim)))\n\n# Which hexagon corresponds to which region?\nasig &lt;- inter |&gt;\n  arrange(poly_id, desc(area)) |&gt;\n  group_by(poly_id) |&gt;\n  slice_head(n = 1) |&gt;\n  ungroup() |&gt;\n  select(poly_id, ine.ccaa.name)\n\ngrid &lt;- left_join(grid, st_drop_geometry(asig), by = \"poly_id\")\n\n# dissolve geometry by region\ngrid_lim &lt;- group_by(grid, ine.ccaa.name) |&gt;\n                 summarise()\n\nplot(grid_lim)"
  },
  {
    "objectID": "blog/hex-map-buuse/index.html#background-hexes-and-locator",
    "href": "blog/hex-map-buuse/index.html#background-hexes-and-locator",
    "title": "Mapping building use with a hexagonal grid",
    "section": "Background hexes and locator",
    "text": "Background hexes and locator\nWe create background hexes to indicate the full coverage and a small segment to locate the Canary Islands.\n\ngrid_aux &lt;- st_make_grid(prov, cellsize = units::set_units(20, km), square = FALSE)\nplot(grid_aux)\n\n\n\n\n\n\nmissing_hex &lt;- st_intersects(grid_aux, filter(prov, nuts2.name != \"Canarias\"))\nmiss &lt;- grid_aux[lengths(missing_hex) != 0] |&gt;\n  st_as_sf() |&gt;\n  dplyr::mutate(id = dplyr::row_number()) |&gt;\n  dplyr::filter(!id %in% c(1465, 899, 1012, 743)) # exclude hexagons of super small islands \n\nplot(miss)\n\n\n\n\n\n\n\n\n# canary separation line for the inset map\ncan_box &lt;- st_linestring(matrix(c(-8.238606, 36.756331,\n                                  -6.2,      35.532012),\n                                nrow = 2, byrow = TRUE)) |&gt;\n  st_sfc(crs = 4326) |&gt;\n  st_transform(25830)"
  },
  {
    "objectID": "blog/hex-map-buuse/index.html#constructing-the-map",
    "href": "blog/hex-map-buuse/index.html#constructing-the-map",
    "title": "Mapping building use with a hexagonal grid",
    "section": "Constructing the map",
    "text": "Constructing the map\nAdditive legend\nWe draw three overlapping circles as a reminder of the color mapping for each use. To build the additive legend, we use geom_circle() from ggforce, which lets us draw perfect circles by specifying a center (x0, y0) and a radius (r). This makes it easy to place three uniformly sized circles representing the three land‑use categories. Since the circles intentionally overlap, we apply blend(\"multiply\") from the ´ggblend´ package, a blending mode that darkens the intersecting areas. This visually mimics how the mixed-use symbols behave on the main map: the more overlap, the stronger the combined color—reinforcing the idea of composition rather than isolated categories.\nSince blend() operates on the previous graphical layer, and here we need to blend multiple layers together, all the geom_circle() calls must be wrapped inside a list. Passing this list through the pipe to blend(\"multiply\") instructs to treat the group of layers as a single blended unit, ensuring that the overlapping colours combine correctly in the legend—just as they do in the main map.\n\n# color and labels\ncols &lt;- c(agricultural = \"#f5d300\", comercial = \"#08f7fe\", industrial = \"#ff1493\")\n\n# artificial data.frame for circles \nlegend_df &lt;- data.frame(\n  x = c(-0.4, 0.4, 0.0),\n  y = c(0.0, 0.0, 0.35),\n  r = c(0.55, 0.55, 0.55),\n  key = c(\"agricultural\", \"comercial\", \"industrial\"),\n  stringsAsFactors = FALSE\n)\n\n# angle position for labels radians!!\nangles &lt;- c(agricultural = 5*pi/4, comercial = 2*pi, industrial = 3*pi/4)\nlabel_vec &lt;- c(agricultural = \"Agricultural\", comercial = \"Commercial\", industrial = \"Industrial\")\n\n# calculate x and y for each label\npos_labels &lt;- within(legend_df, {\n  key &lt;- as.character(key)\n  theta &lt;- angles[key]\n  lab1_x &lt;- x + r * cos(theta)\n  lab1_y &lt;- y + r * sin(theta)\n  lab2_x &lt;- x - r * cos(theta)\n  lab2_y &lt;- y - r * sin(theta)\n  lab1 &lt;- label_vec[key]\n  lab2 &lt;- label_vec[key]\n})\n\n# legend\nlegend_plot &lt;- ggplot() +\n  list(\n    geom_circle(data = subset(legend_df, key == \"agricultural\"),\n                         aes(x0 = x, y0 = y, r = r),\n                         fill = cols[\"agricultural\"], color = NA, alpha = 0.85),\n    geom_circle(data = subset(legend_df, key == \"comercial\"),\n                         aes(x0 = x, y0 = y, r = r),\n                         fill = cols[\"comercial\"], color = NA, alpha = 0.85),\n    geom_circle(data = subset(legend_df, key == \"industrial\"),\n                         aes(x0 = x, y0 = y, r = r),\n                         fill = cols[\"industrial\"], color = NA, alpha = 0.85)\n  ) |&gt;\n  blend(\"multiply\") +\n  geom_label(data = pos_labels, aes(lab1_x, lab1_y, label = lab1),\n             fill = alpha(\"white\", .5), size = 5, linewidth = 0) +\n  coord_equal(xlim = c(-1.3, 1.3), ylim = c(-0.6, 1.2), expand = FALSE, clip = \"off\") +\n  theme_void(base_family = \"sans\")\n\nlegend_plot\n\n\n\n\n\n\n\nMain map\nWe plot three proportional‑symbol layers (one per use) at the centroids of each hexagon and blend them using multiplication in the same way as for the legend. To ensure that the proportional symbols remain visually coherent within the map, the size of the circles must be constrained so that even the largest symbol does not exceed the width of a hexagon. Since the symbols are plotted at the centroid of each cell, oversized circles would spill over into neighbouring hexagons, creating visual clutter and making category comparisons harder to read.\n\ng &lt;- ggplot() +\n  geom_sf(data = miss, fill = \"grey90\", color = \"white\") +\n  geom_sf(data = can_box, colour = \"grey85\") +\n  geom_sf(data = ms_innerlines(grid_lim), colour = \"white\", linewidth = 1.1) +\n  list(\n    geom_sf(data = st_centroid(grid) |&gt;\n              dplyr::filter(use == \"agriculture\"),\n            aes(color = use, size = cut(nbu_rel, cl))),\n    geom_sf(data = st_centroid(grid) |&gt;\n              dplyr::filter(use == \"comercial\"),\n            aes(color = use, size = cut(nbu_rel, cl))),\n    geom_sf(data = st_centroid(grid) |&gt;\n              dplyr::filter(use == \"industrial\"),\n            aes(color = use, size = cut(nbu_rel, cl)))\n  ) |&gt;\n  ggblend::blend(\"multiply\") +\n  scale_color_manual(values = c(\"agriculture\" = \"#f5d300\",\n                                \"comercial\"   = \"#08f7fe\",\n                                \"industrial\"  = \"#ff1493\"),\n                     breaks = c(\"agriculture\",\"comercial\",\"industrial\"),\n                     labels = c(\"Agricultural\",\"Commercial\",\"Industrial\")) +\n  scale_size_manual(values = c(1, 2, 4, 6, 8) * 0.62,\n                    labels = c(\"&lt; 15\",\"15–30\",\"30–60\",\"60–80\",\"80–100 %\")) +\n  labs(size = \"Share of buildings\",\n       title = stringr::str_wrap(\"Geography of building use in Spain | 2020\", 60),\n       subtitle = stringr::str_wrap(\n         \"Residential use is excluded. 'Commercial' merges public services and office uses to simplify spatial interpretation and comparability.\",\n         90),\n       caption = \"HISDAC-ES. Uhl et al. 2023. 10.5194/essd-2023-53\") +\n  guides(color = \"none\") +\n  theme_void(base_family = \"sans\") +\n  theme(legend.position = c(.83, .90),\n        legend.title.position = \"top\",\n        legend.text.position = \"bottom\",\n        legend.direction = \"horizontal\",\n        plot.title = element_text(size = 18, face = \"bold\"),\n        plot.margin = margin(20, 20, 20, 300))\n\nCanary Islands inset\nWe process the Canary Islands separately (in REGCAN95 projection) and keep sizes and colours consistent.\n\nlanduse_can &lt;- dir_ls(\"canary\", regexp = \"2020.tif$\") |&gt; rast()\n\nlanduse_can[landuse_can == 0] &lt;- NA\ncomercial_can &lt;- sum(subset(landuse_can, c(2, 4, 5)), na.rm = TRUE)\nlanduse_can &lt;- c(subset(landuse_can, c(1, 3)), comercial_can)\nnames(landuse_can) &lt;- c(\"agriculture\", \"industrial\", \"comercial\")\n\nlim_can &lt;- esp_get_ccaa(moveCAN = FALSE) |&gt;\n             st_transform(4083) |&gt;\n              filter(ccaa.shortname.es == \"Canarias\") \n\ngrid_can &lt;- st_make_grid(lim_can, cellsize = units::set_units(20, km), square = FALSE) |&gt;\n  st_as_sf() |&gt;\n  mutate(poly_id = row_number())\n\nextr_pixels &lt;- terra::extract(landuse_can, vect(grid_can))\n\nabudf_can &lt;- extr_pixels |&gt;\n  pivot_longer(2:4, names_to = \"use\", values_to = \"abu\") |&gt;\n  group_by(ID, use) |&gt;\n  summarise(abu = sum(abu, na.rm = TRUE), .groups = \"drop\")\n\ngrid_can &lt;- dplyr::left_join(grid_can, abudf_can, by = join_by(poly_id == ID)) |&gt;\n             filter(abu != 0) |&gt;\n              group_by(poly_id) |&gt;\n               mutate(abu_rel = abu * 100 / sum(abu, na.rm = TRUE)) |&gt;\n                ungroup()\n\nmap_can &lt;- ggplot() +\n  geom_sf(data = grid_can, fill = \"grey90\", color = \"white\") +\n  list(\n    geom_sf(data = st_centroid(grid_can) |&gt;\n              dplyr::filter(use == \"agriculture\"),\n            aes(color = use, size = cut(abu_rel, cl))),\n    geom_sf(data = st_centroid(grid_can) |&gt;\n              dplyr::filter(use == \"comercial\"),\n            aes(color = use, size = cut(abu_rel, cl))),\n    geom_sf(data = st_centroid(grid_can) |&gt;\n              dplyr::filter(use == \"industrial\"),\n            aes(color = use, size = cut(abu_rel, cl)))\n  ) |&gt;\n  ggblend::blend(\"multiply\") +\n  scale_color_manual(values = c(\"agriculture\" = \"#f5d300\",\n                                \"comercial\"   = \"#08f7fe\",\n                                \"industrial\"  = \"#ff1493\"),\n                     breaks = c(\"agriculture\",\"comercial\",\"industrial\"),\n                     labels = c(\"Agricultural\",\"Commercial\",\"Industrial\")) +\n  scale_size_manual(values = c(1, 2, 4, 6, 8) * 0.60) +\n  labs(size = NULL, title = \"Canary Islands\") +\n  guides(color = \"none\", size = \"none\") +\n  theme_void(base_family = \"sans\") +\n  theme(legend.position = c(.85, .87),\n        legend.title.position = \"top\",\n        legend.text.position = \"bottom\",\n        legend.direction = \"horizontal\",\n        plot.margin = margin(10, 10, 10, 10),\n        plot.title = element_text(vjust = 1, hjust = .05, size = 11))\n\nCompose and export\nWe insert the additive legend and the Canary Islands inset and export the final figure.\n\ngfinal &lt;- g +\n  inset_element(legend_plot, .70, .80, .95, 1.3) +\n  inset_element(map_can, 0, -0.2, .30, .34, align_to = \"full\")\n\nggsave(\"esp_buiuse_2020.png\", gfinal,\n       height = 13.3, width = 16, units = \"in\", bg = \"white\", dpi = 300)"
  },
  {
    "objectID": "blog/hex-map-buuse/index.html#what-this-map-communicates",
    "href": "blog/hex-map-buuse/index.html#what-this-map-communicates",
    "title": "Mapping building use with a hexagonal grid",
    "section": "What this map communicates",
    "text": "What this map communicates\n\n\nDominance: areas where one use exceeds ~60% are visible by symbol size and dominant colour.\n\nInterpretation caution: since the map shows the relative number of buildings by use, the categories reflect building functions, which do not necessarily correspond to the underlying economic activities of each area.\n\nMixing: blending reveals coexistence of uses.\n\nRegional patterns: subtle borders help orientation without clutter."
  },
  {
    "objectID": "blog/hex-map-buuse/index.html#notes-and-good-practices",
    "href": "blog/hex-map-buuse/index.html#notes-and-good-practices",
    "title": "Mapping building use with a hexagonal grid",
    "section": "Notes and good practices",
    "text": "Notes and good practices\n\nKeep rasters and vectors in a projected CRS before terra::extract().\nCompute centroids on projected geometries.\nFixed size breaks (c(0, 15, 30, 60, 80, 100)) match legend labels\nUse exact=TRUE in extract() only if you need area weighting."
  },
  {
    "objectID": "blog/firefly-maps/index.html#data",
    "href": "blog/firefly-maps/index.html#data",
    "title": "Firefly cartography",
    "section": "Data",
    "text": "Data\nFirst we download all the necessary data. For the base map we will use the Blue Marble imagery via the access to worldview.earthdata.nasa.gov where I have downloaded a selection of the area of interest in geoTiff format with a resolution of 1 km. It is important to adjust the resolution to the necessary detail of the map.\n\nBlue Marble selection via worldview.earthdata.nasa.gov ( ~ 66 MB) download\n\nRecords of historical earthquakes in southwestern Europe from IGN download"
  },
  {
    "objectID": "blog/firefly-maps/index.html#import",
    "href": "blog/firefly-maps/index.html#import",
    "title": "Firefly cartography",
    "section": "Import",
    "text": "Import\nThe first thing we do is to import the RGB Blue Marble raster and the earthquake data. To import the raster I use the new package terra which is the successor of the raster package. You can find a recent comparison here.\n\n# earthquakes\n\nearthquakes &lt;- read.csv2(\"catalogoComunSV_1621713848556.csv\")\nstr(earthquakes)\n\n# Blue Marble RGB raster\n\nbm &lt;- rast(\"snapshot-2017-11-30T00_00_00Z.tiff\")\nbm # contains three layers (red, green, blue)\n\n\n# country boundaries\n\nlimits &lt;- gisco_get_countries(resolution = \"10\")\n\n# plot\n\nplotRGB(bm)"
  },
  {
    "objectID": "blog/firefly-maps/index.html#earthquakes",
    "href": "blog/firefly-maps/index.html#earthquakes",
    "title": "Firefly cartography",
    "section": "Earthquakes",
    "text": "Earthquakes\nIn this step we clean the imported earthquakes data. 1) We convert longitude, latitude and magnitude into numeric using the parse_number() function and clean the column names with the clean_names() function, 2) We create a spatial object sf and project it using the EPSG:3035 corresponding to ETRS89-extended/LAEA Europe.\n\n# we clean the data and create an sf object\n\nearthquakes &lt;- earthquakes |&gt;\n  clean_names() |&gt;\n  mutate(across(c(mag, latitud, longitud), parse_number)) |&gt;\n  st_as_sf(\n    coords = c(\"longitud\", \"latitud\"),\n    crs = 4326\n  ) |&gt;\n  st_transform(3035) # project to Laea"
  },
  {
    "objectID": "blog/firefly-maps/index.html#blue-marble-background-map",
    "href": "blog/firefly-maps/index.html#blue-marble-background-map",
    "title": "Firefly cartography",
    "section": "Blue Marble background Map",
    "text": "Blue Marble background Map\nWe cropped the background map to a smaller extent, but we still haven’t limited to the final area yet.\n\n# clip to the desired area\n\nbm &lt;- crop(bm, ext(-20, 10, 30, 50)) # W, E, S, N\n\nTo obtain an unsaturated version of the Blue Marble RGB raster, we must apply a function created for this purpose. In this, we use the colorize(), which helps us converting RGB to HSL and vice versa. The HSL model is defined by Hue, Saturation, Lightness. The last two parameters are expressed in ratio or percentage. The hue is defined on a color wheel from 0 to 360º. 0 is red, 120 is green, 240 is blue. To change the saturation we only have to reduce the value of S.\n\n# apply the function to unsaturate with 5%\n\nbm_desat &lt;- colorize(bm, to = \"hsl\")\nbm_desat[[2]] &lt;- .05 # ratio of saturation\nset.RGB(bm_desat, 1:3, \"hsl\")\nbm_desat &lt;- colorize(bm_desat, to = \"rgb\")\n\n# project\n\nbm_desat &lt;- terra::project(bm_desat, \"epsg:3035\")\n\n# plot new RGB image\n\nplotRGB(bm_desat)"
  },
  {
    "objectID": "blog/firefly-maps/index.html#boundaries-and-graticules",
    "href": "blog/firefly-maps/index.html#boundaries-and-graticules",
    "title": "Firefly cartography",
    "section": "Boundaries and graticules",
    "text": "Boundaries and graticules\nBefore starting to build the map, we create graticules and set the final map limits.\n\n# define the final map extent\n\nbx &lt;- tibble(x = c(-13, 6.7), y = c(31, 47)) |&gt;\n  st_as_sf(coords = c(\"x\", \"y\"), crs = 4326) |&gt;\n  st_transform(3035) |&gt;\n  st_bbox()\n\n# create map graticules\n\ngrid &lt;- st_graticule(earthquakes)"
  },
  {
    "objectID": "blog/firefly-maps/index.html#map-with-image-background",
    "href": "blog/firefly-maps/index.html#map-with-image-background",
    "title": "Firefly cartography",
    "section": "Map with image background",
    "text": "Map with image background\nThe layer_spatial() function of ggspatial allows us to add an RGB raster without major problems, however, it still does not support the newSpatRaster class. Therefore, we must convert it to the stack class with the stack() function. It is also possible to use instead of geom_sf(), the layer_spatial() function for vector objects of class sf or sp.\n\nggplot() +\n  layer_spatial(data = bm_desat) + # blue marble background map\n  geom_sf(data = limits, fill = NA, size = .3, colour = \"white\") + # country boundaries\n  coord_sf(\n    xlim = bx[c(1, 3)],\n    ylim = bx[c(2, 4)],\n    crs = 3035,\n    expand = FALSE\n  ) +\n  theme_void()"
  },
  {
    "objectID": "blog/firefly-maps/index.html#map-with-background-and-earthquakes",
    "href": "blog/firefly-maps/index.html#map-with-background-and-earthquakes",
    "title": "Firefly cartography",
    "section": "Map with background and earthquakes",
    "text": "Map with background and earthquakes\nTo create the glow effect on firefly maps, we use the geom_glowpoint() function from the ggshadow package. There is also the same function for lines. Since our data is of spatial class sf and the geometry sf is not directly supported, we must indicate as an argument stats = \"sf_coordinates\" and inside aes() indicate geometry = geometry. We will map the size of the points as a function of magnitude. In addition, we filter those earthquakes with a magnitude greater than 3.\nInside the geom_glowpoint() function, 1) we define the desired color for the point and the glow effect, 2) the degree of transparency with alpha either for the point or for the glow. Finally, in the scale_size() function we set the range (minimum, maximum) of the size that the points will have.\n\nggplot() +\n  layer_spatial(data = bm_desat) +\n  geom_sf(data = limits, fill = NA, size = .3, colour = \"white\") +\n  geom_sf(data = grid, colour = \"white\", size = .1, alpha = .5) +\n  geom_glowpoint(\n    data = filter(earthquakes, mag &gt; 3),\n    aes(geometry = geometry, size = mag),\n    alpha = .8,\n    color = \"#6bb857\",\n    shadowcolour = \"#6bb857\",\n    shadowalpha = .1,\n    stat = \"sf_coordinates\",\n    show.legend = FALSE\n  ) +\n  scale_size(range = c(.1, 1.5)) +\n  coord_sf(\n    xlim = bx[c(1, 3)],\n    ylim = bx[c(2, 4)],\n    crs = 3035,\n    expand = FALSE\n  ) +\n  theme_void()"
  },
  {
    "objectID": "blog/firefly-maps/index.html#final-map",
    "href": "blog/firefly-maps/index.html#final-map",
    "title": "Firefly cartography",
    "section": "Final map",
    "text": "Final map\nThe glow effect of firefly maps is characterized by having a white tone or a lighter tone in the center of the points. To achieve this, we must duplicate the previous created layer, changing only the color and make the glow points smaller.\nBy default, ggplot2 does not allow to use multiple scales for the same characteristic (size, color, etc) of different layers. But the ggnewscale package gives us the ability to incorporate multiple scales of a feature from different layers. The only important thing to achieve this is the order in which each layer (geom) and scale is added. First we must add the geometry and then its corresponding scale. We indicate with new_scale('size') that the next layer and scale is a new one independent of the previous one. If we used color or fill it would be done with new_scale_*().\n\nggplot() +\n  layer_spatial(data = bm_desat) +\n  geom_sf(data = limits, fill = NA, size = .3, colour = \"white\") +\n  geom_sf(data = grid, colour = \"white\", size = .1, alpha = .5) +\n  geom_glowpoint(\n    data = filter(earthquakes, mag &gt; 3),\n    aes(geometry = geometry, size = mag),\n    alpha = .8,\n    color = \"#6bb857\",\n    shadowcolour = \"#6bb857\",\n    shadowalpha = .1,\n    stat = \"sf_coordinates\",\n    show.legend = FALSE\n  ) +\n  scale_size(range = c(.1, 1.5)) +\n  new_scale(\"size\") +\n  geom_glowpoint(\n    data = filter(earthquakes, mag &gt; 3),\n    aes(geometry = geometry, size = mag),\n    alpha = .6,\n    shadowalpha = .05,\n    color = \"#ffffff\",\n    stat = \"sf_coordinates\",\n    show.legend = FALSE\n  ) +\n  scale_size(range = c(.01, .7)) +\n  labs(title = \"EARTHQUAKES\") +\n  coord_sf(\n    xlim = bx[c(1, 3)], ylim = bx[c(2, 4)], crs = 3035,\n    expand = FALSE\n  ) +\n  theme_void() +\n  theme(plot.title = element_text(size = 50, vjust = -5, colour = \"white\", hjust = .95))"
  },
  {
    "objectID": "blog/climate-anomalies/index.html",
    "href": "blog/climate-anomalies/index.html",
    "title": "Visualize climate anomalies",
    "section": "",
    "text": "When we visualize precipitation and temperature anomalies, we simply use time series as bar graph indicating negative and positive values in red and blue. However, in order to have a better overview we need both anomalies in a single graph. In this way we could more easly answer the question of whether a particular season or month was dry-warm or wet-cold, and even compare these anomalies in the context of previous years."
  },
  {
    "objectID": "blog/climate-anomalies/index.html#preparing-the-data",
    "href": "blog/climate-anomalies/index.html#preparing-the-data",
    "title": "Visualize climate anomalies",
    "section": "Preparing the data",
    "text": "Preparing the data\nFirst we import the daily precipitation and temperature data from the selected weather station (download). We will use the data from Tenerife South (Spain) [1981-2020] accessible through Open Data AEMET. In R there is a package called meteoland that facilitates the download with specific functions to access data from AEMET (Spanish State Meteorological Agency), Meteogalicia (Galician Meteorological Service) and Meteocat (Catalan Meteorological Service).\nStep 1: import the data\nWe import the data in csv format, the first column is the date, the second column the precipitation (pr) and the last column the average daily temperature (ta).\n\ndata &lt;- read_csv(\"meteo_tenerife.csv\")\ndata\n\nStep 2: preparing the data\nIn the second step we prepare the data to calculate the anomalies. To do this, we create three new columns: the month, the year, and the season of the year. Since our objective is to analyse winter anomalies, we cannot use the calendar year, because winter includes the month of December of one year and the months of January and February of the following. The concept is similar to the hydrological year in which it starts on October 1.\nWe will use many functions of the package collection tidyverse. The mutate() function helps to add new columns or change existing ones. To define the seasons, we use the case_when() function from the dplyr package, which has many advantages compared to a chain of ifelse(). In case_when() we use two-side formulas, on the one hand the condition and on the other the action when that condition is met. A two-sided formula in R consists of the operator ~. The binary operator %in% allows us to filter several values in a greater set.\n\ndata &lt;- mutate(data,\n  winter_yr = ifelse(month(date) == 12, year(date)+1, year(date)),\n  month = month(date),\n  season = case_when(\n    month %in% c(12, 1:2) ~ \"Winter\",\n    month %in% 3:5 ~ \"Spring\",\n    month %in% 6:8 ~ \"Summer\",\n    month %in% 9:11 ~ \"Autum\"\n  )\n)\n\ndata\n\nStep 3: estimate winter anomalies\nIn the next step we create a subset of the winter months. Then we group by the defined meteorological year and calculate the sum and average for precipitation and temperature, respectively. To facilitate the work, the magrittr package and later R Base introduces the operator called pipe in the form %&gt;% and |&gt; with the aim of combining several functions without the need to assign the result to a new object. The pipe operator passes the output of a function applied to the first argument of the next function. This way of combining functions allows you to chain several steps simultaneously. The |&gt; must be understood and pronounced as then.\n\ndata_inv &lt;- filter(\n  data,\n  season == \"Winter\"\n) |&gt;\n  group_by(winter_yr) |&gt;\n  summarise(\n    pr = sum(pr, na.rm = TRUE),\n    ta = mean(ta, na.rm = TRUE)\n  )\n\nNow we only have to calculate the anomalies of precipitation and temperature. The columns pr_mean and ta_mean will contain the climate average, the reference for the anomalies with respect to the normal period 1981-2010. Therefore, we need to filter the values to the period before 2010, which we will do in the usual way of filtering vectors in R. Once we have the references we estimate the anomalies pr_anom and ta_anom. To facilitate the interpretation, in the case of precipitation we express the anomalies as percentage, with the average set at 0% instead of 100%.\nIn addition, we add three required columns with information for the creation of the graph: 1) labyr contains the year of each anomaly as long as it has been greater/less than -+10% or -+0.5ºC, respectively (this is for reducing the number of labels), 2) symb_point is a dummy variable in order to be able to create different symbols between the cases of (1), and 3) lab_font for highlighting in bold the year 2020.\n\ndata_inv &lt;- mutate(data_inv,\n  pr_mean = mean(pr[winter_yr &lt;= 2010]),\n  ta_mean = mean(ta[winter_yr &lt;= 2010]),\n  pr_anom = (pr * 100 / pr_mean) - 100,\n  ta_anom = ta - ta_mean,\n  labyr = case_when(\n    pr_anom &lt; -10 & ta_anom &lt; -.5 ~ winter_yr,\n    pr_anom &lt; -10 & ta_anom &gt; .5 ~ winter_yr,\n    pr_anom &gt; 10 & ta_anom &lt; -.5 ~ winter_yr,\n    pr_anom &gt; 10 & ta_anom &gt; .5 ~ winter_yr\n  ),\n  symb_point = ifelse(!is.na(labyr), \"yes\", \"no\"),\n  lab_font = ifelse(labyr == 2020, \"bold\", \"plain\")\n)"
  },
  {
    "objectID": "blog/climate-anomalies/index.html#creating-the-graph",
    "href": "blog/climate-anomalies/index.html#creating-the-graph",
    "title": "Visualize climate anomalies",
    "section": "Creating the graph",
    "text": "Creating the graph\nWe will build the chart adding layer by layer the distinctive elements: 1) the background with the different grids (Dry-Warm, Dry-Cold, etc.), 2) the points and labels, and 3) the style adjustments.\nPart 1\nThe idea is that the points with dry-warm anomalies are located in quadrant I (top-right) and those with wet-cold in quadrant III (bottom-left). Therefore, we must invert the sign in the precipitation anomalies. Then we create a data.frame with the label positions of the four quadrants. For the positions in x and y Inf and -Inf are used, which is equivalent to the maximum panel sides with respect to the data. However, it is necessary to adjust the position towards the extreme points within the panel with the known arguments of ggplot2: hjust and vjust.\n\ndata_inv_p &lt;- mutate(data_inv, pr_anom = pr_anom * -1)\n\nbglab &lt;- data.frame(\n  x = c(-Inf, Inf, -Inf, Inf),\n  y = c(Inf, Inf, -Inf, -Inf),\n  hjust = c(1, 1, 0, 0),\n  vjust = c(1, 0, 1, 0),\n  lab = c(\n    \"Wet-Warm\", \"Dry-Warm\",\n    \"Wet-Cold\", \"Dry-Cold\"\n  )\n)\n\n\nbglab\n\nPart 2\nIn the second part we can start building the chart by adding all graphical elements. First we create the background with different colors of each quadrant. The function annotate() allows adding geometry layers without the use of variables within data.frames. With the geom_hline() and geom_vline() function we mark the quadrants horizontally and vertically using a dashed line. Finally, we draw the labels of each quadrant, using the function geom_text(). When we use other data sources than the main one used in ggplot(), we must indicate it with the argument data in the corresponding geometry function.\n\ng1 &lt;- ggplot(\n  data_inv_p,\n  aes(pr_anom, ta_anom)\n) +\n  annotate(\"rect\", xmin = -Inf, xmax = 0, ymin = 0, ymax = Inf, fill = \"#fc9272\", alpha = .6) + # wet-warm\n  annotate(\"rect\", xmin = 0, xmax = Inf, ymin = 0, ymax = Inf, fill = \"#cb181d\", alpha = .6) + # dry-warm\n  annotate(\"rect\", xmin = -Inf, xmax = 0, ymin = -Inf, ymax = 0, fill = \"#2171b5\", alpha = .6) + # wet-cold\n  annotate(\"rect\", xmin = 0, xmax = Inf, ymin = -Inf, ymax = 0, fill = \"#c6dbef\", alpha = .6) + # dry-cold\n  geom_hline(\n    yintercept = 0,\n    linetype = \"dashed\"\n  ) +\n  geom_vline(\n    xintercept = 0,\n    linetype = \"dashed\"\n  ) +\n  geom_label(\n    data = bglab,\n    aes(x, y, label = lab, hjust = hjust, vjust = vjust),\n    fontface = \"italic\", size = 5,\n    label.size = .000001,\n    fill = NA,\n    angle = 90, colour = \"white\"\n  )\n\ng1\n\n\n\n\nPart 3\nIn the third part we simply add the points of the anomalies and the labels of the years. The geom_text_repel() function is similar to the one known by default in ggplot2, geom_text(), but it repels overlapping text labels away from each other.\n\ng2 &lt;- g1 + geom_point(aes(fill = symb_point, colour = symb_point),\n  size = 2.8, shape = 21, show.legend = FALSE\n) +\n  geom_text_repel(aes(label = labyr, fontface = lab_font),\n    max.iter = 5000,\n    size = 3.5\n  )\ng2\n\n\n\n\nPart 4\nIn the last part we adjust, in addition to the general style, the axes, the color type and the (sub)title. Remember that we changed the sign on precipitation anomalies. Hence, we must use the arguments breaks and labels in the function scale_x_continouous() to reverse the sign in the labels corresponding to the breaks.\n\ng3 &lt;- g2 + \n  scale_x_continuous(\n  breaks = seq(-100, 250, 10) * -1,\n  labels = seq(-100, 250, 10),\n  limits = c(min(data_inv_p$pr_anom), 100),\n  expand = expansion(.01)\n  ) +\n  scale_y_continuous(\n    breaks = seq(-2, 2, 0.5),\n    expand = expansion(.01)\n  ) +\n  scale_fill_manual(values = c(\"black\", \"white\")) +\n  scale_colour_manual(values = rev(c(\"black\", \"white\"))) +\n  labs(\n    y = \"Mean temperature anomaly in ºC\",\n    x = \"Precipitation anomaly in %\",\n    title = \"Winter anomalies in Tenerife South\",\n    caption = \"Data: AEMET\\nNormal period 1981-2010\"\n  ) +\n  theme_bw() +\n  theme(panel.grid.minor = element_blank())\n\ng3"
  },
  {
    "objectID": "blog/calendar-heatmap/index.html",
    "href": "blog/calendar-heatmap/index.html",
    "title": "A heatmap as calendar",
    "section": "",
    "text": "Recently I was looking for a visual representation to show the daily changes of temperature, precipitation and wind in an application xeo81.shinyapps.io/MeteoExtremosGalicia (in Spanish), which led me to use a heatmap in the form of a calendar. The shiny application is updated every four hours with new data showing calendars for each weather station. The heatmap as a calendar allows you to visualize any variable with a daily time reference."
  },
  {
    "objectID": "blog/calendar-heatmap/index.html#data",
    "href": "blog/calendar-heatmap/index.html#data",
    "title": "A heatmap as calendar",
    "section": "Data",
    "text": "Data\nIn this example we will use the daily precipitation of Santiago de Compostela for this year 2020 (until December 20). Download data\n\n# import the data\ndat_pr &lt;- read_csv(\"precipitation_santiago.csv\")\ndat_pr"
  },
  {
    "objectID": "blog/calendar-heatmap/index.html#preparation",
    "href": "blog/calendar-heatmap/index.html#preparation",
    "title": "A heatmap as calendar",
    "section": "Preparation",
    "text": "Preparation\nIn the first step we must 1) complement the time series from December 21 to December 31 with NA, 2) add the day of the week, the month, the week number and the day. Depending on whether we want each week to start on Sunday or Monday, we indicate it in the wday() function.\n\ndat_pr &lt;- dat_pr |&gt;\n  complete(date = seq(\n    ymd(\"2020-01-01\"),\n    ymd(\"2020-12-31\"),\n    \"day\"\n  )) |&gt;\n  mutate(\n    weekday = wday(date, label = T, week_start = 1),\n    month = month(date, label = T, abbr = F),\n    week = isoweek(date),\n    day = day(date)\n  )\n\nIn the next step we need to make a change in the week of the year, which is because in certain years there may be, for example, a few days at the end of the year as the first week of the following year. We also create two new columns. On the one hand, we categorize precipitation into 14 classes and on the other, we define a white text color for darker tones in the heatmap.\n\ndat_pr &lt;- mutate(dat_pr,\n  week = case_when(\n    month == \"December\" & week == 1 ~ 53,\n    month == \"January\" & week %in% 52:53 ~ 0,\n    TRUE ~ week\n  ),\n  pcat = cut(pr, c(-1, 0, .5, 1:5, 7, 9, 15, 20, 25, 30, 300)),\n  text_col = ifelse(pcat %in% c(\"(15,20]\", \"(20,25]\", \"(25,30]\", \"(30,300]\"),\n    \"white\", \"black\"\n  )\n)\n\ndat_pr"
  },
  {
    "objectID": "blog/calendar-heatmap/index.html#visualization",
    "href": "blog/calendar-heatmap/index.html#visualization",
    "title": "A heatmap as calendar",
    "section": "Visualization",
    "text": "Visualization\nFirst we create a color ramp from Brewer colors.\n\n# color ramp\npubu &lt;- RColorBrewer::brewer.pal(9, \"PuBu\")\ncol_p &lt;- colorRampPalette(pubu)\n\nSecond, before building the chart, we define a custom theme as a function. To do this, we specify all the elements and their modifications with the help of the theme() function.\n\ntheme_calendar &lt;- function() {\n  theme_void(base_family = \"Montserrat\") %+replace%\n  theme(\n    aspect.ratio = 1 / 2,\n    strip.text = element_text(face = \"bold\", size = 15),\n    legend.position = \"top\",\n    legend.text = element_text(hjust = .5),\n    legend.title = element_text(size = 9, hjust = 1),\n    plot.caption = element_text(hjust = 1, size = 8),\n    panel.border = element_rect(colour = \"grey\", fill = NA,linewidth = 1),\n    plot.title = element_text(\n      hjust = .5, size = 26,\n      face = \"bold\",\n      margin = margin(0, 0, 0.5, 0, unit = \"cm\")\n    ),\n    plot.subtitle = element_text(hjust = .5, size = 16)\n  )\n}\n\nFinally, we build the final chart using geom_tile() and specify the day of the week as the X axis and the week number as the Y axis. As you can see in the variable of the week number (-week), I change the sign so that the first day of each month is in the first row. With geom_text() we add the number of each day with its color according to what we defined previously. In guides we make the adjustments of the colorbar and in scale_fill/colour_manual() we define the corresponding colors. An important step is found in facet_wrap() where we specify the facets composition of each month. The facets should have free scales and the ideal would be a 4 x 3 facet distribution. It is possible to modify the position of the day number to another using the arguments nudge_* in geom_text() (eg bottom-right corner: nudge_x = .35, nudge_y = -.25).\n\nggplot(\n  dat_pr,\n  aes(weekday, -week, fill = pcat)\n) +\n  geom_tile(colour = \"white\", size = .4) +\n  geom_text(aes(label = day, colour = text_col), size = 2.5) +\n  guides(fill = guide_colorsteps(\n    barwidth = 25,\n    barheight = .4,\n    title.position = \"top\"\n  )) +\n  scale_fill_manual(\n    values = c(\"white\", col_p(13)),\n    na.value = \"grey90\", drop = FALSE\n  ) +\n  scale_colour_manual(values = c(\"black\", \"white\"), guide = FALSE) +\n  facet_wrap(~month, nrow = 4, ncol = 3, scales = \"free\") +\n  labs(\n    title = \"How is 2020 being in Santiago?\",\n    subtitle = \"Precipitation\",\n    caption = \"Data: Meteogalicia\",\n    fill = \"mm\"\n  ) +\n  theme_calendar()\n\n\n\nggsave(\"pr_calendar.png\", height = 10, width = 8)\n\nIn other heatmap calendars I have added the predominant wind direction of each day as an arrow using geom_arrow() from the metR package (it can be seen in the aforementioned application). Another specific package for calendar heatmaps is calendR."
  },
  {
    "objectID": "blog/broken-charts/show_case.html",
    "href": "blog/broken-charts/show_case.html",
    "title": "Visualizing monthly temperature",
    "section": "",
    "text": "This is a selection of charts from my recent post on a broken chart to visualize monthly temperature. Column charts are inappropriate for absolut temperature. So, what kind of good alternatives can we choose?\n\n\n\n\n\n\nPackage\nDescription\n\n\n\ntidyverse\nCollection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.\n\n\ngeomtextpath\nan extension of the ggplot2 package, designed to simplify the process of adding text in charts, especially when you need the text to follow a curved path\n\n\nggrepel\nprovides geoms for ggplot2 to repel overlapping text labels\n\n\n\n\n# install the packages if necessary\n\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\n\nCargando paquete requerido: tidyverse\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.6\n✔ forcats   1.0.1     ✔ stringr   1.6.0\n✔ ggplot2   4.0.1     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.2.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nif (!require(\"geomtextpath\")) install.packages(\"geomtextpath\")\n\nCargando paquete requerido: geomtextpath\n\nif (!require(\"ggrepel\")) install.packages(\"ggrepel\")\n\nCargando paquete requerido: ggrepel\n\n# packages\n\nlibrary(tidyverse)\nlibrary(geomtextpath)\nlibrary(ggrepel)\n\nFirst, we load the prepared dataset and compute the monthly average temperature across all stations. Next, we calculate the climatological normals for the reference periods 1971-2000, 1991–2020. Finally, we add additional columns for the month and label to complete the data preparation.\n\n# load station data\nload(\"aemet_refstations.RData\")\n\n# add year-month column and calculate average temperature by month-year\ntmed_esp &lt;- mutate(data_daily, yrmo = floor_date(date, \"month\")) |&gt;\n               select(yrmo, tmed) |&gt;\n                group_by(yrmo) |&gt;\n                   summarise(tmed = mean(tmed, na.rm = T))\n\n\n# normal reference for each month 1971-2000, 1991-2020\nnorm_p1 &lt;- filter(tmed_esp, year(yrmo) %in% 1971:2000) |&gt;\n  group_by(mo = month(yrmo)) |&gt;\n  summarise(\n    tmed_norm = mean(tmed)\n  ) |&gt;\n  mutate(period = \"1971-2000\")\n\nnorm_p2 &lt;- filter(tmed_esp, year(yrmo) %in% 1991:2020) |&gt;\n  group_by(mo = month(yrmo)) |&gt;\n  summarise(\n    tmed_norm = mean(tmed)\n    ) |&gt;\n  mutate(period = \"1991-2020\")\n\n# main dataset with month label\ntmed_esp &lt;- mutate(tmed_esp,\n                   mo = month(yrmo),\n                   mo_lab = month(yrmo, label = T)\n                   )\n\nThe first posibility would be a dumbbell chart. For each month of 2025, the chart shows observed mean temperature (red) against the climatological normal (white), connected by a vertical segment. A dumbbell chart is essentially a way to show the difference between two values for the same category, connected by a line. The label above each point reports the anomaly, allowing quick identification of warmer or cooler months and the magnitude of the difference. The use of geom_text_repel(), a function from the ggrepel R package that allows you to add text labels while automatically preventing overlap, ensuring that annotations remain clear and readable even when points are densely packed.\n\nleft_join(tmed_esp, norm_p2, by = \"mo\") |&gt;\n     filter(year(yrmo) == 2025) |&gt;          # filter only 2025\n       mutate(anom = tmed - tmed_norm) |&gt;\n  ggplot(aes(yrmo, tmed)) +\n  # the connected line is first added, you need here to specify the end point \n  geom_segment(aes(y = tmed_norm, yend = tmed), linewidth = 1.3) +\n  # observed temperature with red color\n  geom_point(colour = \"#b30000\", size = 2) +\n  # reference temperature \n  geom_point(aes(y = tmed_norm), shape = 21, fill = \"white\", size = 2.5) +\n  # anomaly value for each month\n  geom_text_repel(aes(label = scales::number(anom, accuracy = 0.1,  #formats the numeric variable\n                                       suffix = \"ºC\", \n                                       style_positive = \"plus\"),\n                      y = tmed), \n                   direction = \"x\", # prioritize repelling labels along the horizontal axis    \n                   nudge_x = 0.05, # fixed horizontal offset\n                   seed = 12345, # deterministic label placement.\n                   size = 2.7, \n                   hjust = .5\n                  ) +\n  scale_x_date(date_breaks = \"month\", date_labels = \"%b\") +\n  scale_y_continuous(breaks = seq(8, 30, 2), expand = expansion(c(0.05, .05))) +\n  labs(x = NULL, y = \"Mean temperature (ºC)\") +\n  theme_minimal() +\n  theme(\n    panel.grid.minor = element_blank(),\n    axis.ticks = element_blank(),\n    axis.title.y = element_text(hjust = 0),\n    panel.grid.major.x = element_blank(),\n    plot.margin = margin(5, 10, 5, 5)\n  )\n\n\n\n\n\n\n\nInstead of using absolut values, we can summarize monthly temperature for Spain in 2025 relative to the recent normal. Background bands mark severity thresholds at 0.5σ, 1σ, and 2σ (σ: standard deviation), computed from 1991–2020 anomalies, while bars show the actual anomaly for each month. Centering the scale at zero makes it straightforward to judge both the sign and the magnitude of departures from normal. In this case, however, using bars is appropriate because the anomalies are centered around a clear reference point at zero.\n\n\n\n\n\n\nTip\n\n\n\nMonthly standard deviation (σ) varies greatly, so using month-specific thresholds would make the same anomaly appear “extreme” in winter but only “warm” in summer, which is confusing in a single annual chart. A single annual σ provides a consistent scale and makes comparisons across months clear.\n\n\n\n# standard deviation for the whole year\nstd_7120 &lt;- filter(tmed_esp, \n                   between(year(yrmo), 1991, 2020)) |&gt; # shortcut for x &gt;= left & x &lt;= right\n               left_join(norm_p1, by = \"mo\") |&gt;\n                 summarise(std = sd(tmed - tmed_norm, na.rm = TRUE)) |&gt;\n                  pull(std)\n\n# anomaly plot \nleft_join(tmed_esp, norm_p2, by = \"mo\") |&gt;\n     filter(year(yrmo) == 2025) |&gt; # filter only current year\n       mutate(anom = tmed - tmed_norm) |&gt; # anomaly\nggplot(aes(yrmo, anom)) +\n  # background for severity thresholds\n  annotate(\"rect\",\n    xmin = -Inf, ymin = c(0, std_7120 * .5, std_7120, std_7120 * 2),\n    xmax = Inf, ymax = c(std_7120 * .5, std_7120, std_7120 * 2, Inf),\n    fill = c(\"white\", \"#fcae91\", \"#fb6a4a\", \"#cb181d\"),\n    alpha = .4\n  ) +\n  # severity labels at right side\n  annotate(\"text\",\n    x = ymd(\"2025-12-01\"),\n    y = c(0, .85, 1.7, 3.2),\n    angle = 90,\n    vjust = 3,\n    label = c(\"Normal\", \"Warm\", \"Very warm\", \"Extremely warm\"),\n    alpha = .8, \n    color = \"white\"\n  ) +\n  # column for anomalies\n  geom_col(width = 20) +\n  scale_x_date(date_breaks = \"month\", date_labels = \"%b\", expand = expansion(c(.01, .07))) +\n  scale_y_continuous(breaks = seq(0, 5, .5), expand = expansion(c(0, .05)),\n                     limits = c(-std_7120 * .5, NA)) +\n  labs(x = NULL, y = \"Anomaly (ºC)\") +\n  theme(\n    panel.grid.minor = element_blank(),\n    axis.ticks = element_blank(),\n    axis.title.y = element_text(hjust = 0),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major = element_line(colour = \"white\")\n  )\n\n\n\n\n\n\n\nA final alternative approach could be a barcode-style chart where each thin vertical bar represents a single year within the historical record for a given month. The bars are positioned along the horizontal axis according to their monthly mean temperature, creating a visual distribution of all observed values. To highlight key information, the most extreme years—both the warmest and the coldest—are labelled, while the current year is marked with a more prominent style, such as a thicker bar. Additionally, a point indicates the long-term climatological average, allowing viewers to quickly assess how individual years compare to the historical norm. By faceting the chart by month, this design provides a compact yet detailed view of variability, extremes, and the position of the current year within the broader climate context.\nFor this barcode chart, we want to highlight extreme years, but at the same time they shouldn’t overlap, so we need a function that removes labels that are too close to each other. The operator { } is called curly-curly (also “embracing”). It unquotes the quosure so that a dplyr verb (like group_by(), arrange(), mutate(), filter()) can treat it exactly as if you had typed the column name directly.\n\n# global parameters\nthres     &lt;- 2 # how close should be labels?\ncurrent_yr  &lt;- 2025\n\n# labeled years lowest/highest 5 by month\nobs_lab &lt;- tmed_esp |&gt;\n  group_by(mo_lab) |&gt;\n  slice_min(order_by = tmed, n = 5, with_ties = FALSE) |&gt;\n  bind_rows(\n    tmed_esp |&gt;\n      group_by(mo_lab) |&gt;\n      slice_max(order_by = tmed, n = 5, with_ties = FALSE)\n  ) |&gt;\n  arrange(mo_lab, yrmo) |&gt;\n  ungroup()\n\n# current year\nobs_current &lt;- filter(tmed_esp, year(yrmo) == current_yr)\n\n# filter function to avoid very close values\nfilter_extreme_and_current &lt;- function(data, x, group, threshold, current_year) {\n\n    #1) Detect clusters of very close values.\n    group_by(data, {{ group }}) |&gt;\n    arrange({{ x }}) |&gt;\n    mutate(cluster = cumsum(({{ x }} - lag({{ x }}, default = -Inf)) &gt; threshold)) |&gt;\n    ungroup() |&gt;\n    # 2) For each month and cluster, extract only the minimum and the maximum.\n    group_by({{ group }}, cluster) |&gt;\n    filter({{ x }} == min({{ x }}) | {{ x }} == max({{ x }})) |&gt;\n    ungroup() |&gt;\n    select(-cluster) |&gt;\n    # 3) Add the rows for the current year (if they exist).\n    filter(year(yrmo) != current_year) |&gt;\n    # 4) Remove duplicates (in case the current year was already marked as an extreme)\n    distinct()\n}\n\n# filter out labels to close\nobs_lab_sel &lt;- filter_extreme_and_current(obs_lab, tmed, mo_lab, thres, current_yr)\n\n# mean temperature by month\nmed &lt;- group_by(tmed_esp, mo_lab) |&gt; summarise(normal = mean(tmed, na.rm = T))\n\n\n# colour palette for bar code lines\ncol_temp &lt;- c(\n  \"#cbebf6\", \"#a7bfd9\", \"#8c99bc\", \"#974ea8\", \"#830f74\",\n  \"#0b144f\", \"#0e2680\", \"#223b97\", \"#1c499a\", \"#2859a5\",\n  \"#1b6aa3\", \"#1d9bc4\", \"#1ca4bc\", \"#64c6c7\", \"#86cabb\",\n  \"#91e0a7\", \"#c7eebf\", \"#ebf8da\", \"#f6fdd1\", \"#fdeca7\",\n  \"#f8da77\", \"#fcb34d\", \"#fc8c44\", \"#f85127\", \"#f52f26\",\n  \"#d10b26\", \"#9c042a\", \"#760324\", \"#18000c\"\n)\n\n# custom break function\ncustom_breaks &lt;- function(limits) {\n  round(c(limits[1], pretty(limits, n = 5), limits[2]))\n}\n\nIn this chart, what stands out is the use of geom_textvline(), a function from the geomtextpath R package. It allows you to draw a vertical reference line and place a text label directly on that line, even when you have curved lines.\n\n# barcode plot\nggplot(tmed_esp) +\n  # barcode vertical lines\n  geom_vline(aes(xintercept = tmed, colour = tmed),\n    alpha = .7,\n    linewidth = 0.1\n  ) +\n  # selected extreme years with label\n  geom_textvline(\n    data = obs_lab_sel,\n    aes(\n      xintercept = tmed, label = year(yrmo),\n      colour = tmed\n    ),\n    linewidth = 0.1, hjust = .8, size = 2.5,\n    vjust = .5\n  ) +\n  # current year labels \n  geom_textvline(\n    data = obs_current,\n    aes(\n      xintercept = tmed, label = year(yrmo),\n      colour = tmed\n    ),\n    linewidth = 0.4, hjust = 1.3, size = 2.5,\n    vjust = .5\n  ) +\n  # add density distribution based on reference period\n  geom_density(data = filter(tmed_esp, year(yrmo) %in% 1991:2020), aes(tmed)) +\n  # add average value from reference period for each month\n  geom_point(data = med, aes(x = normal, y = 0), shape = 1, stroke = 1) +\n  scale_colour_gradientn(\n    colours = col_temp,\n    limits = c(4.4, 26.8),\n    guide = \"none\"\n  ) +\n  scale_x_continuous(\n    breaks = custom_breaks,\n    expand = expansion(.01)\n  ) +\n  scale_y_continuous(expand = expansion()) +\n  labs(y = NULL, x = \"Monthly mean temperature\") +\n  facet_wrap(mo_lab ~ ., ncol = 3, scale = \"free_x\") +\n  coord_cartesian(clip = \"off\") +\n  theme_minimal() +\n  theme(\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.grid = element_blank(),\n    axis.title.x = element_text(hjust = 0, size = 8),\n    strip.text.x = element_text(hjust = 0, size = 10)\n  )\n\n\n\n\n\n\n\n\n\n\n Back to topReuseCC BY-SA 4.0CitationFor attribution, please cite this work as:\nRoyé, Dominic. n.d. “Visualizing Monthly Temperature.” https://dominicroye.github.io/blog/broken-charts/show_case.html."
  },
  {
    "objectID": "blog/bivariate-dasymetric-map/index.html#data",
    "href": "blog/bivariate-dasymetric-map/index.html#data",
    "title": "Bivariate dasymetric map",
    "section": "Data",
    "text": "Data\nFirst we download all the necessary data. With the exception of the CORINE Land Cover (~ 200 MB), the data stored on this blog can be obtained directly via the indicated links.\n\nCORINE Land Cover 2018 (geotiff): COPERNICUS\n\nIncome data and Gini index (excel): INE (download)\nCensus limits of Spain (vectorial): INE (download)"
  },
  {
    "objectID": "blog/bivariate-dasymetric-map/index.html#import",
    "href": "blog/bivariate-dasymetric-map/index.html#import",
    "title": "Bivariate dasymetric map",
    "section": "Import",
    "text": "Import\nThe first thing we do is to import the land use raster, the income and Gini index data, and the census boundaries.\n\n# raster of CORINE LAND COVER 2018\nurb &lt;- rast(\"U2018_CLC2018_V2020_20u1.tif\")\n\n# income data and Gini index\nrenta &lt;- read_excel(\"30824.xlsx\")\ngini &lt;- read_excel(\"37677.xlsx\")\n\n# census boundaries\nlimits &lt;- read_sf(\"SECC_CE_20200101.shp\")"
  },
  {
    "objectID": "blog/bivariate-dasymetric-map/index.html#land-uses",
    "href": "blog/bivariate-dasymetric-map/index.html#land-uses",
    "title": "Bivariate dasymetric map",
    "section": "Land uses",
    "text": "Land uses\nIn this first step we filter the census sections to obtain those of the Autonomous Community of Madrid, and we create the municipal limits. To dissolve the polygons of census tracts we apply the function group_by() in combination with summarise().\n\n# filter the Autonomous Community of Madrid\nlimits &lt;- filter(limits, NCA == \"Comunidad de Madrid\")\n\n# obtain the municipal limits\nmun_limit &lt;- group_by(limits, CUMUN) |&gt; summarise()\n\nIn the next step we cut the land use raster with the limits of Madrid. I recommend always using the crop() function first and then mask(), the first function crop to the required extent and the second mask the values. Subsequently, we remove all the cells that correspond to 1 or 2 (urban continuous, discontinuous). Finally, we project the raster.\n\n# project the limits\nlimits_prj &lt;- st_transform(limits, crs(urb))\n\n# crop and mask\nurb_mad &lt;- crop(urb, limits_prj) |&gt;\n  mask(limits_prj)\n\n# remove non-urban pixels\nurb_mad[!urb_mad %in% 1:2] &lt;- NA\n\n# plot the raster\nplot(urb_mad)\n\n\n\n\n\n# project\nurb_mad &lt;- project(urb_mad, \"EPSG:4326\")\n\nIn this step, we convert the raster data into a point sf object.\n\n# transform the raster to xyz and a sf object\nurb_mad &lt;- as.data.frame(urb_mad, xy = TRUE) |&gt;\n              st_as_sf(coords = c(\"x\", \"y\"), crs = 4326)\n\n# add the columns of the coordinates\nurb_mad &lt;- urb_mad |&gt; rename(urb = 1) |&gt;\n            cbind(st_coordinates(urb_mad))"
  },
  {
    "objectID": "blog/bivariate-dasymetric-map/index.html#income-data-and-gini-index",
    "href": "blog/bivariate-dasymetric-map/index.html#income-data-and-gini-index",
    "title": "Bivariate dasymetric map",
    "section": "Income data and Gini index",
    "text": "Income data and Gini index\nThe format of the Excels does not coincide with the original of the INE, since I have cleaned the format before in order to make this post easier. What remains is to create a column with the codes of the census sections and exclude data that correspond to another administrative level.\n\n## income and Gini index data\n\nrenta_sec &lt;- mutate(renta,\n  NATCODE = str_extract(CUSEC, \"[0-9]{5,10}\"),\n  nc_len = str_length(NATCODE),\n  mun_name = str_remove(CUSEC, NATCODE) |&gt; str_trim()\n) |&gt;\n  filter(nc_len &gt; 5)\n\ngini_sec &lt;- mutate(gini,\n  NATCODE = str_extract(CUSEC, \"[0-9]{5,10}\"),\n  nc_len = str_length(NATCODE),\n  mun_name = str_remove(CUSEC, NATCODE) |&gt; str_trim()\n) |&gt;\n  filter(nc_len &gt; 5)\n\nIn the next step we join both tables with the census tracts using left_join() and convert columns of interest in numerical mode.\n\n# join both the income and Gini tables with the census limits\nmad &lt;- left_join(limits, renta_sec, by = c(\"CUSEC\" = \"NATCODE\")) |&gt;\n            left_join(gini_sec, by = c(\"CUSEC\" = \"NATCODE\"))\n\n# convert selected columns to numeric\nmad &lt;- mutate(mad, across(c(23:27, 30:31), as.numeric))"
  },
  {
    "objectID": "blog/bivariate-dasymetric-map/index.html#bivariate-variable",
    "href": "blog/bivariate-dasymetric-map/index.html#bivariate-variable",
    "title": "Bivariate dasymetric map",
    "section": "Bivariate variable",
    "text": "Bivariate variable\nTo create a bivariate map we must construct a single variable that combines different classes of two variables. Usually we make three classes of each variable which leads to nine combinations; in our case, the average income and the Gini index. The biscale package includes helper functions to carry out this process. With the bi_class() function we create the classification variable using quantiles as algorithm. Since in both variables we find missing values, we correct those combinations between both variables where an NA appears.\n\n# create bivariate classification\nmapbivar &lt;- bi_class(mad, GINI_2017, RNMP_2017, style = \"quantile\", dim = 3) |&gt;\n              mutate(bi_class = ifelse(str_detect(bi_class, \"NA\"), NA, bi_class))\n\n# results\nhead(dplyr::select(mapbivar, GINI_2017, RNMP_2017, bi_class))\n\nWe finish by redistributing the inequality variable over the pixels of urban land use. The st_join() function joins the data with the land use points.\n\n# redistribute urban pixels to inequality\nmapdasi &lt;- st_join(urb_mad, st_transform(mapbivar, 4326))"
  },
  {
    "objectID": "blog/bivariate-dasymetric-map/index.html#legend-and-font",
    "href": "blog/bivariate-dasymetric-map/index.html#legend-and-font",
    "title": "Bivariate dasymetric map",
    "section": "Legend and font",
    "text": "Legend and font\nBefore constructing both maps we must create the legend using the bi_legend() function. In the function we define the titles for each variable, the number of dimensions and the color scale. Finally, we add the Montserrat font for the final titles in the graphic.\n\n# bivariate legend\nlegend2 &lt;- bi_legend(\n  pal = \"DkViolet\",\n  dim = 3,\n  xlab = \"Higher inequality\",\n  ylab = \"Higher income\",\n  size = 9\n)"
  },
  {
    "objectID": "blog/bivariate-dasymetric-map/index.html#dasymetric-map",
    "href": "blog/bivariate-dasymetric-map/index.html#dasymetric-map",
    "title": "Bivariate dasymetric map",
    "section": "Dasymetric map",
    "text": "Dasymetric map\nWe build this map using geom_tile() for the pixels and geom_sf() for the municipal boundaries. In addition, it will be the map on the right where we also place the legend. To add the legend we use the annotation_custom() function indicating the position in the geographical coordinates of the map. The biscale package also helps us with the color definition via the bi_scale_fill() function.\n\np2 &lt;- ggplot(mapdasi) +\n  geom_tile(\n    aes(X, Y,\n      fill = bi_class\n    ),\n    show.legend = FALSE\n  ) +\n  geom_sf(\n    data = mun_limit,\n    color = \"grey80\",\n    fill = NA,\n    size = 0.2\n  ) +\n  annotation_custom(ggplotGrob(legend2),\n    xmin = -3.25, xmax = -2.65,\n    ymin = 40.55, ymax = 40.95\n  ) +\n  bi_scale_fill(\n    pal = \"DkViolet\",\n    dim = 3,\n    na.value = \"grey90\"\n  ) +\n  labs(title = \"dasymetric\", x = NULL, y = NULL) +\n  bi_theme() +\n  theme(plot.title = element_text(family = \"Montserrat\", size = 30, face = \"bold\"),\n        plot.margin = margin(5, 50, 5, 5)) +\n  coord_sf(crs = 4326, clip = \"off\")"
  },
  {
    "objectID": "blog/bivariate-dasymetric-map/index.html#choropleth-map",
    "href": "blog/bivariate-dasymetric-map/index.html#choropleth-map",
    "title": "Bivariate dasymetric map",
    "section": "Choropleth map",
    "text": "Choropleth map\nThe choropleth map is built in a similar way to the previous map with the difference that we use geom_sf().\n\np1 &lt;- ggplot(mapbivar) +\n  geom_sf(aes(fill = bi_class),\n    colour = NA,\n    size = .1,\n    show.legend = FALSE\n  ) +\n  geom_sf(\n    data = mun_limit,\n    color = \"white\",\n    fill = NA,\n    size = 0.2\n  ) +\n  bi_scale_fill(\n    pal = \"DkViolet\",\n    dim = 3,\n    na.value = \"grey90\"\n  ) +\n  labs(title = \"choropleth\", x = NULL, y = NULL) +\n  bi_theme() +\n  theme(plot.title = element_text(family = \"Montserrat\", size = 30, face = \"bold\")) +\n  coord_sf(crs = 4326)"
  },
  {
    "objectID": "blog/bivariate-dasymetric-map/index.html#merge-both-maps",
    "href": "blog/bivariate-dasymetric-map/index.html#merge-both-maps",
    "title": "Bivariate dasymetric map",
    "section": "Merge both maps",
    "text": "Merge both maps\nWith the help of the patchwork package, we combine both maps in a single row, first the choropleth map and on its right the dasymmetric map. More details of the grammar used for the combination of graphics here.\n\n# combine\np &lt;- p1 | p2\n\n# final map\np"
  },
  {
    "objectID": "blog/accessing-osm-data-with-r/index.html#the-database-of-open-street-maps",
    "href": "blog/accessing-osm-data-with-r/index.html#the-database-of-open-street-maps",
    "title": "Accessing OpenStreetMap data with R",
    "section": "The database of Open Street Maps",
    "text": "The database of Open Street Maps\nRecently I created a map of the distribution of gas stations and electric charging stations in Europe.\n\nHow can you obtain this data?\nWell, in this case I used points of interest (POIs) from the database of Open Street Maps (OSM). Obviously OSM not only contains streets and highways, but also information that can be useful when we use a map such as locations of hospitals or gas stations. To avoid downloading the entire OSM and extracting the required information, you can use an overpass API, which allows us to query the OSM database with our own criteria.\nAn easy way to access an overpass API is through overpass-turbo.eu, which even includes a wizard to build a query and display the results on a interactive map. A detailed explanation of the previous web can be found here. However, we have at our disposal a package osmdata that allows us to create and make queries directly from the R environment. Nevertheless, the use of the overpass-turbo.eu can be useful when we are not sure what we are looking for or when we have some difficulty in building the query."
  },
  {
    "objectID": "blog/accessing-osm-data-with-r/index.html#accessing-the-overpass-api-from-r",
    "href": "blog/accessing-osm-data-with-r/index.html#accessing-the-overpass-api-from-r",
    "title": "Accessing OpenStreetMap data with R",
    "section": "Accessing the overpass API from R",
    "text": "Accessing the overpass API from R\nThe first step is to install several packages, in case they are not installed. In almost all my scripts I use tidyverse which is a fundamental collection of different packages, including dplyr (data manipulation), ggplot2 (visualization), etc. The sf package is the new standard for working with spatial data and is compatible with ggplot2 and dplyr. Finally, ggmap makes it easier for us to create maps.\n\n# install the osmdata, sf, tidyverse and ggmap package\nif (!require(\"osmdata\")) install.packages(\"osmdata\")\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"sf\")) install.packages(\"sf\")\nif (!require(\"ggmap\")) install.packages(\"ggmap\")\n\n# load packages\nlibrary(tidyverse)\nlibrary(osmdata)\nlibrary(sf)\nlibrary(ggmap)"
  },
  {
    "objectID": "blog/accessing-osm-data-with-r/index.html#build-a-query",
    "href": "blog/accessing-osm-data-with-r/index.html#build-a-query",
    "title": "Accessing OpenStreetMap data with R",
    "section": "Build a query",
    "text": "Build a query\nBefore creating a query, we need to know what we can filter. The available_features() function returns a list of available OSM features that have different tags. More details are available in the OSM wiki here. For example, the feature shop contains several tags among others supermarket, fishing, books, etc.\n\n# the first five features\nhead(available_features())\n\n\n# amenities\nhead(available_tags(\"amenity\"))\n\n\n# shops\nhead(available_tags(\"shop\"))\n\nThe first query: Where are cinemas in Madrid?\nTo build the query, we use the pipe operator |&gt; from R Base, which helps to chain several functions without assigning the result to a new object. The first pipe in R was %&gt;% very extended especially within the tidyverse package collection. If you want to know more about its use, you can find here a tutorial or some details on differences between both here.\nIn the first part of the query we need to indicate the place where we want to extract the information. The getbb() function creates a boundering box for a given place, looking for the name. The main function is opq() which build the final query. We add our filter criteria with the add_osm_feature() function. In this first query we will look for cinemas in Madrid. That’s why we use as key amenity and cinema as tag. There are several formats to obtain the resulting spatial data of the query. The osmdata_*() function sends the query to the server and, depending on the suffix * sf/sp/xml, returns a simple feature, spatial or XML format.\n\n# building the query\nq &lt;- getbb(\"Madrid\") |&gt;\n  opq() |&gt;\n  add_osm_feature(\"amenity\", \"cinema\")\n\nstr(q) # query structure\n\n\ncinema &lt;- osmdata_sf(q)\ncinema\n\nWe see that the result is a list of different spatial objects. In our case, we are only interested in osm_points.\nHow can we visulise these points?\nThe advantage of sf objects is that for ggplot2 already exists a geometry function geom_sf(). Furthermore, we can include a background map using ggmap. The get_map() function downloads the map for a given place. Alternatively, it can be an address, latitude/longitude or a bounding box. The maptype argument allows us to indicate the style or type of map. You can find more details in the help of the ?get_map function.\nWhen we build a graph with ggplot we usually start with ggplot(). In this case, we start with ggmap() that includes the object with our background map. Then we add with geom_sf() the points of the cinemas in Madrid. It is important to indicate with the argument inherit.aes = FALSE that it has to use the aesthetic mappings of the spatial object osm_points. In addition, we change the color, fill, transparency (alpha), type and size of the circles.\nYou need to register your key for Stadia Maps: register_stadiamaps(_key_)\n\n# our background map\nmad_map &lt;- get_map(getbb(\"Madrid\"), maptype = \"stamen_toner_background\")\n\n# final map\nggmap(mad_map) +\n  geom_sf(\n    data = cinema$osm_points,\n    inherit.aes = FALSE,\n    colour = \"#238443\",\n    fill = \"#004529\",\n    alpha = .5,\n    size = 4,\n    shape = 21\n  ) +\n  theme_void()\n\n\n\n\nWhere can we find Mercadona supermarkets?\nInstead of obtaining a bounding box with the function getbb() we can build our own box. To do this, we create a vector of four elements, the order has to be West/South/East/North. In the query we use two features: name and shop to filter supermarkets that are of this particular brand. Depending on the area or volume of the query, it is necessary to extend the waiting time. By default, the limit is set at 25 seconds (timeout).\nThe map, we create in this case, consists only of the supermarket points. Therefore, we use the usual grammar by adding the geometry geom_sf(). The theme_void() function removes everything except for the points.\n\n# bounding box for the Iberian Peninsula\nm &lt;- c(-10, 30, 5, 46)\n\n# building the query\nq &lt;- m |&gt;\n  opq(timeout = 25 * 100) |&gt;\n  add_osm_feature(\"name\", \"Mercadona\") |&gt;\n  add_osm_feature(\"shop\", \"supermarket\")\n\n# query\nmercadona &lt;- osmdata_sf(q)\n\n# final map\nggplot(mercadona$osm_points) +\n  geom_sf(\n    colour = \"#08519c\",\n    fill = \"#08306b\",\n    alpha = .5,\n    size = 1,\n    shape = 21\n  ) +\n  theme_void()"
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "Dominic Royé",
    "section": "",
    "text": "Hello, and welcome! I’m glad you stopped by.\n\nThe “where”, “why”, and the “how”\nI work as a Ramon y Cajal reseacher at the MBG-CSIC. My research interests include bioclimatology and spatial data science. I am an enthusiastic R user, with a lot of curiosity for spatial analysis, data visualizations, management and manipulation, and GIS. Keep up with my R tinkering in my blog. Learn more about my research interests in publications.\nGet in touch by sending me a note!"
  },
  {
    "objectID": "about/index.html#about-me",
    "href": "about/index.html#about-me",
    "title": "Dominic Royé",
    "section": "About me",
    "text": "About me\n\n\nClimate scientist, curious about all intersections of data and society.\nI am a climate scientist and actually, I am Ramon y Cajal researcher at the Misión Biologica de Galicia - The Spanish National Research Council (CSIC), previously I was the head of data science at the Climate Research Foundation (FIC) and researcher at the University of Santiago de Compostela. I am originally from Grevenbroich, near by Cologne, in Germany. I graduated in Geography and Hispanic Philology at the University of Cologne and RWTH-Aachen University in 2010. After I met my wife in Galicia, I came to Santiago de Compostela, in northwest Spain, and made my Ph.D. in 2015 about the relationship between health and climate at the same University.\n\n\nInterests: applied climatology, physical geography, biometeorology, public health, geographic information systems, R programming, data management, manipulation and visualization\n\n\n\n\nI am a member of the Public Health Research Group at the University of Santiago de Compostela. In addition, I am a close collaborator of two other research groups, Geobiomet at the University of Cantabria and Climatology Group at the University of Barcelona. Since 2019 I am a member of the MCC Collaborative Research Network, an international research program on the associations between environmental stressors, climate, and health.\nI’m particularly interested in biometeorology, among others, the relationship between human health and the atmospheric environment, and on the other hand, applied physical geography with a focus on atmospheric variables and their spatio-temporal behaviors.\n\n\nPhD in Physical Geography | University of Santiago de Compostela, Spain | 2015\n\n\nB.S. in Geography and Hispanic Philology | University of Cologne | RWTH-Aachen University, Germany | 2010"
  },
  {
    "objectID": "about/index.html#lately",
    "href": "about/index.html#lately",
    "title": "Dominic Royé",
    "section": "Lately …",
    "text": "Lately …\n\nBlog\n\n\n\n\n\n\n\n\n\nMapping building use with a hexagonal grid\n\n\n\n\n\n\n\n\n\n\n\n\n\nBroken Chart: discover 9 visualization alternatives\n\n\n\n\n\n\n\n\nNo matching items\n\nSee all →\nPublications\n\n\nWagatsuma K, Feurer D, Yu W, Xu R, Riffe T, Kniffka MS, Acosta E, Armstrong B, Mistry M, Lowe R, Royé D, Hashizume M, Tobias A, Vicedo‑Cabrera AM, Madaniyazi L, Ng CFS, Íñiguez C, Ragettli MS, Lavigne E, Matus Correa P, Valdés Ortega N, Kyselý J, Urban A, Orru H, Indermitte E, Maasikmets M, Breitner‑Busch S, Schneider A, Honda Y, Alahmad B, Zanobetti A, Schwartz J, Carrasco G, Holobâca IH, Kim H, Lee W, Bell ML, Scovronick N, Acquaotta F, de Sousa Zanotti Stagliorio Coelho M, Hurtado Diaz M, Félix Arellano EE, Michelozzi P, Stafoggia M, de’Donato F, Rao S, Seposo X, Tong S, Klompmaker J, Guo Y, Masselot P, Gasparrini A, Sera F (2026). The joint impact of temperature, humidity, and air pollution on COVID-19 incidence: a multi-country time-series study in 439 cities. Environment International.  10.1016/j.envint.2026.110090\n\n\nTorres‑Vázquez MÁ, Dalle Vaglie M, Kettridge N, Martellozzo F, Miguez‑Macho G, Provenzale A, Royé D, Randelli F, Turco M (2026). Assessing decadal changes in human exposure near wildfires in a Mediterranean region. Scientific Reports, vol. 208, art. no. 110090.  10.1038/s41598-026-35426-4\n\n\nSee all →\nData Viz\n\n\n\n\n\n\n\n\n\nNo matching items\n\nSee all →"
  },
  {
    "objectID": "bioclim/index.html",
    "href": "bioclim/index.html",
    "title": "Bioclim research group",
    "section": "",
    "text": "Welcome to BIOCLIM! We are glad you stopped by.\n\nBioclimatology and Global Change\n\n\n\n\n\nThe BIOCLIMA: Bioclimatology and Global Change group at the Misión Biologica de Galicia (MBG) - The Spanish National Research Council (CSIC) studies how the atmospheric environment affects the health and well-being of living beings, analyzing climatic patterns, Earth system interactions, and the adaptation of the planet and its inhabitants to climatic risks. With a multidisciplinary approach, it investigates the vulnerability of populations in the context of global change.\nThe staff associated with BIOCLIM have a multi- and interdisciplinary background and translational experience in the fields of geography, ecology, physics, biometeorology, epidemiology, and biostatistics.\nGet in touch by sending a note!"
  },
  {
    "objectID": "bioclim/index.html#about-us",
    "href": "bioclim/index.html#about-us",
    "title": "Bioclim research group",
    "section": "About us",
    "text": "About us\n\n\nResearch Lines\n\n\nThe effects of the atmospheric environment on mortality and morbidity.\n\n\nSpatiotemporal and geographical behaviors of atmospheric variables.\n\n\nInteraction processes among different components of the Earth system in the context of Global Change.\n\n\nAdaptation to climate risks: vulnerability and exposure.\n\n\nCreation of open data to understand many natural, anthropogenic, and social processes.\n\n\nJoin the MBG and the BIOCLIM Group!\nThe MBG-CSIC is the perfect place to boost your career in science. If you want to grow in a collaborative environment committed to advancing knowledge, don’t hesitate to get in touch with us. We are open to receiving expressions of interest and applications for doctoral theses (PhD), master’s theses (TFM), undergraduate theses (TFG), or internships for undergraduate and vocational training programs.\nLet us know if you need anything else!\n\n\nBIOCLIM in scientific collaboration platforms"
  },
  {
    "objectID": "bioclim/index.html#activities",
    "href": "bioclim/index.html#activities",
    "title": "Bioclim research group",
    "section": "Activities",
    "text": "Activities\n\n\nVisiting Researchers\n\n2025\n\nDr. Alba Viana-Soto (Technical University of Munich) [invited researcher]\nPaola Rapisarda (Università di Catania) [PhD Student research stay]\nMaria Castrogiovanni (Università di Catania) [PhD Student research stay]\n\n\n\n\n\n\n\nConferences and other stuff\n\n2026\n\nVisualising Climate 2026 | Bologna, Italy • 4–6 November co-organization of the first global conference dedicated to how data visualisation can transform public understanding of our changing planet and support informed decision-making in the face of climate challenges.\n\n2025\n\nThe Footprints of Forest Disturbances in Europe: Remote Sensing for Damage and Recovery Assessment Dr. Alba Viana-Soto (Technical University of Munich) [10-10-2025]\nImproving Information for Managing Climate-Resilient Forests for Ecological Restoration Dr. Jaime Ribalaygua Batalla (FIC) [16-10-2025]\nSummer course VII Edition of the Introduction to Geographic Information Systems and Cartography with the R environment [1/4-07-2025] Santiago de Compostela."
  },
  {
    "objectID": "blog/always-normalize-your-data/index.html",
    "href": "blog/always-normalize-your-data/index.html",
    "title": "Always normalize your data",
    "section": "",
    "text": "I recently came across a map from the National Atlas of Spain showing the number of libraries by municipality. However, one thing directly caught my attention. There’s a saying that many maps show only the population, and this seems to be the case here. The map does not provide any remarkable information about the distribution of libraries; it merely shows where the most people live. It’s a very common pitfall. There are many phenomena that depend on population. It can be assumed that the number of libraries largely depends on the number of inhabitants in each municipality. Therefore, we see cities like Madrid, Barcelona, Seville, Valencia, and many provincial capitals with a higher number of libraries.\nNormalization of population-dependent variables can be performed in different ways, depending on the context and type of data. In our case, it involves dividing the number of libraries by the total population. To avoid very small numbers, it is common to multiply by a fixed population, such as 10,000. Another alternative, but not in this case, would be the use of percent.\n\\[  \n\\text{Libraries per 10,000 inhabitants} = \\left( \\frac{\\text{Number of libraries}}{\\text{Total population}}\\right) \\times 10,000\n\\]\nIf you divide the other way around, it gives you a different perspective. You are calculating how many people, on average, have access to a single library.\n\\[  \n\\text{Inhabitants per library} = \\frac{\\text{Total population}}{\\text{Number of libraries}}\n\\]\nLets get to work!"
  },
  {
    "objectID": "blog/always-normalize-your-data/index.html#packages",
    "href": "blog/always-normalize-your-data/index.html#packages",
    "title": "Always normalize your data",
    "section": "Packages",
    "text": "Packages\n\n\n\n\n\n\nPackage\nDescription\n\n\n\ntidyverse\nCollection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.\n\n\nmapSpain\nAdministrative boundaries of Spain at different levels\n\n\nsf\nSimple Feature: import, export and manipulate vector data\n\n\njanitor\nSimple functions for examining and cleaning dirty data\n\n\npatchwork\nSimple grammar to combine separate ggplots into the same graphic\n\n\n\n\n# install the packages if necessary\n\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"mapSpain\")) install.packages(\"mapSpain\")\nif (!require(\"sf\")) install.packages(\"sf\")\nif (!require(\"janitor\")) install.packages(\"janitor\")\nif (!require(\"patchwork\")) install.packages(\"patchwork\")\n\n# packages\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(sf)\nlibrary(mapSpain)\nlibrary(janitor)\nlibrary(patchwork)"
  },
  {
    "objectID": "blog/always-normalize-your-data/index.html#data",
    "href": "blog/always-normalize-your-data/index.html#data",
    "title": "Always normalize your data",
    "section": "Data",
    "text": "Data\nIn this post we will use a dataset of libraries from Spain for 2022 (download)1 which I obtained from the Ministry of Culture. In this step we also import the population data from the INE and municipality boundaries from the mapSpain package.\n\n# import library data\nbib &lt;- read_excel(\"datos.xlsx\") |&gt;\n  clean_names() |&gt;\n  filter(pais == \"España\")\nbib\n\n\n# region and municipality boundaries\nccaa &lt;- esp_get_ccaa() # for the map\nmun &lt;- esp_get_munic()\nmun\n\n\n# population data\npob &lt;- read_csv2(\"33570.csv\") |&gt; janitor::clean_names()\npob"
  },
  {
    "objectID": "blog/always-normalize-your-data/index.html#preparation",
    "href": "blog/always-normalize-your-data/index.html#preparation",
    "title": "Always normalize your data",
    "section": "Preparation",
    "text": "Preparation\nFor the library data, all that is needed is to create the municipality code and count the number of libraries. Then, we use the left_join() function to join the vector data of the municipalities and the number of libraries. We also prepare the population data. Here, we must choose the whole population (any gender and age) and the year 2022. The municipality code must be extracted as a 5-digit number.\n\n# select needed columns and create municipality code\nbib &lt;- select(bib, codigo_provincia, codigo_municipio) |&gt;\n  mutate(LAU_CODE = str_c(codigo_provincia, codigo_municipio))\n\n# count libraries\nbib_count &lt;- count(bib, LAU_CODE)\n\n# join with boundaries\nmun &lt;- left_join(mun, bib_count)\n\n# filter population data\npob_mun &lt;- filter(\n  pob, sexo == \"Total\",\n  municipios != \"Total Nacional\",\n  edad_grupos_quinquenales == \"Todas las edades\",\n  str_detect(periodo, \"2022\")\n) |&gt;\n  select(municipios, total) |&gt;\n  mutate(LAU_CODE = str_extract(municipios, \"[0-9]{5}\"))"
  },
  {
    "objectID": "blog/always-normalize-your-data/index.html#visualization",
    "href": "blog/always-normalize-your-data/index.html#visualization",
    "title": "Always normalize your data",
    "section": "Visualization",
    "text": "Visualization\nTo create a proportional symbol map, we simply use the centroid of the municipality for the location. It is important to order the observations from highest to lowest, which ensures that the smaller circles are drawn on top of the larger ones.\nIn ggplot2, we use geom_sf() for the vector data and indicate size with the column n. Additionally, we set the size range with scale_size() and specify the breaks in the legend. We are also making a few small aesthetic changes.\n\nm1 &lt;- st_centroid(mun) |&gt; arrange(-n)\n\np1 &lt;- ggplot() +\n  geom_sf(data = ccaa, fill = \"grey90\", colour = \"white\") +\n  geom_sf(\n    data = m1,\n    aes(size = n),\n    alpha = .5, shape = 21, fill = \"#7a0177\", colour = \"white\"\n  ) +\n  scale_size(range = c(1, 20), breaks = c(10, 50, 150, 400)) +\n  labs(size = NULL, title = \"Absolute number of libraries\") +\n  theme_void()\np1\n\n\nThis map clearly resembles the one in the national atlas. Big cities, such as Madrid, Barcelona or Valencia, are highlighted.\nBut what would we see if we normalize the variable?\nTo do this, we must first join the population data and calculate the rate.\n\nm2 &lt;- st_centroid(mun) |&gt;\n  left_join(pob_mun) |&gt;\n  mutate(norm_pob = n * 10000 / total) |&gt;\n  arrange(-norm_pob)\n\nselect(m2, n, total:norm_pob)\n\nNow we simply repeat the same map using the norm_pob column.\n\np2 &lt;- ggplot() +\n  geom_sf(data = ccaa, fill = \"grey90\", colour = \"white\") +\n  geom_sf(\n    data = m2,\n    aes(size = norm_pob),\n    alpha = .5, shape = 21, fill = \"#7a0177\", colour = \"white\"\n  ) +\n  scale_size(range = c(.5, 10), breaks = c(1, 10, 100, 500)) +\n  labs(size = NULL, title = \"Libraries per 10,000 inhabitants\") +\n  theme_void()\np2\n\n\nThis map now tells a completely different story. We see a high number of libraries per inhabitant in certain regions, while others are more homogeneous with a consistently low number of libraries. However, there are also impossible values that stand out. For example, in the north, Roncesvalles reaches 526 libraries per 10,000 inhabitants! That can’t be right, can it? This issue is caused by the very small municipalities. In this case, there is one library for every 19 inhabitants. In any case, what is also noticeable is that there are significantly fewer libraries per inhabitant in major cities like Madrid and Barcelona, with only 1 library per 10,000 inhabitants. It is not easy to find a multiplier that works uniformly to reflect both small and large municipalities.\nTo solve the problem of small municipalities, one possible good strategy would be to exclude all those with less than 100 inhabitants. It can even help in reducing overlapping.\n\np3 &lt;- ggplot() +\n  geom_sf(data = ccaa, fill = \"grey90\", colour = \"white\") +\n  geom_sf(\n    data = filter(m2, total &gt; 100),\n    aes(size = norm_pob),\n    alpha = .5, shape = 21, fill = \"#7a0177\", colour = \"white\"\n  ) +\n  scale_size(range = c(.1, 10), breaks = c(1, 10, 50, 90)) +\n  labs(size = NULL, title = \"Libraries per 10,000 inhabitants (without municipalities &lt; 100)\") +\n  theme_void()\n\np3\n\n\nFinally, we create a comparison with the patchwork grammar.\n\np1 + p2 + p3 & theme(plot.title = element_text(size = 20, hjust = .5),\n                    legend.text = element_text(size = 12))\n\n\nDifferent ways of telling different stories! A completely different question is how much the overlapping of circles prevents us from reading the map accurately. For instance, we could use a Dorling cartogram for the population and use color to show the number of libraries. Below, you see an example with the foreign population by origin. The R Code for this I will post another time."
  },
  {
    "objectID": "blog/always-normalize-your-data/index.html#footnotes",
    "href": "blog/always-normalize-your-data/index.html#footnotes",
    "title": "Always normalize your data",
    "section": "Footnotes",
    "text": "Footnotes\n\nInclude also population data.↩︎"
  },
  {
    "objectID": "blog/broken-charts/index.html",
    "href": "blog/broken-charts/index.html",
    "title": "Broken Chart: discover 9 visualization alternatives",
    "section": "",
    "text": "I’ve wanted to write a post for a while about a graph that the Spanish Ministry for Ecological Transition publishes every month, summarizing the average monthly temperature in Spain. If we look closely, there is a misuse of the geometry type to present the temperature variable. In this specific case, columns have always a baseline at 0. The issue here is that 0 in degrees Celsius doesn’t represent an absolute zero or a meaningful starting point for comparison of magnitudes.\nWhy column charts are inappropriate for temperature? Well, column charts are used to show magnitude, with height being the visual variable used for encoding, and the zero-baseline is essential. They are typically used for ratio scale or absolute quantity data (e.g., population, sales, frequency counts). The height of the column is directly proportional to the value, allowing for easy, accurate comparison of ratios (e.g., one bar being twice as tall means the value is twice as large). Temperature scales like Celsius (\\(^{\\circ}C\\)) and Fahrenheit (\\(^{\\circ}F\\)) are interval scales. The zero point is arbitrary (it doesn’t mean “no temperature” or “absence of heat”), and although the \\(0^{\\circ}C\\) case is the freezing point, it is still inadequate. Furthermore, when using the zero-baseline for temperatures, the visual representation can be misleading, visually distorting the variability and difference between months and reducing it.\nMoreover, there is a visual inconsistency when columns are used to display the temperature for a specific year (such as 2025) while lines are simultaneously employed to represent the temperature of previous years (such as 2024) or the normal reference period. This mixing of chart types for the same kind of data (temperature over time) hinders direct comparison and can confuse the reader about which magnitude is being emphasized. Additionally, this increases cognitive load, as the reader must first identify the midpoint of the line and then mentally compare its position with the height of the column, adding an extra step and reducing the clarity of the message.\nSo, what alternatives can we propose? Let’s not forget that our visualization is conditioned by its objective and also by the audience."
  },
  {
    "objectID": "blog/broken-charts/index.html#packages",
    "href": "blog/broken-charts/index.html#packages",
    "title": "Broken Chart: discover 9 visualization alternatives",
    "section": "Packages",
    "text": "Packages\n\n\n\n\n\n\nPackage\nDescription\n\n\n\ntidyverse\nCollection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.\n\n\nggh4x\na flexible extension for ggplot2 that provides advanced and less common graphic components\n\n\nclimaemet\na specialized tool that simplifies the download, cleaning, and preparation of meteorological and climate data directly from the Spanish State Meteorological Agency (AEMET)\n\n\nggdist\nan extension for ggplot2 specialized in visualizing distributions and uncertainty using tidy data principles\n\n\nggbeeswarm\nprovides quasirandom and beeswarm plots for ggplot2\n\n\nggtext\nimproved text rendering support for ggplot2\n\n\ngeomtextpath\nan extension of the ggplot2 package, designed to simplify the process of adding text in charts, especially when you need the text to follow a curved path\n\n\nggrepel\nprovides geoms for ggplot2 to repel overlapping text labels\n\n\nMetBrewer\nprovides color palettes based on objects from the Metropolitan Museum of Art in New York\n\n\n\n\n# install the packages if necessary\n\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"ggh4x\")) install.packages(\"ggh4x\")\nif (!require(\"ggdist\")) install.packages(\"ggdist\")\nif (!require(\"ggbeeswarm\")) install.packages(\"ggbeeswarm\")\nif (!require(\"ggtext\")) install.packages(\"ggtext\")\nif (!require(\"climaemet\")) install.packages(\"climaemet\")\nif (!require(\"geomtextpath\")) install.packages(\"geomtextpath\")\nif (!require(\"ggrepel\")) install.packages(\"ggrepel\")\n\n# packages\n\nlibrary(tidyverse)\nlibrary(ggh4x)\nlibrary(ggdist)\nlibrary(ggbeeswarm)\nlibrary(ggtext)\nlibrary(geomtextpath)\nlibrary(ggrepel)\nlibrary(MetBrewer)\nlibrary(climaemet)"
  },
  {
    "objectID": "blog/broken-charts/index.html#data",
    "href": "blog/broken-charts/index.html#data",
    "title": "Broken Chart: discover 9 visualization alternatives",
    "section": "Data",
    "text": "Data\nIn this post, we will use the monthly average temperature for Spain derived from 42 reference weather stations. These stations are no longer used by AEMET for calculating the national temperature, as the agency now relies on gridded datasets which are not publicly available.\nWe can download and access data from the Spanish AEMET API using the climaemet package. Anyone who wants to perform this step will find all the details in the following code chunk. In any case, I have prepared the data to make it easier (download), see the following code chunk for the API use.\n\nCode## API key\naemet_api_key() # get it from https://opendata.aemet.es/centrodedescargas/inicio\n\n# stations IDs\nstats &lt;- c(\n  \"0076\", \"0367\", \"1024E\", \"1082\", \"1109\", \"1249I\", \"1387\", \"1484C\",\n  \"1690A\", \"2030\", \"2331\", \"2462\", \"2539\", \"2614\", \"2661\", \"2867\",\n  \"3013\", \"3195\", \"3260B\", \"3469A\", \"4121\", \"4452\", \"4642E\", \"5270B\",\n  \"5402\", \"5514\", \"5783\", \"6155A\", \"6325O\", \"7031\", \"8025\", \"8175\",\n  \"8368U\", \"8416\", \"9170\", \"9263D\", \"9434\", \"9771C\", \"9981A\", \"B228\",\n  \"B893\", \"B954\"\n)\n\n# you should use the following robust function from github issue\n# https://github.com/rOpenSpain/climaemet/issues/74#issuecomment-3172675722\n\ndata_daily &lt;- robust_climate_download(stats, start_date = \"1971-01-01\", end_date = today())\n\n# clean up\ndata_daily &lt;- select(data_daily, date = fecha, id = indicativo, tmed, tmin, tmax) |&gt;\n  mutate(date = ymd(date), across(tmed:tmax, parse_number))\n\n\nFirst, we load the prepared dataset and compute the monthly average temperature across all stations. Next, we calculate the climatological normals for the reference periods 1971–2000 and 1991–2020. Finally, we add additional columns for the month and label to complete the data preparation.\n\nCode# load station data\nload(\"aemet_refstations.RData\")\n\n# add year-month column and calculate average temperature by month-year\ntmed_esp &lt;- mutate(data_daily, yrmo = floor_date(date, \"month\")) |&gt;\n  select(yrmo, tmed) |&gt;\n  group_by(yrmo) |&gt;\n  summarise(tmed = mean(tmed, na.rm = T))\n\n\n# normal reference for each month 1971-2000 and 1991-2020\nnorm_p1 &lt;- filter(tmed_esp, year(yrmo) %in% 1971:2000) |&gt;\n  group_by(mo = month(yrmo)) |&gt;\n  summarise(\n    tmed_norm = mean(tmed)\n  ) |&gt;\n  mutate(period = \"1971-2000\")\n\nnorm_p2 &lt;- filter(tmed_esp, year(yrmo) %in% 1991:2020) |&gt;\n  group_by(mo = month(yrmo)) |&gt;\n  summarise(\n    tmed_norm = mean(tmed)\n    ) |&gt;\n  mutate(period = \"1991-2020\")\n\n# main dataset with month label\ntmed_esp &lt;- mutate(tmed_esp,\n  mo = month(yrmo),\n  mo_lab = month(yrmo, label = T)\n)\n\n\n\n\n\n\n\n\nTipWhat is a “normal period” and why does it matter?\n\n\n\nAccording to the World Meteorological Organization (WMO), a climatological normal is the average of a meteorological variable (such as temperature or precipitation) calculated over a 30-year period. These periods provide a consistent reference for comparing current conditions with long-term climate patterns. For instance, the actual normal is 1991–2020 (previously 1981–2010).\nThe WMO recommends using 1961–1990 when possible for illustrating climate change, because it represents a baseline before the most significant warming trends began. This makes it easier to show how much the climate has shifted. However, national meteorological services usually adopt the most recent normal period (e.g., 1991–2020) to describe the current climate, as this is more relevant for operational forecasting and public information."
  },
  {
    "objectID": "blog/broken-charts/index.html#option-set-1",
    "href": "blog/broken-charts/index.html#option-set-1",
    "title": "Broken Chart: discover 9 visualization alternatives",
    "section": "Option Set 1",
    "text": "Option Set 1\nThe first option is straightforward. We use a simple line chart combined with a colored shaded area between the 2025 observations and the recent normal period to highlight the observed anomaly (blue for negative anomalies or red for positive anomalies). Unlike column charts, a line chart does not require a baseline at zero, which allows us to better appreciate the actual magnitude of the difference.\n\nCodeleft_join(tmed_esp, norm_p2, by = \"mo\") |&gt; # join with reference period\nfilter(year(yrmo) == 2025) |&gt; # only 2025 \n  ggplot(aes(yrmo, tmed)) +\n  stat_difference(aes(ymin = tmed_norm, ymax = tmed),\n    alpha = 0.6,\n    levels = c(\"above normal\", \"below normal\"),\n    show.legend = F,\n  ) +\n  #geom_line(colour = \"grey85\") +\n  geom_point(fill = \"white\", shape = 21, stroke = .3) +\n  geom_line(aes(y = tmed_norm)) +\n  geom_point(aes(y = tmed_norm)) +\n  annotate(\"text\", \n           label = \"above normal\", \n           x = ymd(\"2025-04-01\"),\n           y = 23, \n           color = \"#d73027\", \n           alpha = .6,\n           fontface = \"bold\") +\n  annotate(\"segment\", \n           x = ymd(\"2025-05-01\"), \n           y = 23, \n           xend = ymd(\"2025-06-10\"),\n           colour = \"#d73027\") +\n  annotate(\"point\", \n           x = ymd(\"2025-06-10\"), \n           y = 23, \n           shape = 15, \n           colour = \"#d73027\") +\n  scale_x_date(date_breaks = \"month\", date_labels = \"%b\") +\n  scale_y_continuous(breaks = seq(8, 30, 2), expand = expansion(c(0.05, .05))) +\n  scale_fill_manual(values = c(\"#d73027\", \"#4575b4\"), drop = F) + \n  labs(x = NULL, y = \"Mean temperature (ºC)\", fill = NULL) +\n  theme_minimal() +\n  theme(\n    panel.grid.minor = element_blank(),\n    axis.ticks = element_blank(),\n    axis.title.y = element_text(hjust = 0),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major = element_line(colour = \"grey85\"),\n    legend.position = \"bottom\",\n    legend.justification = 0,\n    legend.key.height = unit(.5, \"lines\"),\n  )\n\n\n\n\n\n\n\nAnother posibility would be a dumbbell chart. For each month of 2025, the chart shows observed mean temperature (red) against the climatological normal (white), connected by a vertical segment. A dumbbell chart is essentially a way to show the difference between two values for the same category, connected by a line. The label above each point reports the anomaly, allowing quick identification of warmer or cooler months and the magnitude of the difference.\n\nCodeleft_join(tmed_esp, norm_p2, by = \"mo\") |&gt;\nfilter(year(yrmo) == 2025) |&gt; # filter only 2025\nmutate(anom = tmed - tmed_norm) |&gt;\n  ggplot(aes(yrmo, tmed)) +\n  geom_segment(aes(y = tmed_norm, yend = tmed), linewidth = 1.3) +\n  geom_point(colour = \"#b30000\", size = 2) +\n  geom_point(aes(y = tmed_norm), shape = 21, fill = \"white\", size = 2.5) +\n  geom_text_repel(aes(label = scales::number(anom, accuracy = 0.1, \n                                       suffix = \"ºC\", \n                                       style_positive = \"plus\"),\n                      y = tmed), \n                   direction = \"x\",     \n                   nudge_x = 0.05, \n                  seed = 12345,\n            size = 2.7, hjust = .5) +\n  scale_x_date(date_breaks = \"month\", date_labels = \"%b\") +\n  scale_y_continuous(breaks = seq(8, 30, 2), expand = expansion(c(0.05, .05))) +\n  labs(x = NULL, y = \"Mean temperature (ºC)\") +\n  theme_minimal() +\n  theme(\n    panel.grid.minor = element_blank(),\n    axis.ticks = element_blank(),\n    axis.title.y = element_text(hjust = 0),\n    panel.grid.major.x = element_blank(),\n    plot.margin = margin(5, 10, 5, 5)\n  )\n\n\n\n\n\n\n\nA line chart or a dumbbell chart are both very effective options for comparing observed mean temperature with the climatological normal because they are simple and easy to interpret. However, this simplicity comes at the cost of losing important context. These charts do not show intra-month variability, extremes, or uncertainty in the data. They are highly accessible even for non-technical audiences."
  },
  {
    "objectID": "blog/broken-charts/index.html#option-set-2",
    "href": "blog/broken-charts/index.html#option-set-2",
    "title": "Broken Chart: discover 9 visualization alternatives",
    "section": "Option Set 2",
    "text": "Option Set 2\nInstead of using absolut values, we can summarize monthly temperature for Spain in 2025 relative to the recent normal. Background bands mark severity thresholds at 0.5σ, 1σ, and 2σ (σ: standard deviation), computed from 1991–2020 anomalies, while bars show the actual anomaly for each month. Centering the scale at zero makes it straightforward to judge both the sign and the magnitude of departures from normal. In this case, however, using bars is appropriate because the anomalies are centered around a clear reference point at zero.\n\nCode# standard deviation for the whole year\nstd_7120 &lt;- filter(tmed_esp, \n                   between(year(yrmo), 1991, 2020)) |&gt;\n            left_join(norm_p1, by = \"mo\") |&gt;\n            summarise(std = sd(tmed - tmed_norm, na.rm = TRUE)) |&gt;\n            pull(std)\n\n# anomaly plot \nleft_join(tmed_esp, norm_p2, by = \"mo\") |&gt;\n  filter(year(yrmo) == 2025) |&gt; # filter only current year\n  mutate(anom = tmed - tmed_norm) |&gt; # anomaly\nggplot(aes(yrmo, anom)) +\n  annotate(\"rect\",\n    xmin = -Inf, ymin = c(0, std_7120 * .5, std_7120, std_7120 * 2),\n    xmax = Inf, ymax = c(std_7120 * .5, std_7120, std_7120 * 2, Inf),\n    fill = c(\"white\", \"#fcae91\", \"#fb6a4a\", \"#cb181d\"),\n    alpha = .4\n  ) +\n  annotate(\"text\",\n    x = ymd(\"2025-12-01\"),\n    y = c(0, .85, 1.7, 3.2),\n    angle = 90,\n    vjust = 3,\n    label = c(\"Normal\", \"Warm\", \"Very warm\", \"Extremely warm\"),\n    alpha = .8, color = \"white\"\n  ) +\n  geom_col(width = 20) +\n  scale_x_date(date_breaks = \"month\", date_labels = \"%b\", expand = expansion(c(.01, .07))) +\n  scale_y_continuous(breaks = seq(0, 5, .5), expand = expansion(c(0, .05)),\n                     limits = c(-std_7120 * .5, NA)) +\n  labs(x = NULL, y = \"Anomaly (ºC)\") +\n  theme(\n    panel.grid.minor = element_blank(),\n    axis.ticks = element_blank(),\n    axis.title.y = element_text(hjust = 0),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major = element_line(colour = \"white\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nMonthly standard deviation (σ) varies greatly, so using month-specific thresholds would make the same anomaly appear “extreme” in winter but only “warm” in summer, which is confusing in a single annual chart. A single annual σ provides a consistent scale and makes comparisons across months clear.\n\n\n\n\n\n\n\n\nImportant\n\n\n\n3D effects in column charts distort perception by shifting comparisons from aligned position/length to noisier cues like area, volume, perspective foreshortening, and occlusion, making identical values look unequal. They add cognitive load and visual clutter (shading, skewed labels, depth) without adding information, harming accuracy, speed, and accessibility.\n\n\n\n\n\nAnother variant would be to select a single month — for instance, July — and show its entire historical time series instead of just the current year. This approach adds much more context because it allows the reader to compare the current value with previous years, identify long-term trends, and clearly see the effect of climate change over time. It shifts the focus from a snapshot comparison to a broader perspective, making anomalies more meaningful by placing them within a historical trajectory.\n\nCode# standard deviation for reference period\nstd_7120_jul &lt;- filter(tmed_esp, between(year(yrmo), 1991, 2020), mo == 7) |&gt;\n                 left_join(norm_p2, by = \"mo\") |&gt;\n                    summarise(std = sd(tmed - tmed_norm, na.rm = T)) |&gt;\n                pull(std)\n\nleft_join(tmed_esp, norm_p1, by = \"mo\") |&gt;\nfilter(mo_lab == \"Jul\") |&gt;  # select July\nmutate(anom = tmed - tmed_norm) |&gt;  # anomaly\n  ggplot(aes(yrmo, anom)) +\n  annotate(\"rect\",\n    xmin = -Inf, ymin = c(0, std_7120_jul * .5, std_7120_jul, std_7120_jul * 2),\n    xmax = Inf, ymax = c(std_7120_jul * .5, std_7120_jul, std_7120_jul * 2, Inf),\n    fill = c(\"white\", \"#fcae91\", \"#fb6a4a\", \"#cb181d\"),\n    alpha = .4\n  ) +\n  annotate(\"rect\",\n    xmin = -Inf, ymin = c(0, std_7120_jul * .5, std_7120_jul, std_7120_jul * 2) * -1,\n    xmax = Inf, ymax = c(std_7120_jul * .5, std_7120_jul, std_7120_jul * 2, Inf) * -1,\n    fill = c(\"white\", \"#bdd7e7\", \"#6baed6\", \"#2171b5\"),\n    alpha = .4\n  ) +\n  geom_col() +\n  annotate(\"text\",\n    x = ymd(c(\"1975-04-10\", \"1973-10-10\", \"1972-01-20\", \n              \"1972-09-20\", \"1972-04-20\", \"1973-10-10\", \"1975-06-10\")),\n    y = c(-3.2, -1.8,-.8, 0.2, .8, 1.8, 5.2),\n    label = c(\"Extremely Cold\", \"Very Cold\", \"Cold\", \n              \"Normal\", \"Warm\", \"Very warm\", \"Extremely warm\"),\n    alpha = .6, color = \"white\"\n  ) +\n  geom_hline(yintercept = 0) +\n  scale_x_date(date_breaks = \"5 year\", \n               date_labels = \"%Y\", \n               expand = expansion(c(.01, .01))) +\n  scale_y_continuous(breaks = seq(-5, 5, 1), \n                     expand = expansion(c(.05, .05))) +\n  labs(x = NULL, y = \"Anomaly (ºC)\") +\n  coord_cartesian(clip = \"off\") +\n  theme(\n    panel.grid.minor = element_blank(),\n    axis.ticks = element_blank(),\n    axis.title.y = element_text(hjust = 0),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major = element_line(colour = \"white\"),\n    plot.margin = margin(5, 5, 5, 5)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nKeep axis labels horizontal because they’re faster to scan, reduce cognitive load, and maintain a consistent baseline that improves legibility and accessibility compared with rotated or stacked labels. In time series charts, avoid labeling every data point since dense annotations create visual noise and obscure the signal; instead rely on clear axis ticks and date formatting, and add labels only at meaningful milestones—peaks, troughs, regime shifts, or events.\n\n\n\n\n\nWhen you need to compare two values side by side and keep a reference in view, another alternative would be a bullet chart. In this case, they give us a snapshot of how 2025 anomalies stack up against 2024.\n\nCode# data prepation \ndf_anom &lt;- tmed_esp |&gt;\n  left_join(norm_p2, by = \"mo\") |&gt;\n  mutate(\n    anom = tmed - tmed_norm,\n    yr   = year(yrmo)\n  ) |&gt;\n  filter(yr %in% 2024:2025) |&gt;\n  select(yr, mo_lab, anom, tmed_norm) |&gt;\n  pivot_wider(\n    names_from   = yr,\n    values_from  = anom,\n    names_glue   = \"yr{yr}\"\n  ) \n\n# bullet chart\nggplot(df_anom) +\n  geom_col(aes(x = mo_lab, y = yr2024), fill = \"grey85\", width = 0.7) +\n  geom_col(aes(x = mo_lab, y = yr2025), fill = \"#e31a1c\", width = 0.4) +\n  geom_hline(yintercept = 0, color = \"grey60\", linewidth = 0.5) +  \n  annotate(\"text\", label= c(\"2025\", \"2024\"), \n           x = \"Feb\", y = c(1.4, 2.4),\n           colour = c(\"#e31a1c\", \"grey85\")) +\n  scale_y_continuous(breaks = seq(-4, 4, 0.5)) +\n  labs(x = NULL, y = \"Anomaly (ºC)\") +\n  theme_minimal() +\n  theme(\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_blank(),\n    axis.title.y = element_text(hjust = 0.1)\n  )\n\n\n\n\n\n\n\nIf we want to display anomalies in their intra-annual context across the entire time range, a heatmap is an effective choice. This type of visualization allows us to represent anomalies by month and year, using color intensity to indicate the magnitude of deviation from the climatological normal. By organizing the data in a grid where rows correspond to years and columns to months, the heatmap provides an immediate overview of seasonal patterns, long-term variability, and extreme events. It also makes it possible to identify trends over time and understand the recent climate context in relation to historical conditions. Importantly, the goal here is not to decode exact numerical values, but rather to reveal trends and patterns in a clear and intuitive way.\n\nCodetmed_esp |&gt;\n  left_join(norm_p1, by = \"mo\") |&gt;\n  mutate(\n    anom = tmed - tmed_norm,\n    anom = case_when(anom &gt; 3.5 ~ 3.5,\n                     anom &lt; -3.5 ~ -3.5,\n                     TRUE ~ anom),\n    yr   = year(yrmo)\n  ) |&gt;\nggplot(aes(mo_lab, yr, fill = anom)) +\n  geom_tile(colour = \"white\") +\n  scale_fill_gradientn(colors = rev(RColorBrewer::brewer.pal(9, \"RdBu\")),\n                       breaks = seq(-3, 3, 1)) +\n  scale_y_continuous(breaks = seq(1970, 2025, 5)) +\n  labs(x = NULL, y = NULL, fill = \"Anomaly (ºC)\") +\n  coord_cartesian(expand = FALSE) +\n  theme_minimal() +\n  theme(panel.grid = element_blank(),\n        legend.position = \"bottom\",\n        legend.key.width = unit(2.5, \"line\"),\n        legend.key.height = unit(.4, \"line\"),\n        legend.title.position = \"top\",\n        legend.justification = 0,\n        plot.margin = margin(10, 10, 10, 10))"
  },
  {
    "objectID": "blog/broken-charts/index.html#option-set-3",
    "href": "blog/broken-charts/index.html#option-set-3",
    "title": "Broken Chart: discover 9 visualization alternatives",
    "section": "Option Set 3",
    "text": "Option Set 3\nInstead of focusing on individual values as in column charts, the following charts shifts the perspective toward distributions—revealing patterns, variability, and extremes that single numbers can’t capture.\nThe first option displays the historical distribution of monthly air temperatures using shaded shapes (density function) that represent how frequently different values occur: wider sections indicate common temperatures, while narrower parts show extremes. Over these distributions, percentile-based colored intervals (such as 50%, 80%, 95%, and 99%) are added to highlight typical ranges and rare conditions. Reference points for two climatological normals (1971–2000 and 1991–2020) are included, along with markers for the year 2025, making it easy to compare current observations against historical variability and standard benchmarks.\nThis approach provides a richer picture of climate variability by showing not only averages but also the full spread and frequency of values. Percentile intervals make it easy to distinguish typical conditions from extremes, while integrating distributions, reference normals, and current observations.\n\nCodeggplot(tmed_esp, aes(mo_lab, tmed)) +\n  stat_slab(fill_type = \"segments\", alpha = 0.2) +\n  stat_interval(.width = c(0.01, 0.05, 0.2, 0.5, 0.8, 0.95, .99), size = 2) +\n  geom_point(\n    data = bind_rows(norm_p1, norm_p2) |&gt; \n                    mutate(mo = factor(month(mo), 1:12, month.abb)),\n    aes(mo, tmed_norm, shape = period),\n    size = 1.8,\n    show.legend = F\n  ) +\n  geom_point(\n    data = filter(tmed_esp, year(yrmo) == 2025),\n    shape = 21, fill = \"white\", size = 2\n  ) +\n  annotate(\"text\",\n    x = \"Jun\", y = 24.7,\n    size = 3, hjust = 1.3,\n    label = \"2025\"\n  ) +\n  annotate(\"text\",\n    x = \"Nov\", y = c(10.9, 11.6),\n    size = 3, hjust = 1.2,\n    label = c(\"1971-2000\", \"1991-2020\")\n  ) +\n  scale_shape_manual(values = c(0, 2)) +\n  scale_y_continuous(breaks = c(0, 5, 10, 15, 20, 25)) +\n  scale_color_manual(\n    values = met.brewer(\"Tam\"),\n    guide = \"none\"\n  ) +\n  labs(fill = NULL, x = NULL, y = \"Mean temperature\") +\n  theme_minimal() +\n  theme(\n    panel.grid = element_blank(),\n    panel.grid.major.y = element_line(linewidth = 0.1, color = \"grey75\"),\n    plot.title = element_text(),\n    plot.title.position = \"plot\",\n    plot.subtitle = element_textbox_simple(\n      margin = margin(t = 4, b = 16), size = 10\n    ),\n    plot.caption = element_textbox_simple(\n      margin = margin(t = 12), size = 7\n    ),\n    plot.caption.position = \"plot\",\n    axis.text.y = element_text(hjust = 0, margin = margin(r = -10), family = \"Fira Sans SemiBold\"),\n    plot.margin = margin(4, 4, 4, 4),\n    axis.title.y = element_text(hjust = 0),\n  )\n\n\n\n\n\n\n\nAnother posibility based on distribution would be quasi-random jittered points which reveal the historical spread for each month. The black tick marks indicate the 1991–2020 mean, while colored markers highlight 2024 and 2025 against the background distribution. This design makes it easy to judge how recent months compare with typical conditions and with the broader historical variability.\n\n\n\n\n\n\nTip\n\n\n\nWhenever possible, direct labeling should be preferred over a legend, as it improves readability and reduces cognitive load for the viewer.\n\n\n\nCodemed &lt;- filter(tmed_esp, year(yrmo) %in% 1991:2020) |&gt;\n  group_by(mo_lab) |&gt;\n  summarise(normal = median(tmed))\n\nggplot() +\n  geom_quasirandom(\n    data = mutate(tmed_esp, dummy = case_when(\n      year(yrmo) == 2025 ~ \"2025\",\n      year(yrmo) == 2024 ~ \"2024\",\n      TRUE ~ \"otros\"\n    )),\n    aes(x = mo_lab, y = tmed, fill = dummy),\n    size = 1.8,\n    shape = 21, stroke = 0.3, color = \"white\"\n  ) +\n  geom_errorbar(\n    data = med, aes(x = mo_lab, ymin = normal, ymax = normal),\n    color = \"black\", linewidth = .5, width = .5\n  ) +\n  annotate(\"text\",\n    x = \"Jun\", y = c(24.8, 21.2, 20.7),\n    hjust = c(1.3, -0.5, 1.6), fontface = \"bold\",\n    label = c(\"2025\", \"2024\", \"mean\"), color = c(\"#d53e4f\", \"#fee08b\", \"black\")\n  ) +\n  scale_fill_manual(\n    values = c(\"#fee08b\", \"#d53e4f\", \"grey85\"),\n    guide = NULL\n  ) +\n  scale_y_continuous(breaks = c(0, 5, 10, 15, 20, 25)) +\n  labs(fill = NULL, x = NULL, y = \"Mean temperature (ºC)\") +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    legend.justification = 0,\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_blank()\n  )\n\n\n\n\n\n\n\nA final alternative approach could be a barcode-style chart where each thin vertical bar represents a single year within the historical record for a given month. The bars are positioned along the horizontal axis according to their monthly mean temperature, creating a visual distribution of all observed values. To highlight key information, the most extreme years—both the warmest and the coldest—are labelled, while the current year is marked with a more prominent style, such as a thicker bar. Additionally, a point indicates the long-term climatological average, allowing viewers to quickly assess how individual years compare to the historical norm. By faceting the chart by month, this design provides a compact yet detailed view of variability, extremes, and the position of the current year within the broader climate context.\n\nCode# global parameters\nthres     &lt;- 2 # how close should be labels?\ncurrent_yr  &lt;- 2025\n\n# labeled years\nobs_lab &lt;- tmed_esp |&gt;\n  group_by(mo_lab) |&gt;\n  slice_min(order_by = tmed, n = 5, with_ties = FALSE) |&gt;\n  bind_rows(\n    tmed_esp |&gt;\n      group_by(mo_lab) |&gt;\n      slice_max(order_by = tmed, n = 5, with_ties = FALSE)\n  ) |&gt;\n  arrange(mo_lab, yrmo) |&gt;\n  ungroup()\n\n# current year\nobs_current &lt;- filter(tmed_esp, year(yrmo) == current_yr)\n\n# filter function for clusters of very close values\nfilter_extreme_and_current &lt;- function(data, x, group, threshold, current_year) {\n\n    #1) Detect clusters of very close values.\n    group_by(data, {{ group }}) |&gt;  # \n    arrange({{ x }}) |&gt;\n    mutate(cluster = cumsum(({{ x }} - lag({{ x }}, default = -Inf)) &gt; threshold)) |&gt;\n    ungroup() |&gt;\n    # 2) For each month and cluster, extract only the minimum and the maximum.\n    group_by({{ group }}, cluster) |&gt;\n    filter({{ x }} == min({{ x }}) | {{ x }} == max({{ x }})) |&gt;\n    ungroup() |&gt;\n    select(-cluster) |&gt;\n    # 3) Add the rows for the current year (if they exist).\n    filter(year(yrmo) != current_year) |&gt;\n    # 4) Remove duplicates (in case the current year was already marked as an extreme)\n    distinct()\n}\n\n# filter out labels to close\nobs_lab_sel &lt;- filter_extreme_and_current(obs_lab, tmed, mo_lab, thres, current_yr)\n\n# mean temperature by month\nmed &lt;- group_by(tmed_esp, mo_lab) |&gt; summarise(normal = mean(tmed, na.rm = T))\n\n\n\nCode# colour palette for bar code lines\ncol_temp &lt;- c(\n  \"#cbebf6\", \"#a7bfd9\", \"#8c99bc\", \"#974ea8\", \"#830f74\",\n  \"#0b144f\", \"#0e2680\", \"#223b97\", \"#1c499a\", \"#2859a5\",\n  \"#1b6aa3\", \"#1d9bc4\", \"#1ca4bc\", \"#64c6c7\", \"#86cabb\",\n  \"#91e0a7\", \"#c7eebf\", \"#ebf8da\", \"#f6fdd1\", \"#fdeca7\",\n  \"#f8da77\", \"#fcb34d\", \"#fc8c44\", \"#f85127\", \"#f52f26\",\n  \"#d10b26\", \"#9c042a\", \"#760324\", \"#18000c\"\n)\n\n# custom break function\ncustom_breaks &lt;- function(limits) {\n  round(c(limits[1], pretty(limits, n = 5), limits[2]))\n}\n\n\n# barcode plot\nggplot(tmed_esp) +\n  geom_vline(aes(xintercept = tmed, colour = tmed),\n    alpha = .7,\n    linewidth = 0.1\n  ) +\n  geom_textvline(\n    data = obs_lab_sel,\n    aes(\n      xintercept = tmed, label = year(yrmo),\n      colour = tmed\n    ),\n    linewidth = 0.1, hjust = .8, size = 2.5,\n    vjust = .5\n  ) +\n  geom_textvline(\n    data = obs_current,\n    aes(\n      xintercept = tmed, label = year(yrmo),\n      colour = tmed\n    ),\n    linewidth = 0.4, hjust = 1.3, size = 2.5,\n    vjust = .5\n  ) +\n  geom_density(data = filter(tmed_esp, year(yrmo) %in% 1991:2020), aes(tmed)) +\n  geom_point(data = med, aes(x = normal, y = 0), shape = 1, stroke = 1) +\n  scale_colour_gradientn(\n    colours = col_temp,\n    limits = c(4.4, 26.8),\n    guide = \"none\"\n  ) +\n  scale_x_continuous(\n    breaks = custom_breaks,\n    expand = expansion(.01)\n  ) +\n  scale_y_continuous(expand = expansion()) +\n  labs(y = NULL, x = \"Monthly mean temperature\") +\n  facet_wrap(mo_lab ~ ., ncol = 3, scale = \"free_x\") +\n  coord_cartesian(clip = \"off\") +\n  theme_minimal() +\n  theme(\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.grid = element_blank(),\n    axis.title.x = element_text(hjust = 0, size = 8),\n    strip.text.x = element_text(hjust = 0, size = 10)\n  )"
  },
  {
    "objectID": "blog/broken-charts/index.html#final-thoughts",
    "href": "blog/broken-charts/index.html#final-thoughts",
    "title": "Broken Chart: discover 9 visualization alternatives",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nThere is no such thing as a perfect visualization. Each of the nine examples comes with its own strengths and weaknesses, and their effectiveness depends largely on the purpose and the audience. I also believe we should not be afraid to use slightly more complex charts or to present data that is inherently complex. Sometimes, embracing complexity is the only way to convey the full story behind the numbers."
  },
  {
    "objectID": "blog/calculating-the-distance-to-the-sea-in-r/index.html",
    "href": "blog/calculating-the-distance-to-the-sea-in-r/index.html",
    "title": "Calculating the distance to the sea in R",
    "section": "",
    "text": "The distance to the sea is a fundamental variable in geography, especially relevant when it comes to modeling. For example, in interpolations of air temperature, the distance to the sea is usually used as a predictor variable, since there is a casual relationship between the two that explains the spatial variation. How can we estimate the (shortest) distance to the coast in R?"
  },
  {
    "objectID": "blog/calculating-the-distance-to-the-sea-in-r/index.html#packages",
    "href": "blog/calculating-the-distance-to-the-sea-in-r/index.html#packages",
    "title": "Calculating the distance to the sea in R",
    "section": "Packages",
    "text": "Packages\nIn this post we will use the following libraries:\n\n\n\n\n\n\nPackage\nDescription\n\n\n\ntidyverse\nCollection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.\n\n\nsf\nSimple Feature: import, export and manipulate vector data\n\n\nraster\nImport, export and manipulate raster\n\n\nrnaturalearth\nSet of vector maps ‘natural earth’\n\n\nRColorBrewer\nColor palettes\n\n\n\n\n#install the libraries if necessary\nif(!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif(!require(\"sf\")) install.packages(\"sf\")\nif(!require(\"raster\")) install.packages(\"raster\")\nif(!require(\"giscoR\")) install.packages(\"giscoR\")\n\n#packages\nlibrary(giscoR)\nlibrary(sf)\nlibrary(raster)\nlibrary(tidyverse)\nlibrary(RColorBrewer)"
  },
  {
    "objectID": "blog/calculating-the-distance-to-the-sea-in-r/index.html#the-coast-of-iceland-as-an-example",
    "href": "blog/calculating-the-distance-to-the-sea-in-r/index.html#the-coast-of-iceland-as-an-example",
    "title": "Calculating the distance to the sea in R",
    "section": "The coast of Iceland as an example",
    "text": "The coast of Iceland as an example\nOur example in this post will be Iceland, and, as it is an island territory it will facilitate the tutorial showing the process in a simple manner. The giscoR package allows you to import the boundaries of countries (with different administrative levels) from around the world. The gisco_get_countries( ) function imports the country boundaries. In this case we indicate with the argument scale the resolution (3, 10, 60m), with country we can indicate the specific country or contries of interest.\n\nworld &lt;- gisco_get_countries(resolution = \"60\") #world map with 50m resolution\n\nplot(world) #sp class by default\n\n\n\n#import the limits of Iceland\niceland &lt;- gisco_get_countries(resolution = \"10\", country = \"Iceland\")\n\n#info of our spatial vector object\niceland\n\n\n#here Iceland\nplot(iceland)\n\n\nBy default, the plot() function with the class sf creates as many facets of the map as there are variables in it. To limit this behavior we can use either a variable name plot(iceland[\"admin\"]) or the limit argument plot(iceland, max.plot = 1). With the argument max.plot = 1 the function uses the first available variable of the map.\nIn addition, we see in the information of the object sf that the projection is WGS84 with decimal degrees (EPSG code: 4326). For the calculation of distances it is more convenient to use meters instead of degrees. Because of this, the first thing we do is to transform the map of Iceland to UTM Zone 27 (EPSG code: 3055). More information about EPSG and projections here. For that purpose, we use the st_transform() function. We simply indicate the map and the EPSG code.\n\n#transform to UTM\niceland &lt;- st_transform(iceland, 3055)"
  },
  {
    "objectID": "blog/calculating-the-distance-to-the-sea-in-r/index.html#create-a-fishnet-of-points",
    "href": "blog/calculating-the-distance-to-the-sea-in-r/index.html#create-a-fishnet-of-points",
    "title": "Calculating the distance to the sea in R",
    "section": "Create a fishnet of points",
    "text": "Create a fishnet of points\nWe still need the points where we want to know the distance. In our case it will be a regular fishnet of points in Iceland with a resolution of 5km. We do this with the function st_make_grid(), indicating the resolution in the unit of the coordinate system (meters in our case) with the argument cellsize, and what geometry we would like to create what (polygons, centers or corners).\n\n#create the fishnet\ngrid &lt;- st_make_grid(iceland, cellsize = 5000, what = \"centers\")\n\n#our fishnet with the extension of Iceland\nplot(grid)\n\n\n\n#only extract the points in the limits of Iceland\ngrid &lt;- st_intersection(grid, iceland)   \n\n#our fishnet now\nplot(grid)"
  },
  {
    "objectID": "blog/calculating-the-distance-to-the-sea-in-r/index.html#calculating-the-distance",
    "href": "blog/calculating-the-distance-to-the-sea-in-r/index.html#calculating-the-distance",
    "title": "Calculating the distance to the sea in R",
    "section": "Calculating the distance",
    "text": "Calculating the distance\nTo estimate the distance we use the st_distance( ) function that returns a vector of distances for all our points in the fishnet. But first it is necessary to transform the map of Iceland from a polygon shape (MULTIPOLYGON) to a line (MULTILINESTRING). More details with ?st_cast.\n\n#transform Iceland from polygon shape to line\niceland &lt;- st_cast(iceland, \"MULTILINESTRING\")\n\n#calculation of the distance between the coast and our points\ndist &lt;- st_distance(iceland, grid)\n\n#distance with unit in meters\nhead(dist[1,])"
  },
  {
    "objectID": "blog/calculating-the-distance-to-the-sea-in-r/index.html#plotting-the-calculated-distance",
    "href": "blog/calculating-the-distance-to-the-sea-in-r/index.html#plotting-the-calculated-distance",
    "title": "Calculating the distance to the sea in R",
    "section": "Plotting the calculated distance",
    "text": "Plotting the calculated distance\nOnce obtained the distance for our points, we can combine them with the coordinates and plot them in ggplot2. For this, we create a data.frame. The object dist is a matrix of one column, so we have to convert it to a vector with the function as.vector( ). In addition, we divide by 1000 to convert the distance in meters to km. The st_coordinates( ) function extracts the coordinates of our points. For the final visualization we use a vector of colors with the RdGy palette (more here).\n\n#create a data.frame with the distance and the coordinates of the points\ndf &lt;- data.frame(dist = as.vector(dist)/1000,\n                    st_coordinates(grid))\n\n#structure\nstr(df)\n\n\n#colors \ncol_dist &lt;- brewer.pal(11, \"RdGy\")\n\n\nggplot(df, aes(X, Y, fill = dist))+ #variables\n        geom_tile()+ #geometry\n          scale_fill_gradientn(colours = rev(col_dist))+ #colors for plotting the distance\n            labs(fill = \"Distance (km)\")+ #legend name\n            theme_void()+ #map theme\n              theme(legend.position = \"bottom\") #legend position"
  },
  {
    "objectID": "blog/calculating-the-distance-to-the-sea-in-r/index.html#export-the-distance-as-a-raster",
    "href": "blog/calculating-the-distance-to-the-sea-in-r/index.html#export-the-distance-as-a-raster",
    "title": "Calculating the distance to the sea in R",
    "section": "Export the distance as a raster",
    "text": "Export the distance as a raster\nTo be able to export the estimated distance to the sea of Iceland, we need to use the rasterize() function of the library raster.\n\n\nFirst, it is necessary to create an empty raster. In this raster we have to indicate the resolution, in our case it is of 5000m, the projection and the extension of the raster.\n\nWe can extract the projection from the information of the map of Iceland.\nThe extension can be extracted from our grid points with the function extent(). However, this last function needs the class sp, so we pass the object grid in sf format, only for this time, to the class sp using the function as() and the argument “Spatial”.\n\n\nIn addition to the above, the data.frame df, that we created earlier, has to be converted into the sf class. Therefore, we apply the function st_as_sf() with the argument coords indicating the names of the coordinates. Additionally, we also define the coordinate system that we know.\n\n\n#get the extension\next &lt;- extent(as(grid, \"Spatial\"))\n\n#extent object\next\n\n\n#raster destination\nr &lt;- raster(resolution = 5000, ext = ext, crs = \"+proj=utm +zone=27 +ellps=intl +towgs84=-73,47,-83,0,0,0,0 +units=m +no_defs\")\n\n#convert the points to a spatial object class sf\ndist_sf &lt;- st_as_sf(df, coords = c(\"X\", \"Y\")) %&gt;%\n                      st_set_crs(3055)\n\n#create the distance raster\ndist_raster &lt;- rasterize(dist_sf, r, \"dist\", fun = mean)\n\n#raster\ndist_raster\n\n\n#plot the raster\nplot(dist_raster)\n\n\n\n#export the raster\nwriteRaster(dist_raster, file = \"dist_islandia.tif\", format = \"GTiff\", overwrite = TRUE)\n\nThe rasterize() function is designed to create rasters from an irregular grid. In case we have a regular grid, like this one, we can use an easier alternative way. The rasterFromXYZ() function converts a data.frame with longitude, latitude and the variable Z into a raster object. It is important that the order should be longitude, latitude, variables.\n\nr &lt;- rasterFromXYZ(df[, c(2:3, 1)], crs = \"+proj=utm +zone=27 +ellps=intl +towgs84=-73,47,-83,0,0,0,0 +units=m +no_defs\")\n\nplot(r)\n\n\nWith the calculation of distance we can create art, as seen in the header of this post, which includes a world map only with the distance to the sea of all continents. A different perspective to our world (here more (spanish)) ."
  },
  {
    "objectID": "blog/climate-animation-maximum-temperature/index.html",
    "href": "blog/climate-animation-maximum-temperature/index.html",
    "title": "Climate animation of maximum temperatures",
    "section": "",
    "text": "In the field of data visualization, the animation of spatial data in its temporal dimension can show fascinating changes and patterns. As a result of one of the last publications in the social networks that I have made, I was asked to make a post about how I created it. Well, here we go to start with an example of data from mainland Spain. You can find more animations in the graphics section of my blog."
  },
  {
    "objectID": "blog/climate-animation-maximum-temperature/index.html#data",
    "href": "blog/climate-animation-maximum-temperature/index.html#data",
    "title": "Climate animation of maximum temperatures",
    "section": "Data",
    "text": "Data\nFirst, we need to download the STEAD dataset of the maximum temperature (tmax_pen.nc) in netCDF format from the CSIC repository here (the size of the data is 2 GB). It is a set of data with a spatial resolution of 5 km and includes daily maximum temperatures from 1901 to 2014. In climatology and meteorology, a widely used format is that of netCDF databases, which allow to obtain a multidimensional structure and to exchange data independently of the usued operating system. It is a space-time format with a regular or irregular grid. The multidimensional structure in the form of arrays or cubes can handle not only spatio-temporal data but also multivariate ones. In our dataset we will have an array of three dimensions: longitude, latitude and time of the maximum temperature."
  },
  {
    "objectID": "blog/climate-animation-maximum-temperature/index.html#import-the-dataset",
    "href": "blog/climate-animation-maximum-temperature/index.html#import-the-dataset",
    "title": "Climate animation of maximum temperatures",
    "section": "Import the dataset",
    "text": "Import the dataset\nThe netCDF format with .nc extension can be imported via two main packages: 1) ncdf4 and 2) raster. Actually, the raster package use the first package to import the netCDF datasets. In this post we will use the raster package since it is somewhat easier, with some very useful and more universal functions for all types of raster format. The main import functions are: raster(), stack() and brick(). The first function only allows you to import a single layer, instead, the last two functions are used for multidimensional data. In our dataset we only have one variable, therefore it would not be necessary to use the varname argument.\n\n# import netCDF data\ntmx &lt;- rast(\"tmax_pen.nc\")\ntmx # metadata\n\nThe SpatRaster object details show you all the necessary metadata: the resolution, the dimensions or the type of projection, or the name of the variable. It also tells us that it only points to the data source and has not imported them into the memory, which makes it easier to work with large datasets.\nTo access any layer we use [[ ]] with the corresponding index. So we can easily plot any day of the 41,638 days we have.\n\n# map any day\nplot(tmx[[200]], col = rev(heat.colors(7)))"
  },
  {
    "objectID": "blog/climate-animation-maximum-temperature/index.html#calculate-the-average-temperature",
    "href": "blog/climate-animation-maximum-temperature/index.html#calculate-the-average-temperature",
    "title": "Climate animation of maximum temperatures",
    "section": "Calculate the average temperature",
    "text": "Calculate the average temperature\nIn this step the objective is to calculate the average maximum temperature for each day of the year. Therefore, the first thing we do is to create a vector, indicating the entire time series for the SpatRaster. In the terra package we have the tapp() function that allows us to apply another function on groups of layers, or rather, indexes.\n\n\n\n\n\n\nNote\n\n\n\nFor the Europe version I did the preprocessing, the calculation of the average, in a cloud computing platform through Google Earth Engine, which makes the whole process faster. In the case of Australia the preprocessing was more complex as the dataset is separated in multiple netCDF files for each year.\n\n\n\n# define time dimension\ntime(tmx) &lt;- seq(as_date(\"1901-01-01\"), as_date(\"2014-12-31\"), \"day\")\n\n# calculate the average\ntmx_mean &lt;- tapp(tmx, \"doy\", \"mean\")"
  },
  {
    "objectID": "blog/climate-animation-maximum-temperature/index.html#smooth-the-temperature-variability",
    "href": "blog/climate-animation-maximum-temperature/index.html#smooth-the-temperature-variability",
    "title": "Climate animation of maximum temperatures",
    "section": "Smooth the temperature variability",
    "text": "Smooth the temperature variability\nBefore we start to smooth the time series of our RasterBrick, an example of why we do it. We extract a pixel from our dataset at coordinates -1º of longitude and 40º of latitude using the extract() function. Since the function with the same name appears in several packages, we must change to the form package_name::function_name. The result is a matrix with a single row corresponding to the pixel and 366 columns of the days of the year. The next step is to create a data.frame with a dummy date and the extracted maximum temperature.\n\n# extract a pixel\npoint_ts &lt;- extract(tmx_mean, matrix(c(-1, 40), nrow = 1)) |&gt; t()\ndim(point_ts) # dimensions\n\n\n# create a data.frame\ndf &lt;- data.frame(\n  date = seq(as_date(\"2000-01-01\"), as_date(\"2000-12-31\"), \"day\"),\n  tmx = point_ts[, 1]\n)\n\n# visualize the maximum temperature\nggplot(\n  df,\n  aes(date, tmx)\n) +\n  geom_line() +\n  scale_x_date(date_breaks = \"month\", date_labels = \"%b\") +\n  scale_y_continuous(breaks = seq(5, 28, 2)) +\n  labs(y = \"maximum temperature\", x = NULL) +\n  theme_minimal()\n\n\n\n\nThe graph clearly shows the still existing variability, which would cause an animation to fluctuate quite a bit. Therefore, we create a smoothing function based on a local polynomial regression fit (LOESS), more details can be found in the help of the loess() function. The most important argument is span, which determines the degree of smoothing, the smaller the value the less smooth the curve will be. I found the best result showed a value of 0.5.\n\ndaily_smooth &lt;- function(x, span = 0.5) {\n  \n  if (all(is.na(x))) {\n    return(x)\n  } else {\n    \n    df &lt;- data.frame(yd = 1:366, ta = x)\n    m &lt;- loess(ta ~ yd, span = span, data = df)\n    est &lt;- predict(m, 1:366)\n\n    return(est)\n  }\n}\n\nWe apply our new smoothing function to the extracted time series and make some changes to be able to visualize the difference between the original and smoothed data.\n\n# smooth the temperature\ndf &lt;- mutate(df, tmx_smoothed = daily_smooth(tmx)) |&gt;\n          pivot_longer(2:3, names_to = \"var\", values_to = \"temp\")\n\n# visualize the difference\nggplot(df,\n  aes(date, temp,\n    colour = var)\n    ) +\n  geom_line() +\n  scale_x_date(date_breaks = \"month\", date_labels = \"%b\") +\n  scale_y_continuous(breaks = seq(5, 28, 2)) +\n  scale_colour_manual(values = c(\"#f4a582\", \"#b2182b\")) +\n  labs(y = \"maximum temperature\", x = NULL, colour = NULL) +\n  theme_minimal()\n\n\n\n\nAs we see in the graph, the smoothed curve follows the original curve very well. In the next step we apply our function with the app() function. The function returns as many layers as those returned by the function used for each of the time series.\n\n# smooth the time serie of each pixel\ntmx_smooth &lt;- app(tmx_mean, fun = daily_smooth, cores = 6)"
  },
  {
    "objectID": "blog/climate-animation-maximum-temperature/index.html#preparation-1",
    "href": "blog/climate-animation-maximum-temperature/index.html#preparation-1",
    "title": "Climate animation of maximum temperatures",
    "section": "Preparation",
    "text": "Preparation\nTo visualize the maximum temperatures throughout the year, first, we convert the SpatRaster to a data.frame, including longitude and latitude.\n\n# convert to data.frame\ntmx_mat &lt;- as.data.frame(tmx_smooth, xy = TRUE)\n\n# rename the columns\ntmx_mat &lt;- set_names(tmx_mat, c(\"lon\", \"lat\", str_c(\"D\", 1:366)))\nstr(tmx_mat[, 1:10])\n\nSecond, we import the administrative boundaries with the gisco_get_countries() function from the giscoR package, limiting the extension to the region of the Iberian Peninsula, southern France and northern Africa.\n\n# import global boundaries\nmap &lt;- gisco_get_countries(resolution = \"10\", spatialtype = \"BN\") \n\n# limit the extension\nmap &lt;- st_crop(map, xmin = -10, xmax = 5, ymin = 35, ymax = 44)\n\n# map of boundaries\nplot(map)\n\n\n\n\nThird, we create a vector with the day of the year as labels in order to include them later in the animation. In addition, we define the break points for the maximum temperature, adapted to the distribution of our data, to obtain a categorization with a total of 20 classes.\nFourth, we apply the cut() function with the breaks to all the columns with temperature data of each day of the year.\n\n# labels of day of the year\nlab &lt;- as_date(0:365, \"2000-01-01\") |&gt; format(\"%d %B\")\n\n# breaks for the temperature data\nct &lt;- c(-5, 0, 4, seq(6, 34, 2), 40, 45)\n\n# categorized data with fixed breaks\ntmx_mat_cat &lt;- mutate(tmx_mat, across(3:368, \\(x) cut(x, breaks = ct)))\n\nWe define the colors corresponding to the created classes.\n\n# define the color ramp\ncol_spec &lt;- colorRampPalette(rev(brewer.pal(11, \"Spectral\")))"
  },
  {
    "objectID": "blog/climate-animation-maximum-temperature/index.html#static-map",
    "href": "blog/climate-animation-maximum-temperature/index.html#static-map",
    "title": "Climate animation of maximum temperatures",
    "section": "Static map",
    "text": "Static map\nIn this first plot we make a map of May 29 (day 150). I am not going to explain all the details of the construction with ggplot2, however, it is important to note that I use the aes_string() function instead of aes() to use the column names in string format. With the geom_raster() function we add the gridded temperature data as the first layer of the graph and with geom_sf() the boundaries in sf class. Finally, the guide_colorsteps() function allows you to create a nice legend based on the classes created by the cut() function.\n\nggplot(tmx_mat_cat) +\n  geom_raster(aes_string(\"lon\", \"lat\", fill = \"D150\")) +\n  geom_sf(\n    data = map,\n    colour = \"grey50\", linewidth = 0.2\n  ) +\n  coord_sf(expand = FALSE) +\n  scale_fill_manual(values = col_spec(20), drop = FALSE, guide = guide_colorsteps()) +\n  theme_void() +\n  theme(\n    legend.position = \"top\",\n    legend.justification = 0,\n    plot.caption = element_text(\n      margin = margin(b = 5, t = 10, unit = \"pt\")\n    ),\n    plot.title = element_text(\n      size = 16, face = \"bold\",\n      margin = margin(b = 2, t = 5, unit = \"pt\")\n    ),\n    legend.key.height = unit(0.5, \"lines\"),\n    legend.key.width = unit(7, \"lines\"),\n    legend.title.position = \"right\",\n      legend.title = element_text(vjust = .08),\n    plot.subtitle = element_text(\n      size = 13,\n      margin = margin(b = 10, t = 5, unit = \"pt\")\n    )\n  ) +\n  labs(\n    title = \"Average maximum temperature during the year in Spain\",\n    subtitle = lab[150],\n    caption = \"Reference period 1901-2014. Data: STEAD\",\n    fill = \"ºC\"\n  )"
  },
  {
    "objectID": "blog/climate-animation-maximum-temperature/index.html#animation-of-the-whole-year",
    "href": "blog/climate-animation-maximum-temperature/index.html#animation-of-the-whole-year",
    "title": "Climate animation of maximum temperatures",
    "section": "Animation of the whole year",
    "text": "Animation of the whole year\nThe final animation consists of creating a gif from all the images of 366 days, in principle, the gganimate package could be used, but in my experience it is slower, since it requires a data.frame in long format. In this example a long table would have more than seven million rows. So what we do here is to walk over the columns and join all the created images with the gifski package that also uses gganimate for rendering.\nBefore mapping we create a vector with the time steps or names of the columns, and another vector with the name of the images, including the name of the folder. In order to obtain a list of images ordered by their number, we must maintain three figures, filling the positions on the left with zeros.\n\ntime_step &lt;- str_c(\"D\", 1:366)\n\nfiles &lt;- str_c(\"./ta_anima/D\", str_pad(1:366, 3, \"left\", \"0\"), \".png\")\n\nLastly, we include the above plot construction in a for loop.\n\nwalk(1:366, \\(i) {\n  ggplot(tmx_mat_cat) +\n    geom_raster(aes_string(\"lon\", \"lat\", fill = time_step[i])) +\n    geom_sf(\n      data = map,\n      colour = \"grey50\", linewidth = 0.2\n    ) +\n    coord_sf(expand = FALSE) +\n    scale_fill_manual(values = col_spec(20), drop = FALSE, guide = guide_colorsteps()) +\n    theme_void() +\n    theme(\n      legend.position = \"top\",\n      legend.justification = 0,\n      plot.caption = element_text(\n        margin = margin(b = 5, t = 10, unit = \"pt\")\n      ),\n      plot.title = element_text(\n        size = 16, face = \"bold\",\n        margin = margin(b = 2, t = 5, unit = \"pt\")\n      ),\n    legend.key.height = unit(0.5, \"lines\"),\n    legend.key.width = unit(7, \"lines\"),\n    legend.title.position = \"right\",\n    legend.title = element_text(vjust = .08),\n      plot.subtitle = element_text(\n        size = 13,\n        margin = margin(b = 10, t = 5, unit = \"pt\")\n      )\n    ) +\n    labs(\n      title = \"Average maximum temperature during the year in Spain\",\n      subtitle = lab[i],\n      caption = \"Reference period 1901-2014. Data: STEAD\",\n      fill = \"ºC\"\n    )\n\n  ggsave(files[i], width = 8.28, height = 7.33, type = \"cairo\")\n  }\n})\n\nAfter having created images for each day of the year, we only have to create the gif.\n\ngifski(files, \"tmx_spain.gif\", width = 800, height = 700, loop = FALSE, delay = 0.05)"
  },
  {
    "objectID": "blog/climate-circles/index.html",
    "href": "blog/climate-circles/index.html",
    "title": "Climate circles",
    "section": "",
    "text": "The climate of a place is usually presented through climographs that combine monthly precipitation and temperature in a single chart. However, it is also interesting to visualize the climate on a daily scale showing the thermal amplitude and the daily average temperature. To do this, the averages for each day of the year of daily minimums, maximums and means are calculated.\nThe annual climate cycle presents a good opportunity to use a radial or polar chart which allows us to clearly visualize seasonal patterns."
  },
  {
    "objectID": "blog/climate-circles/index.html#data",
    "href": "blog/climate-circles/index.html#data",
    "title": "Climate circles",
    "section": "Data",
    "text": "Data\nWe download the temperature data for a selection of US cities here. You can access other cities of the entire world through the WMO or GHCN datasets at NCDC/NOAA.\n\nsource(\"terminator.R\") # import the functions"
  },
  {
    "objectID": "blog/climate-circles/index.html#import",
    "href": "blog/climate-circles/index.html#import",
    "title": "Climate circles",
    "section": "Import",
    "text": "Import\nTo import the temperature time series of each city, which we find in several files, we apply the read_csv() function using map(). The dir_ls() function of the fs package returns the list of files with csv extension. The list_rbind() function join all imported tables into a single one.\nThen we obtain the names of the weather stations and define a new vector with the new city names.\n\n# import data\nmeteo &lt;- dir_ls(regexp = \".csv$\") |&gt;\n          map(read_csv) |&gt; list_rbind()\nmeteo\n\n# station names\nstats_names &lt;- unique(meteo$NAME)\nstats_names\n\n# new city names\ncities &lt;- c(\n  \"CHICAGO\", \"NEW YORK\", \"MIAMI\",\n  \"HOUSTON\", \"ATLANTA\", \"SAN FRANCISCO\",\n  \"SEATTLE\", \"DENVER\", \"LAS VEGAS\"\n)"
  },
  {
    "objectID": "blog/climate-circles/index.html#preparation-1",
    "href": "blog/climate-circles/index.html#preparation-1",
    "title": "Climate circles",
    "section": "Preparation",
    "text": "Preparation\nIn the first step, we will modify the original data, 1) selecting only the columns of interest, 2) filtering the period 1991-2020, 3) defining the new city names, 4) calculating the average temperature where it is absent, 5) cleaning the column names, and 6) creating a new variable with the days of the year. The clean_names() function of the janitor package is very useful for getting clean column names.\n\nmeteo &lt;- select(meteo, NAME, DATE, TAVG:TMIN) |&gt;\n  filter(DATE &gt;= \"1991-01-01\", \n          DATE &lt;= \"2020-12-31\") |&gt;\n  mutate(\n    NAME = factor(NAME, stats_names, cities),\n    TAVG = ifelse(is.na(TAVG), (TMAX + TMIN) / 2, TAVG),\n    yd = yday(DATE)\n  ) |&gt;\n  clean_names()\n\nIn the next step, we calculate the daily maximum, minimum and mean temperature for each day of the year. It now only remains to convert the days of the year into a dummy date. Here we use the year 2000 since it is a leap year, and we have a total of 366 days.\n\n# estimate the daily averages\nmeteo_yday &lt;- group_by(meteo, name, yd) |&gt;\n  summarise(\n    ta = mean(tavg, na.rm = TRUE),\n    tmx = mean(tmax, na.rm = TRUE),\n    tmin = mean(tmin, na.rm = TRUE)\n  )\nmeteo_yday\n\n# convert the days of the year into a dummy date\nmeteo_yday &lt;- mutate(meteo_yday, yd = as_date(yd, origin = \"1999-12-31\"))"
  },
  {
    "objectID": "blog/climate-circles/index.html#predefinitions",
    "href": "blog/climate-circles/index.html#predefinitions",
    "title": "Climate circles",
    "section": "Predefinitions",
    "text": "Predefinitions\nWe define a divergent vector of various hues.\n\ncol_temp &lt;- c(\n  \"#cbebf6\", \"#a7bfd9\", \"#8c99bc\", \"#974ea8\", \"#830f74\",\n  \"#0b144f\", \"#0e2680\", \"#223b97\", \"#1c499a\", \"#2859a5\",\n  \"#1b6aa3\", \"#1d9bc4\", \"#1ca4bc\", \"#64c6c7\", \"#86cabb\",\n  \"#91e0a7\", \"#c7eebf\", \"#ebf8da\", \"#f6fdd1\", \"#fdeca7\",\n  \"#f8da77\", \"#fcb34d\", \"#fc8c44\", \"#f85127\", \"#f52f26\",\n  \"#d10b26\", \"#9c042a\", \"#760324\", \"#18000c\"\n)\n\nWe create a table with the x-axis grid lines.\n\ngrid_x &lt;- tibble(\n  x = seq(ymd(\"2000-01-01\"), ymd(\"2000-12-31\"), \"month\"),\n  y = rep(-10, 12),\n  xend = seq(ymd(\"2000-01-01\"), ymd(\"2000-12-31\"), \"month\"),\n  yend = rep(41, 12)\n)\n\nWe define all the style elements of the graph in our own theme theme_cc().\n\ntheme_cc &lt;- function() {\n  theme_void(base_family = \"Montserrat\") %+replace%\n    theme(\n      plot.title = element_text(hjust = 0.5, colour = \"white\", size = 30, margin = margin(b = 20)),\n      plot.caption = element_text(colour = \"white\", size = 9, hjust = .5, vjust = -30),\n      plot.background = element_rect(fill = \"black\"),\n      plot.margin = margin(1, 1, 2, 1, unit = \"cm\"),\n      axis.text.x = element_text(face = \"italic\", colour = \"white\", margin = margin()),\n      axis.title.y = element_blank(),\n      axis.text.y = element_blank(),\n      legend.title = element_text(colour = \"white\"),\n      legend.position = \"bottom\",\n      legend.justification = 0.5,\n      legend.text = element_text(colour = \"white\"),\n      strip.text = element_text(colour = \"white\", face = \"bold\", size = 14),\n      panel.spacing.y = unit(1, \"lines\"),\n      panel.background = element_rect(fill = \"black\"),\n      panel.grid = element_blank()\n    )\n}"
  },
  {
    "objectID": "blog/climate-circles/index.html#graph",
    "href": "blog/climate-circles/index.html#graph",
    "title": "Climate circles",
    "section": "Graph",
    "text": "Graph\nWe start by building a chart for New York City only. We will use geom_linerange() to define line range with the daily maximum and minimum temperature. Also, we will draw the range line colour based on the mean temperature. Finally, we can adjust alpha and size to get a nicer look.\n\n# filter New York\nny_city &lt;- filter(meteo_yday, name == \"NEW YORK\")\n\n# graph\nggplot(ny_city) +\n  geom_linerange(\n    aes(yd,\n      ymax = tmx,\n      ymin = tmin,\n      colour = ta\n    ),\n    size = 0.5,\n    alpha = .7\n  ) +\n  scale_y_continuous(\n    breaks = seq(-30, 50, 10),\n    limits = c(-11, 42),\n    expand = expansion()\n  ) +\n  scale_colour_gradientn(\n    colours = col_temp,\n    limits = c(-12, 35),\n    breaks = seq(-12, 34, 5)\n  ) +\n  scale_x_date(\n    date_breaks = \"month\",\n    date_labels = \"%b\"\n  ) +\n  labs(\n    title = \"CLIMATE CIRCLES\",\n    colour = \"Daily average temperature\"\n  )\n\nTo get the polar graph it would only be necessary to add the coord_radial() function.\n\n# polar chart\nggplot(ny_city) +\n  geom_linerange(\n    aes(yd,\n      ymax = tmx,\n      ymin = tmin,\n      colour = ta\n    ),\n    size = 0.5,\n    alpha = .7\n  ) +\n  scale_y_continuous(\n    breaks = seq(-30, 50, 10),\n    limits = c(-11, 42),\n    expand = expansion()\n  ) +\n  scale_colour_gradientn(\n    colours = col_temp,\n    limits = c(-12, 35),\n    breaks = seq(-12, 34, 5)\n  ) +\n  scale_x_date(\n    date_breaks = \"month\",\n    date_labels = \"%b\"\n  ) +\n  coord_radial(expand = F) +\n  labs(\n    title = \"CLIMATE CIRCLES\",\n    colour = \"Daily average temperature\"\n  )\n\n\n\n \nIn the final graph, we add the grid defining the lines on the y-axis with geom_hline() and those on the x-axis with geom_segement(). The most important thing here is the facet_wrap() function, which allows multiple facets of charts. The formula format is used to specify how the facets are created: row ~ column. If we do not have a second variable, a point . is indicated in the formula. In addition, we make changes to the appearance of the colour bar with guides() and guide_colourbar(), and we include the theme_cc() style.\n\nggplot(meteo_yday) +\n  geom_texthline(\n    data = tibble(y = c(-10, 0, 10, 20, 30, 40)),\n    aes(yintercept = y, label = y),\n    colour = \"white\",\n    linewidth = .4,\n    size = 2\n  ) +\n  geom_segment(\n    data = grid_x,\n    aes(\n      x = x,\n      y = y,\n      xend = xend,\n      yend = yend\n    ),\n    linetype = \"dashed\",\n    colour = \"white\",\n    linewidth = .2\n  ) +\n  geom_linerange(\n    aes(yd,\n      ymax = tmx,\n      ymin = tmin,\n      colour = ta\n    ),\n    linewidth = 0.5,\n    alpha = .7\n  ) +\n  scale_y_continuous(\n    breaks = seq(-30, 50, 10),\n    limits = c(-15, 41.5),\n    expand = expansion()\n  ) +\n  scale_colour_gradientn(\n    colours = col_temp,\n    limits = c(-12, 35),\n    breaks = seq(-12, 34, 5)\n  ) +\n  scale_x_date(\n    date_breaks = \"month\",\n    date_labels = \"%b\"\n  ) +\n  guides(colour = guide_colourbar(\n    barwidth = 15,\n    barheight = 0.5,\n    title.position = \"top\"\n  ),\n  theta = \"axis_textpath\") +\n1  facet_wrap(~name, nrow = 3) +\n  coord_radial(r.axis.inside = T, expand = F) +\n  labs(\n    title = \"CLIMATE CIRCLES\",\n    colour = \"Daily average temperature\"\n  ) +\n  theme_cc()\n\n\n1\n\nFor curved text on theta (x axis in polar coordinate systems)"
  },
  {
    "objectID": "blog/geographic-distance/index.html",
    "href": "blog/geographic-distance/index.html",
    "title": "Geographic distance",
    "section": "",
    "text": "The first post of this year 2020, I will dedicate to a question that I was recently asked. The question was how to calculate the shortest distance between different points and how to know which is the closest point. When we work with spatial data in R, currently the easiest thing is to use the sf package in combination with the tidyverse collection of packages. We also use the units package which is very useful for working with units of measurement."
  },
  {
    "objectID": "blog/geographic-distance/index.html#measurement-units",
    "href": "blog/geographic-distance/index.html#measurement-units",
    "title": "Geographic distance",
    "section": "Measurement units",
    "text": "Measurement units\nThe use of vectors and matrices with the units class allows us to calculate and transform units of measurement.\n\n# length\nl &lt;- set_units(1:10, m)\nl\n\n\n# convert units\nset_units(l, cm)\n\n\n# sum different units\nset_units(l, cm) + l\n\n\n# area\na &lt;- set_units(355, ha)\nset_units(a, km2)\n\n\n# velocity\nvel &lt;- set_units(seq(20, 50, 10), km / h)\nset_units(vel, m / s)"
  },
  {
    "objectID": "blog/geographic-distance/index.html#capital-cities-of-the-world",
    "href": "blog/geographic-distance/index.html#capital-cities-of-the-world",
    "title": "Geographic distance",
    "section": "Capital cities of the world",
    "text": "Capital cities of the world\nWe will use the capital cities of the whole world with the objective of calculating the distance to the nearest capital city and indicating the name/country.\n\n# set of world cities with coordinates\nhead(world.cities) # from the maps package\n\nTo convert points with longitude and latitude into a spatial object of class sf, we use the function st_as_sf(), indicating the coordinate columns and the coordinate reference system (WSG84, epsg: 4326).\n\n# convert the points into an sf object with CRS WSG84\ncities &lt;- st_as_sf(world.cities, coords = c(\"long\", \"lat\"), crs = 4326)\ncities\n\nIn the next step, we filter by the capital cities encoded in the column capital with 1. The advantage of the sf package is the possibility of applying functions of the tidyverse collection to manipulate the attributes. In addition, we add a column with new labels using the str_c() function of the stringr package, which is similar to that of R Base paste().\n\n# filter the capital cities\ncapitals &lt;- filter(cities, capital == 1)\n\n# create a new label combining name and country\ncapitals &lt;- mutate(capitals, city_country = str_c(name, \" (\", country.etc, \")\"))\n\ncapitals"
  },
  {
    "objectID": "blog/geographic-distance/index.html#calculate-distances",
    "href": "blog/geographic-distance/index.html#calculate-distances",
    "title": "Geographic distance",
    "section": "Calculate distances",
    "text": "Calculate distances\nGeographical distance (Euclidean or greater circle) is calculated with the st_distance() function, either between two points, between one point and others or between all points. In the latter case we obtain a symmetric matrix of distances (NxN), taken pairwise between the elements of the capital city set. In the diagonal we find the combinations between the same points giving all null values.\n\n\n\nA\nB\nC\n\n\n\nA\n0\n229\n272\n\n\nB\n229\n0\n181\n\n\nC\n272\n181\n0\n\n\n\nFor instance, when we want to know the distance from Amsterdam to Abu Dhabi, Washington and Tokyo we pass two spatial objects.\n\n# calculate distance\ndist_amsterdam &lt;- st_distance(\n  slice(capitals, 10),\n  slice(capitals, c(2, 220, 205))\n)\n\ndist_amsterdam # distance in meters\n\nThe result is a matrix with a single row or column (depending on the order of the spatial objects) with a class of units. Thus it is possible to convert easily to another unit of measure. If we want to obtain a vector without class units, we only have to apply the function as.vector().\n\n# change from m to km\nset_units(dist_amsterdam, \"km\")\n\n\n# units class to vector\nas.vector(dist_amsterdam)\n\nIn the second step, we estimate the distance matrix between all the capital cities. It is important to convert the null values to NA to subsequently obtain the correct matrix index.\n\n# calculate distance\nm_distance &lt;- st_distance(capitals)\n\n# matrix\ndim(m_distance)\n\n\n# change m to km\nm_distance_km &lt;- set_units(m_distance, km)\n\n# replace the distance of 0 m with NA\nm_distance_km[m_distance_km == set_units(0, km)] &lt;- NA\n\n\n\n\n\n\n\nNote\n\n\n\nWhen the result is of the units class, it is necessary to use the same class to be able to make logical queries. For example, set_units(1, m) == set_units(1, m) vs. set_units(1, m) == 1.\n\n\nTo obtain the shortest distance, in addition to its position, we use the apply() function which in turn allows us to apply the function which.min() and min() on each row. It would also be possible to use the function on columns giving the same result. Finally, we add the results as new columns with the mutate() function. The indices in pos allow us to obtain the names of the nearest cities.\n\n# get the index (position) of the city and the distance\npos &lt;- apply(m_distance_km, 1, which.min)\ndist &lt;- apply(m_distance_km, 1, min, na.rm = TRUE)\n\n# add the distance and get the name of the city\ncapitals &lt;- mutate(capitals,\n  nearest_city = city_country[pos],\n  geometry_nearest = geometry[pos],\n  distance_city = dist\n)"
  },
  {
    "objectID": "blog/geographic-distance/index.html#map-of-distances-to-the-next-capital-city",
    "href": "blog/geographic-distance/index.html#map-of-distances-to-the-next-capital-city",
    "title": "Geographic distance",
    "section": "Map of distances to the next capital city",
    "text": "Map of distances to the next capital city\nFinally, we build a map representing the distance in proportional circles. To do this, we use the usual grammar of ggplot() by adding the geometry geom_sf(), first for the world map as background and then for the cities. In aes() we indicate, with the argument size = distance_city, the variable which we want to map proportionally. The theme_void() function removes all style elements. In addition, we define with the function coord_sf() a new projection indicating the proj4 format.\n\n# world map\nworld &lt;- gisco_get_countries(resolution = \"10\")\n\n# map\nggplot(world) +\n  geom_sf(fill = \"black\", colour = \"white\") +\n  geom_sf(\n    data = arrange(capitals, distance_city),\n    aes(size = distance_city),\n    alpha = 0.5,\n    colour = \"white\",\n    fill = \"#bd0026\",\n    shape = 21\n  ) +\n  scale_size(range = c(.2, 6), breaks = c(100, 250, 750, 2000)) +\n  coord_sf(crs = \"ESRI:54030\") +\n  labs(size = \"km\", title = \"Distance to the next capital city\") +\n  theme_void() +\n  theme(plot.title = element_text(hjust = .5, margin = margin(b = 10)),\n        legend.position = \"top\",\n        legend.title.position = \"right\",\n        plot.margin = margin(5, 5, 5, 5))"
  },
  {
    "objectID": "blog/hillshade-effect/index.html",
    "href": "blog/hillshade-effect/index.html",
    "title": "Hillshade effects",
    "section": "",
    "text": "It is very common to see relief maps with shadow effects, also known as ‘hillshade’, which generates visual depth. How can we create these effects in R and how to include them in ggplot2?\nPackages\n\n\n\n\n\n\nPackage\nDescription\n\n\n\ntidyverse\nCollection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.\n\n\nsf\nSimple Feature: import, export and manipulate vector data\n\n\nelevatr\nAccess to elevation data from various APIs\n\n\nterra\nImport, export and manipulate raster ({raster} successor package)\n\n\nwhitebox\nAn R interface to the ‘WhiteboxTools’ library, which is an advanced geospatial data analysis platform\n\n\ntidyterra\nHelper functions for working with {terra}\n\n\ngiscoR\nAdministrative boundaries of the world\n\n\nggnewscale\nExtension for ggplot2 of multiple ‘scales’\n\n\nggblend\nExtension for mixing colors in ggplot graphs\n\n\n\n\n# install the packages if necessary\n\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"sf\")) install.packages(\"sf\")\nif (!require(\"elevatr\")) install.packages(\"elevatr\")\nif (!require(\"terra\")) install.packages(\"terra\")\nif (!require(\"whitebox\")) install.packages(\"whitebox\")\nif (!require(\"tidyterra\")) install.packages(\"tidyterra\")\nif (!require(\"giscoR\")) install.packages(\"giscoR\")\nif (!require(\"ggnewscale\")) install.packages(\"ggnewscale\")\nif (!require(\"ggblend\")) install.packages(\"ggblend\")\n\n# packages\nlibrary(sf)\nlibrary(elevatr)\nlibrary(tidyverse)\nlibrary(terra)\nlibrary(whitebox)\nlibrary(ggnewscale)\nlibrary(tidyterra)\nlibrary(giscoR)\nlibrary(units)\nlibrary(ggblend)\n\nData\nAs an area of interest, we use Switzerland in this example. Except for lake boundaries download, the necessary data is obtained through APIs using different packages. For example, the giscoR package allows you to get country boundaries with different resolutions.\n\nsuiz &lt;- gisco_get_countries(country = \"Switzerland\", resolution = \"03\")\n\nplot(suiz)\n\n\nThe lake boundaries correspond to a layer of digital cartographic models (DKM500) provided by swisstopo. The objective is to keep only the largest lakes; therefore, we exclude all those with less than 50 km2 and also those located entirely in Italian territory. Remember that with the units package, we can indicate units and thus do calculations.\n\n# import the lakes boundaries\nsuiz_lakes &lt;- st_read(\"22_DKM500_GEWAESSER_PLY.shp\")\n\n# filter the largest ones\nsuiz_lakes &lt;- mutate(suiz_lakes, areakm = set_units(SHP_AREA, \"m2\") |&gt;\n  set_units(\"km2\")) |&gt;\n  filter(\n    areakm &gt; set_units(50, \"km2\"),\n    !NAMN1 %in% c(\n      \"Lago di Como / Lario\",\n      \"Lago d'Iseo\",\n      \"Lago di Garda\"\n    )\n  )\n\nplot(suiz_lakes)\n\n\nDigital Elevation Model (DEM)\nThe get_elev_raster() function allows us to download a DEM from any region of the world through different providers in raster format. By default, it uses AWS. An essential argument is the latitude-dependent resolution, which can be specified as the zoom level (see function help). For example, we use level 10, which at a latitude of 45º would correspond to approximately 100 m.\nAfter obtaining the DEM from Switzerland, we must mask the country’s boundaries. The object’s class is RasterLayer from the raster package, however, the new standard is terra with the class SpatRaster. That’s why we convert it and then apply the mask. Finally, we reproject to the Swiss coordinate system obtained from the vector data.\n\n# get the DEM with\nmdt &lt;- get_elev_raster(suiz, z = 10)\n\nmdt # old RasterLayer class\n\nplot(mdt)\n\n\n\n# convert to terra and mask area of interest\nmdt &lt;- rast(mdt) |&gt;\n  mask(vect(suiz))\n\n# reproject\nmdt &lt;- project(mdt, crs(suiz_lakes))\n\n# reproject vect\nsuiz &lt;- st_transform(suiz, st_crs(suiz_lakes))\n\nBefore calculating the shadow effect, we create a simple relief map. In ggplot2, we use the geom_raster() geometry, indicating the longitude, latitude and the variable to define the color. We add the boundaries of the lakes using geom_sf() since it is an sf object. Here we only indicate the fill color with a light blue. Then, with the help of scale_fill_hypso_tint_c(), we apply a range of colors corresponding to the relief, also called hypsometric tinting, and we define the breaks in the legend. We make appearance adjustments in the legend and the graph’s style in the rest of the functions.\n\n# convert the raster into a data.frame of xyz\nmdtdf &lt;- as.data.frame(mdt, xy = TRUE)\nnames(mdtdf)[3] &lt;- \"alt\"\n\n# map\nggplot() +\n  geom_raster(\n    data = mdtdf,\n    aes(x, y, fill = alt)\n  ) +\n  geom_sf(\n    data = suiz_lakes,\n    fill = \"#c6dbef\",\n    colour = NA\n  ) +\n  scale_fill_hypso_tint_c(breaks = c(\n    180, 250, 500, 1000,\n    1500, 2000, 2500,\n    3000, 3500, 4000\n  )) +\n  guides(fill = guide_colorsteps(\n    barwidth = 20,\n    barheight = .5,\n    title.position = \"right\"\n  )) +\n  labs(fill = \"m\") +\n  coord_sf() +\n  theme_void() +\n  theme(legend.position = \"bottom\")\n\n\nCalculate the hillshade\nLet’s remember that the hillshade effect is nothing more than adding a hypothetical illumination with respect to a position of a light source to gain depth. Shadows depend on two variables, azimuth, the angle from the orientation on the surface of a sphere, and elevation, the angle from the height of the source.\n\nThe information required to simulate lighting is the digital elevation model. The slope and aspect can be derived from the DEM using the terrain() function from the terra package. The unit must be radians. Once we have all the data, we can use the shade() function to indicate the angle (elevation) and direction (azimuth). The result is a raster with values between 0 and 255, which shows shadows with low values, being 0 black and 255 white.\n\n# estimate the slope\nsl &lt;- terrain(mdt, \"slope\", unit = \"radians\")\nplot(sl)\n\n\n\n\n\n# estimate the aspect or orientation\nasp &lt;- terrain(mdt, \"aspect\", unit = \"radians\")\nplot(asp)\n\n\n\n\n\n# calculate the hillshade effect with 45º of elevation\nhill_single &lt;- shade(sl, asp,\n  angle = 45,\n  direction = 300,\n  normalize = TRUE\n)\n\n# final hillshade\nplot(hill_single, col = grey(1:100 / 100))\n\n\n\n\nCombine the relief and shadow effect\nThe problem with adding both the relief with its hypsometric tints and the hillshade effect inside ggplot2 is that we have two different fills or scales for each layer. The solution is to use the ggnewscale extension, which allows you to add multiple scales of the same argument. First, we add the hillshade with geom_raster(), then we define the grey tones, and before adding the altitude, we include the new_scale_fill() function to mark a different fill. To achieve the effect, it is necessary to give a degree of transparency to the relief layer; in this case, it is 70%. The choice of direction is important, which is why we must always take into account the place and the apparent path of the sun (sunearthtools).\n\n# convert the hillshade to xyz\nhilldf_single &lt;- as.data.frame(hill_single, xy = TRUE)\n\n# map\nggplot() +\n  geom_raster(\n    data = hilldf_single,\n    aes(x, y, fill = hillshade),\n    show.legend = FALSE\n  ) +\n  scale_fill_distiller(palette = \"Greys\") +\n  new_scale_fill() +\n  geom_raster(\n    data = mdtdf,\n    aes(x, y, fill = alt),\n    alpha = .7\n  ) +\n  scale_fill_hypso_tint_c(breaks = c(\n    180, 250, 500, 1000,\n    1500, 2000, 2500,\n    3000, 3500, 4000\n  )) +\n  geom_sf(\n    data = suiz_lakes,\n    fill = \"#c6dbef\", colour = NA\n  ) +\n  guides(fill = guide_colorsteps(\n    barwidth = 20,\n    barheight = .5,\n    title.position = \"right\"\n  )) +\n  labs(fill = \"m\") +\n  coord_sf() +\n  theme_void() +\n  theme(legend.position = \"bottom\")\n\n\nMultidirectional shadows\nWe have seen a unidirectional effect; although it is the most common, we can create a smoother and even more realistic effect by combining several directions.\nWe map onto a vector of various directions to which the shade() function is applied with a fixed elevation angle. We then convert the raster list to a multi-layered object to reduce them by adding all the layers.\n\n# pass multiple directions to shade()\nhillmulti &lt;- map(c(270, 15, 60, 330), function(dir) {\n  shade(sl, asp,\n    angle = 45,\n    direction = dir,\n    normalize = TRUE\n  )\n})\n\n# create a multidimensional raster and reduce it by summing up\nhillmulti &lt;- rast(hillmulti) |&gt; sum()\n\n# multidirectional\nplot(hillmulti, col = grey(1:100 / 100))\n\n\n\n\n\n# unidirectional\nplot(hill_single, col = grey(1:100 / 100))\n\n\n\n\nWe do the same as before to visualize the relief with multidirectional shadows.\n\n# convert the hillshade to xyz\nhillmultidf &lt;- as.data.frame(hillmulti, xy = TRUE)\n\n# map\nggplot() +\n  geom_raster(\n    data = hillmultidf,\n    aes(x, y, fill = sum),\n    show.legend = FALSE\n  ) +\n  scale_fill_distiller(palette = \"Greys\") +\n  new_scale_fill() +\n  geom_raster(\n    data = mdtdf,\n    aes(x, y, fill = alt),\n    alpha = .7\n  ) +\n  scale_fill_hypso_tint_c(breaks = c(\n    180, 250, 500, 1000,\n    1500, 2000, 2500,\n    3000, 3500, 4000\n  )) +\n  geom_sf(\n    data = suiz_lakes,\n    fill = \"#c6dbef\", colour = NA\n  ) +\n  guides(fill = guide_colorsteps(\n    barwidth = 20,\n    barheight = .5,\n    title.position = \"right\"\n  )) +\n  labs(fill = \"m\") +\n  coord_sf() +\n  theme_void() +\n  theme(legend.position = \"top\")\n\n\n\n\nThe color blending technique is very useful to obtain remarkable results in the shading effect. Recently the ggblend package offers this possibility. In order to blend several layers, it is necessary to insert the geom_raster() and the scale_fill_*() objects in a comma-separated list. Then follows the pipe with the blend(\"mix_type\") function to which we add the other ggplot2 objects. In this case we apply multiplication as a form of blending.\n\n# map\nm &lt;- ggplot() +\n  list(\n    geom_raster(\n      data = hillmultidf,\n      aes(x, y, fill = sum),\n      show.legend = FALSE\n    ),\n    scale_fill_distiller(palette = \"Greys\"),\n    new_scale_fill(),\n    geom_raster(\n      data = mdtdf,\n      aes(x, y, fill = alt),\n      alpha = .7\n    ),\n    scale_fill_hypso_tint_c(breaks = c(\n      180, 250, 500, 1000,\n      1500, 2000, 2500,\n      3000, 3500, 4000\n    ))\n  ) |&gt; blend(\"multiply\") +\n  geom_sf(\n    data = suiz_lakes,\n    fill = \"#c6dbef\", colour = NA\n  ) +\n  guides(fill = guide_colorsteps(\n    barwidth = 20,\n    barheight = .5,\n    title.position = \"right\"\n  )) +\n  labs(fill = \"m\") +\n  coord_sf() +\n  theme_void() +\n  theme(legend.position = \"top\")\n\nggsave(\"mdt_hillshade_blend.png\", m,\n  width = 10,\n  height = 8,\n  unit = \"in\",\n  device = png,\n  type = \"cairo\",\n  bg = \"white\"\n)\n\n\nAnother alternative for multidirectional shadows\nWith less control over the directions, it would also be possible to apply the wbt_multidirectional_hillshade() function from the whitebox package. WhiteboxTool contains many tools as an advanced geospatial data analysis platform. The disadvantage is that we lose control over the directions and that it is also necessary to export the DEM to geotiff to obtain another raster with the shadows.\nWe first install the library with the install_whitebox() function.\n\n# instal whitebox\ninstall_whitebox()\n\n\n# export the DEM\nwriteRaster(mdt, \"mdt.tiff\", overwrite = TRUE)\n\n# launch whitebox\nwbt_init()\n\n# create the hillshade\nwbt_multidirectional_hillshade(\n  \"mdt.tiff\",\n  \"hillshade.tiff\"\n)\n\n# re-import the hillshade\nhillwb &lt;- rast(\"hillshade.tiff\")\n\n# remask\nhillwb &lt;- mask(hillwb, vect(suiz))\n\n\n# convert the hillshade to xyz\nhillwbdf &lt;- as.data.frame(hillwb, xy = TRUE)\n\n# map\nggplot() +\n  geom_raster(\n    data = hillwbdf,\n    aes(x, y, fill = hillshade),\n    show.legend = FALSE\n  ) +\n  scale_fill_distiller(palette = \"Greys\") +\n  new_scale_fill() +\n  geom_raster(\n    data = mdtdf,\n    aes(x, y, fill = alt),\n    alpha = .7\n  ) +\n  scale_fill_hypso_tint_c(breaks = c(\n    180, 250, 500, 1000,\n    1500, 2000, 2500,\n    3000, 3500, 4000\n  )) +\n  guides(fill = guide_colorsteps(\n    barwidth = 20,\n    barheight = .5,\n    title.position = \"right\"\n  )) +\n  labs(fill = \"m\") +\n  coord_sf() +\n  theme_void() +\n  theme(legend.position = \"top\")\n\n\n\n\n Back to topReuseCC BY-SA 4.0CitationFor attribution, please cite this work as:\nRoyé, Dominic. 2022. “Hillshade Effects.” July 20, 2022. https://dominicroye.github.io/blog/hillshade-effect/."
  },
  {
    "objectID": "blog/import-excel-sheets-with-r/index.html",
    "href": "blog/import-excel-sheets-with-r/index.html",
    "title": "Import Excel sheets with R",
    "section": "",
    "text": "We usually work with different data sources, and sometimes we can find tables distributed over several Excel sheets. In this post we are going to import the average daily temperature of Madrid and Berlin which is found in two Excel files with sheets for each year between 2000 and 2005: download."
  },
  {
    "objectID": "blog/import-excel-sheets-with-r/index.html#packages",
    "href": "blog/import-excel-sheets-with-r/index.html#packages",
    "title": "Import Excel sheets with R",
    "section": "Packages",
    "text": "Packages\nIn this post we will use the following packages:\n\n\n\n\n\n\nPackage\nDescription\n\n\n\ntidyverse\nCollection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.\n\n\nfs\nProvides a cross-platform, uniform interface to file system operations\n\n\nreadxl\nImport Excel files\n\n\n\n\n# install the packages if necessary\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"fs\")) install.packages(\"fs\")\nif (!require(\"readxl\")) install.packages(\"readxl\")\n\n\n# load packages\nlibrary(tidyverse)\nlibrary(fs)\nlibrary(readxl)"
  },
  {
    "objectID": "blog/import-excel-sheets-with-r/index.html#import-excel-files",
    "href": "blog/import-excel-sheets-with-r/index.html#import-excel-files",
    "title": "Import Excel sheets with R",
    "section": "Import excel files",
    "text": "Import excel files\nBy default, the read_excel() function imports the first sheet. To import a different sheet it is necessary to indicate the number or name with the argument sheet (second argument).\n\n# import first sheet\nread_excel(\"madrid_temp.xlsx\")\n\n\n# import third sheet\nread_excel(\"madrid_temp.xlsx\", 3)\n\nThe excel_sheets() function can extract the names of the sheets.\n\npath &lt;- \"madrid_temp.xlsx\"\n\npath |&gt;\n  excel_sheets()\n\nThe results are the sheet names and we find the years from 2000 to 2005. The most important function to read multiple sheets is map() of the purrr package, which is part of the tidyverse collection. map() allows you to apply a function to each element of a vector or list.\n\npath &lt;- \"madrid_temp.xlsx\"\n\nmad &lt;- path |&gt;\n  excel_sheets() |&gt;\n  set_names() |&gt;\n  map(read_excel,\n    path = path\n  )\n\nstr(mad)\n\nThe result is a named list with the name of each sheet that contains the data.frame. To bind all rows from the list we can use the list_rbind() function, but we will lose the sheet names.\n\npath &lt;- \"madrid_temp.xlsx\"\n\nmad &lt;- path |&gt;\n  excel_sheets() |&gt;\n  set_names() |&gt;\n  map(read_excel,\n    path = path\n  ) |&gt;\n  list_rbind()\n\nmad"
  },
  {
    "objectID": "blog/import-excel-sheets-with-r/index.html#import-multiple-sheets",
    "href": "blog/import-excel-sheets-with-r/index.html#import-multiple-sheets",
    "title": "Import Excel sheets with R",
    "section": "Import multiple sheets",
    "text": "Import multiple sheets\nIn our case we don’t have a column in each sheet that differentiates each table, so we need to use the name of the sheets as a new column when joining all of them.\n\npath &lt;- \"madrid_temp.xlsx\"\n\nmad &lt;- path |&gt;\n  excel_sheets() |&gt;\n  set_names() |&gt;\n  map(read_excel,\n    path = path\n  ) |&gt;\n  list_rbind(names_to = \"yr\")\n\nstr(mad)\n\nBut how do we import multiple Excel files?\nTo do this, first we must know the dir_ls() function from the fs package. Indeed, there is the dir() function of R Base, but the advantages of the recent package are several, especially the compatibility with the tidyverse collection.\n\ndir_ls()\n\n\n# we can filter the files that we want\ndir_ls(regexp = \"xlsx\")\n\nWe import the two Excel files.\n\n# without joining\ndir_ls(regexp = \"xlsx\") |&gt;\n  map(read_excel)\n\n\n# joining with a new id column\ndir_ls(regexp = \"xlsx\") |&gt;\n  map(read_excel) |&gt;\n  list_rbind(names_to = \"city\")\n\nHowever, in this case we only import the first sheet of each Excel file. To solve this problem, we must create our own function. In this function we do what we previously did individually.\n\nread_multiple_excel &lt;- function(path) {\n  path |&gt;\n    excel_sheets() |&gt;\n    set_names() |&gt;\n    map(read_excel, path = path) |&gt;\n    list_rbind()\n}\n\nWe apply our created function to import multiple sheets of several Excel files.\n\n# separately\ndata &lt;- dir_ls(regexp = \"xlsx\") |&gt;\n  map(read_multiple_excel)\n\nstr(data)\n\n\n# joining all data.frames\ndata_df &lt;- dir_ls(regexp = \"xlsx\") |&gt;\n  map(read_multiple_excel) |&gt;\n  list_rbind(names_to = \"city\")\n\nstr(data_df)\n\n\n# clean up city names\ndata_df &lt;- mutate(data_df, city = path_ext_remove(city) |&gt; str_remove(\"_temp\"))"
  },
  {
    "objectID": "blog/inserted-map/index.html",
    "href": "blog/inserted-map/index.html",
    "title": "Inserted maps with ggplot2",
    "section": "",
    "text": "Today I present a short post on how we can position an outermost territory near the main map or insert an orientation map. In this example we use the typical map of Spain where the Canary Islands are located in the southwest of the peninsula."
  },
  {
    "objectID": "blog/inserted-map/index.html#packages",
    "href": "blog/inserted-map/index.html#packages",
    "title": "Inserted maps with ggplot2",
    "section": "Packages",
    "text": "Packages\n\n\n\n\n\n\nPackage\nDescription\n\n\n\ntidyverse\nCollection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.\n\n\nmapSpain\nAdministrative boundaries of Spain at different levels\n\n\nsf\nSimple Feature: import, export and manipulate vector data\n\n\ngiscoR\nAdministrative boundaries of the world\n\n\npatchwork\nSimple grammar to combine separate ggplots into the same graphic\n\n\nrmapshaper\nmapshaper library client for geospatial operations\n\n\n\n\n# install the packages if necessary\nif(!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif(!require(\"mapSpain\")) install.packages(\"mapSpain\")\nif(!require(\"sf\")) install.packages(\"sf\")\nif(!require(\"giscoR\")) install.packages(\"giscoR\")\nif(!require(\"patchwork\")) install.packages(\"patchwork\")\nif(!require(\"rmapshaper\")) install.packages(\"rmapshaper\")\n\n# packages\nlibrary(sf)\nlibrary(giscoR)\nlibrary(mapSpain)\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(rmapshaper)"
  },
  {
    "objectID": "blog/inserted-map/index.html#option-1",
    "href": "blog/inserted-map/index.html#option-1",
    "title": "Inserted maps with ggplot2",
    "section": "Option 1",
    "text": "Option 1\nWe can easily find some administrative boundaries of states such as Spain, where the actual geographical position of a remote territory has been changed, such as the Canary Islands. The default mapSpain package shifts the islands to the southwest of the Iberian Peninsula, a common position we see in many maps. However, these vector boundaries with displacement cannot be used in all assumptions, as this is a false geographical position and is not suitable for spatial calculations or other projections.\nWe obtain the vector boundaries using the esp_get_prov() function for the provincial level with the projection code EPSG:4326 (WGS84). In the construction of the map via ggplot2 we simply add the object to the geom_sf() geometry specifically designed for handling vector objects of class sf.\n\n# province boundaries with Canary Islands displacement\nesp &lt;- esp_get_prov(epsg = 4326)\n\n# simple map\nggplot(esp) +\n  geom_sf(colour = \"white\", linewidth = .2) +\n    theme_void()\n\n\n\n\nmapSpain also includes a function to get the separator box (esp_get_can_box()) in order to indicate the false location. With the gisco_get_countries() function we get the global country boundaries to add as geographical context, although we clipped it to the extent of the Iberian Peninsula. It may be surprising to see a curved cutout using the WGS84 projection, but this is because spherical geometry is used by default in all sf operations (sf_use_s2()).\n\n# we add the Canary Islands box and the boundaries of the environment\ncan_bx &lt;- esp_get_can_box(epsg = 4326)\nentorno &lt;- gisco_get_countries(resolution = \"10\") |&gt; \n            st_crop(xmin = -10, xmax = 5, ymin = 34, ymax = 45)\n\n# with displacement\nggplot(esp) +\n  geom_sf(data = entorno, fill = \"grey70\", colour = NA) +\n  geom_sf(colour = \"white\", linewidth = .2) +\n  geom_sf(data = can_bx, linewidth = .3, colour = \"grey80\") +\n  theme_void()"
  },
  {
    "objectID": "blog/inserted-map/index.html#option-2",
    "href": "blog/inserted-map/index.html#option-2",
    "title": "Inserted maps with ggplot2",
    "section": "Option 2",
    "text": "Option 2\nThe most correct way is to create an object for the inserted map, here the Canary Islands, and another one for the main map, mainland Spain and the Balearic Islands. In the esp_get_prov() function we must indicate that it returns the limits without displacement with the agrument moveCAN = FALSE. First, we build the map of the Canary Islands, filtering the autonomous community. The geometries geom_hline() and geom_vline() will draw the separation line to the peninsula. The second step is to create the main map excluding the Canary Islands. Then the map of the Canary Islands needs to be included as an object using the annotation_custom() function. The ggplot object must be converted to a grob with ggplotGrob() and the position area (the X and Y extreme points) must be indicated in the coordinate system of the main map. This form can be used for all types of maps.\n\n# boundaries of provinces without displacement of the Canary Islands\nesp &lt;- esp_get_prov(epsg = 4326, moveCAN = F)\n\n# Canary Island map\ncan &lt;-  filter(esp, nuts2.name == \"Canarias\") |&gt;\n          ggplot() +\n            geom_vline(xintercept = -13.3, colour = \"grey80\") +\n            geom_hline(yintercept = 29.5, colour = \"grey80\") +\n            geom_sf(fill = \"red\", colour = \"white\") +\n            coord_sf(expand = F) +\n            theme_void() \ncan\n\n\n\n\n\n# add ggplot map with annotation_custom() absolute position according to the SRC\nfilter(esp, nuts2.name != \"Canarias\") |&gt;\n  ggplot() +\n  geom_sf(data = entorno, fill = \"grey70\", colour = NA) +\n  geom_sf(colour = \"white\", linewidth = .2) +\n  annotation_custom(ggplotGrob(can),\n                    xmin = -14, xmax = -9,\n                    ymin = 33, ymax = 38) +\n  theme_void()\n\n\n\n\nIf we want to project the main map, we only need to project the position area of the inserted map first.\n\n# position box with some adjustment \npos &lt;- c(xmin = -13.5, ymin = 32.5, xmax = -8.5, ymax = 37.5) \nclass(pos) &lt;- \"bbox\" # definimos como bbox\n\n# reproject to LAEA Europe EPSG:3035\npos_prj &lt;- st_as_sfc(pos) |&gt; \n  st_set_crs(4326) |&gt;\n  st_transform(3035) |&gt; \n  st_bbox()\n\n# create the final map\nfilter(esp, nuts2.name != \"Canarias\") |&gt;\n  ggplot() +\n  geom_sf(data = entorno, fill = \"grey70\", colour = NA) +\n  geom_sf(colour = \"white\", linewidth = .2) +\n  annotation_custom(ggplotGrob(can),\n                    xmin = pos_prj[1], xmax = pos_prj[3],\n                    ymin = pos_prj[2], ymax = pos_prj[4]) +\n  coord_sf(crs = 3035) +\n  theme_void()"
  },
  {
    "objectID": "blog/inserted-map/index.html#option-3",
    "href": "blog/inserted-map/index.html#option-3",
    "title": "Inserted maps with ggplot2",
    "section": "Option 3",
    "text": "Option 3\nThe last option for inserting a secondary map is to use the inset_element() function of the patchwork package. The difference with the previous method is the relative position, which limits the use. In this case proportional symbols should not be represented as the relative insertion does not maintain the same dimensions as the main map.\n\n# provincial boundaries\nesp &lt;- esp_get_prov(epsg = 4326, moveCAN = F)\n\n# Canary Island map\ncan &lt;-  filter(esp, nuts2.name == \"Canarias\") |&gt;\n          ggplot() +\n            geom_vline(xintercept = -13.3, colour = \"grey80\") +\n            geom_hline(yintercept = 29.5, colour = \"grey80\") +\n            geom_sf(fill = \"red\", colour = \"white\") +\n            coord_sf(expand = F) +\n            theme_void() \n\n# main map\nm &lt;- filter(esp, nuts2.name != \"Canarias\") |&gt;\n  ggplot() +\n  geom_sf(colour = \"white\", linewidth = .2) +\n  theme_void()\n\n# insert with relative position \nm + inset_element(can, left = -.1, bottom = 0, \n                  right = .2, top = .2, \n                  align_to = \"full\")"
  },
  {
    "objectID": "blog/inserted-map/index.html#earth-globe-as-inset-map",
    "href": "blog/inserted-map/index.html#earth-globe-as-inset-map",
    "title": "Inserted maps with ggplot2",
    "section": "Earth globe as inset map",
    "text": "Earth globe as inset map\nThe only difficulty here is the orthogonal projection while preserving the visible geometry of the earth. The first step is the creation of the “ocean” using the radius of the earth from the point 0,0. Then we only have to cut out the visible part and reproject the boundaries. In the definition of the orthogonal projection it is possible to centre at different latitudes and longitudes by changing the +lat_0 and +lon_0 values. The ms_innerlines() functions of the rmapshaper package easily create the inner boundaries of polygons, which is recommended to avoid blurring small areas.\n\n# overall country boundaries\nwld &lt;- gisco_get_countries(resolution = \"20\")\n\n# definition of orthogonal projection\northo_crs &lt;-'+proj=ortho +lat_0=30 +lon_0=0.5 +x_0=0 +y_0=0 +R=6371000 +units=m +no_defs +type=crs'\n\n# creation of the ocean \nocean &lt;- st_point(x = c(0,0)) |&gt;\n            st_buffer(dist = 6371000) |&gt; # radio Tierra\n              st_sfc(crs = ortho_crs)\nplot(ocean)\n\n\n\n\n\n# cut out the visible land and reproject it\nworld &lt;-   st_intersection(wld, st_transform(ocean, 4326)) |&gt;\n            st_transform(crs = ortho_crs) |&gt; \n            mutate(dummy = ifelse(NAME_ENGL == \"Spain\", \"yes\", \"no\"))\n\nplot(world)\n\n\n\n\n\n# obtain only the inner limits\nworld_line &lt;- ms_innerlines(world)\nplot(world_line)\n\n\n\n# main map of Spain \nwld_map &lt;- ggplot(world) +\n            geom_sf(data = ocean, fill = \"#deebf7\", linewidth = .2) +\n            geom_sf(aes(fill = dummy), \n                    colour = NA,\n                    show.legend = F) +\n            geom_sf(data = world_line, linewidth = .05, colour = \"white\") +\n            scale_fill_manual(values = c(\"grey50\", \"red\")) + \n            theme_void()\n\n# insert the globe marking the location of Spain \nm + inset_element(wld_map, left = 0.65, bottom = 0.82, right = 1.1, top = 1, align_to = \"full\")"
  },
  {
    "objectID": "blog/night-day-world/index.html",
    "href": "blog/night-day-world/index.html",
    "title": "Visualize the day-night cycle on a world map",
    "section": "",
    "text": "In April of this year, I made an animation of the 24-hour average temperature of January 2020, also showing the day-night cycle.\nMy biggest problem was finding a way to project correctly the area at night without breaking the geometry. The easiest solution I found was rasterising the night polygon and then reprojecting it. Indeed, a vector approach could be used, but I have preferred to use raster data here."
  },
  {
    "objectID": "blog/night-day-world/index.html#external-functions",
    "href": "blog/night-day-world/index.html#external-functions",
    "title": "Visualize the day-night cycle on a world map",
    "section": "External functions",
    "text": "External functions\nThe functions to estimate the separator line between day and night are based on a javascript L.Terminator.js from the {Leaflet} package I found on stackoverflow. You can download the script with the functions here or access it on github.\n\nsource(\"terminator.R\") # import the functions"
  },
  {
    "objectID": "blog/night-day-world/index.html#custom-functions",
    "href": "blog/night-day-world/index.html#custom-functions",
    "title": "Visualize the day-night cycle on a world map",
    "section": "Custom functions",
    "text": "Custom functions\nThe primary function terminator() based on the javascript of {Leaflet} needs as arguments: the date-time, the minimum and maximum extension, as well as the resolution or the interval of longitude.\n\nt0 &lt;- Sys.time() # date and time of our operating system\nt0\n\n\ncoord_nightday &lt;- terminator(t0, -180, 180, 0.2) # estimate the day-night line\n\n# convert it into a spatial object of class sf\nline_nightday &lt;- st_linestring(as.matrix(coord_nightday)) |&gt; st_sfc(crs = 4326)\n\n# plot\nplot(line_nightday)\n\n\n\n\nIn the next step, we obtain the polygons corresponding to the day and the night that separates the previously estimated line. To do this, we create a rectangle covering the entire planet and use the st_split() function from the lwgeom package that divides the rectangle.\n\n# rectangle\nwld_bbx &lt;- st_bbox(\n  c(\n    xmin = -179.99, xmax = 179.99,\n    ymin = -90, ymax = 90\n  ),\n  crs = 4326\n) |&gt;\n  st_as_sfc() \n\n# division with the day-night line\npoly_nightday &lt;- st_split(wld_bbx, line_nightday) |&gt;\n  st_collection_extract(c(\"POLYGON\")) |&gt;\n  st_sf()\n\n# plot\nplot(poly_nightday)\n\n\n\n\nThe question now arises which of the two polygons corresponds to the night and which to the day. That will depend on what day of the year we are, given the changes in the Earth’s position concerning the Sun. Between the first summer equinox and the autumn equinox, it corresponds to the first polygon, when we can also observe the polar day at the north pole, and in the opposite case, it would be the second. The terra package only accepts its vector class called SpatVector, so we convert the vector object sf with the vect() function.\n\n# select the second polygon\npoly_nightday &lt;- slice(poly_nightday, 2) |&gt;\n  mutate(daynight = 1)\n\n# create the raster with a resolution of 0.5º and the extent of the world\nr &lt;- rast(vect(wld_bbx), resolution = .1)\n\n# rasterize the night polygon\nnight_rast &lt;- rasterize(vect(poly_nightday), r)\n\n# result in raster format\nplot(night_rast)\n\n\n\n\nIn the last step we reproject the raster to Mollweide.\n\n# define the raster projection (WGS84)\ncrs(night_rast) &lt;- \"EPSG:4326\"\n\n# reproject\nnight_rast_prj &lt;- project(night_rast, \"ESRI:54009\")\n# map\nplot(night_rast_prj)\n\n\n\n\nFinally we include the individual steps that we have done in a custom function.\n\nrast_determiner &lt;- function(x_min, date, res) {\n  # create date with time adding the number of minutes\n  t0 &lt;- as_date(date) + minutes(x_min)\n  # estimate the coordinates of the line that separates day and night\n  night_step &lt;- terminator(t0, -180, 180, 0.2) |&gt; as.matrix()\n  # pass the points to line\n  night_line &lt;- st_linestring(night_step) |&gt; st_sfc(crs = 4326)\n\n  # define the rectangle of the planet\n  wld_bbx &lt;- st_bbox(\n    c(\n    xmin = -179.99, xmax = 179.99,\n    ymin = -90, ymax = 90\n    ),\n    crs = 4326\n  ) |&gt;\n    st_as_sfc()\n\n  # divide the polygon with the day-night line\n  poly_nightday &lt;- st_split(wld_bbx, night_line) |&gt;\n    st_collection_extract(c(\"POLYGON\")) |&gt;\n    st_sf()\n\n  # select the polygon according to the date\n  if (date &lt;= make_date(year(date), 3, 20) | date &gt;= make_date(year(date), 9, 23)) {\n    poly_nightday &lt;- slice(poly_nightday, 2) |&gt;\n      mutate(daynight = 1)\n  } else {\n    poly_nightday &lt;- slice(poly_nightday, 1) |&gt;\n      mutate(daynight = 1)\n  }\n\n  # create the raster with the resolution given in the argument res\n  r &lt;- rast(vect(wld_bbx), resolution = res)\n\n  # rasterize the night polygon\n  night_rast &lt;- rasterize(vect(poly_nightday), r)\n\n  return(night_rast)\n}\n\nSince we want to obtain the area at night for different day hours, we construct a second function to apply the first one at different day intervals (in minutes).\n\nnight_determinator &lt;- function(time_seq, # minutes\n                                date = Sys.Date(), # date (system default)\n                                res = .5) { # raster resolution 0.5º\n\n  # apply the first function on a vector of day intervals\n  night_raster &lt;- map(time_seq,\n    rast_determiner,\n    date = date,\n    res = res\n  )\n\n  # convert the raster into an object with as many layers as day intervals\n  night_raster &lt;- rast(night_raster)\n\n  # define the WGS84 projection\n  crs(night_raster) &lt;- \"EPSG:4326\"\n\n  return(night_raster)\n}"
  },
  {
    "objectID": "blog/night-day-world/index.html#preparation-1",
    "href": "blog/night-day-world/index.html#preparation-1",
    "title": "Visualize the day-night cycle on a world map",
    "section": "Preparation",
    "text": "Preparation\nTo create a 24-hour animation showing the movement of the night on the Earth, we must do a few previous steps. First we get the world boundaries with the gisco_get_countries() function and reproject them to the new Winkel II projection. Then we convert the raster data into a data.frame indicating to keep missing values. We can see that each layer of the raster (of each 30-minute interval) is a column in the data.frame. We rename the columns and convert the table into a long format using the pivot_longer() function. What we do is to merge all the columns of the layers into a single one. As the last step, we exclude the missing values with the filter() function.\n\n# country boundaries\nwld &lt;- gisco_get_countries(resolution = \"10\") |&gt; st_transform(\"ESRI:54019\")\n\n# convert the raster to a data.frame with xyz\ndf_winkel &lt;- as.data.frame(night_raster_winkel, xy = TRUE, na.rm = FALSE)\n\n# rename all the columns corresponding to the day intervals\nnames(df_winkel)[3:length(df_winkel)] &lt;- str_c(\"H\", as_hms(seq(0, 1410, 30) * 60))\n\n# change to a long format\ndf_winkel &lt;- pivot_longer(df_winkel, 3:length(df_winkel), names_to = \"hour\", values_to = \"night\")\n\n# exclude missing values to reduce table size\ndf_winkel &lt;- filter(df_winkel, !is.na(night))\n\nIt only remains to create a graticule and obtain the extent of the world map.\n\n# graticule\ngrid &lt;- st_graticule() |&gt; st_transform(\"ESRI:54019\")\n\n# get the extension of the world\nbbx &lt;- st_bbox(wld)\n\nNow we will build a map at a single interval with ggplot2, adding the vector geometry using the geom_sf() function (the boundaries and the graticule) and the raster data using the geom_raster() function. In the title, we are using a unicode symbol as a clock. We also define the map’s extent in coord_sf() to keet it constant over all maps in the animation. Finally, we make use of { } from the rlang package within the filter()function to be able to filter our raster data in table form. So that our function can correctly evaluate the values that we pass in x (the intervals of the day) it is necessary to use this grammar of tidy evaluation due to data masking in tidyverse. Honestly, it is a topic for another post.\n\n# example 5 UTC\nx &lt;- \"H05:00:00\"\n# map\nggplot() +\n  # boundaries\n  geom_sf(\n    data = wld,\n    fill = \"#74a9cf\",\n    colour = \"white\",\n    linewidth = .1\n  ) +\n  # graticule\n  geom_sf(data = grid, linewidth = .1) +\n  # filtered raster data\n  geom_raster(\n    data = filter(df_winkel, hour == {{ x }}),\n    aes(x, y),\n    fill = \"grey90\",\n    alpha = .6\n  ) +\n  # title\n  labs(title = str_c(\"\\U1F551\", str_remove(x, \"H\"), \" UTC\")) +\n  # extension limits\n  coord_sf(\n    xlim = bbx[c(1, 3)],\n    ylim = bbx[c(2, 4)]\n  ) +\n  # map style\n  theme_void() +\n  theme(plot.title = element_text(hjust = .1, vjust = .9))"
  },
  {
    "objectID": "blog/night-day-world/index.html#animation",
    "href": "blog/night-day-world/index.html#animation",
    "title": "Visualize the day-night cycle on a world map",
    "section": "Animation",
    "text": "Animation\nWe create the animation by applying the walk() function, which in turn will go through the interval vector to filter our data and map each step using ggplot.\n\nwalk(str_c(\"H\", as_hms(seq(0, 1410, 30) * 60)), function(step) {\n  g &lt;- ggplot() +\n    geom_sf(\n      data = wld,\n      fill = \"#74a9cf\",\n      colour = \"white\",\n      linewidth = .1\n    ) +\n    geom_sf(\n      data = grid,\n      linewidth = .1\n    ) +\n    geom_raster(\n      data = filter(df_winkel, hour == {{ step }}), aes(x, y),\n      fill = \"grey90\",\n      alpha = .6\n    ) +\n    labs(title = str_c(\"\\U1F551\", str_remove(x, \"H\"), \" UTC\")) +\n    coord_sf(xlim = bbx[c(1, 3)], ylim = bbx[c(2, 4)]) +\n    theme_void() +\n    theme(plot.title = element_text(hjust = .1, vjust = .9))\n\n\n  ggsave(str_c(\"wld_night_\", str_remove_all(step, \":\"), \".png\"), g,\n    height = 4.3, width = 8.4, bg = \"white\", dpi = 300, units = \"in\"\n  )\n})\n\nThe creation of the final gif is done with gifski() passing it the names of the images in the order as they should appear in the animation.\n\nfiles &lt;- str_c(\"wld_night_H\", str_remove_all(as_hms(seq(0, 1410, 30) * 60), \":\"), \".png\")\n\ngifski(files, \"night_day.gif\", width = 807, height = 409, loop = TRUE, delay = 0.1)"
  },
  {
    "objectID": "blog/tidy-correlation-tests-in-r/index.html",
    "href": "blog/tidy-correlation-tests-in-r/index.html",
    "title": "Tidy correlation tests in R",
    "section": "",
    "text": "When we try to estimate the correlation coefficient between multiple variables, the task is more complicated in order to obtain a simple and tidy result. A simple solution is to use the tidy() function from the broom package. In this post we are going to estimate the correlation coefficients between the annual precipitation of several Spanish cities and climate teleconnections indices: download. The data of the teleconnections are preprocessed, but can be downloaded directly from crudata.uea.ac.uk. The daily precipitation data comes from ECA&D."
  },
  {
    "objectID": "blog/tidy-correlation-tests-in-r/index.html#packages",
    "href": "blog/tidy-correlation-tests-in-r/index.html#packages",
    "title": "Tidy correlation tests in R",
    "section": "Packages",
    "text": "Packages\nIn this post we will use the following packages:\n\n\n\n\n\n\nPackage\nDescription\n\n\n\ntidyverse\nCollection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.\n\n\nbroom\nConvert results of statistical functions (lm, t.test, cor.test, etc.) into tidy tables\n\n\nfs\nProvides a cross-platform, uniform interface to file system operations\n\n\n\n\n# install the packages if necessary\n\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"broom\")) install.packages(\"broom\")\nif (!require(\"fs\")) install.packages(\"fs\")\n\n\n# load packages\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(fs)"
  },
  {
    "objectID": "blog/tidy-correlation-tests-in-r/index.html#import-data",
    "href": "blog/tidy-correlation-tests-in-r/index.html#import-data",
    "title": "Tidy correlation tests in R",
    "section": "Import data",
    "text": "Import data\nFirst we have to import the daily precipitation of the selected weather stations.\n\nCreate a vector with all precipitation files using the function dir_ls() of the fs package.\nImport the data using the map() function of the purrr package that applies another function to a vector or list, and then we can join them together in a single data.frame with list_rbind().\nSelect the columns that interest us, b) Convert the date string into a date object using the ymd() function of the lubridate package, c) Create a new column yr with the years, d) Divide the precipitation values by 10 and reclassify absent values -9999 by NA, e) Finally, reclassify the ID of each weather station creating a factor with new labels.\n\nMore details about the use of the dir_ls() and list_rbind() functions can be found in this previous post.\n\n# precipitation files\nfiles &lt;- dir_ls(regexp = \"txt\")\nfiles\n\n\n# import all files and join them together\npr &lt;- files |&gt; map(read_csv, skip = 20) |&gt; list_rbind()\npr\n\n\n# create levels for the factor\nid &lt;- unique(pr$STAID)\n\n# the corresponding labels\nlab &lt;- c(\"Bilbao\", \"Santiago\", \"Barcelona\", \"Madrid\", \"Valencia\")\n\n# first changes\npr &lt;- select(pr, STAID, DATE, RR) |&gt;\n  mutate(\n    DATE = ymd(DATE),\n    RR = ifelse(RR == -9999, NA, RR / 10),\n    STAID = factor(STAID, id, lab),\n    yr = year(DATE)\n  )\npr\n\nWe still need to filter and calculate the annual amount of precipitation. Actually, it is not correct to sum up precipitation without taking into account that there are missing values, but it should be enough for this practice. Then, we change the table format with the spread() function, passing from a long to a wide table, that is, we want to obtain one column per weather station.\n\npr_yr &lt;- filter(pr, DATE &gt;= \"1950-01-01\", \n                DATE &lt; \"2018-01-01\") |&gt;\n          group_by(STAID, yr) |&gt;\n          summarise(pr = sum(RR, na.rm = TRUE))\npr_yr\n\n\npr_yr &lt;- spread(pr_yr, STAID, pr)\npr_yr\n\nThe next step is to import the climate teleconnection indices.\n\n# teleconnections\ntelecon &lt;- read_csv(\"teleconnections_indices.csv\")\ntelecon\n\nFinally we need to join both tables by year.\n\ndata_all &lt;- left_join(pr_yr, telecon, by = \"yr\")\ndata_all"
  },
  {
    "objectID": "blog/tidy-correlation-tests-in-r/index.html#correlation-test",
    "href": "blog/tidy-correlation-tests-in-r/index.html#correlation-test",
    "title": "Tidy correlation tests in R",
    "section": "Correlation test",
    "text": "Correlation test\nA correlation test between paired samples can be done with the cor.test() function of R Base. In this case between the annual precipitation of Bilbao and the NAO index.\n\ncor_nao_bil &lt;- cor.test(data_all$Bilbao, \n                        data_all$NAO,\n                        method = \"spearman\"\n                )\ncor_nao_bil\n\n\nstr(cor_nao_bil)\n\nWe see that the result is in an unmanageable and untidy format. It is a console summary of the correlation with all the statistical parameters necessary to get a conclusion about the relationship. The orginal structure is a list of vectors. However, the tidy() function of the broom package allows us to convert the result into a table format.\n\ntidy(cor_nao_bil)"
  },
  {
    "objectID": "blog/tidy-correlation-tests-in-r/index.html#apply-the-correlation-test-to-multiple-variables",
    "href": "blog/tidy-correlation-tests-in-r/index.html#apply-the-correlation-test-to-multiple-variables",
    "title": "Tidy correlation tests in R",
    "section": "Apply the correlation test to multiple variables",
    "text": "Apply the correlation test to multiple variables\nThe objective is to apply the correlation test to all weather stations and climate teleconnection indices.\nFirst, we must pass the table to the long format, that is, create a column/variable for the city and for the value of the corresponding precipitation. Then we repeat the same for the teleconnections indices.\n\ndata &lt;- pivot_longer(data_all, Bilbao:Valencia, names_to = \"city\", values_to = \"pr\") |&gt;\n            pivot_longer(NAO:AO, names_to = \"telecon\", values_to = \"index\")\ndata\n\nTo apply the test to all cities, we need the corresponding groupings. Therefore, we use the group_by() function for indicating the two groups: city and telecon. In addition, we apply the nest() function of the tidyr package (tidyverse collection) with the aim of creating lists of tables nested per row. In other words, in each row of each city and teleconnection index we will have a new table that contains the year, the precipitation value and the value of each teleconection, correspondingly.\n\ndata_nest &lt;- group_by(data, city, telecon) |&gt; nest()\nhead(data_nest)\n\n\nstr(head(slice(data_nest, 1)))\n\nThe next step is to create a function, in which we define the correlation test and pass it to the clean format using the tidy() function, which we apply to each groupings.\n\ncor_fun &lt;- function(df) cor.test(df$pr, df$index, method = \"spearman\") |&gt; tidy()\n\nNow we only have to apply our function to the column that contains the tables for each combination between city and teleconnection. To do this, we use the map() function that applies another function to a vector or list. What we do is create a new column that contains the result, a statistical summary table, for each combination.\n\ndata_nest &lt;- mutate(data_nest, model = map(data, cor_fun))\nhead(data_nest)\n\n\nstr(head(slice(data_nest, 1)))\n\nHow can we undo the list of tables in each row of our table?\nFirst we eliminate the column with the data and then simply we can apply the unnest() function.\n\ncorr_pr &lt;- select(data_nest, -data) |&gt; unnest()\ncorr_pr\n\nThe result is a table in which we can see the correlations and their statistical significance for each city and teleconnection index."
  },
  {
    "objectID": "blog/tidy-correlation-tests-in-r/index.html#heatmap-of-the-results",
    "href": "blog/tidy-correlation-tests-in-r/index.html#heatmap-of-the-results",
    "title": "Tidy correlation tests in R",
    "section": "Heatmap of the results",
    "text": "Heatmap of the results\nFinally, we make a heatmap of the obtained result. But, previously we create a column that indicates whether the correlation is significant with p-value less than 0.05.\n\ncorr_pr &lt;- mutate(corr_pr, sig = ifelse(p.value &lt; 0.05, \"Sig.\", \"Non Sig.\"))\n\n\nggplot() +\n  geom_tile(\n    data = corr_pr,\n    aes(city, telecon, fill = estimate),\n    linewidth = 1,\n    colour = \"white\"\n  ) +\n  geom_tile(\n    data = filter(corr_pr, sig == \"Sig.\"),\n    aes(city, telecon),\n    linewidth = 1,\n    colour = \"black\",\n    fill = NA\n  ) +\n  geom_text(\n    data = corr_pr,\n    aes(city, telecon,\n      label = round(estimate, 2),\n      fontface = ifelse(sig == \"Sig.\", \"bold\", \"plain\")\n    )\n  ) +\n  scale_fill_gradient2(breaks = seq(-1, 1, 0.2)) +\n  labs(x = NULL, y = NULL, fill = NULL) +\n  coord_cartesian(expand = F) +\n  theme_void() +\n  theme(axis.text = element_text())"
  },
  {
    "objectID": "blog/use-multidimensional-spatial-data/index.html#spain",
    "href": "blog/use-multidimensional-spatial-data/index.html#spain",
    "title": "Use of multidimensional spatial data",
    "section": "Spain",
    "text": "Spain\nTo create a map of drought severity in 2017, we must first make some modifications. With the subset() function, we obtain a layer or several as a subset. Here we select the last one to see the state of drought for the whole year.\nWe replace all values greater than -0.5 with NA in the next step. Drought is considered when the SPEI index is below -0.5 and, on the other hand, if it is above 0.5, we would speak of a wet period.\nThe raster class is not directly compatible with ggplot, so we convert it to an xyz table with longitude, latitude and the variable. When we do the same conversion of multiple layers, each column will represent one layer. Finally, we rename our index column and add a new column with different levels of drought severity.\n\n# extract layer(s) with their index\nspei_anual &lt;- subset(spei, 48)\n\n# substitute non-drought values with NA\nspei_anual[spei_anual &gt; -0.5] &lt;- NA\n\n# convert our raster into an xyz table\nspei_df &lt;- as.data.frame(spei_anual, xy = TRUE)\nhead(spei_df)\n\n# change the name of the variable\nnames(spei_df)[3] &lt;- \"spei\"\n\n# categorize the index and fix the order of the factor\nspei_df &lt;- mutate(spei_df, spei_cat = case_when(\n  spei &gt; -0.9 ~ \"slight\",\n  spei &gt; -1.5 & spei &lt; -0.9 ~ \"moderate\",\n  spei &gt; -2 & spei &lt;= -1.5 ~ \"severe\",\n  TRUE ~ \"extreme\"\n) |&gt;\n  fct_relevel(c(\"slight\", \"moderate\", \"severe\", \"extreme\")))\n\nWe can create a raster map with the geom_tile() geometry indicating longitude, latitude and the fill of the pixels with our categorized variable.\n\n# boundaries\nccaa &lt;- esp_get_ccaa() |&gt;\n  filter(!ine.ccaa.name %in% c(\"Canarias\", \"Ceuta\", \"Melilla\")) |&gt;\n  st_transform(25830)\n\n# mapa\nggplot(spei_df) +\n  geom_tile(aes(x, y, fill = spei_cat)) +\n  geom_sf(data = ccaa, fill = NA, linewdith = .1, colour = \"white\", alpha = .4) +\n  scale_fill_manual(\n    values = c(\"#ffffcc\", \"#F3641D\", \"#DE2929\", \"#8B1A1A\"),\n    na.value = NA\n  ) +\n  coord_sf() +\n  labs(fill = \"DROUGHT\") +\n  theme_void() +\n  theme(\n    legend.position = \"top\",\n    legend.justification = 0.2,\n    plot.background = element_rect(fill = \"black\", colour = NA),\n    legend.title = element_text(colour = \"white\", size = 20, hjust = .5),\n    legend.text = element_text(colour = \"white\"),\n    plot.margin = margin(t = 10),\n    legend.key.height = unit(0.3, \"lines\"),\n    legend.key.width = unit(2, \"lines\"),\n    legend.text.position = \"bottom\",\n    legend.title.position = \"top\"\n  )"
  },
  {
    "objectID": "blog/use-multidimensional-spatial-data/index.html#aragon",
    "href": "blog/use-multidimensional-spatial-data/index.html#aragon",
    "title": "Use of multidimensional spatial data",
    "section": "Aragon",
    "text": "Aragon\nIn this last map example, we select the drought situation 12 months ahead, at the beginning and end of the year. The main function we use is crop() that cuts to the extent of a spatial object; in our case, it is Aragon, then we apply the mask() function that masks all those pixels within limits leaving the others in NA.\n\n# subset first and last week 2017\nspei_sub &lt;- subset(spei, c(1, 48))\n\n# crop and mask Aragon\nspei_arag &lt;- crop(spei_sub, aragon) |&gt;\n  mask(vect(aragon))\n\n# convert the data to xyz\nspei_df_arag &lt;- as.data.frame(spei_arag, xy = TRUE)\n\n# rename layers\nnames(spei_df_arag)[3:4] &lt;- c(\"January\", \"December\")\n\n# changing to the long table format by merging both months\nspei_df_arag &lt;- pivot_longer(spei_df_arag, 3:4,\n  names_to = \"mo\",\n  values_to = \"spei\"\n) |&gt;\n  mutate(mo = fct_relevel(mo, c(\"January\", \"December\")))\n\nWe will make the two maps in the same way as the one for whole Spain. The main difference is that we use the SPEI index directly as a continuous variable. Also, to create two maps as facets in one row, we add the facet_grid() function. Finally, the index shows negative and positive values; therefore, a divergent range of colours is necessary. To centre the midpoint at 0, we must rescale the index values using the rescale() function from the scales package.\n\n# map of Aragon\nggplot(spei_df_arag) +\n  geom_tile(aes(x, y, fill = spei)) +\n  scale_fill_distiller(\n    palette = \"RdYlGn\", direction = 1,\n    values = scales::rescale(c(-2.1, 0, 0.9)),\n    breaks = seq(-2, 1, .5)\n  ) +\n  facet_grid(. ~ mo) +\n  coord_sf() +\n  labs(fill = \"SPEI-12\", title = \"Aragon\") +\n  theme_void() +\n  theme(\n    legend.position = \"top\",\n    legend.justification = 0.5,\n    legend.title = element_text(colour = \"white\", vjust = 1.1),\n    strip.text = element_text(colour = \"white\"),\n    plot.background = element_rect(fill = \"black\", colour = NA),\n    plot.title = element_text(\n      colour = \"white\", size = 20, hjust = .5, vjust = 2.5,\n      margin = margin(b = 10, t = 10)\n    ),\n    legend.text = element_text(colour = \"white\"),\n      legend.key.height = unit(0.5, \"lines\"),\n    legend.key.width = unit(3, \"lines\"),\n    plot.margin = margin(10, 10, 10, 10)\n  )"
  },
  {
    "objectID": "blog/visualize-urban-growth/index.html",
    "href": "blog/visualize-urban-growth/index.html",
    "title": "Visualize urban growth",
    "section": "",
    "text": "The General Directorate for the Cadastre of Spain has spatial information of the all buildings except for the Basque Country and Navarra. This data set is part of the implementation of INSPIRE, the Space Information Infrastructure in Europe. More information can be found here. We will use the links (urls) in ATOM format, which is an RSS type for web feeds, allowing us to obtain the download link for each municipality. Since 2022, a package to access the API is directly available CatastRo."
  },
  {
    "objectID": "blog/visualize-urban-growth/index.html#access-the-data",
    "href": "blog/visualize-urban-growth/index.html#access-the-data",
    "title": "Visualize urban growth",
    "section": "Access the data",
    "text": "Access the data\nTo import the building data we use the catr_atom_get_buildings() function.\n\nbuildings_val &lt;- catr_atom_get_buildings(\"Valencia\", to = \"Valencia\")\n\nbuildings_val[,1:5]"
  },
  {
    "objectID": "blog/visualize-urban-growth/index.html#data-preparation",
    "href": "blog/visualize-urban-growth/index.html#data-preparation",
    "title": "Visualize urban growth",
    "section": "Data preparation",
    "text": "Data preparation\nWe only have to convert the column of the construction year (beginning) into a Date class. The date column contains some dates in --01-01 format, which does not correspond to any recognizable date. Therefore, we replace the first - with 0000.\n\nbuildings_val &lt;- mutate(buildings_val,\n  beginning = str_replace(beginning, \"^-\", \"0000\") |&gt;\n    ymd_hms() |&gt; as_date()\n)"
  },
  {
    "objectID": "blog/visualize-urban-growth/index.html#distribution-chart",
    "href": "blog/visualize-urban-growth/index.html#distribution-chart",
    "title": "Visualize urban growth",
    "section": "Distribution chart",
    "text": "Distribution chart\nBefore creating the maps of the construction years, which will reflect urban growth, we will make a graph of distribution of the beginning variable. We can clearly identify periods of urban expansion. We will use the ggplot2 package with the geometry of geom_density() for this purpose.\n\n# limit the period after 1750\nfilter(buildings_val, beginning &gt;= \"1750-01-01\") |&gt;\n  ggplot(aes(beginning)) +\n  geom_density(fill = \"#2166ac\", alpha = 0.7) +\n  scale_x_date(\n    date_breaks = \"20 year\",\n    date_labels = \"%Y\"\n  ) +\n  labs(y = NULL, x = NULL, title = \"Evolution of urban development\") +\n  theme_minimal(base_family = \"Montserrat\") +\n  theme(panel.grid.minor = element_blank())"
  },
  {
    "objectID": "blog/visualize-urban-growth/index.html#buffer-of-25-km-for-valencia",
    "href": "blog/visualize-urban-growth/index.html#buffer-of-25-km-for-valencia",
    "title": "Visualize urban growth",
    "section": "Buffer of 2,5 km for Valencia",
    "text": "Buffer of 2,5 km for Valencia\nTo visualize better the distribution of urban growth, we limit the map to a radius of 2.5 km from the city center. Therefore, we use the geocode_OSM() function of the tmaptools package to obtain the coordinates of Valencia in class sf. Then we project the points to the system we use for the buildings (EPSG: 25830). The st_crs() function returns the coordinate system of a spatial object sf. Finally, we create with the function st_buffer() a buffer with 2500 m and the intersection with our building data. It is also possible to create a buffer in the form of a rectangle indicating the style with the argument endCapStyle =\" SQUARE \".\n\n# get the coordinates of Valencia\nciudad_point &lt;- tmaptools::geocode_OSM(\"Valencia\", as.sf = TRUE)\n\n#  project the points\nciudad_point &lt;- st_transform(ciudad_point, st_crs(buildings_val))\n\n# create the buffer\npoint_bf &lt;- st_buffer(ciudad_point, 2500) # radius of 2500 m\n\n\n# get the intersection between the buffer and the building\nbuildings_val25 &lt;- st_intersection(buildings_val, point_bf)"
  },
  {
    "objectID": "blog/visualize-urban-growth/index.html#prepare-data-for-mapping",
    "href": "blog/visualize-urban-growth/index.html#prepare-data-for-mapping",
    "title": "Visualize urban growth",
    "section": "Prepare data for mapping",
    "text": "Prepare data for mapping\nWe categorize the year into 15 groups using quartiles. It is also possible to modify the number of classes or the applied method (eg jenks, fisher, etc), you can find more details in the help ?classIntervals.\n\n# find 15 classes\nbr &lt;- classIntervals(year(buildings_val25$beginning), 15, \"quantile\")\n\n\n# create labels\nlab &lt;- names(print(br, under = \"&lt;\", over = \"&gt;\", cutlabels = FALSE))\n\n\n# categorize the year\nbuildings_val25 &lt;- mutate(buildings_val25,\n  yr_cl = cut(year(beginning),\n    br$brks,\n    labels = lab,\n    include.lowest = TRUE\n  )\n)"
  },
  {
    "objectID": "blog/visualize-urban-growth/index.html#map-of-valencia",
    "href": "blog/visualize-urban-growth/index.html#map-of-valencia",
    "title": "Visualize urban growth",
    "section": "Map of Valencia",
    "text": "Map of Valencia\nFor the mapping, we will use the tmap package. It is an interesting alternative to ggplot2. It is a package of functions specialized in creating thematic maps. The philosophy of the package follows the same as in ggplot2, creating multiple layers with different functions, which always start with tm_*and combine with +. Building a map with tmap always starts with tm_shape(), where the data, we want to draw, is defined. Then we add the corresponding geometry to the data type (tm_polygon(), tm_border(), tm_dots() or even tm_raster()). The tm_layout() function help us to configure the map style.\nWhen we need more colors than the maximum allowed by RColorBrewer, we can pass the colors to the colorRampPalette() function. This function interpolates a set of given colors.\n\n# colours\ncol_spec &lt;- RColorBrewer::brewer.pal(11, \"Spectral\")\n\n# colour ramp function\ncol_spec_fun &lt;- colorRampPalette(col_spec)\n\n# create the final map\ntm_shape(buildings_val25) +\n  tm_polygons(\"yr_cl\",\n    border.col = \"transparent\",\n    palette = col_spec_fun(15), # adapt to the number of classes\n    textNA = \"Without data\",\n    title = \"\"\n  ) +\n  tm_layout(\n    bg.color = \"black\",\n    outer.bg.color = \"black\",\n    legend.outside = TRUE,\n    legend.text.color = \"white\",\n    legend.text.fontfamily = \"Montserrat\",\n    panel.label.fontfamily = \"Montserrat\",\n    panel.label.color = \"white\",\n    panel.label.bg.color = \"black\",\n    panel.label.size = 5,\n    panel.label.fontface = \"bold\"\n  )\n\n\nWe can export our map using the function tmap_save(\"name.png\", dpi = 300). I recommend using the dpi = 300 argument for a good image quality.\nAn alternative way to the tmap package is ggplot2.\n\n# create the final map\nggplot(buildings_val25) +\n  geom_sf(aes(fill = yr_cl), colour = NA) +\n  scale_fill_manual(values = col_spec_fun(15), na.translate = FALSE) + # adapt to the number of classes\n  labs(title = \"VALÈNCIA\", fill = NULL) +\n  theme_void(base_family = \"Montserrat\") +\n  theme(\n    panel.background = element_rect(fill = \"black\"),\n    plot.background = element_rect(fill = \"black\"),\n    legend.justification = .5,\n    legend.text = element_text(colour = \"white\", size = 12),\n    legend.key.height = unit(3, \"lines\"),\n    legend.key.width = unit(.5, \"lines\"),\n    plot.title = element_text(\n      colour = \"white\", hjust = .5, size = 60,\n      margin = margin(t = 30)\n    ),\n    plot.caption = element_text(\n      colour = \"white\",\n      margin = margin(b = 20), hjust = .5, size = 16\n    ),\n    plot.margin = margin(r = 40, l = 40)\n  )\n\n\n# create the final map\nggplot(buildings_val25) +\n  geom_sf(aes(fill = yr_cl), colour = NA) +\n  scale_fill_manual(values = col_spec_fun(15), na.translate = FALSE) + # adapt to the number of classes\n  labs(title = \"VALÈNCIA\", fill = NULL) +\n  theme_void(base_family = \"Montserrat\") +\n  theme(\n    panel.background = element_rect(fill = \"black\"),\n    plot.background = element_rect(fill = \"black\"),\n    legend.justification = .5,\n    legend.text = element_text(colour = \"white\", size = 12),\n    legend.key.height = unit(3, \"lines\"),\n    legend.key.width = unit(.5, \"lines\"),\n    plot.title = element_text(\n      colour = \"white\", hjust = .5, size = 60,\n      margin = margin(t = 30)\n    ),\n    plot.caption = element_text(\n      colour = \"white\",\n      margin = margin(b = 20), hjust = .5, size = 16\n    ),\n    plot.margin = margin(r = 40, l = 40)\n  )\n\n\nTo export the result of ggplot we can use the function ggsave(\"name.png\")."
  },
  {
    "objectID": "blog/visualize-urban-growth/index.html#dynamic-map-with-leaflet",
    "href": "blog/visualize-urban-growth/index.html#dynamic-map-with-leaflet",
    "title": "Visualize urban growth",
    "section": "Dynamic map with leaflet",
    "text": "Dynamic map with leaflet\nA very interesting advantage is the tmap_leaflet() function of the tmap package to easily pass a map created in the same frame to leaflet.\n\n# tmap object\nm &lt;- tm_shape(buildings_val25) +\n  tm_polygons(\"yr_cl\",\n    border.col = \"transparent\",\n    palette = col_spec_fun(15), # adapt to the number of classes\n    textNA = \"Without data\",\n    title = \"\"\n  )\n\n\n# dynamic map\ntmap_leaflet(m)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dr. Dominic Royé",
    "section": "",
    "text": "I am a climate scientist and R educator with a love for community. My research is focused on biometeorology, among others, the relationship between human health and the atmospheric environment. My community projects value the partnership between open source tools and data literacy and graphicacy as a way to build power and effect change.\nLearn more about me →\n\n    \n    \n  \n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "project/index.html",
    "href": "project/index.html",
    "title": "Data Vizualization",
    "section": "",
    "text": "CLIMATE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n  \n\n\n\n\nGEOGRAPHY\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n  \n\n\n\n\nANIMATIONS\n\nSmoothed daily maximum temperature throughout the year in Europe. Data: ERA5-Land.\n\n\n\nHow cloudiness changes throughout the year in Europe. Data: METEOSAT.\n\n\n\nThe average temperature of 24 hours in August 2020 for Europe. Data: ERA5-Land.\n\n\n\nThe average temperature of 24 hours in January 2020. Data: ERA5-Land.\n\n\n\nSmoothed daily rainfall throughout the year in Australia. Data: SILO.\n\n\n\nSmoothed daily maximum temperature throughout the year in Australia. Data: SILO.\n\n\n\nSmoothed daily sea surface temperature throughout the year for the Northeast Atlantic, the Mediterranean, North and Black Sea. Data: NOAA/NODC.\n\n\n\nProbability of a summer day (maximum temperature greater than 25ºC/77ºF) through the year in Europe. Data: E-OBS.\n\n\n\nProbability of a frost day (minimum temperature less than 0ºC) through the year in Europe. Data: ERA5-Land.\n\n\n\nEvolution of 3G and 4G mobile telephony in the Iberian Peninsula from 2012 to 2022.Data: opencellid.org\n\n\n\n\n\n\n\n Back to top"
  }
]