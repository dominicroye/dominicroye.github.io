<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | Dr. Dominic Royé</title>
    <link>https://dominicroye.github.io/en/post/</link>
      <atom:link href="https://dominicroye.github.io/en/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2018-2022 Dominic Royé. All rights reserved</copyright><lastBuildDate>Mon, 20 Feb 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://dominicroye.github.io/media/logo_hu6637600e1c36fe7812a10a6623aaebda_116520_300x300_fit_lanczos_3.png</url>
      <title>Posts</title>
      <link>https://dominicroye.github.io/en/post/</link>
    </image>
    
    <item>
      <title>Tomorrow&#39;s weather</title>
      <link>https://dominicroye.github.io/en/2023/tomorrows-weather/</link>
      <pubDate>Mon, 20 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://dominicroye.github.io/en/2023/tomorrows-weather/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2023/tomorrows-weather/index.en_files/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://dominicroye.github.io/en/2023/tomorrows-weather/index.en_files/jquery/jquery.min.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://dominicroye.github.io/en/2023/tomorrows-weather/index.en_files/leaflet/leaflet.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://dominicroye.github.io/en/2023/tomorrows-weather/index.en_files/leaflet/leaflet.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://dominicroye.github.io/en/2023/tomorrows-weather/index.en_files/leafletfix/leafletfix.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://dominicroye.github.io/en/2023/tomorrows-weather/index.en_files/proj4/proj4.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://dominicroye.github.io/en/2023/tomorrows-weather/index.en_files/Proj4Leaflet/proj4leaflet.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://dominicroye.github.io/en/2023/tomorrows-weather/index.en_files/rstudio_leaflet/rstudio_leaflet.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://dominicroye.github.io/en/2023/tomorrows-weather/index.en_files/leaflet-binding/leaflet.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://dominicroye.github.io/en/2023/tomorrows-weather/index.en_files/leaflet-providers/leaflet-providers_1.9.0.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://dominicroye.github.io/en/2023/tomorrows-weather/index.en_files/leaflet-providers-plugin/leaflet-providers-plugin.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://dominicroye.github.io/en/2023/tomorrows-weather/index.en_files/clipboard/setClipboardText.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#packages&#34; id=&#34;toc-packages&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;1&lt;/span&gt; Packages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#part-i.-geoprocessing-with-google-earth-engine-gee&#34; id=&#34;toc-part-i.-geoprocessing-with-google-earth-engine-gee&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2&lt;/span&gt; Part I. Geoprocessing with Google Earth Engine (GEE)&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#before-using-gee-in-r&#34; id=&#34;toc-before-using-gee-in-r&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.1&lt;/span&gt; Before using GEE in R&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#access-the-global-forecast-system&#34; id=&#34;toc-access-the-global-forecast-system&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.2&lt;/span&gt; Access the Global Forecast System&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#dynamic-map-via-gee&#34; id=&#34;toc-dynamic-map-via-gee&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.3&lt;/span&gt; Dynamic map via GEE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#export-multiple-images&#34; id=&#34;toc-export-multiple-images&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.4&lt;/span&gt; Export multiple images&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#part-ii.-orthographic-map&#34; id=&#34;toc-part-ii.-orthographic-map&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3&lt;/span&gt; Part II. Orthographic map&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#data&#34; id=&#34;toc-data&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.1&lt;/span&gt; Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#administrative-boundaries-and-graticules&#34; id=&#34;toc-administrative-boundaries-and-graticules&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.2&lt;/span&gt; Administrative boundaries and graticules&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#map-construction&#34; id=&#34;toc-map-construction&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.3&lt;/span&gt; Map construction&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#select-tomorrow&#34; id=&#34;toc-select-tomorrow&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.3.1&lt;/span&gt; Select tomorrow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-shadow-of-the-globe&#34; id=&#34;toc-the-shadow-of-the-globe&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.3.2&lt;/span&gt; The shadow of the globe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#adding-other-layers&#34; id=&#34;toc-adding-other-layers&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.3.3&lt;/span&gt; Adding other layers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;My climate this week looks at the Arctic freeze that is sweeping across large parts of northern Asia, w/ &lt;a href=&#34;https://twitter.com/Emiliyadotcom?ref_src=twsrc%5Etfw&#34;&gt;@Emiliyadotcom&lt;/a&gt; &lt;a href=&#34;https://t.co/u49jvHKxvK&#34;&gt;https://t.co/u49jvHKxvK&lt;/a&gt;  &lt;a href=&#34;https://twitter.com/hashtag/dataviz?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#dataviz&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/gistribe?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#gistribe&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/cartography?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#cartography&lt;/a&gt; &lt;a href=&#34;https://t.co/6mX22bKZqF&#34;&gt;pic.twitter.com/6mX22bKZqF&lt;/a&gt;&lt;/p&gt;&amp;mdash; Chris Campbell (@digitalcampbell) &lt;a href=&#34;https://twitter.com/digitalcampbell/status/1619362463157456897?ref_src=twsrc%5Etfw&#34;&gt;January 28, 2023&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;p&gt;A while back I saw Chris Campbell’s global maps from the Financial Times like in this Tweet and I thought I needed to do it in R. In this first post of 2023 we’ll see how we can access the GFS (Global Forecast System) data and visualize it with &lt;code&gt;{ggplot2}&lt;/code&gt;, even though there are several ways, in this case we use the Google Earth Engine API via the &lt;code&gt;{rgee}&lt;/code&gt; package for accessing the GFS data. We will select the most recent run and calculate the maximum temperature for the next few days.&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level1&#34; number=&#34;1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Packages&lt;/h1&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;10%&#34; /&gt;
&lt;col width=&#34;89%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Package&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lubridate&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Easy manipulation of dates and times&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Simple Feature: import, export and manipulate vector data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;terra&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Import, export and manipulate raster ({raster} successor package)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;rgee&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Access to Google Earth Engine API&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;giscoR&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Administrative boundaries of the world&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ggshadow&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Extension to ggplot2 for shaded and glow geometries&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;fs&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Provides a cross-platform, uniform interface to file system operations&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ggforce&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Provides missing functionality to ggplot2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#  install the packages if necessary
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;sf&amp;quot;)) install.packages(&amp;quot;sf&amp;quot;)
if(!require(&amp;quot;terra&amp;quot;)) install.packages(&amp;quot;terra&amp;quot;)
if(!require(&amp;quot;fs&amp;quot;)) install.packages(&amp;quot;fs&amp;quot;)
if(!require(&amp;quot;rgee&amp;quot;)) install.packages(&amp;quot;rgee&amp;quot;)
if(!require(&amp;quot;giscoR&amp;quot;)) install.packages(&amp;quot;giscoR&amp;quot;)
if(!require(&amp;quot;ggshadow&amp;quot;)) install.packages(&amp;quot;ggshadow&amp;quot;)
if(!require(&amp;quot;ggforce&amp;quot;)) install.packages(&amp;quot;ggforce&amp;quot;)

#  packages
library(rgee)
library(terra)
library(sf)
library(giscoR)

library(fs)
library(tidyverse)
library(lubridate)
library(ggshadow)
library(ggforce)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;part-i.-geoprocessing-with-google-earth-engine-gee&#34; class=&#34;section level1&#34; number=&#34;2&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; Part I. Geoprocessing with Google Earth Engine (GEE)&lt;/h1&gt;
&lt;div id=&#34;before-using-gee-in-r&#34; class=&#34;section level2&#34; number=&#34;2.1&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.1&lt;/span&gt; Before using GEE in R&lt;/h2&gt;
&lt;p&gt;The first step is to sign up at earthengine.google.com. In addition, it is necessary to install &lt;em&gt;CLI&lt;/em&gt; of &lt;em&gt;gcloud&lt;/em&gt; (&lt;a href=&#34;https://cloud.google.com/sdk/docs/install?hl=es-419&#34; class=&#34;uri&#34;&gt;https://cloud.google.com/sdk/docs/install?hl=es-419&lt;/a&gt;), you just have to follow the instructions in Google. Regarding the GEE language, many functions that are applied are similar to what is known from &lt;code&gt;{tidyverse}&lt;/code&gt;. More help can be found at &lt;a href=&#34;https://r-spatial.github.io/rgee/reference/rgee-package.html&#34; class=&#34;uri&#34;&gt;https://r-spatial.github.io/rgee/reference/rgee-package.html&lt;/a&gt; and on the GEE page itself.&lt;/p&gt;
&lt;p&gt;The most essential of GEE’s native Javascript language is that it is characterized by the way of combining functions and variables using the dot, which is replaced by the $ in R. All GEE functions start with the prefix ee_* (&lt;code&gt;ee_print( )&lt;/code&gt;, &lt;code&gt;ee_image_to_drive()&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Once we have &lt;em&gt;gcloud&lt;/em&gt; and the &lt;code&gt;{rgee}&lt;/code&gt; package installed we can proceed to create the Python virtual environment. The &lt;code&gt;ee_install()&lt;/code&gt; function takes care of installing Anaconda 3 and all necessary packages. To check the correct installation of Python, and particularly of the &lt;em&gt;numpy&lt;/em&gt; and &lt;em&gt;earthengine-api&lt;/em&gt; packages, we can use &lt;code&gt;ee_check()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ee_install() # create python virtual environment
ee_check() # check if everything is correct&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before programming with GEE’s own syntax, GEE must be authenticated and initialized using the &lt;code&gt;ee_Initialize()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ee_Initialize(drive = TRUE) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── rgee 1.1.5 ─────────────────────────────────────── earthengine-api 0.1.339 ── 
##  ✔ user: not_defined
##  ✔ Google Drive credentials:
 ✔ Google Drive credentials:  FOUND
##  ✔ Initializing Google Earth Engine:
 ✔ Initializing Google Earth Engine:  DONE!
## 
 ✔ Earth Engine account: users/dominicroye 
## ────────────────────────────────────────────────────────────────────────────────&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;access-the-global-forecast-system&#34; class=&#34;section level2&#34; number=&#34;2.2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.2&lt;/span&gt; Access the Global Forecast System&lt;/h2&gt;
&lt;p&gt;A time series of images or multidimensional data is called an &lt;em&gt;ImageCollection&lt;/em&gt; in GEE. Each dataset is assigned an ID and we can access it by making the following call &lt;code&gt;ee$ImageCollection(&#39;ID_IMAGECOLLECTION&#39;)&lt;/code&gt;. There are helper functions that allow conversion of purely R classes to Javascript, e.g. for dates &lt;code&gt;rdate_to_eedate()&lt;/code&gt;. The first thing we do is to filter to the most recent date with the last run of the GFS model.&lt;/p&gt;
&lt;p&gt;We have to know that, unlike R, only when GEE tasks are sent, the calculation are executed on the servers using all the created GEE objects. Most steps create only &lt;em&gt;EarthEngine&lt;/em&gt; objects what you will see soon in this post.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## GFS forecast
dataset &amp;lt;- ee$ImageCollection(&amp;#39;NOAA/GFS0P25&amp;#39;)$filter(ee$Filter$date(rdate_to_eedate(today()-days(1)),
                                                                    rdate_to_eedate(today()+days(1))))
dataset&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## EarthEngine Object: ImageCollection&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The model runs every 6 hours (0, 6, 12, 18), so the &lt;code&gt;ee_get_date_ic()&lt;/code&gt; function extracts the dates to choose the most recent one. This is the first time that calculations are run.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# vector of unique run dates
last_run &amp;lt;- ee_get_date_ic(dataset)$time_start |&amp;gt; unique()
last_run&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2023-02-22 00:00:00 GMT&amp;quot; &amp;quot;2023-02-22 06:00:00 GMT&amp;quot;
## [3] &amp;quot;2023-02-22 12:00:00 GMT&amp;quot; &amp;quot;2023-02-22 18:00:00 GMT&amp;quot;
## [5] &amp;quot;2023-02-23 00:00:00 GMT&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# select the last one
last_run &amp;lt;- max(last_run)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next we filter the date of the last run and select the band of the air temperature at 2m. Forecast dates are attributes of each model run up to 336 hours (14 days) from the day of execution. When we want to make changes to each image in an ImageCollection we must make use of the &lt;code&gt;map()&lt;/code&gt; function, similar to the one we know from the &lt;code&gt;{purrr}&lt;/code&gt; package. In this case we redefine the date of each image (&lt;em&gt;system:time_start&lt;/em&gt;: run date) by that of the forecast (&lt;em&gt;forecast_time&lt;/em&gt;). It is important that the R function to apply is inside &lt;code&gt;ee_utils_pyfunc()&lt;/code&gt;, which translates it into Python. Then we extract the dates from the 14 day forecast.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# last run and variable selection
temp &amp;lt;- dataset$filter(ee$Filter$date(rdate_to_eedate(last_run)))$select(&amp;#39;temperature_2m_above_ground&amp;#39;)

# define the forecast dates for each hour
forcast_time &amp;lt;- temp$map(ee_utils_pyfunc(function(img)  {
  
 return(ee$Image(img)$set(&amp;#39;system:time_start&amp;#39;,ee$Image(img)$get(&amp;quot;forecast_time&amp;quot;)))

  })
)

# get the forecast dates
date_forcast &amp;lt;- ee_get_date_ic(forcast_time)
head(date_forcast)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                            id          time_start
## 1 NOAA/GFS0P25/2023022300F000 2023-02-23 00:00:00
## 2 NOAA/GFS0P25/2023022300F001 2023-02-23 01:00:00
## 3 NOAA/GFS0P25/2023022300F002 2023-02-23 02:00:00
## 4 NOAA/GFS0P25/2023022300F003 2023-02-23 03:00:00
## 5 NOAA/GFS0P25/2023022300F004 2023-02-23 04:00:00
## 6 NOAA/GFS0P25/2023022300F005 2023-02-23 05:00:00&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we could export the hourly temperature data, but it would also be possible to estimate the maximum or minimum daily temperature for the next 14 days. To achieve this we define the beginning and end of the period, and calculate the number of days. What we do in simple terms is map over the number of days to filter on each day and apply the &lt;code&gt;max()&lt;/code&gt; function or any other similar function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# define start end of the period
endDate &amp;lt;- rdate_to_eedate(round_date(max(date_forcast$time_start)-days(1), &amp;quot;day&amp;quot;))
startDate &amp;lt;- rdate_to_eedate(round_date(min(date_forcast$time_start), &amp;quot;day&amp;quot;))

# number of days
numberOfDays &amp;lt;- endDate$difference(startDate, &amp;#39;days&amp;#39;)

# calculate the daily maximum
daily &amp;lt;- ee$ImageCollection(
  ee$List$sequence(0, numberOfDays$subtract(1))$
  map(ee_utils_pyfunc(function (dayOffset) {
    start = startDate$advance(dayOffset, &amp;#39;days&amp;#39;)
    end = start$advance(1, &amp;#39;days&amp;#39;)
    return(forcast_time$
    filterDate(start, end)$
    max()$ # alternativa: min(), mean()
    set(&amp;#39;system:time_start&amp;#39;, start$millis()))
  }))
)

# dates of the daily maximum
head(ee_get_date_ic(daily))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      id time_start
## 1 no_id 2023-02-23
## 2 no_id 2023-02-24
## 3 no_id 2023-02-25
## 4 no_id 2023-02-26
## 5 no_id 2023-02-27
## 6 no_id 2023-02-28&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;dynamic-map-via-gee&#34; class=&#34;section level2&#34; number=&#34;2.3&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.3&lt;/span&gt; Dynamic map via GEE&lt;/h2&gt;
&lt;p&gt;Since there is the possibility of adding images to a dynamic map in the GEE code editor, we can also do it from R using the GEE function &lt;a href=&#34;https://developers.google.com/earth%20-engine/apidocs/map-addlayer&#34;&gt;&lt;code&gt;Map.addLayer()&lt;/code&gt;&lt;/a&gt;. We simply select the first day with &lt;code&gt;first()&lt;/code&gt;. In the other argument we define the range of the temperature values and the color ramp.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Map$addLayer(
       eeObject = daily$first(),
       visParams = list(min = -45, max = 45,
                        palette = rev(RColorBrewer::brewer.pal(11, &amp;quot;RdBu&amp;quot;))),
       name = &amp;quot;GFS&amp;quot;) + 
Map$addLegend(
  list(min = -45, max = 45, 
       palette = rev(RColorBrewer::brewer.pal(11, &amp;quot;RdBu&amp;quot;))), 
       name = &amp;quot;Maximum temperature&amp;quot;, 
       position = &amp;quot;bottomright&amp;quot;, 
       bins = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;leaflet html-widget html-fill-item-overflow-hidden html-fill-item&#34; id=&#34;htmlwidget-1&#34; style=&#34;width:672px;height:480px;&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;options&#34;:{&#34;minZoom&#34;:1,&#34;maxZoom&#34;:24,&#34;crs&#34;:{&#34;crsClass&#34;:&#34;L.CRS.EPSG3857&#34;,&#34;code&#34;:null,&#34;proj4def&#34;:null,&#34;projectedBounds&#34;:null,&#34;options&#34;:{}},&#34;preferCanvas&#34;:false,&#34;bounceAtZoomLimits&#34;:false,&#34;maxBounds&#34;:[[[-90,-370]],[[90,370]]]},&#34;calls&#34;:[{&#34;method&#34;:&#34;addProviderTiles&#34;,&#34;args&#34;:[&#34;CartoDB.Positron&#34;,&#34;CartoDB.Positron&#34;,&#34;CartoDB.Positron&#34;,{&#34;errorTileUrl&#34;:&#34;&#34;,&#34;noWrap&#34;:false,&#34;detectRetina&#34;:false,&#34;pane&#34;:&#34;tilePane&#34;,&#34;maxZoom&#34;:24}]},{&#34;method&#34;:&#34;addProviderTiles&#34;,&#34;args&#34;:[&#34;OpenStreetMap&#34;,&#34;OpenStreetMap&#34;,&#34;OpenStreetMap&#34;,{&#34;errorTileUrl&#34;:&#34;&#34;,&#34;noWrap&#34;:false,&#34;detectRetina&#34;:false,&#34;pane&#34;:&#34;tilePane&#34;,&#34;maxZoom&#34;:24}]},{&#34;method&#34;:&#34;addProviderTiles&#34;,&#34;args&#34;:[&#34;CartoDB.DarkMatter&#34;,&#34;CartoDB.DarkMatter&#34;,&#34;CartoDB.DarkMatter&#34;,{&#34;errorTileUrl&#34;:&#34;&#34;,&#34;noWrap&#34;:false,&#34;detectRetina&#34;:false,&#34;pane&#34;:&#34;tilePane&#34;,&#34;maxZoom&#34;:24}]},{&#34;method&#34;:&#34;addProviderTiles&#34;,&#34;args&#34;:[&#34;Esri.WorldImagery&#34;,&#34;Esri.WorldImagery&#34;,&#34;Esri.WorldImagery&#34;,{&#34;errorTileUrl&#34;:&#34;&#34;,&#34;noWrap&#34;:false,&#34;detectRetina&#34;:false,&#34;pane&#34;:&#34;tilePane&#34;,&#34;maxZoom&#34;:24}]},{&#34;method&#34;:&#34;addProviderTiles&#34;,&#34;args&#34;:[&#34;OpenTopoMap&#34;,&#34;OpenTopoMap&#34;,&#34;OpenTopoMap&#34;,{&#34;errorTileUrl&#34;:&#34;&#34;,&#34;noWrap&#34;:false,&#34;detectRetina&#34;:false,&#34;pane&#34;:&#34;tilePane&#34;,&#34;maxZoom&#34;:24}]},{&#34;method&#34;:&#34;addLayersControl&#34;,&#34;args&#34;:[[&#34;CartoDB.Positron&#34;,&#34;OpenStreetMap&#34;,&#34;CartoDB.DarkMatter&#34;,&#34;Esri.WorldImagery&#34;,&#34;OpenTopoMap&#34;],[],{&#34;collapsed&#34;:true,&#34;autoZIndex&#34;:true,&#34;position&#34;:&#34;topleft&#34;}]},{&#34;method&#34;:&#34;addScaleBar&#34;,&#34;args&#34;:[{&#34;maxWidth&#34;:100,&#34;metric&#34;:true,&#34;imperial&#34;:true,&#34;updateWhenIdle&#34;:true,&#34;position&#34;:&#34;bottomleft&#34;}]},{&#34;method&#34;:&#34;addTiles&#34;,&#34;args&#34;:[&#34;https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/a008b4a6531d66c1e0fee8a84fcedf1a-1bfc3a7d5d0add3872bf4326ef07976c/tiles/{z}/{x}/{y}&#34;,&#34;GFS&#34;,&#34;GFS&#34;,{&#34;minZoom&#34;:0,&#34;maxZoom&#34;:24,&#34;tileSize&#34;:256,&#34;subdomains&#34;:&#34;abc&#34;,&#34;errorTileUrl&#34;:&#34;&#34;,&#34;tms&#34;:false,&#34;noWrap&#34;:false,&#34;zoomOffset&#34;:0,&#34;zoomReverse&#34;:false,&#34;opacity&#34;:1,&#34;zIndex&#34;:1,&#34;detectRetina&#34;:false}]},{&#34;method&#34;:&#34;addLayersControl&#34;,&#34;args&#34;:[[&#34;CartoDB.Positron&#34;,&#34;OpenStreetMap&#34;,&#34;CartoDB.DarkMatter&#34;,&#34;Esri.WorldImagery&#34;,&#34;OpenTopoMap&#34;],&#34;GFS&#34;,{&#34;collapsed&#34;:true,&#34;autoZIndex&#34;:true,&#34;position&#34;:&#34;topleft&#34;}]},{&#34;method&#34;:&#34;hideGroup&#34;,&#34;args&#34;:[null]},{&#34;method&#34;:&#34;addLegend&#34;,&#34;args&#34;:[{&#34;colors&#34;:[&#34;#053061 , #154D8A 5.55555555555556%, #3984BB 16.6666666666667%, #82BAD8 27.7777777777778%, #CAE1EE 38.8888888888889%, #F7F7F7 50%, #FDD5BF 61.1111111111111%, #EE9676 72.2222222222222%, #CA4C41 83.3333333333333%, #900C26 94.4444444444444%, #67001F &#34;],&#34;labels&#34;:[&#34;-40&#34;,&#34;-30&#34;,&#34;-20&#34;,&#34;-10&#34;,&#34;0&#34;,&#34;10&#34;,&#34;20&#34;,&#34;30&#34;,&#34;40&#34;],&#34;na_color&#34;:null,&#34;na_label&#34;:&#34;NA&#34;,&#34;opacity&#34;:1,&#34;position&#34;:&#34;bottomright&#34;,&#34;type&#34;:&#34;numeric&#34;,&#34;title&#34;:&#34;Maximum temperature&#34;,&#34;extra&#34;:{&#34;p_1&#34;:0.0555555555555556,&#34;p_n&#34;:0.944444444444444},&#34;layerId&#34;:null,&#34;className&#34;:&#34;info legend&#34;,&#34;group&#34;:null}]}],&#34;setView&#34;:[[0,0],1,[]]},&#34;evals&#34;:[],&#34;jsHooks&#34;:{&#34;render&#34;:[{&#34;code&#34;:&#34;function(el, x, data) {\n  return (\n      function(el, x, data) {\n      // get the leaflet map\n      var map = this; //HTMLWidgets.find(&#39;#&#39; + el.id);\n      // we need a new div element because we have to handle\n      // the mouseover output separately\n      // debugger;\n      function addElement () {\n      // generate new div Element\n      var newDiv = $(document.createElement(&#39;div&#39;));\n      // append at end of leaflet htmlwidget container\n      $(el).append(newDiv);\n      //provide ID and style\n      newDiv.addClass(&#39;lnlt&#39;);\n      newDiv.css({\n      &#39;position&#39;: &#39;relative&#39;,\n      &#39;bottomleft&#39;:  &#39;0px&#39;,\n      &#39;background-color&#39;: &#39;rgba(255, 255, 255, 0.7)&#39;,\n      &#39;box-shadow&#39;: &#39;0 0 2px #bbb&#39;,\n      &#39;background-clip&#39;: &#39;padding-box&#39;,\n      &#39;margin&#39;: &#39;0&#39;,\n      &#39;padding-left&#39;: &#39;5px&#39;,\n      &#39;color&#39;: &#39;#333&#39;,\n      &#39;font&#39;: &#39;9px/1.5 \&#34;Helvetica Neue\&#34;, Arial, Helvetica, sans-serif&#39;,\n      &#39;z-index&#39;: &#39;700&#39;,\n      });\n      return newDiv;\n      }\n\n\n      // check for already existing lnlt class to not duplicate\n      var lnlt = $(el).find(&#39;.lnlt&#39;);\n\n      if(!lnlt.length) {\n      lnlt = addElement();\n\n      // grab the special div we generated in the beginning\n      // and put the mousmove output there\n\n      map.on(&#39;mousemove&#39;, function (e) {\n      if (e.originalEvent.ctrlKey) {\n      if (document.querySelector(&#39;.lnlt&#39;) === null) lnlt = addElement();\n      lnlt.text(\n                           &#39; lon: &#39; + (e.latlng.lng).toFixed(5) +\n                           &#39; | lat: &#39; + (e.latlng.lat).toFixed(5) +\n                           &#39; | zoom: &#39; + map.getZoom() +\n                           &#39; | x: &#39; + L.CRS.EPSG3857.project(e.latlng).x.toFixed(0) +\n                           &#39; | y: &#39; + L.CRS.EPSG3857.project(e.latlng).y.toFixed(0) +\n                           &#39; | epsg: 3857 &#39; +\n                           &#39; | proj4: +proj=merc +a=6378137 +b=6378137 +lat_ts=0.0 +lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m +nadgrids=@null +no_defs &#39;);\n      } else {\n      if (document.querySelector(&#39;.lnlt&#39;) === null) lnlt = addElement();\n      lnlt.text(\n                      &#39; lon: &#39; + (e.latlng.lng).toFixed(5) +\n                      &#39; | lat: &#39; + (e.latlng.lat).toFixed(5) +\n                      &#39; | zoom: &#39; + map.getZoom() + &#39; &#39;);\n      }\n      });\n\n      // remove the lnlt div when mouse leaves map\n      map.on(&#39;mouseout&#39;, function (e) {\n      var strip = document.querySelector(&#39;.lnlt&#39;);\n      if( strip !==null) strip.remove();\n      });\n\n      };\n\n      //$(el).keypress(67, function(e) {\n      map.on(&#39;preclick&#39;, function(e) {\n      if (e.originalEvent.ctrlKey) {\n      if (document.querySelector(&#39;.lnlt&#39;) === null) lnlt = addElement();\n      lnlt.text(\n                      &#39; lon: &#39; + (e.latlng.lng).toFixed(5) +\n                      &#39; | lat: &#39; + (e.latlng.lat).toFixed(5) +\n                      &#39; | zoom: &#39; + map.getZoom() + &#39; &#39;);\n      var txt = document.querySelector(&#39;.lnlt&#39;).textContent;\n      console.log(txt);\n      //txt.innerText.focus();\n      //txt.select();\n      setClipboardText(&#39;\&#34;&#39; + txt + &#39;\&#34;&#39;);\n      }\n      });\n\n      }\n      ).call(this.getMap(), el, x, data);\n}&#34;,&#34;data&#34;:null},{&#34;code&#34;:&#34;function(el, x, data) {\n  return (function(el,x,data){\n           var map = this;\n\n           map.on(&#39;keypress&#39;, function(e) {\n               console.log(e.originalEvent.code);\n               var key = e.originalEvent.code;\n               if (key === &#39;KeyE&#39;) {\n                   var bb = this.getBounds();\n                   var txt = JSON.stringify(bb);\n                   console.log(txt);\n\n                   setClipboardText(&#39;\\&#39;&#39; + txt + &#39;\\&#39;&#39;);\n               }\n           })\n        }).call(this.getMap(), el, x, data);\n}&#34;,&#34;data&#34;:null}]}}&lt;/script&gt;
&lt;/div&gt;
&lt;div id=&#34;export-multiple-images&#34; class=&#34;section level2&#34; number=&#34;2.4&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.4&lt;/span&gt; Export multiple images&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;{rgee}&lt;/code&gt; package has a very useful function for exporting an &lt;em&gt;ImageCollection&lt;/em&gt;: &lt;code&gt;ee_imagecollection_to_local()&lt;/code&gt;. Before using it, we need to set a region, the one that is intended to be exported. In this case, we export the entire globe with a rectangle covering the whole Earth.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# earth extension
geom &amp;lt;- ee$Geometry$Polygon(coords = list(
  c(-180, -90), 
  c(180, -90),
  c(180, 90),
  c(-180, 90),
  c(-180, -90)
),
proj = &amp;quot;EPSG:4326&amp;quot;,
geodesic = FALSE)

geom # EarthEngine object of type geometry&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## EarthEngine Object: Geometry&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# temporary download folder
tmp &amp;lt;- tempdir()

# run tasks and download each day
ic_drive_files_2 &amp;lt;- ee_imagecollection_to_local(
  ic = daily$filter(ee$Filter$date(rdate_to_eedate(today()), rdate_to_eedate(today()+days(2)))), # we choose only the next 2 days
  region = geom,
  scale = 20000,# resolution 
  lazy = FALSE,
  dsn = path(tmp, &amp;quot;rast_&amp;quot;), # name of each raster
  add_metadata = TRUE
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ───────────────────────────────────── Downloading ImageCollection - via drive ──- region parameters
##  sfg      : POLYGON ((-180 -90, 180 -90, 180 90, -180 90, -180 -90)) 
##  CRS      : GEOGCRS[&amp;quot;WGS 84&amp;quot;,
##     DATUM[&amp;quot;World Geodetic System 1984&amp;quot;,
##         ELLIPSOID[&amp;quot;WGS 84&amp;quot;,6378137,298.257223563, ..... 
##  geodesic : FALSE 
##  evenOdd  : TRUE 
## 
## Downloading: C:/Users/xeo19/AppData/Local/Temp/Rtmp8UpV6S/rast_0.tif
## Downloading: C:/Users/xeo19/AppData/Local/Temp/Rtmp8UpV6S/rast_1.tif
##  ────────────────────────────────────────────────────────────────────────────────&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;part-ii.-orthographic-map&#34; class=&#34;section level1&#34; number=&#34;3&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; Part II. Orthographic map&lt;/h1&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34; number=&#34;3.1&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.1&lt;/span&gt; Data&lt;/h2&gt;
&lt;p&gt;Of course, the first step is to import the data with the help of &lt;code&gt;rast()&lt;/code&gt;. We also define the name of each layer according to its temporal dimension correctly.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# paths to downloaded data
forecast_world &amp;lt;- dir_ls(tmp, regexp = &amp;quot;tif&amp;quot;)

# guarantee the file order 
file_ord &amp;lt;- str_extract(forecast_world, &amp;quot;_[0-9]{1,2}&amp;quot;) |&amp;gt; parse_number()

forecast_rast &amp;lt;- rast(forecast_world[order(file_ord)]) # import
forecast_rast&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class       : SpatRaster 
## dimensions  : 1002, 2004, 2  (nrow, ncol, nlyr)
## resolution  : 0.1796631, 0.1796631  (x, y)
## extent      : -180.0224, 180.0224, -90.01119, 90.01119  (xmin, xmax, ymin, ymax)
## coord. ref. : lon/lat WGS 84 (EPSG:4326) 
## sources     : rast_0.tif  
##               rast_1.tif  
## names       : temperature_2m_above_ground, temperature_2m_above_ground&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# define the temporal dimension as the name of each layer
names(forecast_rast) &amp;lt;- seq(today(), today() + days(1), &amp;quot;day&amp;quot;)
forecast_rast&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class       : SpatRaster 
## dimensions  : 1002, 2004, 2  (nrow, ncol, nlyr)
## resolution  : 0.1796631, 0.1796631  (x, y)
## extent      : -180.0224, 180.0224, -90.01119, 90.01119  (xmin, xmax, ymin, ymax)
## coord. ref. : lon/lat WGS 84 (EPSG:4326) 
## sources     : rast_0.tif  
##               rast_1.tif  
## names       : 2023-02-23, 2023-02-24&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# plot
plot(forecast_rast)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2023/tomorrows-weather/index.en_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now we can define the orthographic projection indicating with +lat_0 and +lon_0 the center of the projection. We then reproject and convert the raster to a &lt;em&gt;data.frame&lt;/em&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# projection definition
ortho_crs &amp;lt;-&amp;#39;+proj=ortho +lat_0=51 +lon_0=0.5 +x_0=0 +y_0=0 +R=6371000 +units=m +no_defs +type=crs&amp;#39;

# reproject the raster
ras_ortho &amp;lt;- project(forecast_rast, ortho_crs)

# convert the raster to a data.frame of xyz
forecast_df &amp;lt;- as.data.frame(ras_ortho, xy = TRUE)

# transform to a long format
forecast_df &amp;lt;- pivot_longer(forecast_df, 3:length(forecast_df), names_to = &amp;quot;date&amp;quot;, values_to = &amp;quot;ta&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;administrative-boundaries-and-graticules&#34; class=&#34;section level2&#34; number=&#34;3.2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.2&lt;/span&gt; Administrative boundaries and graticules&lt;/h2&gt;
&lt;p&gt;We import the administrative boundaries with &lt;code&gt;gisco_get_countries()&lt;/code&gt; which we need prepare for the orthographic projection. In the same way we create the graticule using &lt;code&gt;st_graticule()&lt;/code&gt;. In order to preserve the geometry, it will be necessary to cut to only the visible part. The ocean is created starting from a point at 0.0 with the radius of the earth. Using the &lt;code&gt;st_intersection()&lt;/code&gt; function we reduce to the visible part and reproject the boundaries.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# obtain the administrative limits
world_poly &amp;lt;- gisco_get_countries(year = &amp;quot;2016&amp;quot;, epsg = &amp;quot;4326&amp;quot;, resolution = &amp;quot;10&amp;quot;) 

# get the global graticule
grid &amp;lt;- st_graticule()

# define what would be ocean
ocean &amp;lt;- st_point(x = c(0,0)) |&amp;gt;
            st_buffer(dist = 6371000) |&amp;gt; # earth radius
              st_sfc(crs = ortho_crs)
plot(ocean)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2023/tomorrows-weather/index.en_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# select only visible from the boundaries and reproject
world &amp;lt;- world_poly |&amp;gt;
            st_intersection(st_transform(ocean, 4326)) |&amp;gt;
            st_transform(crs = ortho_crs) # 
plot(world)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2023/tomorrows-weather/index.en_files/figure-html/unnamed-chunk-14-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For the graticules we must repeat the same selection, although we previously limit the grid of lines to the ocean. The ocean boundary is used to create the globe’s shadow, but to use it in &lt;code&gt;geom_glowpath()&lt;/code&gt; you need to convert it to a &lt;em&gt;data.frame&lt;/em&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# eliminate the lines that pass over the continents
grid_crp &amp;lt;- st_difference(grid, st_union(world_poly))

# select the visible part
grid_crp &amp;lt;- st_intersection(grid_crp, st_transform(ocean, 4326)) |&amp;gt;
                  st_transform(crs = ortho_crs)

plot(grid_crp)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2023/tomorrows-weather/index.en_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# convert the boundary of the globe into a data.frame
ocean_df &amp;lt;- st_cast(ocean, &amp;quot;LINESTRING&amp;quot;) |&amp;gt; st_coordinates() |&amp;gt; as.data.frame()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;map-construction&#34; class=&#34;section level2&#34; number=&#34;3.3&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.3&lt;/span&gt; Map construction&lt;/h2&gt;
&lt;div id=&#34;select-tomorrow&#34; class=&#34;section level3&#34; number=&#34;3.3.1&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.3.1&lt;/span&gt; Select tomorrow&lt;/h3&gt;
&lt;p&gt;First we select the day of tomorrow, in my case when I write this post it is February 22, 2023. In addition, we limit the temperature range to -45ºC and +45ºC.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;forecast_tomorrow &amp;lt;- filter(forecast_df, date == today() + days(1)) |&amp;gt;
                        mutate(ta_limit = case_when(ta &amp;gt; 45 ~ 45,
                                              ta &amp;lt; -45 ~ -45,
                                               TRUE ~ ta))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-shadow-of-the-globe&#34; class=&#34;section level3&#34; number=&#34;3.3.2&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.3.2&lt;/span&gt; The shadow of the globe&lt;/h3&gt;
&lt;p&gt;We create the shadow effect using the &lt;code&gt;geom_glowpath()&lt;/code&gt; function from the &lt;code&gt;{ggshadow}&lt;/code&gt; package. Aiming for a more smooth transition I duplicate this layer with different transparency and shadow settings.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# build a simple shadow
ggplot() + 
   geom_glowpath(data = ocean_df, 
                aes(X, Y, group = &amp;quot;L1&amp;quot;),
                shadowcolor=&amp;#39;grey90&amp;#39;,
                     colour = &amp;quot;white&amp;quot;,
                alpha = .01,
                shadowalpha=0.05,
                shadowsize = 1.5) +
    geom_glowpath(data = ocean_df, 
                aes(X, Y, group = &amp;quot;L1&amp;quot;),
                shadowcolor=&amp;#39;grey90&amp;#39;,
                       colour = &amp;quot;white&amp;quot;,
                alpha = .01,
                shadowalpha=0.01,
                shadowsize = 1) +
   coord_sf() +
   theme_void()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2023/tomorrows-weather/index.en_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# combining several layers of shadow
g &amp;lt;- ggplot() +
   geom_glowpath(data = ocean_df, 
                aes(X, Y, group = &amp;quot;L1&amp;quot;),
                shadowcolor=&amp;#39;grey90&amp;#39;,
                     colour = &amp;quot;white&amp;quot;,
                alpha = .01,
                shadowalpha=0.05,
                shadowsize = 1.8) +
   geom_glowpath(data = ocean_df, 
                aes(X, Y, group = &amp;quot;L1&amp;quot;),
                shadowcolor=&amp;#39;grey90&amp;#39;,
                       colour = &amp;quot;white&amp;quot;,
                alpha = .01,
                shadowalpha=0.02,
                shadowsize = 1) +
   geom_glowpath(data = ocean_df, 
                aes(X, Y, group = &amp;quot;L1&amp;quot;),
                shadowcolor=&amp;#39;grey90&amp;#39;,
                       colour = &amp;quot;white&amp;quot;,
                alpha = .01,
                shadowalpha=0.01,
                shadowsize = .5) &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;adding-other-layers&#34; class=&#34;section level3&#34; number=&#34;3.3.3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.3.3&lt;/span&gt; Adding other layers&lt;/h3&gt;
&lt;p&gt;In the next step we add the temperature layer and both vector layers.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;g2 &amp;lt;- g + geom_raster(data = forecast_tomorrow, aes(x, y, fill = ta_limit)) +
          geom_sf(data = grid_crp, 
                  colour = &amp;quot;white&amp;quot;, 
                  linewidth = .2) +
          geom_sf(data = world, 
                   fill = NA,
                   colour = &amp;quot;grey10&amp;quot;,
                   linewidth = .2) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What we need to add are the last definitions of the color, the legend and the general style of the map.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;g2 + scale_fill_distiller(palette = &amp;quot;RdBu&amp;quot;, 
                          limits = c(-45, 45),
                          breaks = c(-45, -25, 0, 25, 45)) +
     guides(fill = guide_colourbar(barwidth = 15, 
                                   barheight = .5, 
                                   title.position = &amp;quot;top&amp;quot;,
                                   title.hjust = .5)) +
  coord_sf() +
  labs(fill = str_wrap(&amp;quot;Maximum temperature at 2 meters for February 14&amp;quot;, 35)) +
  theme_void() +
  theme(legend.position = &amp;quot;bottom&amp;quot;,
        legend.title = element_text(size = 7),
        plot.margin = margin(10, 10, 10, 10)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2023/tomorrows-weather/index.en_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If we wanted to add labels for the points with the lowest and highest temperatures, we would need to filter the extremes from our table.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;labeling &amp;lt;- slice(forecast_tomorrow, which.min(ta), which.max(ta))
labeling&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 × 5
##           x         y date          ta ta_limit
##       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 -1397101.  3923352. 2023-02-24 -42.5    -42.5
## 2  2119554. -4121598. 2023-02-24  43.9     43.9&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;geom_mark_circle()&lt;/code&gt; function allows you to include a circle label at any position. We create the label using &lt;code&gt;str_glue()&lt;/code&gt; where the variable will be replaced by each temperature of both extremes, at the same time we can define the format of the number with &lt;code&gt;number()&lt;/code&gt; from the &lt;code&gt;{scales}&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;g2 +  geom_mark_circle(data = labeling, 
                       aes(x, y, 
                          description = str_glue(&amp;#39;{scales::number(ta, accuracy = .1, decimal.mark = &amp;quot;.&amp;quot;, style_positive = &amp;quot;plus&amp;quot;, suffix = &amp;quot;ºC&amp;quot;)}&amp;#39;)
                          ), 
                   expand = unit(1, &amp;quot;mm&amp;quot;), 
                   label.buffer = unit(4, &amp;quot;mm&amp;quot;),
                   label.margin = margin(1, 1, 1, 1, &amp;quot;mm&amp;quot;),
                   con.size = 0.3,
                   label.fontsize = 8,
                   label.fontface = &amp;quot;bold&amp;quot;,
                   con.type = &amp;quot;straight&amp;quot;,
                  label.fill = alpha(&amp;quot;white&amp;quot;, .5)) +
     scale_fill_distiller(palette = &amp;quot;RdBu&amp;quot;, 
                          limits = c(-45, 45),
                          breaks = c(-45, -25, 0, 25, 45)) +
     guides(fill = guide_colourbar(barwidth = 15, 
                                   barheight = .5, 
                                   title.position = &amp;quot;top&amp;quot;,
                                   title.hjust = .5)) +
  coord_sf(crs = ortho_crs) +
  labs(fill = str_wrap(&amp;quot;Maximum temperature at 2 meters for February 14&amp;quot;, 35)) +
  theme_void() +
  theme(legend.position = &amp;quot;bottom&amp;quot;,
        legend.title = element_text(size = 7),
        plot.margin = margin(10, 10, 10, 10)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2023/tomorrows-weather/index.en_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/drxeo&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;41&#34; width=&#34;174&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Hillshade effects</title>
      <link>https://dominicroye.github.io/en/2022/hillshade-effects/</link>
      <pubDate>Wed, 20 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://dominicroye.github.io/en/2022/hillshade-effects/</guid>
      <description>


&lt;p&gt;It is very common to see relief maps with shadow effects, also known as ‘hillshade’, which generates visual depth. How can we create these effects in R and how to include them in ggplot2?&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Packages&lt;/h1&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;9%&#34; /&gt;
&lt;col width=&#34;90%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Package&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Simple Feature: import, export and manipulate vector data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;elevatr&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Access to elevation data from various APIs&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;terra&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Import, export and manipulate raster ({raster} successor package)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;whitebox&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;An R interface to the ‘WhiteboxTools’ library, which is an advanced geospatial data analysis platform&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyterra&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Helper functions for working with {terra}&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;giscoR&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Administrative boundaries of the world&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ggnewscale&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Extension for ggplot2 of multiple ‘scales’&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install the packages if necessary

if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;sf&amp;quot;)) install.packages(&amp;quot;sf&amp;quot;)
if(!require(&amp;quot;elevatr&amp;quot;)) install.packages(&amp;quot;elevatr&amp;quot;)
if(!require(&amp;quot;terra&amp;quot;)) install.packages(&amp;quot;terra&amp;quot;)
if(!require(&amp;quot;whitebox&amp;quot;)) install.packages(&amp;quot;whitebox&amp;quot;)
if(!require(&amp;quot;tidyterra&amp;quot;)) install.packages(&amp;quot;tidyterra&amp;quot;)
if(!require(&amp;quot;giscoR&amp;quot;)) install.packages(&amp;quot;giscoR&amp;quot;)
if(!require(&amp;quot;ggnewscale&amp;quot;)) install.packages(&amp;quot;ggnewscale&amp;quot;)

# packages
library(sf)
library(elevatr)
library(tidyverse)
library(terra)
library(whitebox)
library(ggnewscale)
library(tidyterra)
library(giscoR)
library(units)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data&lt;/h1&gt;
&lt;p&gt;As an area of interest, we use Switzerland in this example. Except for lake boundaries &lt;a href=&#34;https://dominicroye.github.io/files/switzerland_lakes.zip&#34;&gt;download&lt;/a&gt;, the necessary data is obtained through APIs using different packages. For example, the &lt;code&gt;giscoR&lt;/code&gt; package allows you to get country boundaries with different resolutions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;suiz &amp;lt;- gisco_get_countries(country = &amp;quot;Switzerland&amp;quot;, resolution = &amp;quot;03&amp;quot;)

plot(suiz)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2022/hillshade-effects/index.en_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The lake boundaries correspond to a layer of digital cartographic models (DKM500) provided by &lt;a href=&#34;https://www.swisstopo.admin.ch/&#34;&gt;swisstopo&lt;/a&gt;. The objective is to keep only the largest lakes; therefore, we exclude all those with less than 50 km2 and also those located entirely in Italian territory. Remember that with the &lt;code&gt;units&lt;/code&gt; package, we can indicate units and thus do calculations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# import the lakes boundaries
suiz_lakes &amp;lt;- st_read(&amp;quot;22_DKM500_GEWAESSER_PLY.shp&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Reading layer `22_DKM500_GEWAESSER_PLY&amp;#39; from data source 
##   `E:\GitHub\blog_update_2021\content\en\post\2022-07-19-hillshade-effect\22_DKM500_GEWAESSER_PLY.shp&amp;#39; 
##   using driver `ESRI Shapefile&amp;#39;
## Simple feature collection with 596 features and 14 fields
## Geometry type: POLYGON
## Dimension:     XY
## Bounding box:  xmin: 2480000 ymin: 1062000 xmax: 2865000 ymax: 1302000
## Projected CRS: CH1903+ / LV95&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# filter the largest ones
suiz_lakes &amp;lt;- mutate(suiz_lakes, areakm = set_units(SHP_AREA, &amp;quot;m2&amp;quot;) %&amp;gt;% 
                                          set_units(&amp;quot;km2&amp;quot;)) %&amp;gt;% 
                filter(areakm &amp;gt; set_units(50, &amp;quot;km2&amp;quot;),
                       !NAMN1 %in% c(&amp;quot;Lago di Como / Lario&amp;quot;,
                                     &amp;quot;Lago d&amp;#39;Iseo&amp;quot;,
                                     &amp;quot;Lago di Garda&amp;quot;))
plot(suiz_lakes)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot
## all&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2022/hillshade-effects/index.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;digital-elevation-model-dem&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Digital Elevation Model (DEM)&lt;/h1&gt;
&lt;p&gt;The &lt;code&gt;get_elev_raster()&lt;/code&gt; function allows us to download a DEM from any region of the world through different providers in raster format. By default, it uses &lt;a href=&#34;https://registry.opendata.aws/terrain-tiles/&#34;&gt;AWS&lt;/a&gt;. An essential argument is the latitude-dependent resolution, which can be specified as the zoom level (see function help). For example, we use level 10, which at a latitude of 45º would correspond to approximately 100 m.&lt;/p&gt;
&lt;p&gt;After obtaining the DEM from Switzerland, we must mask the country’s boundaries. The object’s class is &lt;em&gt;RasterLayer&lt;/em&gt; from the &lt;code&gt;raster&lt;/code&gt; package, however, the new standard is &lt;code&gt;terra&lt;/code&gt; with the class &lt;em&gt;SpatRaster&lt;/em&gt;. That’s why we convert it and then apply the mask. Finally, we reproject to the Swiss coordinate system obtained from the vector data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get the DEM with
mdt &amp;lt;- get_elev_raster(suiz, z = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Mosaicing &amp;amp; Projecting&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Note: Elevation units are in meters.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mdt # old RasterLayer class&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class      : RasterLayer 
## dimensions : 3869, 7913, 30615397  (nrow, ncol, ncell)
## resolution : 0.0006219649, 0.0006219649  (x, y)
## extent     : 5.625, 10.54661, 45.58354, 47.98992  (xmin, xmax, ymin, ymax)
## crs        : +proj=longlat +datum=WGS84 +no_defs 
## source     : file1a383b30325d.tif 
## names      : file1a383b30325d 
## values     : -32768, 32767  (min, max)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(mdt)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2022/hillshade-effects/index.en_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# convert to terra and mask area of interest
mdt &amp;lt;- rast(mdt) %&amp;gt;% 
         mask(vect(suiz)) 

# reproject
mdt &amp;lt;- project(mdt, crs(suiz_lakes))

# reproject vect
suiz &amp;lt;- st_transform(suiz, st_crs(suiz_lakes))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before calculating the shadow effect, we create a simple relief map. In &lt;code&gt;ggplot2&lt;/code&gt;, we use the &lt;code&gt;geom_raster()&lt;/code&gt; geometry, indicating the longitude, latitude and the variable to define the color. We add the boundaries of the lakes using &lt;code&gt;geom_sf()&lt;/code&gt; since it is an &lt;em&gt;sf&lt;/em&gt; object. Here we only indicate the fill color with a light blue. Then, with the help of &lt;code&gt;scale_fill_hypso_tint_c()&lt;/code&gt;, we apply a range of colors corresponding to the relief, also called hypsometric tinting, and we define the breaks in the legend. We make appearance adjustments in the legend and the graph’s style in the rest of the functions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# convert the raster into a data.frame of xyz
mdtdf &amp;lt;- as.data.frame(mdt, xy = TRUE)
names(mdtdf)[3] &amp;lt;- &amp;quot;alt&amp;quot;

# map
ggplot() +
  geom_raster(data = mdtdf,
              aes(x, y, fill = alt)) +
   geom_sf(data = suiz_lakes,
          fill = &amp;quot;#c6dbef&amp;quot;, 
          colour = NA) +
  scale_fill_hypso_tint_c(breaks = c(180, 250, 500, 1000,
                                     1500,  2000, 2500,
                                     3000, 3500, 4000)) +
  guides(fill = guide_colorsteps(barwidth = 20,
                                 barheight = .5,
                                 title.position = &amp;quot;right&amp;quot;)) +
  labs(fill = &amp;quot;m&amp;quot;) +
  coord_sf() +
  theme_void() +
  theme(legend.position = &amp;quot;bottom&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2022/hillshade-effects/index.en_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;calculate-the-hillshade&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Calculate the hillshade&lt;/h1&gt;
&lt;p&gt;Let’s remember that the hillshade effect is nothing more than adding a hypothetical illumination with respect to a position of a light source to gain depth. Shadows depend on two variables, azimuth, the angle from the orientation on the surface of a sphere, and elevation, the angle from the height of the source.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;hillshade_effect.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The information required to simulate lighting is the digital elevation model. The slope and aspect can be derived from the DEM using the &lt;code&gt;terrain()&lt;/code&gt; function from the &lt;code&gt;terra&lt;/code&gt; package. The unit must be radians. Once we have all the data, we can use the &lt;code&gt;shade()&lt;/code&gt; function to indicate the angle (elevation) and direction (azimuth). The result is a raster with values between 0 and 255, which shows shadows with low values, being 0 black and 255 white.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# estimate the slope
sl &amp;lt;- terrain(mdt, &amp;quot;slope&amp;quot;, unit = &amp;quot;radians&amp;quot;)
plot(sl)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2022/hillshade-effects/index.en_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# estimate the aspect or orientation
asp &amp;lt;- terrain(mdt, &amp;quot;aspect&amp;quot;, unit = &amp;quot;radians&amp;quot;)
plot(asp)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2022/hillshade-effects/index.en_files/figure-html/unnamed-chunk-7-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# calculate the hillshade effect with 45º of elevation
hill_single &amp;lt;- shade(sl, asp, 
      angle = 45, 
      direction = 300,
      normalize= TRUE)

# final hillshade 
plot(hill_single, col = grey(1:100/100))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2022/hillshade-effects/index.en_files/figure-html/unnamed-chunk-7-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;combine-the-relief-and-shadow-effect&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Combine the relief and shadow effect&lt;/h1&gt;
&lt;p&gt;The problem with adding both the relief with its hypsometric tints and the hillshade effect inside &lt;code&gt;ggplot2&lt;/code&gt; is that we have two different fills or scales for each layer.
The solution is to use the &lt;code&gt;ggnewscale&lt;/code&gt; extension, which allows you to add multiple &lt;em&gt;scales&lt;/em&gt; of the same argument. First, we add the hillshade with &lt;code&gt;geom_raster()&lt;/code&gt;, then we define the grey tones, and before adding the altitude, we include the &lt;code&gt;new_scale_fill()&lt;/code&gt; function to mark a different fill. To achieve the effect, it is necessary to give a degree of transparency to the relief layer; in this case, it is 70%. The choice of direction is important, which is why we must always take into account the place and the apparent path of the sun (&lt;a href=&#34;https://www.sunearthtools.com/dp/tools/pos_sun.php?lang=es&#34;&gt;sunearthtools&lt;/a&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# convert the hillshade to xyz
hilldf_single &amp;lt;- as.data.frame(hill_single, xy = TRUE)

# map 
ggplot() +
  geom_raster(data = hilldf_single,
              aes(x, y, fill = lyr1),
              show.legend = FALSE) +
  scale_fill_distiller(palette = &amp;quot;Greys&amp;quot;) +
  new_scale_fill() +
  geom_raster(data = mdtdf,
              aes(x, y, fill = alt),
              alpha = .7) +
  scale_fill_hypso_tint_c(breaks = c(180, 250, 500, 1000,
                                     1500,  2000, 2500,
                                     3000, 3500, 4000)) +
  geom_sf(data = suiz_lakes,
          fill = &amp;quot;#c6dbef&amp;quot;, colour = NA) +
  guides(fill = guide_colorsteps(barwidth = 20,
                                 barheight = .5,
                                 title.position = &amp;quot;right&amp;quot;)) +
  labs(fill = &amp;quot;m&amp;quot;) +
  coord_sf() +
  theme_void() +
  theme(legend.position = &amp;quot;bottom&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2022/hillshade-effects/index.en_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multidirectional-shadows&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Multidirectional shadows&lt;/h1&gt;
&lt;p&gt;We have seen a unidirectional effect; although it is the most common, we can create a smoother and even more realistic effect by combining several directions.&lt;/p&gt;
&lt;p&gt;We map onto a vector of various directions to which the &lt;code&gt;shade()&lt;/code&gt; function is applied with a fixed elevation angle. We then convert the raster list to a multi-layered object to reduce them by adding all the layers.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# pass multiple directions to shade()
hillmulti &amp;lt;- map(c(270, 15, 60, 330), function(dir){ 
                    shade(sl, asp, 
                          angle = 45, 
                          direction = dir,
                          normalize= TRUE)}
  )

# create a multidimensional raster and reduce it by summing up
hillmulti &amp;lt;- rast(hillmulti) %&amp;gt;% sum()

# multidirectional
plot(hillmulti, col = grey(1:100/100))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2022/hillshade-effects/index.en_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# unidirectional
plot(hill_single, col = grey(1:100/100))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2022/hillshade-effects/index.en_files/figure-html/unnamed-chunk-9-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We do the same as before to visualize the relief with multidirectional shadows.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# convert the hillshade to xyz
hillmultidf &amp;lt;- as.data.frame(hillmulti, xy = TRUE)

# map
ggplot() +
  geom_raster(data = hillmultidf,
              aes(x, y, fill = sum),
              show.legend = FALSE) +
  scale_fill_distiller(palette = &amp;quot;Greys&amp;quot;) +
  new_scale_fill() +
  geom_raster(data = mdtdf,
              aes(x, y, fill = alt),
              alpha = .7) +
  scale_fill_hypso_tint_c(breaks = c(180, 250, 500, 1000,
                                     1500,  2000, 2500,
                                     3000, 3500, 4000)) +
  geom_sf(data = suiz_lakes,
          fill = &amp;quot;#c6dbef&amp;quot;, colour = NA) +
  guides(fill = guide_colorsteps(barwidth = 20,
                                 barheight = .5,
                                 title.position = &amp;quot;right&amp;quot;)) +
  labs(fill = &amp;quot;m&amp;quot;) +
  coord_sf() +
  theme_void() +
    theme(legend.position = &amp;quot;top&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2022/hillshade-effects/index.en_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;another-alternative-for-multidirectional-shadows&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Another alternative for multidirectional shadows&lt;/h1&gt;
&lt;p&gt;With less control over the directions, it would also be possible to apply the &lt;code&gt;wbt_multidirectional_hillshade()&lt;/code&gt; function from the &lt;code&gt;whitebox&lt;/code&gt; package. WhiteboxTool contains many tools as an advanced geospatial data analysis platform. The disadvantage is that we lose control over the directions and that it is also necessary to export the DEM to geotiff to obtain another raster with the shadows.&lt;/p&gt;
&lt;p&gt;We first install the library with the &lt;code&gt;install_whitebox()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# instal whitebox
install_whitebox()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# export the DEM
writeRaster(mdt, &amp;quot;mdt.tiff&amp;quot;, overwrite = TRUE)

# launch whitebox
wbt_init()

# create the hillshade
wbt_multidirectional_hillshade(&amp;quot;mdt.tiff&amp;quot;,
                               &amp;quot;hillshade.tiff&amp;quot;)

# re-import the hillshade
hillwb &amp;lt;- rast(&amp;quot;hillshade.tiff&amp;quot;)
plot(hillwb)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2022/hillshade-effects/index.en_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# remask 
hillwb &amp;lt;- mask(hillwb, vect(suiz))
plot(hillwb)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2022/hillshade-effects/index.en_files/figure-html/unnamed-chunk-12-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# convert the hillshade to xyz
hillwbdf &amp;lt;- as.data.frame(hillwb, xy = TRUE)

# map
ggplot() +
  geom_raster(data = hillwbdf,
              aes(x, y, fill = hillshade),
              show.legend = FALSE) +
  scale_fill_distiller(palette = &amp;quot;Greys&amp;quot;) +
  new_scale_fill() +
  geom_raster(data = mdtdf,
              aes(x, y, fill = alt),
              alpha = .7) +
  scale_fill_hypso_tint_c(breaks = c(180, 250, 500, 1000,
                                     1500,  2000, 2500,
                                     3000, 3500, 4000)) +
  guides(fill = guide_colorsteps(barwidth = 20,
                                 barheight = .5,
                                 title.position = &amp;quot;right&amp;quot;)) +
  labs(fill = &amp;quot;m&amp;quot;) +
  coord_sf() +
  theme_void()  +
  theme(legend.position = &amp;quot;top&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2022/hillshade-effects/index.en_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/drxeo&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;41&#34; width=&#34;174&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Use of multidimensional spatial data</title>
      <link>https://dominicroye.github.io/en/2022/use-of-multidimensional-spatial-data/</link>
      <pubDate>Tue, 08 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://dominicroye.github.io/en/2022/use-of-multidimensional-spatial-data/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2022/use-of-multidimensional-spatial-data/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;initial-considerations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Initial considerations&lt;/h1&gt;
&lt;p&gt;Space-time information is vital in many disciplines, especially in climatology or meteorology, and this makes it necessary to have a format that allows a multidimensional structure. It is also important that this format has a high degree of interchange compatibility and can store a large number of data. These characteristics led to the development of the open standard netCDF (NetworkCommon Data Form). The netCDF format is an open multi-dimensional scientific data exchange standard used with observational or model data, primarily in disciplines such as climatology, meteorology, and oceanography. The netCDF convention is managed by Unidata (&lt;a href=&#34;https://www.unidata.ucar.edu/software/netcdf/&#34; class=&#34;uri&#34;&gt;https://www.unidata.ucar.edu/software/netcdf/&lt;/a&gt;). It is a space-time format with a regular or irregular grid. The multidimensional structure in the form of an array allows the use of space-time and multivariable data. The general characteristics of netCDF refer to the use of an n-dimensional coordinate system, multiple variables, and a regular or irregular grid. In addition, metadata describing the contents are included. The extension of the netCDF format is “nc”.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;3d_ncdf.en.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I recently used drought data from Spain in netCDF format with a resolution of 1 km to represent the state of drought for each year since 1960 (&lt;a href=&#34;https://monitordesequia.csic.es/historico/&#34; class=&#34;uri&#34;&gt;https://monitordesequia.csic.es/historico/&lt;/a&gt;). The SPEI index (Standardized Precipitation-Evapotranspiration Index) is widely used to describe the drought with different time intervals (3, 6, 12 months, etc.).&lt;/p&gt;
&lt;p&gt;{{&amp;lt; tweet 1490260694851362821 &amp;gt;}}&lt;/p&gt;
&lt;p&gt;I have been asked on several occasions about handling the netCDF format. For this reason, in this post, we will use a subset of these same data, the year 2017 of the SPEI 12 months.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Packages&lt;/h1&gt;
&lt;p&gt;Data handling in netCDF format is possible through various packages directly or indirectly. The specifically designed &lt;code&gt;{ncdf4}&lt;/code&gt; package stands out, which is also used by other packages, although we don’t see it. Handling with &lt;code&gt;{ncdf4}&lt;/code&gt; is somewhat complex, mainly because of the need to manage RAM when dealing with large datasets or also because of the way to handle the &lt;em&gt;array&lt;/em&gt; class. Another very powerful package is &lt;code&gt;{terra}&lt;/code&gt;, which we know when working with raster data and allows us to use its functions also for handling the netCDF format.&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;10%&#34; /&gt;
&lt;col width=&#34;89%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Packages&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Simple Feature: import, export and manipulate vector data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lubridate&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Easy manipulation of dates and times&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;terra&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Import, export and manipulate raster (raster successor package)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mapSpain&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Spanish administrative limits&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install the packages if necessary
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;sf&amp;quot;)) install.packages(&amp;quot;sf&amp;quot;)
if(!require(&amp;quot;lubridate&amp;quot;)) install.packages(&amp;quot;lubridate&amp;quot;)
if(!require(&amp;quot;terra&amp;quot;)) install.packages(&amp;quot;terra&amp;quot;)
if(!require(&amp;quot;mapSpain&amp;quot;)) install.packages(&amp;quot;mapSpain&amp;quot;)

# load packages
library(tidyverse)
library(sf)
library(terra)
library(lubridate)
library(mapSpain)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For those less experienced with &lt;code&gt;tidyverse&lt;/code&gt;, I recommend the brief introduction on this blog &lt;a href=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/&#34;&gt;post&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data&lt;/h1&gt;
&lt;p&gt;First, we download the data &lt;a href=&#34;https://www.dropbox.com/s/ioo2ky7wb3zxkdx/spei12_2017.nc?dl=0&#34;&gt;here&lt;/a&gt;. Then, we import the SPEI-12 index data for 2017 using the &lt;code&gt;rast()&lt;/code&gt; function. Actually, in this step, we have only created a reference to the file without importing all the data into memory. We see in the metadata the number of layers available. The SPEI-12 index is calculated weekly with four weeks per month. If we look at the metadata, the definition of the coordinate system is missing, so we define it by assigning the code EPSG:25830 (ETRS89/UTM 30N).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# import
spei &amp;lt;- rast(&amp;quot;spei12_2017.nc&amp;quot;)
# metadata
spei&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class       : SpatRaster 
## dimensions  : 834, 1115, 48  (nrow, ncol, nlyr)
## resolution  : 1100, 1100  (x, y)
## extent      : -80950, 1145550, 3979450, 4896850  (xmin, xmax, ymin, ymax)
## coord. ref. :  
## source      : spei12_2017.nc 
## names       : spei1~017_1, spei1~017_2, spei1~017_3, spei1~017_4, spei1~017_5, spei1~017_6, ... 
## time        : 2017-01-01 to 2017-12-23&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# define the coordinate system
crs(spei) &amp;lt;- &amp;quot;EPSG:25830&amp;quot;

# map first weeks
plot(spei)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2022/use-of-multidimensional-spatial-data/index.en_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;extract-metadata&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Extract metadata&lt;/h1&gt;
&lt;p&gt;There are different functions to access metadata, such as dates, layer names or variable names. Remember that netCDF files can also contain several variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# time
t &amp;lt;- time(spei)
head(t)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2017-01-01 UTC&amp;quot; &amp;quot;2017-01-09 UTC&amp;quot; &amp;quot;2017-01-16 UTC&amp;quot; &amp;quot;2017-01-23 UTC&amp;quot;
## [5] &amp;quot;2017-02-01 UTC&amp;quot; &amp;quot;2017-02-09 UTC&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# layer names
names(spei) %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;spei12_2017_1&amp;quot; &amp;quot;spei12_2017_2&amp;quot; &amp;quot;spei12_2017_3&amp;quot; &amp;quot;spei12_2017_4&amp;quot;
## [5] &amp;quot;spei12_2017_5&amp;quot; &amp;quot;spei12_2017_6&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# variable names
varnames(spei)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;spei12_2017&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;time-series-extraction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Time-series extraction&lt;/h1&gt;
&lt;p&gt;One possibility that netCDF data allows is time-series extraction, either from points or areas. For example, we will create here the SPEI-12 time series for the city of Zaragoza and the average for the entire autonomous community of Aragon.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Zaragoza coordinates
zar &amp;lt;- st_point(c(-0.883333, 41.65)) %&amp;gt;% 
          st_sfc(crs = 4326) %&amp;gt;% 
           st_as_sf() %&amp;gt;% 
            st_transform(25830)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;{terra}&lt;/code&gt; package only accepts its vector class &lt;em&gt;SpatVector&lt;/em&gt;, so it is necessary to convert the point of class &lt;em&gt;sf&lt;/em&gt; with the &lt;code&gt;vect()&lt;/code&gt; function. To extract the time series we use the &lt;code&gt;extract()&lt;/code&gt; function. The extracted data is given back in the form of a table, each row is an element of the vector data, and each column is a layer. In our case, it is only a single row corresponding to the city of Zaragoza.&lt;/p&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Some functions may conflict with the names of other packages; to avoid this, we can write the package’s name in front of the function we want to use, separated by the colon symbol written twice (&lt;code&gt;package_name::function_name&lt;/code&gt;).
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract time series
spei_zar &amp;lt;- terra::extract(spei, vect(zar))

# dimensions
dim(spei_zar)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  1 49&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create a data.frame
spei_zar &amp;lt;- tibble(date = t, zar = unlist(spei_zar)[-1])
head(spei_zar)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 2
##   date                  zar
##   &amp;lt;dttm&amp;gt;              &amp;lt;dbl&amp;gt;
## 1 2017-01-01 00:00:00 0.280
## 2 2017-01-09 00:00:00 0.25 
## 3 2017-01-16 00:00:00 0.220
## 4 2017-01-23 00:00:00 0.210
## 5 2017-02-01 00:00:00 0.350
## 6 2017-02-09 00:00:00 0.220&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We obtain the average of the autonomous community of Aragon using the polygon geometry and indicating the type of function with which we want to summarize the area. The &lt;code&gt;esp_get_ccaa()&lt;/code&gt; function of the &lt;code&gt;mapSpain()&lt;/code&gt; package is very useful when importing Spanish administrative boundaries of different levels. In the extraction, we must pass the &lt;code&gt;na.rm = TRUE&lt;/code&gt; argument to the &lt;code&gt;mean()&lt;/code&gt; function to exclude pixels with no value.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# boundaries of Aragon
aragon &amp;lt;- esp_get_ccaa(&amp;quot;Aragon&amp;quot;) %&amp;gt;% 
            st_transform(25830)

# extract the average values of the SPEI-12
spei_arag &amp;lt;- terra::extract(spei, vect(aragon), fun = &amp;quot;mean&amp;quot;, na.rm = TRUE)

# add the new values to our data.frame
spei_zar &amp;lt;- mutate(spei_zar, arag = unlist(spei_arag)[-1])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the next step, we transform the table to the long format with &lt;code&gt;pivot_longer()&lt;/code&gt;, merging the value of the SPEI index of Zaragoza and Aragon. We will also add a column with the interpretation of the index and change the labels.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spei_zar &amp;lt;-  pivot_longer(spei_zar, 2:3, names_to = &amp;quot;reg&amp;quot;, values_to = &amp;quot;spei&amp;quot;) %&amp;gt;%
             mutate(sign = case_when(spei &amp;lt; -0.5 ~ &amp;quot;drought&amp;quot;, 
                                    spei &amp;gt; 0.5 ~ &amp;quot;wet&amp;quot;,
                                    TRUE ~ &amp;quot;normal&amp;quot;),
                    date = as_date(date),
                    reg = factor(reg, c(&amp;quot;zar&amp;quot;, &amp;quot;arag&amp;quot;), c(&amp;quot;Zaragoza&amp;quot;, &amp;quot;Aragon&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now it remains to build the graph in which we compare the SPEI-12 of Zaragoza with the average of Aragon. The &lt;code&gt;geom_rect()&lt;/code&gt; function helps us draw different background rectangles to mark drought and normal state.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# time series graph
ggplot(spei_zar) +
      geom_rect(aes(xmin = min(date), xmax = max(date), 
                    ymin = -0.5, ymax = 0.5), 
                fill = &amp;quot;#41ab5d&amp;quot;) +
      geom_rect(aes(xmin = min(date), xmax = max(date), 
                    ymin = -1, ymax = -0.5), 
                fill = &amp;quot;#ffffcc&amp;quot;) +
      geom_rect(aes(xmin = min(date), xmax = max(date), 
                    ymin = -1.5, ymax = -1), 
                fill = &amp;quot;#F3641D&amp;quot;) +
      geom_hline(yintercept = 0, size = 1, colour = &amp;quot;white&amp;quot;) +
      geom_line(aes(date, spei, linetype = reg), size = 1, alpha = .7) +
  scale_x_date(date_breaks = &amp;quot;month&amp;quot;, date_labels = &amp;quot;%b&amp;quot;) +
  labs(linetype = &amp;quot;&amp;quot;, y = &amp;quot;SPEI-12&amp;quot;, x = &amp;quot;&amp;quot;) +
  coord_cartesian(expand = FALSE) +
  theme_minimal() +
  theme(legend.position = c(.25, .9),
        panel.grid.minor = element_blank(),
        panel.ontop = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2022/use-of-multidimensional-spatial-data/index.en_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;drought-map&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Drought map&lt;/h1&gt;
&lt;div id=&#34;spain&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Spain&lt;/h2&gt;
&lt;p&gt;To create a map of drought severity in 2017, we must first make some modifications. With the &lt;code&gt;subset()&lt;/code&gt; function, we obtain a layer or several as a subset. Here we select the last one to see the state of drought for the whole year.&lt;/p&gt;
&lt;p&gt;We replace all values greater than -0.5 with &lt;code&gt;NA&lt;/code&gt; in the next step. Drought is considered when the SPEI index is below -0.5 and, on the other hand, if it is above 0.5, we would speak of a wet period.&lt;/p&gt;
&lt;p&gt;The raster class is not directly compatible with &lt;code&gt;ggplot&lt;/code&gt;, so we convert it to an xyz table with longitude, latitude and the variable. When we do the same conversion of multiple layers, each column will represent one layer. Finally, we rename our index column and add a new column with different levels of drought severity.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract layer(s) with their index
spei_anual &amp;lt;- subset(spei, 48) 

# substitute non-drought values with NA
spei_anual[spei_anual &amp;gt; -0.5] &amp;lt;- NA

# convert our raster into an xyz table
spei_df &amp;lt;- as.data.frame(spei_anual, xy = TRUE)
head(spei_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            x       y spei12_2017_48
## 38096 123100 4858900          -1.48
## 39195 105500 4857800          -1.59
## 39197 107700 4857800          -1.40
## 39211 123100 4857800          -1.47
## 39212 124200 4857800          -1.50
## 40310 105500 4856700          -1.63&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# change the name of the variable
names(spei_df)[3] &amp;lt;- &amp;quot;spei&amp;quot;

# categorize the index and fix the order of the factor
spei_df &amp;lt;- mutate(spei_df, spei_cat = case_when(spei &amp;gt; -0.9 ~ &amp;quot;slight&amp;quot;,
                                                spei &amp;gt; -1.5 &amp;amp; spei &amp;lt; -0.9 ~ &amp;quot;moderate&amp;quot;,
                                                spei &amp;gt; -2 &amp;amp; spei &amp;lt;= -1.5 ~ &amp;quot;severe&amp;quot;,
                                                TRUE ~ &amp;quot;extreme&amp;quot;) %&amp;gt;% 
                                      fct_relevel(c(&amp;quot;slight&amp;quot;, &amp;quot;moderate&amp;quot;, &amp;quot;severe&amp;quot;, &amp;quot;extreme&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can create a raster map with the &lt;code&gt;geom_tile()&lt;/code&gt; geometry indicating longitude, latitude and the fill of the pixels with our categorized variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# boundaries
ccaa &amp;lt;- esp_get_ccaa() %&amp;gt;% 
            filter(!ine.ccaa.name %in% c(&amp;quot;Canarias&amp;quot;, &amp;quot;Ceuta&amp;quot;, &amp;quot;Melilla&amp;quot;)) %&amp;gt;% 
              st_transform(25830)

# mapa
ggplot(spei_df) +
   geom_tile(aes(x , y, fill = spei_cat)) +
  geom_sf(data = ccaa, fill = NA, size = .1, colour = &amp;quot;white&amp;quot;, alpha = .4) +
  scale_fill_manual(values = c(&amp;quot;#ffffcc&amp;quot;, &amp;quot;#F3641D&amp;quot;, &amp;quot;#DE2929&amp;quot;, &amp;quot;#8B1A1A&amp;quot;),
                    na.value = NA) +
  guides(fill = guide_legend(keywidth = 2, keyheight = .3, label.position = &amp;quot;bottom&amp;quot;,
                             title.position = &amp;quot;top&amp;quot;)) +
  coord_sf() +
  labs(fill = &amp;quot;DROUGHT&amp;quot;) +
  theme_void() +
  theme(legend.position = &amp;quot;top&amp;quot;,
        legend.justification = 0.2,
        plot.background = element_rect(fill = &amp;quot;black&amp;quot;, colour = NA),
        legend.title = element_text(colour = &amp;quot;white&amp;quot;, size = 20, hjust = .5),
        legend.text = element_text(colour = &amp;quot;white&amp;quot;),
        plot.margin = margin(t = 10))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2022/use-of-multidimensional-spatial-data/index.en_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;758.4&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;aragon&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Aragon&lt;/h2&gt;
&lt;p&gt;In this last map example, we select the drought situation 12 months ahead, at the beginning and end of the year. The main function we use is &lt;code&gt;crop()&lt;/code&gt; that cuts to the extent of a spatial object; in our case, it is Aragon, then we apply the &lt;code&gt;mask()&lt;/code&gt; function that masks all those pixels within limits leaving the others in &lt;code&gt;NA&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# subset first and last week 2017
spei_sub &amp;lt;- subset(spei, c(1, 48)) 

# crop and mask Aragon
spei_arag &amp;lt;- crop(spei_sub, aragon) %&amp;gt;% 
                    mask(vect(aragon)) 

# convert the data to xyz
spei_df_arag &amp;lt;- as.data.frame(spei_arag, xy = TRUE)

# rename layers
names(spei_df_arag)[3:4] &amp;lt;- c(&amp;quot;January&amp;quot;, &amp;quot;December&amp;quot;)

# changing to the long table format by merging both months
spei_df_arag &amp;lt;- pivot_longer(spei_df_arag, 3:4, 
                             names_to = &amp;quot;mo&amp;quot;, 
                             values_to = &amp;quot;spei&amp;quot;) %&amp;gt;% 
                mutate(mo = fct_relevel(mo, c(&amp;quot;January&amp;quot;, &amp;quot;December&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will make the two maps in the same way as the one for whole Spain. The main difference is that we use the SPEI index directly as a continuous variable. Also, to create two maps as facets in one row, we add the &lt;code&gt;facet_grid()&lt;/code&gt; function. Finally, the index shows negative and positive values; therefore, a divergent range of colours is necessary. To centre the midpoint at 0, we must rescale the index values using the &lt;code&gt;rescale()&lt;/code&gt; function from the &lt;code&gt;scales&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# map of Aragon
ggplot(spei_df_arag) +
   geom_tile(aes(x , y, fill = spei)) +
  geom_sf(data = aragon, fill = NA, size = .1, colour = &amp;quot;white&amp;quot;, alpha = .4) +
  scale_fill_distiller(palette = &amp;quot;RdYlGn&amp;quot;, direction = 1, 
                       values = scales::rescale(c(-2.1, 0, 0.9)),
                       breaks = seq(-2, 1, .5)) +
  guides(fill = guide_colorbar(barwidth = 8, barheight = .3, label.position = &amp;quot;bottom&amp;quot;)) +
  facet_grid(. ~ mo) +
  coord_sf() +
  labs(fill = &amp;quot;SPEI-12&amp;quot;, title = &amp;quot;Aragon&amp;quot;) +
  theme_void() +
  theme(legend.position = &amp;quot;top&amp;quot;,
        legend.justification = 0.5,
        legend.title = element_text(colour = &amp;quot;white&amp;quot;, vjust = 1.1),
        strip.text = element_text(colour = &amp;quot;white&amp;quot;),
        plot.background = element_rect(fill = &amp;quot;black&amp;quot;, colour = NA),
        plot.title = element_text(colour = &amp;quot;white&amp;quot;, size = 20, hjust = .5, vjust = 2.5,
                                  margin = margin(b = 10, t = 10)),
        legend.text = element_text(colour = &amp;quot;white&amp;quot;),
        plot.margin = margin(10, 10, 10, 10))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2022/use-of-multidimensional-spatial-data/index.en_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;more-possibilities&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;More possibilities&lt;/h1&gt;
&lt;p&gt;It is possible to regroup the different layers by applying a function. For example, using the months of each week of the SPEI-12 we can calculate the monthly average in 2017. To do this, we use the &lt;code&gt;tapp()&lt;/code&gt; function, which in turn applies another function to each group. It is crucial that the group is either a factor or the index of each layer. Both &lt;code&gt;tapp()&lt;/code&gt; and &lt;code&gt;app()&lt;/code&gt; functions have an argument to process in parallel using more than one core.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# months as factor
mo &amp;lt;- month(t, label = TRUE)
mo&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] ene ene ene ene feb feb feb feb mar mar mar mar abr abr abr abr may may may
## [20] may jun jun jun jun jul jul jul jul ago ago ago ago sep sep sep sep oct oct
## [39] oct oct nov nov nov nov dic dic dic dic
## 12 Levels: ene &amp;lt; feb &amp;lt; mar &amp;lt; abr &amp;lt; may &amp;lt; jun &amp;lt; jul &amp;lt; ago &amp;lt; sep &amp;lt; ... &amp;lt; dic&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# average by month
spei_mo &amp;lt;- tapp(spei, mo, mean)
spei_mo&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class       : SpatRaster 
## dimensions  : 834, 1115, 12  (nrow, ncol, nlyr)
## resolution  : 1100, 1100  (x, y)
## extent      : -80950, 1145550, 3979450, 4896850  (xmin, xmax, ymin, ymax)
## coord. ref. : ETRS89 / UTM zone 30N (EPSG:25830) 
## source      : memory 
## names       :     ene,     feb,     mar,     abr,     may,     jun, ... 
## min values  : -1.2800, -1.4675, -2.2400, -2.6500, -2.5775, -2.4675, ... 
## max values  :  1.3875,  1.9175,  1.7475,  1.8375,  1.7500,  1.7000, ...&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# maps
plot(spei_mo)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2022/use-of-multidimensional-spatial-data/index.en_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;mean()&lt;/code&gt; function used directly on a multidimensional &lt;code&gt;SpatRaster&lt;/code&gt; class object returns the average per cell. The same result can be obtained with the &lt;code&gt;app()&lt;/code&gt; function that applies any function. The number of resulting layers depends on the function; for example, using &lt;code&gt;range()&lt;/code&gt; results in two layers, one for the minimum value and one for the maximum value. Finally, the &lt;code&gt;global()&lt;/code&gt; function summarizes each layer in the form of a table with the indicated function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# average over layers
spei_mean &amp;lt;- mean(spei)
spei_mean&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class       : SpatRaster 
## dimensions  : 834, 1115, 1  (nrow, ncol, nlyr)
## resolution  : 1100, 1100  (x, y)
## extent      : -80950, 1145550, 3979450, 4896850  (xmin, xmax, ymin, ymax)
## coord. ref. : ETRS89 / UTM zone 30N (EPSG:25830) 
## source      : memory 
## name        :      mean 
## min value   : -2.127083 
## max value   :  1.568542&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# map
plot(spei_mean)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2022/use-of-multidimensional-spatial-data/index.en_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# alternative
spei_min &amp;lt;- app(spei, min)
spei_min&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class       : SpatRaster 
## dimensions  : 834, 1115, 1  (nrow, ncol, nlyr)
## resolution  : 1100, 1100  (x, y)
## extent      : -80950, 1145550, 3979450, 4896850  (xmin, xmax, ymin, ymax)
## coord. ref. : ETRS89 / UTM zone 30N (EPSG:25830) 
## source      : memory 
## name        :   min 
## min value   : -3.33 
## max value   :  0.29&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spei_range &amp;lt;- app(spei, range)
names(spei_range) &amp;lt;- c(&amp;quot;min&amp;quot;, &amp;quot;max&amp;quot;)
spei_range&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class       : SpatRaster 
## dimensions  : 834, 1115, 2  (nrow, ncol, nlyr)
## resolution  : 1100, 1100  (x, y)
## extent      : -80950, 1145550, 3979450, 4896850  (xmin, xmax, ymin, ymax)
## coord. ref. : ETRS89 / UTM zone 30N (EPSG:25830) 
## source      : memory 
## names       :   min,   max 
## min values  : -3.33, -1.06 
## max values  :  0.29,  2.02&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# map
plot(spei_range)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2022/use-of-multidimensional-spatial-data/index.en_files/figure-html/unnamed-chunk-15-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# statistical summary by layer
global(spei, &amp;quot;mean&amp;quot;, na.rm = TRUE) %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                      mean
## spei12_2017_1 -0.03389126
## spei12_2017_2 -0.17395742
## spei12_2017_3 -0.13228593
## spei12_2017_4 -0.07536089
## spei12_2017_5  0.06718260
## spei12_2017_6 -0.03461822&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/drxeo&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;41&#34; width=&#34;174&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Visualize the day-night cycle on a world map</title>
      <link>https://dominicroye.github.io/en/2021/visualize-the-day-night-cycle-on-a-world-map/</link>
      <pubDate>Mon, 20 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://dominicroye.github.io/en/2021/visualize-the-day-night-cycle-on-a-world-map/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2021/visualize-the-day-night-cycle-on-a-world-map/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;In April of this year, I made an animation of the 24-hour average temperature of January 2020, also showing the day-night cycle.&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;The average temperature of 24 hours in January 2020 with the day/night cycle. You can see a lot of geographic patterns. I love this kind of hypnotic temperature gifs. &lt;a href=&#34;https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rstats&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/rspatial?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rspatial&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/dataviz?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#dataviz&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/climate?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#climate&lt;/a&gt; &lt;a href=&#34;https://t.co/NA5haUlnie&#34;&gt;pic.twitter.com/NA5haUlnie&lt;/a&gt;&lt;/p&gt;&amp;mdash; Dr. Dominic Royé (@dr_xeo) &lt;a href=&#34;https://twitter.com/dr_xeo/status/1383486611707494406?ref_src=twsrc%5Etfw&#34;&gt;April 17, 2021&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/p&gt;
&lt;p&gt;My biggest problem was finding a way to project correctly the area at night without breaking the geometry. The easiest solution I found was rasterising the night polygon and then reprojecting it. Indeed, a vector approach could be used, but I have preferred to use raster data here.&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Packages&lt;/h1&gt;
&lt;p&gt;We will use the following packages:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;12%&#34; /&gt;
&lt;col width=&#34;87%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Package&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Simple Feature: import, export and manipulate vector data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lubridate&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Easy manipulation of dates and times&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;hms&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Provides a simple class to store durations or time of day values and display them in hh:mm:ss format&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;terra&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Import, export and manipulate raster (raster successor package)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lwgeom&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Access to the liblwgeom library with additional vector functions for sf&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;rnaturalearth&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Vector maps of the world ‘Natural Earth’&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;gifski&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Creating animations in gif format&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install the packages if necessary

if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;sf&amp;quot;)) install.packages(&amp;quot;sf&amp;quot;)
if(!require(&amp;quot;lubridate&amp;quot;)) install.packages(&amp;quot;lubridate&amp;quot;)
if(!require(&amp;quot;hms&amp;quot;)) install.packages(&amp;quot;hms&amp;quot;)
if(!require(&amp;quot;terra&amp;quot;)) install.packages(&amp;quot;terra&amp;quot;)
if(!require(&amp;quot;lwgeom&amp;quot;)) install.packages(&amp;quot;lwgeom&amp;quot;)
if(!require(&amp;quot;rnaturalearth&amp;quot;)) install.packages(&amp;quot;rnaturalearth&amp;quot;)
if(!require(&amp;quot;gifski&amp;quot;)) install.packages(&amp;quot;gifski&amp;quot;)



# packages
library(rnaturalearth)
library(tidyverse)
library(lwgeom)
library(sf)
library(terra)
library(lubridate)
library(hms)
library(gifski)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    To use the 50 and 10 m resolution of the &lt;code&gt;{rnaturalearth}&lt;/code&gt; package it is necessary to install the following additional packages. The &lt;code&gt;{devtools}&lt;/code&gt; package must be installed.
&lt;code&gt;devtools::install_github(&amp;ldquo;ropensci/rnaturalearthdata&amp;rdquo;)&lt;/code&gt;
&lt;code&gt;devtools::install_github(&amp;ldquo;ropensci/rnaturalearthhires&amp;rdquo;)&lt;/code&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;preparation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Preparation&lt;/h1&gt;
&lt;div id=&#34;external-functions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;External functions&lt;/h2&gt;
&lt;p&gt;The functions to estimate the separator line between day and night are based on a javascript &lt;em&gt;L.Terminator.js&lt;/em&gt; from the &lt;code&gt;{Leaflet}&lt;/code&gt; package I found on &lt;a href=&#34;https://stackoverflow.com/questions/48384058/world-map-showing-day-and-night-regions&#34;&gt;stackoverflow&lt;/a&gt;. You can download the script with the functions &lt;a href=&#34;https://dominicroye.github.io/files/terminator.R&#34;&gt;here&lt;/a&gt; or access it on &lt;a href=&#34;https://github.com/JoGall/terminator/blob/master/terminator.R&#34;&gt;github&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;source(&amp;quot;terminator.R&amp;quot;) # import the functions&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;custom-functions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Custom functions&lt;/h2&gt;
&lt;p&gt;The primary function &lt;code&gt;terminator()&lt;/code&gt; based on the javascript of &lt;code&gt;{Leaflet}&lt;/code&gt; needs as arguments: the date-time, the minimum and maximum extension, as well as the resolution or the interval of longitude.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t0 &amp;lt;- Sys.time() # date and time of our operating system
t0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2022-03-27 11:36:26 CEST&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coord_nightday &amp;lt;- terminator(t0, -180, 180, 0.2) # estimate the day-night line

# convert it into a spatial object of class sf
line_nightday &amp;lt;- st_linestring(as.matrix(coord_nightday)) %&amp;gt;% st_sfc(crs = 4326) 

# plot
plot(line_nightday)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2021/visualize-the-day-night-cycle-on-a-world-map/index.en_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the next step, we obtain the polygons corresponding to the day and the night that separates the previously estimated line. To do this, we create a rectangle covering the entire planet and use the &lt;code&gt;st_split()&lt;/code&gt; function from the &lt;code&gt;{lwgeom}&lt;/code&gt; package that divides the rectangle.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# rectangle
wld_bbx &amp;lt;- st_bbox(c(xmin = -180, xmax = 180,
                       ymin = -90, ymax = 90), 
                     crs = 4326) %&amp;gt;% 
             st_as_sfc()

# division with the day-night line
poly_nightday &amp;lt;-  st_split(wld_bbx, line_nightday) %&amp;gt;% 
                      st_collection_extract(c(&amp;quot;POLYGON&amp;quot;)) %&amp;gt;% 
                       st_sf() 

# plot
plot(poly_nightday)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2021/visualize-the-day-night-cycle-on-a-world-map/index.en_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The question now arises which of the two polygons corresponds to the night and which to the day. That will depend on what day of the year we are, given the changes in the Earth’s position concerning the Sun. Between the first summer equinox and the autumn equinox, it corresponds to the first polygon, when we can also observe the polar day at the north pole, and in the opposite case, it would be the second. The &lt;code&gt;{terra}&lt;/code&gt; package only accepts its vector class called &lt;code&gt;SpatVector&lt;/code&gt;, so we convert the vector object sf with the &lt;code&gt;vect()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# select the second polygon
poly_nightday &amp;lt;- slice(poly_nightday, 2) %&amp;gt;% 
                    mutate(daynight = 1)

# create the raster with a resolution of 0.5º and the extent of the world
r &amp;lt;- rast(vect(wld_bbx), resolution = .5)

# rasterize the night polygon 
night_rast &amp;lt;- rasterize(vect(poly_nightday), r) 

# result in raster format
plot(night_rast)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2021/visualize-the-day-night-cycle-on-a-world-map/index.en_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the last step we reproject the raster to &lt;a href=&#34;https://epsg.io/54009&#34;&gt;Mollweide&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# define the raster projection (WGS84)
crs(night_rast) &amp;lt;- &amp;quot;EPSG:4326&amp;quot;

# reproject
night_rast_prj &amp;lt;- project(night_rast, &amp;quot;ESRI:54009&amp;quot;, 
                          mask = TRUE, 
                          method = &amp;quot;near&amp;quot;)
# map
plot(night_rast_prj)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2021/visualize-the-day-night-cycle-on-a-world-map/index.en_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Finally we include the individual steps that we have done in a custom function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rast_determiner &amp;lt;- function(x_min, date, res) {
  
  # create date with time adding the number of minutes
  t0 &amp;lt;- as_date(date) + minutes(x_min) 
  # estimate the coordinates of the line that separates day and night
  night_step &amp;lt;- terminator(t0, -180, 180, 0.2) %&amp;gt;% as.matrix()
  # pass the points to line
  night_line &amp;lt;- st_linestring(night_step) %&amp;gt;% st_sfc(crs = 4326)
  
  # define the rectangle of the planet
  wld_bbx &amp;lt;- st_bbox(c(xmin = -180, xmax = 180,
                       ymin = -90, ymax = 90), 
                     crs = 4326) %&amp;gt;% 
             st_as_sfc()
  
  # divide the polygon with the day-night line
  poly_nightday &amp;lt;-  st_split(wld_bbx, night_line) %&amp;gt;% 
                      st_collection_extract(c(&amp;quot;POLYGON&amp;quot;)) %&amp;gt;% 
                       st_sf()  
  
  # select the polygon according to the date
  if(date &amp;lt;= make_date(year(date), 3, 20) | date &amp;gt;= make_date(year(date), 9, 23)) {
    
    poly_nightday &amp;lt;- slice(poly_nightday, 2) %&amp;gt;% 
      mutate(daynight = 1)
    
  } else {
    
    poly_nightday &amp;lt;- slice(poly_nightday, 1) %&amp;gt;% 
      mutate(daynight = 1)
  }
  
  # create the raster with the resolution given in the argument res
  r &amp;lt;- rast(vect(wld_bbx), resolution = res)
  
  # rasterize the night polygon
  night_rast &amp;lt;- rasterize(vect(poly_nightday), r) 
  
  return(night_rast)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since we want to obtain the area at night for different day hours, we construct a second function to apply the first one at different day intervals (in minutes).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;night_determinator &amp;lt;- function(time_seq, # minutes
                               date = Sys.Date(), # date (system default)
                               res = .5) { # raster resolution 0.5º

# apply the first function on a vector of day intervals
night_raster &amp;lt;-  map(time_seq, 
                     rast_determiner,
                     date = date, 
                     res = res)

# convert the raster into an object with as many layers as day intervals
night_raster &amp;lt;- rast(night_raster)

# define the WGS84 projection
crs(night_raster) &amp;lt;- &amp;quot;EPSG:4326&amp;quot;

return(night_raster)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;create-a-day-night-cycle&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Create a day-night cycle&lt;/h1&gt;
&lt;p&gt;First, we create the area of nights for the day of our operating system with intervals of 30 minutes. Then we reproject it to &lt;a href=&#34;https://epsg.io/54019&#34;&gt;Winkel II&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# apply our function for a 24 hour day in 30 minute intervals
night_rast &amp;lt;- night_determinator(seq(0, 1410, 30), Sys.Date(), res = .5)

# reproject to Winkel II
night_raster_winkel &amp;lt;- project(night_rast, 
                               &amp;quot;ESRI:54019&amp;quot;, 
                                mask = TRUE,
                                method = &amp;quot;near&amp;quot;)
# map of the first 5 intervals
plot(night_raster_winkel, maxnl = 5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2021/visualize-the-day-night-cycle-on-a-world-map/index.en_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;animation-of-the-day-night-cycle&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Animation of the day-night cycle&lt;/h1&gt;
&lt;div id=&#34;preparation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Preparation&lt;/h2&gt;
&lt;p&gt;To create a 24-hour animation showing the movement of the night on the Earth, we must do a few previous steps. First we get the world boundaries with the &lt;code&gt;ne_countries()&lt;/code&gt; function and reproject them to the new Winkel II projection. Then we convert the raster data into a &lt;code&gt;data.frame&lt;/code&gt; indicating to keep missing values. We can see that each layer of the raster (of each 30-minute interval) is a column in the &lt;code&gt;data.frame&lt;/code&gt;. We rename the columns and convert the table into a long format using the &lt;code&gt;pivot_longer()&lt;/code&gt; function. What we do is to merge all the columns of the layers into a single one. As the last step, we exclude the missing values with the &lt;code&gt;filter()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# country boundaries
wld &amp;lt;- ne_countries(scale = 10, returnclass = &amp;quot;sf&amp;quot;) %&amp;gt;% 
         st_transform(&amp;quot;ESRI:54019&amp;quot;)

# convert the raster to a data.frame with xyz
df_winkel &amp;lt;- as.data.frame(night_raster_winkel, xy = TRUE, na.rm = FALSE)

# rename all the columns corresponding to the day intervals
names(df_winkel)[3:length(df_winkel)] &amp;lt;- str_c(&amp;quot;H&amp;quot;, as_hms(seq(0, 1410, 30)*60))

# change to a long format
df_winkel &amp;lt;- pivot_longer(df_winkel, 3:length(df_winkel), names_to = &amp;quot;hour&amp;quot;, values_to = &amp;quot;night&amp;quot;) 

# exclude missing values to reduce table size
df_winkel &amp;lt;- filter(df_winkel, !is.na(night))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It only remains to create a graticule and obtain the extent of the world map.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# graticule
grid &amp;lt;- st_graticule() %&amp;gt;%   st_transform(&amp;quot;ESRI:54019&amp;quot;)

# get the extension of the world
bbx &amp;lt;- st_bbox(wld)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we will build a map at a single interval with &lt;code&gt;ggplot2&lt;/code&gt;, adding the vector geometry using the &lt;code&gt;geom_sf()&lt;/code&gt; function (the boundaries and the graticule) and the raster data using the &lt;code&gt;geom_raster()&lt;/code&gt; function. In the title, we are using a unicode symbol as a clock. We also define the map’s extent in &lt;code&gt;coord_sf()&lt;/code&gt; to keet it constant over all maps in the animation. Finally, we make use of &lt;code&gt;{{ }}&lt;/code&gt; from the &lt;a href=&#34;https://www.tidyverse.org/blog/2019/06/rlang-0-4-0/&#34;&gt;{rlang}&lt;/a&gt; package within the &lt;code&gt;filter()&lt;/code&gt;function to be able to filter our raster data in table form. So that our function can correctly evaluate the values that we pass in &lt;code&gt;x&lt;/code&gt; (the intervals of the day) it is necessary to use this grammar of tidy evaluation due to data masking in &lt;code&gt;tidyverse&lt;/code&gt;. Honestly, it is a topic for another post.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# example 5 UTC
x &amp;lt;- &amp;quot;H05:00:00&amp;quot;
# map
ggplot() +
  # boundaries
  geom_sf(data = wld,
          fill = &amp;quot;#74a9cf&amp;quot;, 
          colour = &amp;quot;white&amp;quot;,
          size = .1) +
  # graticule
  geom_sf(data = grid, size = .1) +
  # filtered raster data 
  geom_raster(data = filter(df_winkel, hour == {{x}}), 
              aes(x, y), 
              fill = &amp;quot;grey90&amp;quot;,
              alpha = .6) +
  # title
  labs(title = str_c(&amp;quot;\U1F551&amp;quot;, str_remove(x, &amp;quot;H&amp;quot;), &amp;quot; UTC&amp;quot;)) + 
  # extension limits
  coord_sf(xlim = bbx[c(1, 3)], 
           ylim = bbx[c(2, 4)])  +
  # map style
  theme_void() +
  theme(plot.title = element_text(hjust = .1, vjust = .9))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;animation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Animation&lt;/h2&gt;
&lt;p&gt;We create the animation by applying the &lt;code&gt;walk()&lt;/code&gt; function, which in turn will go through the interval vector to filter our data and map each step using &lt;code&gt;ggplot&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;walk(str_c(&amp;quot;H&amp;quot;, as_hms(seq(0, 1410, 30)*60)), function(step){
  
  g &amp;lt;- ggplot() +
    geom_sf(data = wld,
            fill = &amp;quot;#74a9cf&amp;quot;, 
            colour = &amp;quot;white&amp;quot;,
            size = .1) +
    geom_sf(data = grid,
            size = .1) +
    geom_raster(data = filter(df_winkel, hour == {{step}}), aes(x, y), 
                fill = &amp;quot;grey90&amp;quot;,
                alpha = .6) +
    labs(title = str_c(&amp;quot;\U1F551&amp;quot;, str_remove(x, &amp;quot;H&amp;quot;), &amp;quot; UTC&amp;quot;)) + 
    coord_sf(xlim = bbx[c(1, 3)], ylim = bbx[c(2, 4)])  +
    theme_void() +
    theme(plot.title = element_text(hjust = .1, vjust = .9))
  
  
  ggsave(str_c(&amp;quot;wld_night_&amp;quot;, str_remove_all(step, &amp;quot;:&amp;quot;), &amp;quot;.png&amp;quot;), g,
         height = 4.3, width = 8.4, bg = &amp;quot;white&amp;quot;, dpi = 300, units = &amp;quot;in&amp;quot;)
  
})&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The creation of the final gif is done with &lt;code&gt;gifski()&lt;/code&gt; passing it the names of the images in the order as they should appear in the animation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;files &amp;lt;- str_c(&amp;quot;wld_night_H&amp;quot;, str_remove_all(as_hms(seq(0, 1410, 30)*60), &amp;quot;:&amp;quot;), &amp;quot;.png&amp;quot;)

gifski(files, &amp;quot;night_day.gif&amp;quot;, width = 807, height = 409, loop = TRUE, delay = 0.1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;night_day.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/drxeo&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;41&#34; width=&#34;174&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Climate circles</title>
      <link>https://dominicroye.github.io/en/2021/climate-circles/</link>
      <pubDate>Sat, 04 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://dominicroye.github.io/en/2021/climate-circles/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2021/climate-circles/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;The climate of a place is usually presented through climographs that combine monthly precipitation and temperature in a single chart. However, it is also interesting to visualize the climate on a daily scale showing the thermal amplitude and the daily average temperature. To do this, the averages for each day of the year of daily minimums, maximums and means are calculated.&lt;/p&gt;
&lt;p&gt;The annual climate cycle presents a good opportunity to use a radial or polar chart which allows us to clearly visualize seasonal patterns.&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Packages&lt;/h1&gt;
&lt;p&gt;We will use the following packages:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;10%&#34; /&gt;
&lt;col width=&#34;89%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Package&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;fs&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Provides a cross-platform, uniform interface to file system operations&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lubridate&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Easy manipulation of dates and times&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;janitor&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Simple functions to examine and clean data&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install the packages if necessary

if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;fs&amp;quot;)) install.packages(&amp;quot;fs&amp;quot;)
if(!require(&amp;quot;lubridate&amp;quot;)) install.packages(&amp;quot;lubridate&amp;quot;)

# packages

library(tidyverse)
library(lubridate)
library(fs)
library(janitor)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;preparation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Preparation&lt;/h1&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;We download the temperature data for a selection of US cities &lt;a href=&#34;https://dominicroye.github.io/files/weather_stats_usa.zip&#34;&gt;here&lt;/a&gt;. You can access other cities of the entire world through the WMO or GHCN datasets at &lt;a href=&#34;https://gis.ncdc.noaa.gov/maps/ncei/cdo/daily&#34;&gt;NCDC/NOAA&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;import&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Import&lt;/h2&gt;
&lt;p&gt;To import the temperature time series of each city, which we find in several files, we apply the &lt;code&gt;read_csv()&lt;/code&gt; function using &lt;code&gt;map_df()&lt;/code&gt;. The &lt;code&gt;dir_ls()&lt;/code&gt; function of the &lt;code&gt;fs&lt;/code&gt; package returns the list of files with &lt;em&gt;csv&lt;/em&gt; extension. The suffix &lt;em&gt;df&lt;/em&gt; of &lt;code&gt;map()&lt;/code&gt; indicates that we want to join all imported tables into a single one. For those with less experience with &lt;code&gt;tidyverse&lt;/code&gt;, I recommend a short introduction on this blog &lt;a href=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/&#34;&gt;post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Then we obtain the names of the weather stations and define a new vector with the new city names.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# import data
meteo &amp;lt;- dir_ls(regexp = &amp;quot;.csv$&amp;quot;) %&amp;gt;% 
          map_df(read_csv)
meteo&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 211,825 x 12
##    STATION     NAME    LATITUDE LONGITUDE ELEVATION DATE        TAVG  TMAX  TMIN
##    &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 USW00094846 CHICAG~     42.0     -87.9      202. 1950-01-01   6.8    NA    NA
##  2 USW00094846 CHICAG~     42.0     -87.9      202. 1950-01-02   8.4    NA    NA
##  3 USW00094846 CHICAG~     42.0     -87.9      202. 1950-01-03  11      NA    NA
##  4 USW00094846 CHICAG~     42.0     -87.9      202. 1950-01-04  -7.2    NA    NA
##  5 USW00094846 CHICAG~     42.0     -87.9      202. 1950-01-05 -10.2    NA    NA
##  6 USW00094846 CHICAG~     42.0     -87.9      202. 1950-01-06  -4.6    NA    NA
##  7 USW00094846 CHICAG~     42.0     -87.9      202. 1950-01-07  -7.1    NA    NA
##  8 USW00094846 CHICAG~     42.0     -87.9      202. 1950-01-08  -5.8    NA    NA
##  9 USW00094846 CHICAG~     42.0     -87.9      202. 1950-01-09   2.9    NA    NA
## 10 USW00094846 CHICAG~     42.0     -87.9      202. 1950-01-10   3.9    NA    NA
## # ... with 211,815 more rows, and 3 more variables: TAVG_ATTRIBUTES &amp;lt;chr&amp;gt;,
## #   TMAX_ATTRIBUTES &amp;lt;chr&amp;gt;, TMIN_ATTRIBUTES &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# station names
stats_names &amp;lt;- unique(meteo$NAME)
stats_names&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;CHICAGO OHARE INTERNATIONAL AIRPORT, IL US&amp;quot;             
## [2] &amp;quot;LAGUARDIA AIRPORT, NY US&amp;quot;                               
## [3] &amp;quot;MIAMI INTERNATIONAL AIRPORT, FL US&amp;quot;                     
## [4] &amp;quot;HOUSTON INTERCONTINENTAL AIRPORT, TX US&amp;quot;                
## [5] &amp;quot;ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPORT, GA US&amp;quot;
## [6] &amp;quot;SAN FRANCISCO INTERNATIONAL AIRPORT, CA US&amp;quot;             
## [7] &amp;quot;SEATTLE TACOMA AIRPORT, WA US&amp;quot;                          
## [8] &amp;quot;DENVER INTERNATIONAL AIRPORT, CO US&amp;quot;                    
## [9] &amp;quot;MCCARRAN INTERNATIONAL AIRPORT, NV US&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# new city names
cities &amp;lt;- c(&amp;quot;CHICAGO&amp;quot;, &amp;quot;NEW YORK&amp;quot;, &amp;quot;MIAMI&amp;quot;, 
            &amp;quot;HOUSTON&amp;quot;, &amp;quot;ATLANTA&amp;quot;, &amp;quot;SAN FRANCISCO&amp;quot;, 
            &amp;quot;SEATTLE&amp;quot;, &amp;quot;DENVER&amp;quot;, &amp;quot;LAS VEGAS&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;modify&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Modify&lt;/h2&gt;
&lt;p&gt;In the first step, we will modify the original data, 1) selecting only the columns of interest, 2) filtering the period 1991-2020, 3) defining the new city names, 4) calculating the average temperature where it is absent, 5) cleaning the column names, and 6) creating a new variable with the days of the year. The &lt;code&gt;clean_names()&lt;/code&gt; function of the &lt;code&gt;janitor&lt;/code&gt; package is very useful for getting clean column names.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meteo &amp;lt;- select(meteo, NAME, DATE, TAVG:TMIN) %&amp;gt;%  
           filter(DATE &amp;gt;= &amp;quot;1991-01-01&amp;quot;, DATE &amp;lt;= &amp;quot;2020-12-31&amp;quot;) %&amp;gt;% 
            mutate(NAME = factor(NAME, stats_names, cities),
                   TAVG = ifelse(is.na(TAVG), (TMAX+TMIN)/2, TAVG),
                   yd = yday(DATE)) %&amp;gt;% 
            clean_names()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the next step, we calculate the daily maximum, minimum and mean temperature for each day of the year. It now only remains to convert the days of the year into a dummy date. Here we use the year 2000 since it is a leap year, and we have a total of 366 days.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# estimate the daily averages
meteo_yday &amp;lt;- group_by(meteo, name, yd) %&amp;gt;% 
                  summarise(ta = mean(tavg, na.rm = TRUE),
                            tmx = mean(tmax, na.rm = TRUE),
                            tmin = mean(tmin, na.rm = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;name&amp;#39;. You can override using the
## `.groups` argument.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meteo_yday&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3,294 x 5
## # Groups:   name [9]
##    name       yd    ta    tmx  tmin
##    &amp;lt;fct&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 CHICAGO     1 -3.77  0.537 -7.86
##  2 CHICAGO     2 -2.64  1.03  -6.68
##  3 CHICAGO     3 -2.88  0.78  -6.93
##  4 CHICAGO     4 -2.86  0.753 -7.10
##  5 CHICAGO     5 -4.13 -0.137 -8.33
##  6 CHICAGO     6 -4.50 -1.15  -8.05
##  7 CHICAGO     7 -4.70 -0.493 -8.57
##  8 CHICAGO     8 -3.97  0.147 -8.02
##  9 CHICAGO     9 -3.47  0.547 -7.49
## 10 CHICAGO    10 -3.41  1.09  -7.64
## # ... with 3,284 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# convert the days of the year into a dummy date
meteo_yday &amp;lt;- mutate(meteo_yday, yd = as_date(yd, origin = &amp;quot;1999-12-31&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-the-climate-circles&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Creating the climate circles&lt;/h1&gt;
&lt;div id=&#34;predefinitions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Predefinitions&lt;/h2&gt;
&lt;p&gt;We define a divergent vector of various hues.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;col_temp &amp;lt;- c(&amp;quot;#cbebf6&amp;quot;,&amp;quot;#a7bfd9&amp;quot;,&amp;quot;#8c99bc&amp;quot;,&amp;quot;#974ea8&amp;quot;,&amp;quot;#830f74&amp;quot;,
              &amp;quot;#0b144f&amp;quot;,&amp;quot;#0e2680&amp;quot;,&amp;quot;#223b97&amp;quot;,&amp;quot;#1c499a&amp;quot;,&amp;quot;#2859a5&amp;quot;,
              &amp;quot;#1b6aa3&amp;quot;,&amp;quot;#1d9bc4&amp;quot;,&amp;quot;#1ca4bc&amp;quot;,&amp;quot;#64c6c7&amp;quot;,&amp;quot;#86cabb&amp;quot;,
              &amp;quot;#91e0a7&amp;quot;,&amp;quot;#c7eebf&amp;quot;,&amp;quot;#ebf8da&amp;quot;,&amp;quot;#f6fdd1&amp;quot;,&amp;quot;#fdeca7&amp;quot;,
              &amp;quot;#f8da77&amp;quot;,&amp;quot;#fcb34d&amp;quot;,&amp;quot;#fc8c44&amp;quot;,&amp;quot;#f85127&amp;quot;,&amp;quot;#f52f26&amp;quot;,
              &amp;quot;#d10b26&amp;quot;,&amp;quot;#9c042a&amp;quot;,&amp;quot;#760324&amp;quot;,&amp;quot;#18000c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We create a table with the x-axis grid lines.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grid_x &amp;lt;- tibble(x = seq(ymd(&amp;quot;2000-01-01&amp;quot;), ymd(&amp;quot;2000-12-31&amp;quot;), &amp;quot;month&amp;quot;), 
                 y = rep(-10, 12), 
                 xend = seq(ymd(&amp;quot;2000-01-01&amp;quot;), ymd(&amp;quot;2000-12-31&amp;quot;), &amp;quot;month&amp;quot;), 
                 yend = rep(41, 12))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We define all the style elements of the graph in our own theme &lt;code&gt;theme_cc()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;theme_cc &amp;lt;- function(){ 
  
 theme_minimal(base_family = &amp;quot;Montserrat&amp;quot;) %+replace%
  theme(plot.title = element_text(hjust = 0.5, colour = &amp;quot;white&amp;quot;, size = 30, margin = margin(b = 20)),
        plot.caption = element_text(colour = &amp;quot;white&amp;quot;, size = 9, hjust = .5, vjust = -30),
        plot.background = element_rect(fill = &amp;quot;black&amp;quot;),
        plot.margin = margin(1, 1, 2, 1, unit = &amp;quot;cm&amp;quot;),
  
        axis.text.x = element_text(face = &amp;quot;italic&amp;quot;, colour = &amp;quot;white&amp;quot;),
        axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        
        legend.title = element_text(colour = &amp;quot;white&amp;quot;),
        legend.position = &amp;quot;bottom&amp;quot;,
        legend.justification = 0.5,
        legend.text = element_text(colour = &amp;quot;white&amp;quot;),
       
        
        strip.text = element_text(colour = &amp;quot;white&amp;quot;, face = &amp;quot;bold&amp;quot;, size = 14),
        
        panel.spacing.y = unit(1, &amp;quot;lines&amp;quot;),
        panel.background = element_rect(fill = &amp;quot;black&amp;quot;),
        panel.grid = element_blank()
      ) 
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;graph&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Graph&lt;/h2&gt;
&lt;p&gt;We start by building a chart for New York City only. We will use &lt;code&gt;geom_linerange()&lt;/code&gt; to define line range with the daily maximum and minimum temperature. Also, we will draw the range line colour based on the mean temperature. Finally, we can adjust &lt;em&gt;alpha&lt;/em&gt; and &lt;em&gt;size&lt;/em&gt; to get a nicer look.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# filter New York
ny_city &amp;lt;- filter(meteo_yday, name == &amp;quot;NEW YORK&amp;quot;) 

# graph
ggplot(ny_city) + 
  geom_linerange(aes(yd, 
                     ymax = tmx, 
                     ymin = tmin, 
                     colour = ta),
                 size=0.5, 
                 alpha = .7) + 
  scale_y_continuous(breaks = seq(-30, 50, 10), 
                     limits = c(-11, 42), 
                     expand = expansion()) +
  scale_colour_gradientn(colours = col_temp, 
                         limits = c(-12, 35), 
                         breaks = seq(-12, 34, 5)) + 
  scale_x_date(date_breaks = &amp;quot;month&amp;quot;,
               date_labels = &amp;quot;%b&amp;quot;) +
  labs(title = &amp;quot;CLIMATE CIRCLES&amp;quot;, 
       colour = &amp;quot;Daily average temperature&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2021/climate-circles/index.en_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;2100&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To get the polar graph it would only be necessary to add the &lt;code&gt;coord_polar()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# polar chart
ggplot(ny_city) + 
  geom_linerange(aes(yd, 
                     ymax = tmx, 
                     ymin = tmin, 
                     colour = ta),
                 size=0.5, 
                 alpha = .7) + 
  scale_y_continuous(breaks = seq(-30, 50, 10), 
                     limits = c(-11, 42), 
                     expand = expansion()) +
  scale_colour_gradientn(colours = col_temp, 
                         limits = c(-12, 35), 
                         breaks = seq(-12, 34, 5)) + 
  scale_x_date(date_breaks = &amp;quot;month&amp;quot;,
               date_labels = &amp;quot;%b&amp;quot;) +
  coord_polar() +
  labs(title = &amp;quot;CLIMATE CIRCLES&amp;quot;, 
       colour = &amp;quot;Daily average temperature&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2021/climate-circles/index.en_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;2100&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the final graph, we add the grid defining the lines on the y-axis with &lt;code&gt;geom_hline()&lt;/code&gt; and those on the x-axis with &lt;code&gt;geom_segement()&lt;/code&gt;. The most important thing here is the &lt;code&gt;facet_wrap()&lt;/code&gt; function, which allows multiple facets of charts. The formula format is used to specify how the facets are created: &lt;code&gt;row ~ column&lt;/code&gt;. If we do not have a second variable, a point &lt;code&gt;.&lt;/code&gt; is indicated in the formula. In addition, we make changes to the appearance of the colour bar with &lt;code&gt;guides()&lt;/code&gt; and &lt;code&gt;guide_colourbar()&lt;/code&gt;, and we include the &lt;code&gt;theme_cc()&lt;/code&gt; style.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(meteo_yday) + 
  geom_hline(yintercept = c(-10, 0, 10, 20, 30, 40), 
             colour = &amp;quot;white&amp;quot;, 
             size = .4) +
  geom_segment(data = grid_x , 
               aes(x = x, 
                   y = y, 
                   xend = xend, 
                   yend = yend), 
               linetype = &amp;quot;dashed&amp;quot;, 
               colour = &amp;quot;white&amp;quot;, 
               size = .2) +
  geom_linerange(aes(yd, 
                     ymax = tmx, 
                     ymin = tmin, 
                     colour = ta),
                 size=0.5, 
                 alpha = .7) + 
  scale_y_continuous(breaks = seq(-30, 50, 10), 
                     limits = c(-11, 42), 
                     expand = expansion())+
  scale_colour_gradientn(colours = col_temp, 
                         limits = c(-12, 35), 
                         breaks = seq(-12, 34, 5)) + 
  scale_x_date(date_breaks = &amp;quot;month&amp;quot;, 
               date_labels = &amp;quot;%b&amp;quot;) +
  guides(colour = guide_colourbar(barwidth = 15,
                                  barheight = 0.5, 
                                  title.position = &amp;quot;top&amp;quot;)
         ) +
  facet_wrap(~name, nrow = 3) +
  coord_polar() + 
  labs(title = &amp;quot;CLIMATE CIRCLES&amp;quot;, 
       colour = &amp;quot;Daily average temperature&amp;quot;) +
  theme_cc()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2021/climate-circles/index.en_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;3540&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/drxeo&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;41&#34; width=&#34;174&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Firefly cartography</title>
      <link>https://dominicroye.github.io/en/2021/firefly-cartography/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://dominicroye.github.io/en/2021/firefly-cartography/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2021/firefly-cartography/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;cartography-firefly&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Cartography &lt;em&gt;firefly&lt;/em&gt;&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;Firefly&lt;/em&gt; maps are promoted and described by
&lt;a href=&#34;https://twitter.com/John_M_Nelson&#34;&gt;John Nelson&lt;/a&gt; who published a &lt;a href=&#34;https://adventuresinmapping.com/2016/10/17/firefly-cartography/&#34;&gt;post&lt;/a&gt; in 2016 about its characteristics. However, these types of maps are linked to ArcGIS, which has led me to try to recreate them in R. The recent &lt;code&gt;ggplot2&lt;/code&gt; extension &lt;a href=&#34;https://github.com/marcmenem/ggshadow&#34;&gt;&lt;code&gt;ggshadow&lt;/code&gt;&lt;/a&gt; facilitates the creation of this cartographic style. It is characterized by three elements 1) a dark and unsaturated basemap (eg satellite imagery) 2) a masked vignette and highlighted area and 3) a single bright thematic layer. The essential are the colors and the brightness that is achieved with cold colors, usually neon colors. John Nelson explains more details in this &lt;a href=&#34;https://www.esri.com/arcgis-blog/products/mapping/mapping/steal-this-firefly-style-please/&#34;&gt;post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;What is the &lt;em&gt;firefly&lt;/em&gt; style for? In the words of &lt;a href=&#34;https://www.esri.com/arcgis-blog/products/mapping/mapping/steal-this-firefly-style-please/&#34;&gt;John Nelson&lt;/a&gt;: “the map style that captures our attention and dutifully honors the First Law of Geography”. John refers to what was said by Waldo Tobler
“everything is related to everything else, but near things are more related than distant things” (Tobler 1970).&lt;/p&gt;
&lt;p&gt;In this post we will visualize all earthquakes recorded in southwestern Europe with a magnitude greater than 3.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Packages&lt;/h1&gt;
&lt;p&gt;We will use the following packages:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;14%&#34; /&gt;
&lt;col width=&#34;85%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Package&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;plotwidgets&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Contains functions for color conversion (RGB, HSL)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;terra&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Import, export and manipulate raster (raster successor package)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;raster&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Import, export and manipulate raster&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Simple Feature: import, export and manipulate vector data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ggshadow&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ggplot2 extension for shaded and glow geometries&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ggspatial&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ggplot2 extension for spatial objects&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ggnewscale&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ggplot2 extension to create multiple scales&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;janitor&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Simple functions to examine and clean data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;rnaturalearth&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Vector maps of the world ‘Natural Earth’&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install the packages if necessary

if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;sf&amp;quot;)) install.packages(&amp;quot;sf&amp;quot;)
if(!require(&amp;quot;terra&amp;quot;)) install.packages(&amp;quot;terra&amp;quot;)
if(!require(&amp;quot;raster&amp;quot;)) install.packages(&amp;quot;raster&amp;quot;)
if(!require(&amp;quot;plotwidgets&amp;quot;)) install.packages(&amp;quot;plotwidgets&amp;quot;)
if(!require(&amp;quot;ggshadow&amp;quot;)) install.packages(&amp;quot;ggshadow&amp;quot;)
if(!require(&amp;quot;ggspatial&amp;quot;)) install.packages(&amp;quot;ggspatial&amp;quot;)
if(!require(&amp;quot;ggnewscale&amp;quot;)) install.packages(&amp;quot;ggnewscale&amp;quot;)
if(!require(&amp;quot;janitor&amp;quot;)) install.packages(&amp;quot;janitor&amp;quot;)
if(!require(&amp;quot;rnaturalearth&amp;quot;)) install.packages(&amp;quot;rnaturalearth&amp;quot;)

# load packages

library(raster)
library(terra)
library(sf)
library(tidyverse)
library(plotwidgets)
library(ggshadow)
library(ggspatial)
library(ggnewscale)
library(janitor)
library(rnaturalearth)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;preparation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Preparation&lt;/h1&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;First we download all the necessary data. For the base map we will use the Blue Marble imagery via the access to worldview.earthdata.nasa.gov where I have downloaded a selection of the area of interest in geoTiff format with a resolution of 1 km. It is important to adjust the resolution to the necessary detail of the map.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Blue Marble selection via &lt;a href=&#34;https://worldview.earthdata.nasa.gov&#34;&gt;worldview.earthdata.nasa.gov&lt;/a&gt; ( ~ 66 MB) &lt;a href=&#34;https://www.dropbox.com/s/bt8qfkzw339q13l/snapshot-2017-11-30T00_00_00Z.tiff?dl=0&#34;&gt;download&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Records of historical earthquakes in southwestern Europe from &lt;a href=&#34;https://www.ign.es/web/ign/portal/sis-catalogo-earthquakes&#34;&gt;IGN&lt;/a&gt; &lt;a href=&#34;https://dominicroye.github.io/files/catalogoComunSV_1621713848556.csv&#34;&gt;download&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;import&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Import&lt;/h2&gt;
&lt;p&gt;The first thing we do is to import the RGB &lt;em&gt;Blue Marble&lt;/em&gt; raster and the earthquake data. To import the raster I use the new package &lt;a href=&#34;https://rspatial.org/terra/pkg/index.html&#34;&gt;&lt;code&gt;terra&lt;/code&gt;&lt;/a&gt; which is the successor of the &lt;code&gt;raster&lt;/code&gt; package. You can find a recent comparison &lt;a href=&#34;https://www.r-bloggers.com/2021/05/a-comparison-of-terra-and-raster-packages/&#34;&gt;here&lt;/a&gt;. Not all packages are yet compatible with the new &lt;code&gt;SpatRaster&lt;/code&gt; class, so we also need the &lt;code&gt;raster&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# earthquakes

earthquakes &amp;lt;- read.csv2(&amp;quot;catalogoComunSV_1621713848556.csv&amp;quot;)
str(earthquakes)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;data.frame&amp;#39;:    149724 obs. of  10 variables:
##  $ Evento       : chr  &amp;quot;          33&amp;quot; &amp;quot;          34&amp;quot; &amp;quot;          35&amp;quot; &amp;quot;          36&amp;quot; ...
##  $ Fecha        : chr  &amp;quot;  02/03/1373&amp;quot; &amp;quot;  03/03/1373&amp;quot; &amp;quot;  08/03/1373&amp;quot; &amp;quot;  19/03/1373&amp;quot; ...
##  $ Hora         : chr  &amp;quot;    00:00:00&amp;quot; &amp;quot;    00:00:00&amp;quot; &amp;quot;    00:00:00&amp;quot; &amp;quot;    00:00:00&amp;quot; ...
##  $ Latitud      : chr  &amp;quot;     42.5000&amp;quot; &amp;quot;     42.5000&amp;quot; &amp;quot;     42.5000&amp;quot; &amp;quot;     42.5000&amp;quot; ...
##  $ Longitud     : chr  &amp;quot;      0.7500&amp;quot; &amp;quot;      0.7500&amp;quot; &amp;quot;      0.7500&amp;quot; &amp;quot;      0.7500&amp;quot; ...
##  $ Prof...Km.   : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ Inten.       : chr  &amp;quot;     VIII-IX&amp;quot; &amp;quot;            &amp;quot; &amp;quot;            &amp;quot; &amp;quot;            &amp;quot; ...
##  $ Mag.         : chr  &amp;quot;            &amp;quot; &amp;quot;            &amp;quot; &amp;quot;            &amp;quot; &amp;quot;            &amp;quot; ...
##  $ Tipo.Mag.    : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ LocalizaciÃ³n: chr  &amp;quot;RibagorÃ§a.L&amp;quot; &amp;quot;RibagorÃ§a.L&amp;quot; &amp;quot;RibagorÃ§a.L&amp;quot; &amp;quot;RibagorÃ§a.L&amp;quot; ...&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Blue Marble RGB raster

bm &amp;lt;- rast(&amp;quot;snapshot-2017-11-30T00_00_00Z.tiff&amp;quot;)
bm # contains three layers (red, green, blue)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class       : SpatRaster 
## dimensions  : 7156, 7156, 3  (nrow, ncol, nlyr)
## resolution  : 0.008789272, 0.008789272  (x, y)
## extent      : -33.49823, 29.39781, 15.77547, 78.67151  (xmin, xmax, ymin, ymax)
## coord. ref. : lon/lat WGS 84 (EPSG:4326) 
## source      : snapshot-2017-11-30T00_00_00Z.tiff 
## colors RGB  : 1, 2, 3 
## names       : snapshot-2~0_00_00Z_1, snapshot-2~0_00_00Z_2, snapshot-2~0_00_00Z_3&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# plot

plotRGB(bm)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2021/firefly-cartography/index.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;2100&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# country boundaries

limits &amp;lt;- ne_countries(scale = 50, returnclass = &amp;quot;sf&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;earthquakes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Earthquakes&lt;/h2&gt;
&lt;p&gt;In this step we clean the imported earthquakes data. 1) We convert longitude, latitude and magnitude into numeric using the &lt;code&gt;parse_number()&lt;/code&gt; function and clean the column names with the &lt;code&gt;clean_names()&lt;/code&gt; function, 2) We create a spatial object &lt;code&gt;sf&lt;/code&gt; and project it using the EPSG:3035 corresponding to ETRS89-extended/LAEA Europe.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# we clean the data and create an sf object

earthquakes &amp;lt;-  earthquakes %&amp;gt;% clean_names() %&amp;gt;%
                  mutate(across(c(mag, latitud, longitud),                                                                                                 parse_number)) %&amp;gt;%
                 st_as_sf(coords = c(&amp;quot;longitud&amp;quot;, &amp;quot;latitud&amp;quot;), 
                       crs = 4326) %&amp;gt;% 
                 st_transform(3035) # project to Laea&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;blue-marble-background-map&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Blue Marble background Map&lt;/h2&gt;
&lt;p&gt;We cropped the background map to a smaller extent, but we still haven’t limited to the final area yet.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# clip to the desired area

bm &amp;lt;- crop(bm, extent(-20, 10, 30, 50)) # W, E, S, N&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To obtain an unsaturated version of the Blue Marble RGB raster, we must apply a function created for this purpose. In this, we use the &lt;code&gt;rgb2hsl()&lt;/code&gt; function from the &lt;code&gt;plotwidgets&lt;/code&gt; package, which helps us converting RGB to HSL and vice versa. The HSL model is defined by Hue, Saturation, Lightness. The last two parameters are expressed in ratio or percentage. The hue is defined on a color wheel from 0 to 360º. 0 is red, 120 is green, 240 is blue. To change the saturation we only have to reduce the value of S.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# function to change saturation from RGB

saturation &amp;lt;- function(rgb, s = .5){
  
  hsl &amp;lt;- rgb2hsl(as.matrix(rgb))
  hsl[2, ] &amp;lt;- s
  
  rgb_new &amp;lt;- as.vector(t(hsl2rgb(hsl)))
  
  return(rgb_new)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We employ our &lt;code&gt;saturation()&lt;/code&gt; function using the &lt;code&gt;app()&lt;/code&gt; function that applies it to each pixel with the three RGB layers. We add the argument &lt;code&gt;s&lt;/code&gt;, which defines the desired saturation level. This step may take several minutes. Then we project our RGB image.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# apply the function to unsaturate with 5%

bm_desat &amp;lt;- app(bm, saturation, s = .05)

# plot new RGB image

plotRGB(bm_desat)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2021/firefly-cartography/index.en_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;2100&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# project 

bm_desat &amp;lt;- terra::project(bm_desat, &amp;quot;epsg:3035&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;firefly-map-construction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;em&gt;Firefly&lt;/em&gt; map construction&lt;/h1&gt;
&lt;div id=&#34;boundaries-and-graticules&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Boundaries and graticules&lt;/h2&gt;
&lt;p&gt;Before starting to build the map, we create graticules and set the final map limits.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# define the final map extent

bx &amp;lt;- tibble(x = c(-13, 6.7), y = c(31, 47)) %&amp;gt;% 
       st_as_sf(coords = c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;), crs = 4326) %&amp;gt;%
        st_transform(3035) %&amp;gt;% 
         st_bbox()

# create map graticules

grid &amp;lt;- st_graticule(earthquakes) &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;map-with-image-background&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Map with image background&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;layer_spatial()&lt;/code&gt; function of &lt;code&gt;ggspatial&lt;/code&gt; allows us to add an RGB raster without major problems, however, it still does not support the new&lt;code&gt;SpatRaster&lt;/code&gt; class. Therefore, we must convert it to the &lt;code&gt;stack&lt;/code&gt; class with the &lt;code&gt;stack()&lt;/code&gt; function. It is also possible to use instead of &lt;code&gt;geom_sf()&lt;/code&gt;, the &lt;code&gt;layer_spatial()&lt;/code&gt; function for vector objects of class &lt;code&gt;sf&lt;/code&gt; or&lt;code&gt;sp&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot() +
  layer_spatial(data = stack(bm_desat)) + # blue marble background map
  geom_sf(data = limits, fill = NA, size = .3, colour = &amp;quot;white&amp;quot;) + # country boundaries
  coord_sf(xlim = bx[c(1, 3)], 
           ylim = bx[c(2, 4)], 
           crs = 3035,
           expand = FALSE) +
  theme_void()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2021/firefly-cartography/index.en_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;4500&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;map-with-background-and-earthquakes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Map with background and earthquakes&lt;/h2&gt;
&lt;p&gt;To create the glow effect on &lt;em&gt;firefly&lt;/em&gt; maps, we use the &lt;code&gt;geom_glowpoint()&lt;/code&gt; function from the &lt;code&gt;ggshadow&lt;/code&gt; package. There is also the same function for lines. Since our data is of spatial class &lt;code&gt;sf&lt;/code&gt; and the geometry &lt;code&gt;sf&lt;/code&gt; is not directly supported, we must indicate as an argument &lt;code&gt;stats = &#34;sf_coordinates&#34;&lt;/code&gt; and inside &lt;code&gt;aes()&lt;/code&gt; indicate &lt;code&gt;geometry = geometry&lt;/code&gt;. We will map the size of the points as a function of magnitude. In addition, we filter those earthquakes with a magnitude greater than 3.&lt;/p&gt;
&lt;p&gt;Inside the &lt;code&gt;geom_glowpoint()&lt;/code&gt; function, 1) we define the desired color for the point and the glow effect, 2) the degree of transparency with &lt;code&gt;alpha&lt;/code&gt; either for the point or for the glow. Finally, in the &lt;code&gt;scale_size()&lt;/code&gt; function we set the range (minimum, maximum) of the size that the points will have.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot() +
  layer_spatial(data = stack(bm_desat)) +
  geom_sf(data = limits, fill = NA, size = .3, colour = &amp;quot;white&amp;quot;) +
  geom_sf(data = grid, colour = &amp;quot;white&amp;quot;, size = .1, alpha = .5) +
  geom_glowpoint(data = filter(earthquakes, mag &amp;gt; 3),
                 aes(geometry = geometry, size = mag), 
                   alpha = .8,
                   color = &amp;quot;#6bb857&amp;quot;,
                   shadowcolour = &amp;quot;#6bb857&amp;quot;,
                   shadowalpha = .1,
                   stat = &amp;quot;sf_coordinates&amp;quot;,
                   show.legend = FALSE) +
  scale_size(range = c(.1, 1.5)) +
  coord_sf(xlim = bx[c(1, 3)], 
           ylim = bx[c(2, 4)], 
           crs = 3035,
           expand = FALSE) +
  theme_void()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2021/firefly-cartography/index.en_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;4500&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;final-map&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Final map&lt;/h2&gt;
&lt;p&gt;The glow effect of &lt;em&gt;firefly&lt;/em&gt; maps is characterized by having a white tone or a lighter tone in the center of the points. To achieve this, we must duplicate the previous created layer, changing only the color and make the glow points smaller.&lt;/p&gt;
&lt;p&gt;By default, &lt;code&gt;ggplot2&lt;/code&gt; does not allow to use multiple scales for the same characteristic (size, color, etc) of different layers. But the &lt;code&gt;ggnewscale&lt;/code&gt; package gives us the ability to incorporate multiple scales of a feature from different layers. The only important thing to achieve this is the order in which each layer (geom) and scale is added. First we must add the geometry and then its corresponding scale. We indicate with &lt;code&gt;new_scale(&#39;size&#39;)&lt;/code&gt; that the next layer and scale is a new one independent of the previous one. If we used &lt;code&gt;color&lt;/code&gt; or &lt;code&gt;fill&lt;/code&gt; it would be done with &lt;code&gt;new_scale_*()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot() +
  layer_spatial(data = stack(bm_desat)) +
  geom_sf(data = limits, fill = NA, size = .3, colour = &amp;quot;white&amp;quot;) +
  geom_sf(data = grid, colour = &amp;quot;white&amp;quot;, size = .1, alpha = .5) +
  geom_glowpoint(data = filter(earthquakes, mag &amp;gt; 3),
                   aes(geometry = geometry, size = mag), 
                   alpha = .8,
                   color = &amp;quot;#6bb857&amp;quot;,
                   shadowcolour = &amp;quot;#6bb857&amp;quot;,
                   shadowalpha = .1,
                   stat = &amp;quot;sf_coordinates&amp;quot;,
                   show.legend = FALSE) +
  scale_size(range = c(.1, 1.5)) +
  new_scale(&amp;quot;size&amp;quot;) +
  geom_glowpoint(data = filter(earthquakes, mag &amp;gt; 3),
                   aes(geometry = geometry, size = mag), 
                   alpha = .6,
                   shadowalpha = .05,
                   color = &amp;quot;#ffffff&amp;quot;,
                   stat = &amp;quot;sf_coordinates&amp;quot;,
                   show.legend = FALSE) +
  scale_size(range = c(.01, .7)) +
  labs(title = &amp;quot;EARTHQUAKES&amp;quot;) +
  coord_sf(xlim = bx[c(1, 3)], ylim = bx[c(2, 4)], crs = 3035,
           expand = FALSE) +
  theme_void() +
  theme(plot.title = element_text(size = 50, vjust = -5, colour = &amp;quot;white&amp;quot;, hjust = .95))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2021/firefly-cartography/index.en_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;4500&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggsave(&amp;quot;firefly_map.png&amp;quot;, width = 15, height = 15, units = &amp;quot;in&amp;quot;, dpi = 300)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/drxeo&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;41&#34; width=&#34;174&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Bivariate dasymetric map</title>
      <link>https://dominicroye.github.io/en/2021/bivariate-dasymetric-map/</link>
      <pubDate>Mon, 01 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://dominicroye.github.io/en/2021/bivariate-dasymetric-map/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2021/bivariate-dasymetric-map/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;initial-considerations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Initial considerations&lt;/h1&gt;
&lt;p&gt;A disadvantage of choropleth maps is that they tend to distort the relationship between the true underlying geography and the represented variable. It is because the administrative divisions do not usually coincide with the geographical reality where people live. Besides, large areas appear to have a weight that they do not really have because of sparsely populated regions. To better reflect reality, more realistic population distributions are used, such as land use. With Geographic Information Systems techniques, it is possible to redistribute the variable of interest as a function of a variable with a smaller spatial unit.&lt;/p&gt;
&lt;p&gt;With point data, the redistribution process is simply clipping points with population based on land use, usually classified as urban. We could also crop and mask with land use polygons when we have a vectorial polygon layer, but an interesting alternative is the same data in raster format. We will see how we can make a dasymetric map using raster data with a resolution of 100 m. This post will use data from census sections of the median income and the Gini index for Spain. We will make a dasymetric and bivariate map, representing both variables with two ranges of colours on the same map.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Packages&lt;/h1&gt;
&lt;p&gt;In this post we will use the following packages:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;10%&#34; /&gt;
&lt;col width=&#34;89%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Package&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;patchwork&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Simple grammar to combine separate ggplots into the same graphic&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;raster&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Import, export and manipulate raster&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Simple Feature: import, export and manipulate vector data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;biscale&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Tools and Palettes for Bivariate Thematic Mapping&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sysfonts&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Load fonts in R&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;showtext&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Use fonts more easily in R graphs&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install the packages if necessary
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;patchwork&amp;quot;)) install.packages(&amp;quot;patchwork&amp;quot;)
if(!require(&amp;quot;sf&amp;quot;)) install.packages(&amp;quot;sf&amp;quot;)
if(!require(&amp;quot;raster&amp;quot;)) install.packages(&amp;quot;raster&amp;quot;)
if(!require(&amp;quot;biscale&amp;quot;)) install.packages(&amp;quot;biscale&amp;quot;)
if(!require(&amp;quot;sysfonts&amp;quot;)) install.packages(&amp;quot;sysfonts&amp;quot;)
if(!require(&amp;quot;showtext&amp;quot;)) install.packages(&amp;quot;showtext&amp;quot;)

# packages
library(tidyverse)
library(sf)
library(readxl)
library(biscale)
library(patchwork)
library(raster)
library(sysfonts)
library(showtext)
library(raster)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;preparation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Preparation&lt;/h1&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;First we download all the necessary data. With the exception of the CORINE Land Cover (~ 200 MB), the data stored on this blog can be obtained directly via the indicated links.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CORINE Land Cover 2018 (geotiff): &lt;a href=&#34;https://land.copernicus.eu/pan-european/corine-land-cover/clc2018?tab=download&#34;&gt;COPERNICUS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Income data and Gini index (excel) [INE]: &lt;a href=&#34;https://dominicroye.github.io/files/renta.zip&#34;&gt;download&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Census limits of Spain (vectorial) [INE]: &lt;a href=&#34;https://dominicroye.github.io/files/SECC_CE_20200101.zip&#34;&gt;download&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;import&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Import&lt;/h2&gt;
&lt;p&gt;The first thing we do is to import the land use raster, the income and Gini index data, and the census boundaries.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# raster of CORINE LAND COVER 2018
urb &amp;lt;- raster(&amp;quot;U2018_CLC2018_V2020_20u1.tif&amp;quot;)

# income data and Gini index
renta &amp;lt;- read_excel(&amp;quot;30824.xlsx&amp;quot;)
gini &amp;lt;- read_excel(&amp;quot;37677.xlsx&amp;quot;)

# census boundaries
limits &amp;lt;- read_sf(&amp;quot;SECC_CE_20200101.shp&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;land-uses&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Land uses&lt;/h2&gt;
&lt;p&gt;In this first step we filter the census sections to obtain those of the Autonomous Community of Madrid, and we create the municipal limits. To dissolve the polygons of census tracts we apply the function &lt;code&gt;group_by()&lt;/code&gt; in combination with &lt;code&gt;summarise()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# filter the Autonomous Community of Madrid
limits &amp;lt;- filter(limits, NCA == &amp;quot;Comunidad de Madrid&amp;quot;)

# obtain the municipal limits
mun_limit &amp;lt;- group_by(limits, CUMUN) %&amp;gt;% summarise()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the next step we cut the land use raster with the limits of Madrid. I recommend always using the &lt;code&gt;crop()&lt;/code&gt; function first and then &lt;code&gt;mask()&lt;/code&gt;, the first function crop to the required extent and the second mask the values. Subsequently, we remove all the cells that correspond to 1 or 2 (urban continuous, discontinuous). Finally, we project the raster.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# project the limits
limits_prj &amp;lt;- st_transform(limits, projection(urb))

# crop and mask 
urb_mad &amp;lt;- crop(urb, limits_prj) %&amp;gt;% 
              mask(limits_prj)

# remove non-urban pixels
urb_mad[!urb_mad %in% 1:2] &amp;lt;- NA 

# plot the raster
plot(urb_mad)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2021/bivariate-dasymetric-map/index.en_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;2100&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# project
urb_mad &amp;lt;- projectRaster(urb_mad, crs = CRS(&amp;quot;+proj=longlat +datum=WGS84 +no_defs&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this step, we convert the raster data into a point &lt;code&gt;sf&lt;/code&gt; object.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# transform the raster to xyz and a sf object
urb_mad &amp;lt;- as.data.frame(urb_mad, xy = TRUE, na.rm = TRUE) %&amp;gt;%
                st_as_sf(coords = c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;), crs = 4326)

# add the columns of the coordinates
urb_mad &amp;lt;- urb_mad %&amp;gt;% rename(urb = 1) %&amp;gt;% cbind(st_coordinates(urb_mad))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;income-data-and-gini-index&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Income data and Gini index&lt;/h2&gt;
&lt;p&gt;The format of the Excels does not coincide with the original of the INE, since I have cleaned the format before in order to make this post easier. What remains is to create a column with the codes of the census sections and exclude data that correspond to another administrative level.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## income and Gini index data

renta_sec &amp;lt;- mutate(renta, NATCODE = str_extract(CUSEC, &amp;quot;[0-9]{5,10}&amp;quot;), 
                nc_len = str_length(NATCODE),
                mun_name = str_remove(CUSEC, NATCODE) %&amp;gt;% str_trim()) %&amp;gt;%
             filter(nc_len &amp;gt; 5)

gini_sec &amp;lt;- mutate(gini, NATCODE = str_extract(CUSEC, &amp;quot;[0-9]{5,10}&amp;quot;), 
               nc_len = str_length(NATCODE),
               mun_name = str_remove(CUSEC, NATCODE) %&amp;gt;% str_trim()) %&amp;gt;%
             filter(nc_len &amp;gt; 5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the next step we join both tables with the census tracts using &lt;code&gt;left_join()&lt;/code&gt; and convert columns of interest in numerical mode.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# join both the income and Gini tables with the census limits
mad &amp;lt;- left_join(limits, renta_sec, by = c(&amp;quot;CUSEC&amp;quot;=&amp;quot;NATCODE&amp;quot;)) %&amp;gt;% 
          left_join(gini_sec, by = c(&amp;quot;CUSEC&amp;quot;=&amp;quot;NATCODE&amp;quot;))

# convert selected columns to numeric
mad &amp;lt;- mutate_at(mad, c(23:27, 30:31), as.numeric)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;bivariate-variable&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bivariate variable&lt;/h2&gt;
&lt;p&gt;To create a bivariate map we must construct a single variable that combines different classes of two variables. Usually we make three classes of each variable which leads to nine combinations; in our case, the average income and the Gini index. The &lt;code&gt;biscale&lt;/code&gt; package includes helper functions to carry out this process. With the &lt;code&gt;bi_class()&lt;/code&gt; function we create the classification variable using quantiles as algorithm. Since in both variables we find missing values, we correct those combinations between both variables where an &lt;code&gt;NA&lt;/code&gt; appears.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create bivariate classification
mapbivar &amp;lt;- bi_class(mad, GINI_2017, RNMP_2017, style = &amp;quot;quantile&amp;quot;, dim = 3) %&amp;gt;% 
             mutate(bi_class = ifelse(str_detect(bi_class, &amp;quot;NA&amp;quot;), NA, bi_class))

# results
head(dplyr::select(mapbivar, GINI_2017, RNMP_2017, bi_class))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Simple feature collection with 6 features and 3 fields
## Geometry type: MULTIPOLYGON
## Dimension:     XY
## Bounding box:  xmin: 415538.9 ymin: 4451487 xmax: 469341.7 ymax: 4552422
## Projected CRS: ETRS89 / UTM zone 30N
## # A tibble: 6 x 4
##   GINI_2017 RNMP_2017 bi_class                                          geometry
##       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;                                   &amp;lt;MULTIPOLYGON [m]&amp;gt;
## 1      NA          NA &amp;lt;NA&amp;gt;     (((446007.9 4552348, 446133.7 4552288, 446207.8 ~
## 2      31       13581 2-2      (((460243.8 4487756, 460322.4 4487739, 460279 44~
## 3      30       12407 2-2      (((457392.5 4486262, 457391.6 4486269, 457391.1 ~
## 4      34.3     13779 3-2      (((468720.8 4481374, 468695.5 4481361, 468664.6 ~
## 5      33.5      9176 3-1      (((417140.2 4451736, 416867.5 4451737, 416436.8 ~
## 6      26.2     10879 1-1      (((469251.9 4480826, 469268.1 4480797, 469292.6 ~&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We finish by redistributing the inequality variable over the pixels of urban land use. The &lt;code&gt;st_join()&lt;/code&gt; function joins the data with the land use points.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# redistribute urban pixels to inequality
mapdasi &amp;lt;- st_join(urb_mad, st_transform(mapbivar, 4326))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;map-building&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Map building&lt;/h1&gt;
&lt;div id=&#34;legend-and-font&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Legend and font&lt;/h2&gt;
&lt;p&gt;Before constructing both maps we must create the legend using the &lt;code&gt;bi_legend()&lt;/code&gt; function. In the function we define the titles for each variable, the number of dimensions and the color scale. Finally, we add the Montserrat font for the final titles in the graphic.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# bivariate legend
legend2 &amp;lt;- bi_legend(pal = &amp;quot;DkViolet&amp;quot;,
                     dim = 3,
                     xlab = &amp;quot;Higher inequality&amp;quot;,
                     ylab = &amp;quot;Higher income&amp;quot;,
                     size = 9)


# download font
font_add_google(&amp;quot;Montserrat&amp;quot;, &amp;quot;Montserrat&amp;quot;)
showtext_auto()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;dasymetric-map&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Dasymetric map&lt;/h2&gt;
&lt;p&gt;We build this map using &lt;code&gt;geom_tile()&lt;/code&gt; for the pixels and &lt;code&gt;geom_sf()&lt;/code&gt; for the municipal boundaries. In addition, it will be the map on the right where we also place the legend. To add the legend we use the &lt;code&gt;annotation_custom()&lt;/code&gt; function indicating the position in the geographical coordinates of the map. The &lt;code&gt;biscale&lt;/code&gt; package also helps us with the color definition via the &lt;code&gt;bi_scale_fill()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p2 &amp;lt;- ggplot(mapdasi) + 
  geom_tile(aes(X, Y, 
                fill = bi_class), 
            show.legend = FALSE) +
  geom_sf(data = mun_limit,  
          color = &amp;quot;grey80&amp;quot;, 
          fill = NA, 
          size = 0.2) +
  annotation_custom(ggplotGrob(legend2), 
                    xmin = -3.25, xmax = -2.65,
                    ymin = 40.55, ymax = 40.95) +
  bi_scale_fill(pal = &amp;quot;DkViolet&amp;quot;, 
                dim = 3, 
                na.value = &amp;quot;grey90&amp;quot;) +
  labs(title = &amp;quot;dasymetric&amp;quot;, x = &amp;quot;&amp;quot;, y =&amp;quot;&amp;quot;) +
  bi_theme() +
  theme(plot.title = element_text(family = &amp;quot;Montserrat&amp;quot;, size = 30, face = &amp;quot;bold&amp;quot;)) +
  coord_sf(crs = 4326)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;choropleth-map&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Choropleth map&lt;/h2&gt;
&lt;p&gt;The choropleth map is built in a similar way to the previous map with the difference that we use &lt;code&gt;geom_sf()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1 &amp;lt;- ggplot(mapbivar) + 
  geom_sf(aes(fill = bi_class), 
          colour = NA, 
          size = .1, 
          show.legend = FALSE) +
  geom_sf(data = mun_limit,  
          color = &amp;quot;white&amp;quot;, 
          fill = NA, 
          size = 0.2) +
  bi_scale_fill(pal = &amp;quot;DkViolet&amp;quot;, 
                dim = 3, 
                na.value = &amp;quot;grey90&amp;quot;) +
  labs(title = &amp;quot;choropleth&amp;quot;,  x = &amp;quot;&amp;quot;, y =&amp;quot;&amp;quot;) +
  bi_theme() +
  theme(plot.title = element_text(family = &amp;quot;Montserrat&amp;quot;, size = 30, face = &amp;quot;bold&amp;quot;)) +
  coord_sf(crs = 4326)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;merge-both-maps&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Merge both maps&lt;/h2&gt;
&lt;p&gt;With the help of the &lt;code&gt;patchwork&lt;/code&gt; package, we combine both maps in a single row, first the choropleth map and on its right the dasymmetric map. More details of the grammar used for the combination of graphics &lt;a href=&#34;https://patchwork.data-imaginist.com/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# combine 
p &amp;lt;- p1 | p2

# final map
p&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2021/bivariate-dasymetric-map/index.en_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;3300&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/drxeo&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;41&#34; width=&#34;174&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A heatmap as calendar</title>
      <link>https://dominicroye.github.io/en/2020/a-heatmap-as-calendar/</link>
      <pubDate>Sun, 20 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://dominicroye.github.io/en/2020/a-heatmap-as-calendar/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2020/a-heatmap-as-calendar/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Recently I was looking for a visual representation to show the daily changes of temperature, precipitation and wind in an application &lt;a href=&#34;https://xeo81.shinyapps.io/MeteoExtremosGalicia/&#34;&gt;xeo81.shinyapps.io/MeteoExtremosGalicia&lt;/a&gt; (in Spanish), which led me to use a heatmap in the form of a calendar. The &lt;a href=&#34;https://shiny.rstudio.com/&#34;&gt;shiny&lt;/a&gt; application is updated every four hours with new data showing calendars for each weather station. The heatmap as a calendar allows you to visualize any variable with a daily time reference.&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Packages&lt;/h2&gt;
&lt;p&gt;In this post we will use the following packages:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;10%&#34; /&gt;
&lt;col width=&#34;89%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Package&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lubridate&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Easy manipulation of dates and times&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ragg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ragg provides a set of high quality and high performance raster devices&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# instalamos los paquetes si hace falta
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;ragg&amp;quot;)) install.packages(&amp;quot;ragg&amp;quot;)
if(!require(&amp;quot;lubridate&amp;quot;)) install.packages(&amp;quot;lubridate&amp;quot;)

# paquetes
library(tidyverse)
library(lubridate)
library(ragg)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For those with less experience with &lt;code&gt;tidyverse&lt;/code&gt;, I recommend the short introduction on this blog &lt;a href=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/&#34;&gt;post&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;In this example we will use the daily precipitation of Santiago de Compostela for this year 2020 (until December 20) &lt;a href=&#34;https://dominicroye.github.io/files/precipitation_santiago.csv&#34;&gt;download&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# import the data
dat_pr &amp;lt;- read_csv(&amp;quot;precipitation_santiago.csv&amp;quot;)
dat_pr&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 355 x 2
##    date          pr
##    &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt;
##  1 2020-01-01   0  
##  2 2020-01-02   0  
##  3 2020-01-03   5.4
##  4 2020-01-04   0  
##  5 2020-01-05   0  
##  6 2020-01-06   0  
##  7 2020-01-07   0  
##  8 2020-01-08   1  
##  9 2020-01-09   3.8
## 10 2020-01-10   0  
## # ... with 345 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;preparation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Preparation&lt;/h2&gt;
&lt;p&gt;In the first step we must 1) complement the time series from December 21 to December 31 with &lt;code&gt;NA&lt;/code&gt;, 2) add the day of the week, the month, the week number and the day. Depending on whether we want each week to start on Sunday or Monday, we indicate it in the &lt;code&gt;wday()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat_pr &amp;lt;- dat_pr %&amp;gt;% 
          complete(date = seq(ymd(&amp;quot;2020-01-01&amp;quot;), 
                              ymd(&amp;quot;2020-12-31&amp;quot;), 
                              &amp;quot;day&amp;quot;)) %&amp;gt;%
          mutate(weekday = wday(date, label = T, week_start = 1), 
                 month = month(date, label = T, abbr = F),
                 week = isoweek(date),
                 day = day(date))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the next step we need to make a change in the week of the year, which is because in certain years there may be, for example, a few days at the end of the year as the first week of the following year. We also create two new columns. On the one hand, we categorize precipitation into 14 classes and on the other, we define a white text color for darker tones in the heatmap.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat_pr &amp;lt;- mutate(dat_pr, 
                 week = case_when(month == &amp;quot;December&amp;quot; &amp;amp; week == 1 ~ 53,
                                  month == &amp;quot;January&amp;quot; &amp;amp; week %in% 52:53 ~ 0,
                                  TRUE ~ week),
                 pcat = cut(pr, c(-1, 0, .5, 1:5, 7, 9, 15, 20, 25, 30, 300)),
                 text_col = ifelse(pcat %in% c(&amp;quot;(15,20]&amp;quot;, &amp;quot;(20,25]&amp;quot;, &amp;quot;(25,30]&amp;quot;, &amp;quot;(30,300]&amp;quot;), 
                                   &amp;quot;white&amp;quot;, &amp;quot;black&amp;quot;)) 
      
dat_pr  &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 366 x 8
##    date          pr weekday month    week   day pcat    text_col
##    &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;ord&amp;gt;   &amp;lt;ord&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt;   &amp;lt;chr&amp;gt;   
##  1 2020-01-01   0   Wed     January     1     1 (-1,0]  black   
##  2 2020-01-02   0   Thu     January     1     2 (-1,0]  black   
##  3 2020-01-03   5.4 Fri     January     1     3 (5,7]   black   
##  4 2020-01-04   0   Sat     January     1     4 (-1,0]  black   
##  5 2020-01-05   0   Sun     January     1     5 (-1,0]  black   
##  6 2020-01-06   0   Mon     January     2     6 (-1,0]  black   
##  7 2020-01-07   0   Tue     January     2     7 (-1,0]  black   
##  8 2020-01-08   1   Wed     January     2     8 (0.5,1] black   
##  9 2020-01-09   3.8 Thu     January     2     9 (3,4]   black   
## 10 2020-01-10   0   Fri     January     2    10 (-1,0]  black   
## # ... with 356 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;visualization&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Visualization&lt;/h2&gt;
&lt;p&gt;First we create a color ramp from Brewer colors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# color ramp
pubu &amp;lt;- RColorBrewer::brewer.pal(9, &amp;quot;PuBu&amp;quot;)
col_p &amp;lt;- colorRampPalette(pubu)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Second, before building the chart, we define a custom theme as a function. To do this, we specify all the elements and their modifications with the help of the &lt;code&gt;theme()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;theme_calendar &amp;lt;- function(){

 theme(aspect.ratio = 1/2,
       
       axis.title = element_blank(),
       axis.ticks = element_blank(),
       axis.text.y = element_blank(),
       axis.text = element_text(family = &amp;quot;Montserrat&amp;quot;),
       
       panel.grid = element_blank(),
       panel.background = element_blank(),
       
       strip.background = element_blank(),
       strip.text = element_text(family = &amp;quot;Montserrat&amp;quot;, face = &amp;quot;bold&amp;quot;, size = 15),
       
       legend.position = &amp;quot;top&amp;quot;,
       legend.text = element_text(family = &amp;quot;Montserrat&amp;quot;, hjust = .5),
       legend.title = element_text(family = &amp;quot;Montserrat&amp;quot;, size = 9, hjust = 1),
       
       plot.caption =  element_text(family = &amp;quot;Montserrat&amp;quot;, hjust = 1, size = 8),
       panel.border = element_rect(colour = &amp;quot;grey&amp;quot;, fill=NA, size=1),
       plot.title = element_text(family = &amp;quot;Montserrat&amp;quot;, hjust = .5, size = 26, 
                                 face = &amp;quot;bold&amp;quot;, 
                                 margin = margin(0,0,0.5,0, unit = &amp;quot;cm&amp;quot;)),
       plot.subtitle = element_text(family = &amp;quot;Montserrat&amp;quot;, hjust = .5, size = 16)
  )
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we build the final chart using &lt;code&gt;geom_tile()&lt;/code&gt; and specify the day of the week as the X axis and the week number as the Y axis. As you can see in the variable of the week number (&lt;code&gt;-week&lt;/code&gt;), I change the sign so that the first day of each month is in the first row. With &lt;code&gt;geom_text()&lt;/code&gt; we add the number of each day with its color according to what we defined previously. In &lt;code&gt;guides&lt;/code&gt; we make the adjustments of the colorbar and in &lt;code&gt;scale_fill/colour_manual()&lt;/code&gt; we define the corresponding colors. An important step is found in &lt;code&gt;facet_wrap()&lt;/code&gt; where we specify the facets composition of each month. The facets should have free scales and the ideal would be a 4 x 3 facet distribution. It is possible to modify the position of the day number to another using the arguments &lt;code&gt;nudge_*&lt;/code&gt; in &lt;code&gt;geom_text()&lt;/code&gt; (eg bottom-right corner: nudge_x = .35, nudge_y = -.25).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;    ggplot(dat_pr, 
           aes(weekday, -week, fill = pcat)) +
      geom_tile(colour = &amp;quot;white&amp;quot;, size = .4)  + 
      geom_text(aes(label = day, colour = text_col), size = 2.5) +
      guides(fill = guide_colorsteps(barwidth = 25, 
                                     barheight = .4,
                                    title.position = &amp;quot;top&amp;quot;)) +
       scale_fill_manual(values = c(&amp;quot;white&amp;quot;, col_p(13)),
                         na.value = &amp;quot;grey90&amp;quot;, drop = FALSE) +
       scale_colour_manual(values = c(&amp;quot;black&amp;quot;, &amp;quot;white&amp;quot;), guide = FALSE) + 
       facet_wrap(~ month, nrow = 4, ncol = 3, scales = &amp;quot;free&amp;quot;) +
       labs(title = &amp;quot;How is 2020 being in Santiago?&amp;quot;, 
             subtitle = &amp;quot;Precipitation&amp;quot;,
             caption = &amp;quot;Data: Meteogalicia&amp;quot;,
             fill = &amp;quot;mm&amp;quot;) +
       theme_calendar()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/a-heatmap-as-calendar/index.en_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To export we will use the &lt;a href=&#34;https://github.com/r-lib/ragg&#34;&gt;&lt;code&gt;ragg&lt;/code&gt;&lt;/a&gt; package, which provides higher performance and quality than the standard raster devices provided by grDevices.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggsave(&amp;quot;pr_calendar.png&amp;quot;, height = 10, width = 8, device = agg_png())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In other heatmap calendars I have added the predominant wind direction of each day as an arrow using &lt;code&gt;geom_arrow()&lt;/code&gt; from the &lt;code&gt;metR&lt;/code&gt; package (it can be seen in the aforementioned application).&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/drxeo&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;41&#34; width=&#34;174&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Climate animation of maximum temperatures</title>
      <link>https://dominicroye.github.io/en/2020/climate-animation-of-maximum-temperatures/</link>
      <pubDate>Sun, 11 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://dominicroye.github.io/en/2020/climate-animation-of-maximum-temperatures/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2020/climate-animation-of-maximum-temperatures/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;In the field of data visualization, the animation of spatial data in its temporal dimension can show fascinating changes and patterns. As a result of one of the last publications in the social networks that I have made, I was asked to make a post about how I created it. Well, here we go to start with an example of data from mainland Spain. You can find more animations in the graphics &lt;a href=&#34;https://dominicroye.github.io/en/graphs/climate/&#34;&gt;section&lt;/a&gt; of my blog.&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;I couldn&amp;#39;t resist to make another animation. Smoothed daily maximum temperature throughout the year in Europe. &lt;a href=&#34;https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rstats&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/ggplot2?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#ggplot2&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/dataviz?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#dataviz&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/climate?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#climate&lt;/a&gt; &lt;a href=&#34;https://t.co/ZC9L0vh3vR&#34;&gt;pic.twitter.com/ZC9L0vh3vR&lt;/a&gt;&lt;/p&gt;&amp;mdash; Dr. Dominic Royé (@dr_xeo) &lt;a href=&#34;https://twitter.com/dr_xeo/status/1259059168817930240?ref_src=twsrc%5Etfw&#34;&gt;May 9, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Packages&lt;/h2&gt;
&lt;p&gt;In this post we will use the following packages:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;14%&#34; /&gt;
&lt;col width=&#34;85%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Packages&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;rnaturalearth&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Vector maps of the world ‘Natural Earth’&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lubridate&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Easy manipulation of dates and times&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Simple Feature: import, export and manipulate vector data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;raster&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Import, export and manipulate raster&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ggthemes&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Themes for ggplot2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;gifski&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Create gifs&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;showtext&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Use fonts more easily in R graphs&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sysfonts&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Load fonts in R&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install the packages if necessary
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;rnaturalearth&amp;quot;)) install.packages(&amp;quot;rnaturalearth&amp;quot;)
if(!require(&amp;quot;lubridate&amp;quot;)) install.packages(&amp;quot;lubridate&amp;quot;)
if(!require(&amp;quot;sf&amp;quot;)) install.packages(&amp;quot;sf&amp;quot;)
if(!require(&amp;quot;ggthemes&amp;quot;)) install.packages(&amp;quot;ggthemes&amp;quot;)
if(!require(&amp;quot;gifski&amp;quot;)) install.packages(&amp;quot;gifski&amp;quot;)
if(!require(&amp;quot;raster&amp;quot;)) install.packages(&amp;quot;raster&amp;quot;)
if(!require(&amp;quot;sysfonts&amp;quot;)) install.packages(&amp;quot;sysfonts&amp;quot;)
if(!require(&amp;quot;showtext&amp;quot;)) install.packages(&amp;quot;showtext&amp;quot;)

# packages
library(raster)
library(tidyverse)
library(lubridate)
library(ggthemes)
library(sf)
library(rnaturalearth)
library(extrafont)
library(showtext)
library(RColorBrewer)
library(gifski)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For those with less experience with &lt;code&gt;tidyverse&lt;/code&gt;, I recommend the short introduction on this blog (&lt;a href=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/&#34;&gt;post&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;preparation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Preparation&lt;/h1&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;First, we need to download the STEAD dataset of the maximum temperature (&lt;em&gt;tmax_pen.nc&lt;/em&gt;) in &lt;em&gt;netCDF&lt;/em&gt; format from the CSIC repository &lt;a href=&#34;https://digital.csic.es/handle/10261/177655&#34;&gt;here&lt;/a&gt; (the size of the data is 2 GB). It is a set of data with a spatial resolution of 5 km and includes daily maximum temperatures from 1901 to 2014. In climatology and meteorology, a widely used format is that of &lt;em&gt;netCDF&lt;/em&gt; databases, which allow to obtain a multidimensional structure and to exchange data independently of the usued operating system. It is a space-time format with a regular or irregular grid. The multidimensional structure in the form of arrays or cubes can handle not only spatio-temporal data but also multivariate ones. In our dataset we will have an array of three dimensions: longitude, latitude and time of the maximum temperature.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://dominicroye.github.io/img/3d_ncdf.en.png&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Royé 2015. Sémata: Ciencias Sociais e Humanidades 27:11-37&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;import-the-dataset&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Import the dataset&lt;/h2&gt;
&lt;p&gt;The &lt;em&gt;netCDF&lt;/em&gt; format with &lt;em&gt;.nc&lt;/em&gt; extension can be imported via two main packages: 1) &lt;code&gt;ncdf4&lt;/code&gt; and 2) &lt;code&gt;raster&lt;/code&gt;. Actually, the &lt;code&gt;raster&lt;/code&gt; package use the first package to import the &lt;em&gt;netCDF&lt;/em&gt; datasets. In this post we will use the &lt;code&gt;raster&lt;/code&gt; package since it is somewhat easier, with some very useful and more universal functions for all types of &lt;em&gt;raster&lt;/em&gt; format. The main import functions are: &lt;code&gt;raster()&lt;/code&gt;, &lt;code&gt;stack()&lt;/code&gt; and &lt;code&gt;brick()&lt;/code&gt;. The first function only allows you to import a single layer, instead, the last two functions are used for multidimensional data. In our dataset we only have one variable, therefore it would not be necessary to use the &lt;code&gt;varname&lt;/code&gt; argument.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# import netCDF data
tmx &amp;lt;- brick(&amp;quot;tmax_pen.nc&amp;quot;, varname = &amp;quot;tx&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required namespace: ncdf4&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tmx # metadata&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class      : RasterBrick 
## dimensions : 190, 230, 43700, 41638  (nrow, ncol, ncell, nlayers)
## resolution : 0.0585, 0.045  (x, y)
## extent     : -9.701833, 3.753167, 35.64247, 44.19247  (xmin, xmax, ymin, ymax)
## crs        : +proj=longlat +datum=WGS84 +no_defs 
## source     : tmax_pen.nc 
## names      : X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14, X15, ... 
## Time (days since 1901-01-01): 1, 41638 (min, max)
## varname    : tx&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;RasterBrick&lt;/code&gt; object details show you all the necessary metadata: the resolution, the dimensions or the type of projection, or the name of the variable. It also tells us that it only points to the data source and has not imported them into the memory, which makes it easier to work with large datasets.&lt;/p&gt;
&lt;p&gt;To access any layer we use &lt;code&gt;[[ ]]&lt;/code&gt; with the corresponding index. So we can easily plot any day of the 41,638 days we have.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# map any day
plot(tmx[[200]], col = rev(heat.colors(7)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/climate-animation-of-maximum-temperatures/index.en_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;calculate-the-average-temperature&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Calculate the average temperature&lt;/h2&gt;
&lt;p&gt;In this step the objective is to calculate the average maximum temperature for each day of the year. Therefore, the first thing we do is to create a vector, indicating the day of the year for the entire time series. In the &lt;code&gt;raster&lt;/code&gt; package we have the &lt;code&gt;stackApply()&lt;/code&gt; function that allows us to apply another function on groups of layers, or rather, indexes. Since our dataset is large, we include this function in parallelization functions.&lt;/p&gt;
&lt;p&gt;For the parallelization we start and end always with the &lt;code&gt;beginClusterr()&lt;/code&gt; and &lt;code&gt;endCluster()&lt;/code&gt;. In the first function we must indicate the number of cores we want to use. In this case, I use 4 of 7 possible cores, however, the number must be changed according to the characteristics of each CPU, the general rule is n-1. So the &lt;code&gt;clusterR&lt;/code&gt; function execute a function in parallel with multiple cores. The first argument corresponds to the raster object, the second to the used function, and as list argument we pass the arguments of the &lt;code&gt;stackApply()&lt;/code&gt; function: the indexes that create the groups and the function used for each of the groups. Adding the argument &lt;code&gt;progress = &#39;text&#39;&lt;/code&gt; shows a progress bar of the calculation process.&lt;/p&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    For the US dataset I did the preprocessing, the calculation of the average, in a cloud computing platform through &lt;a href=&#34;https://earthengine.google.com/&#34;&gt;Google Earth Engine&lt;/a&gt;, which makes the whole process faster. In the case of Australia the preprocessing was more complex as the dataset is separated in multiple &lt;em&gt;netCDF&lt;/em&gt; files for each year.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# convert the dates between 1901 and 2014 to days of the year
time_days &amp;lt;- yday(seq(as_date(&amp;quot;1901-01-01&amp;quot;), as_date(&amp;quot;2014-12-31&amp;quot;), &amp;quot;day&amp;quot;))

# calculate the average
beginCluster(4)
tmx_mean &amp;lt;- clusterR(tmx, stackApply, args = list(indices = time_days, fun = mean))
endCluster()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;smooth-the-temperature-variability&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Smooth the temperature variability&lt;/h2&gt;
&lt;p&gt;Before we start to smooth the time series of our &lt;em&gt;RasterBrick&lt;/em&gt;, an example of why we do it. We extract a pixel from our dataset at coordinates -1º of longitude and 40º of latitude using the &lt;code&gt;extract()&lt;/code&gt; function. Since the function with the same name appears in several packages, we must change to the form &lt;code&gt;package_name::function_name&lt;/code&gt;. The result is a matrix with a single row corresponding to the pixel and 366 columns of the days of the year. The next step is to create a &lt;em&gt;data.frame&lt;/em&gt; with a &lt;em&gt;dummy&lt;/em&gt; date and the extracted maximum temperature.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract a pixel
point_ts &amp;lt;- raster::extract(tmx_mean, matrix(c(-1, 40), nrow = 1))
dim(point_ts) # dimensions&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]   1 366&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create a data.frame
df &amp;lt;- data.frame(date = seq(as_date(&amp;quot;2000-01-01&amp;quot;), as_date(&amp;quot;2000-12-31&amp;quot;), &amp;quot;day&amp;quot;),
                 tmx = point_ts[1,])

# visualize the maximum temperature
ggplot(df, 
       aes(date, tmx)) + 
     geom_line() + 
  scale_x_date(date_breaks = &amp;quot;month&amp;quot;, date_labels = &amp;quot;%b&amp;quot;) +
  scale_y_continuous(breaks = seq(5, 28, 2)) +
  labs(y = &amp;quot;maximum temperature&amp;quot;, x = &amp;quot;&amp;quot;, colour =  &amp;quot;&amp;quot;) +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/climate-animation-of-maximum-temperatures/index.en_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The graph clearly shows the still existing variability, which would cause an animation to fluctuate quite a bit. Therefore, we create a smoothing function based on a local polynomial regression fit (LOESS), more details can be found in the help of the &lt;code&gt;loess()&lt;/code&gt; function. The most important argument is &lt;code&gt;span&lt;/code&gt;, which determines the degree of smoothing, the smaller the value the less smooth the curve will be. I found the best result showed a value of 0.5.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;daily_smooth &amp;lt;- function(x, span = 0.5){
  
  if(all(is.na(x))){
   
    return(x) 
   
  } else {
    
  df &amp;lt;- data.frame(yd = 1:366, ta = x)
  m &amp;lt;- loess(ta ~ yd, span = span, data = df)
  est &amp;lt;- predict(m, 1:366)

  return(est)
  
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We apply our new smoothing function to the extracted time series and make some changes to be able to visualize the difference between the original and smoothed data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# smooth the temperature
df &amp;lt;- mutate(df, tmx_smoothed = daily_smooth(tmx)) %&amp;gt;% 
          pivot_longer(2:3, names_to = &amp;quot;var&amp;quot;, values_to = &amp;quot;temp&amp;quot;)

# visualize the difference
ggplot(df, 
       aes(date, temp, 
           colour = var)) + 
     geom_line() + 
  scale_x_date(date_breaks = &amp;quot;month&amp;quot;, date_labels = &amp;quot;%b&amp;quot;) +
  scale_y_continuous(breaks = seq(5, 28, 2)) +
  scale_colour_manual(values = c(&amp;quot;#f4a582&amp;quot;, &amp;quot;#b2182b&amp;quot;)) +
  labs(y = &amp;quot;maximum temperature&amp;quot;, x = &amp;quot;&amp;quot;, colour =  &amp;quot;&amp;quot;) +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/climate-animation-of-maximum-temperatures/index.en_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As we see in the graph, the smoothed curve follows the original curve very well. In the next step we apply our function to the &lt;em&gt;RasterBrick&lt;/em&gt; with the &lt;code&gt;calc()&lt;/code&gt; function. The function returns as many layers as those returned by the function used for each of the time series.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# smooth the RasterBrick
tmx_smooth &amp;lt;- calc(tmx_mean, fun = daily_smooth)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;visualization&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Visualization&lt;/h1&gt;
&lt;div id=&#34;preparation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Preparation&lt;/h2&gt;
&lt;p&gt;To visualize the maximum temperatures throughout the year, first, we convert the &lt;em&gt;RasterBrick&lt;/em&gt; to a &lt;em&gt;data.frame&lt;/em&gt;, including longitude and latitude, but removing all time series without values (&lt;code&gt;NA&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# convert to data.frame
tmx_mat &amp;lt;- as.data.frame(tmx_smooth, xy = TRUE, na.rm = TRUE)

# rename the columns 
tmx_mat &amp;lt;- set_names(tmx_mat, c(&amp;quot;lon&amp;quot;, &amp;quot;lat&amp;quot;, str_c(&amp;quot;D&amp;quot;, 1:366)))
str(tmx_mat[, 1:10])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;data.frame&amp;#39;:    20676 obs. of  10 variables:
##  $ lon: num  -8.03 -7.98 -7.92 -7.86 -7.8 ...
##  $ lat: num  43.8 43.8 43.8 43.8 43.8 ...
##  $ D1 : num  10.5 10.3 10 10.9 11.5 ...
##  $ D2 : num  10.5 10.3 10.1 10.9 11.5 ...
##  $ D3 : num  10.5 10.3 10.1 10.9 11.5 ...
##  $ D4 : num  10.6 10.4 10.1 10.9 11.5 ...
##  $ D5 : num  10.6 10.4 10.1 11 11.6 ...
##  $ D6 : num  10.6 10.4 10.1 11 11.6 ...
##  $ D7 : num  10.6 10.4 10.2 11 11.6 ...
##  $ D8 : num  10.6 10.4 10.2 11 11.6 ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Second, we import the administrative boundaries with the &lt;code&gt;ne_countries()&lt;/code&gt; function from the &lt;code&gt;rnaturalearth&lt;/code&gt; package, limiting the extension to the region of the Iberian Peninsula, southern France and northern Africa.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# import global boundaries
map &amp;lt;- ne_countries(scale = 10, returnclass = &amp;quot;sf&amp;quot;) %&amp;gt;% st_cast(&amp;quot;MULTILINESTRING&amp;quot;)

# limit the extension
map &amp;lt;- st_crop(map, xmin = -10, xmax = 5, ymin = 35, ymax = 44) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: attribute variables are assumed to be spatially constant throughout all
## geometries&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# map of boundaries
plot(map)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: plotting the first 9 out of 94 attributes; use max.plot = 94 to plot
## all&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/climate-animation-of-maximum-temperatures/index.en_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Third, we create a vector with the day of the year as labels in order to include them later in the animation. In addition, we define the break points for the maximum temperature, adapted to the distribution of our data, to obtain a categorization with a total of 20 classes.&lt;/p&gt;
&lt;p&gt;Fourth, we apply the &lt;code&gt;cut()&lt;/code&gt; function with the breaks to all the columns with temperature data of each day of the year.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# labels of day of the year
lab &amp;lt;- as_date(0:365, &amp;quot;2000-01-01&amp;quot;) %&amp;gt;% format(&amp;quot;%d %B&amp;quot;)

# breaks for the temperature data
ct &amp;lt;- c(-5, 0, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 40, 45)

# categorized data with fixed breaks
tmx_mat_cat &amp;lt;- mutate_at(tmx_mat, 3:368, cut, breaks = ct)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Fifth, we download the Montserrat font and define the colors corresponding to the created classes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# download font
font_add_google(&amp;quot;Montserrat&amp;quot;, &amp;quot;Montserrat&amp;quot;)

# use of showtext with 300 DPI
showtext_opts(dpi = 300)
showtext_auto()

# define the color ramp
col_spec &amp;lt;- colorRampPalette(rev(brewer.pal(11, &amp;quot;Spectral&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;static-map&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Static map&lt;/h2&gt;
&lt;p&gt;In this first plot we make a map of May 29 (day 150). I am not going to explain all the details of the construction with &lt;code&gt;ggplot2&lt;/code&gt;, however, it is important to note that I use the &lt;code&gt;aes_string()&lt;/code&gt; function instead of &lt;code&gt;aes()&lt;/code&gt; to use the column names in string format. With the &lt;code&gt;geom_raster()&lt;/code&gt; function we add the gridded temperature data as the first layer of the graph and with &lt;code&gt;geom_sf()&lt;/code&gt; the boundaries in &lt;code&gt;sf&lt;/code&gt; class. Finally, the &lt;code&gt;guide_colorsteps()&lt;/code&gt; function allows you to create a nice legend based on the classes created by the &lt;code&gt;cut()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(tmx_mat_cat) + 
         geom_raster(aes_string(&amp;quot;lon&amp;quot;, &amp;quot;lat&amp;quot;, fill = &amp;quot;D150&amp;quot;)) +
         geom_sf(data = map,
                 colour = &amp;quot;grey50&amp;quot;, size = 0.2) +
  coord_sf(expand = FALSE) +
  scale_fill_manual(values = col_spec(20), drop = FALSE) +
  guides(fill = guide_colorsteps(barwidth = 30, 
                                 barheight = 0.5,
                                 title.position = &amp;quot;right&amp;quot;,
                                 title.vjust = .1)) +
   theme_void() +
   theme(legend.position = &amp;quot;top&amp;quot;,
      legend.justification = 1,
      plot.caption = element_text(family = &amp;quot;Montserrat&amp;quot;, 
                                  margin = margin(b = 5, t = 10, unit = &amp;quot;pt&amp;quot;)),                
      plot.title = element_text(family = &amp;quot;Montserrat&amp;quot;, 
                                size = 16, face = &amp;quot;bold&amp;quot;, 
                                margin = margin(b = 2, t = 5, unit = &amp;quot;pt&amp;quot;)),
     legend.text = element_text(family = &amp;quot;Montserrat&amp;quot;),
     plot.subtitle = element_text(family = &amp;quot;Montserrat&amp;quot;, 
                                  size = 13, 
                                  margin = margin(b = 10, t = 5, unit = &amp;quot;pt&amp;quot;))) +
   labs(title = &amp;quot;Average maximum temperature during the year in Spain&amp;quot;, 
     subtitle = lab[150], 
     caption = &amp;quot;Reference period 1901-2014. Data: STEAD&amp;quot;,
     fill = &amp;quot;ºC&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/img/fig_1.en.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;animation-of-the-whole-year&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Animation of the whole year&lt;/h2&gt;
&lt;p&gt;The final animation consists of creating a gif from all the images of 366 days, in principle, the &lt;code&gt;gganimate&lt;/code&gt; package could be used, but in my experience it is slower, since it requires a &lt;code&gt;data.frame&lt;/code&gt; in long format. In this example a long table would have more than seven million rows. So what we do here is to use a loop over the columns and join all the created images with the &lt;code&gt;gifski&lt;/code&gt; package that also uses &lt;code&gt;gganimate&lt;/code&gt; for rendering.&lt;/p&gt;
&lt;p&gt;Before looping we create a vector with the time steps or names of the columns, and another vector with the name of the images, including the name of the folder. In order to obtain a list of images ordered by their number, we must maintain three figures, filling the positions on the left with zeros.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;time_step &amp;lt;- str_c(&amp;quot;D&amp;quot;, 1:366)

files &amp;lt;- str_c(&amp;quot;./ta_anima/D&amp;quot;, str_pad(1:366, 3, &amp;quot;left&amp;quot;, &amp;quot;0&amp;quot;), &amp;quot;.png&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Lastly, we include the above plot construction in a for loop.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;for(i in 1:366){

 ggplot(tmx_mat_cat) + 
         geom_raster(aes_string(&amp;quot;lon&amp;quot;, &amp;quot;lat&amp;quot;, fill = time_step[i])) +
         geom_sf(data = map,
                 colour = &amp;quot;grey50&amp;quot;, size = 0.2) +
  coord_sf(expand = FALSE) +
  scale_fill_manual(values = col_spec(20), drop = FALSE) +
  guides(fill = guide_colorsteps(barwidth = 30, 
                                 barheight = 0.5,
                                 title.position = &amp;quot;right&amp;quot;,
                                 title.vjust = .1)) +
   theme_void() +
   theme(legend.position = &amp;quot;top&amp;quot;,
      legend.justification = 1,
      plot.caption = element_text(family = &amp;quot;Montserrat&amp;quot;, 
                                  margin = margin(b = 5, t = 10, unit = &amp;quot;pt&amp;quot;)),                
      plot.title = element_text(family = &amp;quot;Montserrat&amp;quot;, 
                                size = 16, face = &amp;quot;bold&amp;quot;, 
                                margin = margin(b = 2, t = 5, unit = &amp;quot;pt&amp;quot;)),
     legend.text = element_text(family = &amp;quot;Montserrat&amp;quot;),
     plot.subtitle = element_text(family = &amp;quot;Montserrat&amp;quot;, 
                                  size = 13, 
                                  margin = margin(b = 10, t = 5, unit = &amp;quot;pt&amp;quot;))) +
   labs(title = &amp;quot;Average maximum temperature during the year in Spain&amp;quot;, 
     subtitle = lab[i], 
     caption = &amp;quot;Reference period 1901-2014. Data: STEAD&amp;quot;,
     fill = &amp;quot;ºC&amp;quot;)
  
  ggsave(files[i], width = 8.28, height = 7.33, type = &amp;quot;cairo&amp;quot;)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After having created images for each day of the year, we only have to create the gif.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gifski(files, &amp;quot;tmx_spain.gif&amp;quot;, width = 800, height = 700, loop = FALSE, delay = 0.05)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/img/tmx_spain.en.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/drxeo&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;41&#34; width=&#34;174&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>River flow directions</title>
      <link>https://dominicroye.github.io/en/2020/river-flow-directions/</link>
      <pubDate>Fri, 24 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://dominicroye.github.io/en/2020/river-flow-directions/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2020/river-flow-directions/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I recently created a visualization of the distribution of river flow directions and also of coastal orientations. Following its publication in social networks (&lt;a href=&#34;%5Btweet%5D(https://twitter.com/dr_xeo/status/1277978724034465798?s=20)&#34;&gt;here&lt;/a&gt;), I was asked to make a post about how I did it. Well, here we go to start with an example of rivers, coastal orientation is somewhat more complex. I did the same for a selection of European rivers here in this &lt;a href=&#34;https://twitter.com/dr_xeo/status/1277243216828473345?s=20&#34;&gt;tweet&lt;/a&gt;. However, originally I started with the orientation of the European coasts.&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Have you ever wondered where the European &lt;a href=&#34;https://twitter.com/hashtag/coasts?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#coasts&lt;/a&gt; are oriented? &lt;a href=&#34;https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rstats&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/ggplot2?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#ggplot2&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/geography?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#geography&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/dataviz?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#dataviz&lt;/a&gt; &lt;a href=&#34;https://t.co/tpWVxSoHlw&#34;&gt;pic.twitter.com/tpWVxSoHlw&lt;/a&gt;&lt;/p&gt;&amp;mdash; Dr. Dominic Royé (@dr_xeo) &lt;a href=&#34;https://twitter.com/dr_xeo/status/1265286552525180929?ref_src=twsrc%5Etfw&#34;&gt;May 26, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Packages&lt;/h2&gt;
&lt;p&gt;In this post we will use the following packages:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;12%&#34; /&gt;
&lt;col width=&#34;87%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Packages&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;remotes&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Installation from remote repositories&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;qgisprocess&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Interface between R and QGIS&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Simple Feature: import, export and manipulate vector data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ggtext&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Improved text rendering support for ggplot2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sysfonts&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Load fonts in R&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;showtext&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Use fonts more easily in R graphs&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;circular&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Functions for working with circular data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;geosphere&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Spherical trigonometry for geographic applications&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;In the case of the &lt;code&gt;qgisprocess&lt;/code&gt; package, it is necessary to install QIGS &amp;gt;= 3.16 &lt;a href=&#34;https://download.qgis.org/&#34;&gt;here&lt;/a&gt;. I will explain the reason for using QGIS later.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install the packages if necessary
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;remotes&amp;quot;)) install.packages(&amp;quot;remotes&amp;quot;)
if(!require(&amp;quot;qgisprocess&amp;quot;)) remotes::install_github(&amp;quot;paleolimbot/qgisprocess&amp;quot;)
if(!require(&amp;quot;sf&amp;quot;)) install.packages(&amp;quot;sf&amp;quot;)
if(!require(&amp;quot;ggtext&amp;quot;)) install.packages(&amp;quot;ggtext&amp;quot;)
if(!require(&amp;quot;circular&amp;quot;)) install.packages(&amp;quot;circular&amp;quot;)
if(!require(&amp;quot;geosphere&amp;quot;)) install.packages(&amp;quot;geosphere&amp;quot;)
if(!require(&amp;quot;sysfonts&amp;quot;)) install.packages(&amp;quot;sysfonts&amp;quot;)
if(!require(&amp;quot;showtext&amp;quot;)) install.packages(&amp;quot;showtext&amp;quot;)

# packages
library(sf)
library(tidyverse)
library(ggtext)
library(circular)
library(geosphere)
library(qgisprocess)
library(showtext)
library(sysfonts)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;initial-considerations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Initial considerations&lt;/h1&gt;
&lt;p&gt;Angles in vectorial lines are based on the angle between two vertices, and the number of vertices depends on the complexity, and therefore the resolution, of the vector data. Consequently, there can be differences in using different resolutions of a spatial line, either from the coast or from the river as in this example. A straight line is simply constructed with two points of longitude and latitude.&lt;/p&gt;
&lt;p&gt;Related to this is fractality, an apparently irregular structure but that is repeated at different scales, known from coastlines or also from river. The most paradoxical feature is that the length of a coastline depends on the measurement scale, the smaller the measurement increment, the longer is the measured coastline.&lt;/p&gt;
&lt;p&gt;There are two possibilities of obtaining the vertice angles. In the first one we calculate the angle between all consecutive vertices.&lt;/p&gt;
&lt;p&gt;For example, imagine two points, Madrid (-3.71, 40.43) and Barcelona (2.14, 41.4).&lt;/p&gt;
&lt;p&gt;What is the angle of a straight line between both cities?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bearingRhumb(c(-3.71, 40.43), c(2.14, 41.4))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 77.62391&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that it is 77º, that is, northeast direction. But what if we go from Barcelona to Madrid?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bearingRhumb(c(2.14, 41.4), c(-3.71, 40.43))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 257.6239&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The angle is different because we &lt;em&gt;move&lt;/em&gt; from the northeast to the southwest. We can easily invert the direction to get the opposite angle.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# opposite angle of Barcelona -&amp;gt; Madrid
bearingRhumb(c(2.14, 41.4), c(-3.71, 40.43)) - 180&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 77.62391&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# opposite angle of Madrid -&amp;gt; Barcelona
bearingRhumb(c(-3.71, 40.43), c(2.14, 41.4)) + 180&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 257.6239&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The direction in which we calculate the angles is important. In the case of rivers, it is expected to be the direction of flow from origin to the mouth, however, a problem may be that the vertices, which build the lines, are not geographically ordered in the attribute table. Another problem may be that the vertices start at the mouth which would give the reverse angle as we have seen before.&lt;/p&gt;
&lt;p&gt;However, there is an easier way. We can take advantage of the attributes of projected coordinate systems (Robinson projection, etc.) that include the angle between the vertices. We will use this last approach in this post. Still, we must pay close attention to the results as stated above.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;preparation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Preparation&lt;/h1&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;We download the central lines of the largest rivers in the world (&lt;a href=&#34;https://dominicroye.github.io/files/RiverHRCenterlinesCombo.zip&#34;&gt;here&lt;/a&gt;), also accessible in &lt;a href=&#34;https://www.sciencebase.gov/catalog/item/5a145fdde4b09fc93dcfd36c&#34;&gt;Zeenatul Basher et al. 2018&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;import-and-project&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Import and project&lt;/h2&gt;
&lt;p&gt;The first thing we do is to import, project the spatial lines and delete the third dimension &lt;em&gt;Z&lt;/em&gt;, chaining the following functions: &lt;code&gt;st_read()&lt;/code&gt; helps us import any vector format, &lt;code&gt;st_zm()&lt;/code&gt; delete the dimension Z or M of a geometry and &lt;code&gt;st_transform()&lt;/code&gt; projects the vector data to the new projection in &lt;em&gt;proj4&lt;/em&gt; format. We combine the functions with the famous pipe (&lt;code&gt;%&amp;gt;%&lt;/code&gt;) that facilitates the application of a sequence of functions on a data set, more details in this &lt;a href=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/&#34;&gt;post&lt;/a&gt;. All functions in the &lt;code&gt;sf&lt;/code&gt; package start with &lt;code&gt;st_*&lt;/code&gt; with reference to the spatial character, similar to &lt;em&gt;PostGIS&lt;/em&gt;. In the same style as &lt;em&gt;PostGIS&lt;/em&gt;, verbs are used as function names.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;proj_rob &amp;lt;- &amp;quot;+proj=robin +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m no_defs&amp;quot;

river_line &amp;lt;- st_read(&amp;quot;RiverHRCenterlinesCombo.shp&amp;quot;) %&amp;gt;% 
                 st_zm() %&amp;gt;% 
                    st_transform(proj_rob)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Reading layer `RiverHRCenterlinesCombo&amp;#39; from data source 
##   `E:\GitHub\blog_update_2021\content\en\post\2020-07-24-river-flow-directions\RiverHRCenterlinesCombo.shp&amp;#39; 
##   using driver `ESRI Shapefile&amp;#39;
## Simple feature collection with 78 features and 6 fields
## Geometry type: MULTILINESTRING
## Dimension:     XYZ
## Bounding box:  xmin: -164.7059 ymin: -36.97094 xmax: 151.5931 ymax: 72.64474
## z_range:       zmin: 0 zmax: 0
## Geodetic CRS:  WGS 84&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;extract-the-angles&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Extract the angles&lt;/h2&gt;
&lt;p&gt;In the next step we have to extract the vertice angles. Unfortunately, as far as I know, it is not possible to extract the attributes with some function from the &lt;code&gt;sf&lt;/code&gt; package. Although the function &lt;code&gt;st_coordinates()&lt;/code&gt; returns the coordinates, it does not include other attributes. Therefore, we must use another way, and that is the open software Quantum GIS in which we can find a tool to extract all the vertice attributes. We could import the vector data into QGIS Desktop and export the vertices from there, but it is also possible to access the QGIS tools from R directly.&lt;/p&gt;
&lt;p&gt;For this, we need to have QGIS installed. The &lt;code&gt;qgisprocess&lt;/code&gt; package allows us to use very easily all the tools of the software in R. First we use the &lt;code&gt;qgis_configure()&lt;/code&gt; function to define all the necessary QGIS paths.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# paths to QGIS
qgis_configure()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## getOption(&amp;#39;qgisprocess.path&amp;#39;) was not found.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Sys.getenv(&amp;#39;R_QGISPROCESS_PATH&amp;#39;) was not found.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Trying &amp;#39;qgis_process&amp;#39; on PATH&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Error in processx::run(&amp;quot;cmd.exe&amp;quot;, c(&amp;quot;/c&amp;quot;, &amp;quot;call&amp;quot;, path, args), ...): System command &amp;#39;cmd.exe&amp;#39; failed, exit status: 1, stderr:
## E&amp;gt; &amp;quot;qgis_process&amp;quot; no se reconoce como un comando interno o externo,
## E&amp;gt; programa o archivo por lotes ejecutable.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Found 1 QGIS installation containing &amp;#39;qgis_process&amp;#39;:
##  C:/Program Files/QGIS 3.18/bin/qgis_process-qgis.bat&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Trying command &amp;#39;C:/Program Files/QGIS 3.18/bin/qgis_process-qgis.bat&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Success!&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## QGIS version: 3.18.1-Zürich&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Metadata of 986 algorithms queried and stored in cache.
## Run `qgis_algorithms()` to see them.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;qgis_algorithms()&lt;/code&gt; function helps us to search for different QGIS tools. In addition the &lt;code&gt;qgis_show_help()&lt;/code&gt; function specifies the way of usage with all the required parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# search tools
qgis_algorithms()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 986 x 5
##    provider provider_title algorithm                algorithm_id algorithm_title
##    &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;          &amp;lt;chr&amp;gt;                    &amp;lt;chr&amp;gt;        &amp;lt;chr&amp;gt;          
##  1 3d       QGIS (3D)      3d:tessellate            tessellate   Tessellate     
##  2 gdal     GDAL           gdal:aspect              aspect       Aspect         
##  3 gdal     GDAL           gdal:assignprojection    assignproje~ Assign project~
##  4 gdal     GDAL           gdal:buffervectors       buffervecto~ Buffer vectors 
##  5 gdal     GDAL           gdal:buildvirtualraster  buildvirtua~ Build virtual ~
##  6 gdal     GDAL           gdal:buildvirtualvector  buildvirtua~ Build virtual ~
##  7 gdal     GDAL           gdal:cliprasterbyextent  cliprasterb~ Clip raster by~
##  8 gdal     GDAL           gdal:cliprasterbymaskla~ cliprasterb~ Clip raster by~
##  9 gdal     GDAL           gdal:clipvectorbyextent  clipvectorb~ Clip vector by~
## 10 gdal     GDAL           gdal:clipvectorbypolygon clipvectorb~ Clip vector by~
## # ... with 976 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# usage of tool
qgis_show_help(&amp;quot;native:extractvertices&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Extract vertices (native:extractvertices)
## 
## ----------------
## Description
## ----------------
## This algorithm takes a line or polygon layer and generates a point layer with points representing the vertices in the input lines or polygons. The attributes associated to each point are the same ones associated to the line or polygon that the point belongs to.
## 
## Additional fields are added to the point indicating the vertex index (beginning at 0), the vertex’s part and its index within the part (as well as its ring for polygons), distance along original geometry and bisector angle of vertex for original geometry.
## 
## ----------------
## Arguments
## ----------------
## 
## INPUT: Input layer
##  Argument type:  source
##  Acceptable values:
##      - Path to a vector layer
## OUTPUT: Vertices
##  Argument type:  sink
##  Acceptable values:
##      - Path for new vector layer
## 
## ----------------
## Outputs
## ----------------
## 
## OUTPUT: &amp;lt;outputVector&amp;gt;
##  Vertices&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In our case the tool to extract the vertices is simple and only has one input and one output. The function &lt;code&gt;qgis_run_algorithm()&lt;/code&gt; executes a QGIS tool indicating the algorithm and its arguments. The advantage of using the algorithm directly from R is that we can pass objects of class &lt;code&gt;sf&lt;/code&gt; (or &lt;code&gt;sp&lt;/code&gt;) and &lt;code&gt;raster&lt;/code&gt; that we have imported or created in R. As output we create a &lt;code&gt;geojson&lt;/code&gt;, it could also be of another vector format, and we save it in a temporary folder. To obtain the QGIS output we need to use &lt;code&gt;qgis_output()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;river_vertices &amp;lt;- qgis_run_algorithm(alg = &amp;quot;native:extractvertices&amp;quot;,
               INPUT = river_line,
               OUTPUT = file.path(tempdir(), &amp;quot;rivers_world_vertices.geojson&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Running cmd.exe /c call \
##   &amp;quot;C:/Program Files/QGIS 3.18/bin/qgis_process-qgis.bat&amp;quot; run \
##   &amp;quot;native:extractvertices&amp;quot; \
##   &amp;quot;--INPUT=C:\Users\xeo19\AppData\Local\Temp\Rtmpkf37V1\file1f54157824f7\file1f54f432848.gpkg&amp;quot; \
##   &amp;quot;--OUTPUT=C:\Users\xeo19\AppData\Local\Temp\Rtmpkf37V1/rivers_world_vertices.geojson&amp;quot;
## 
## ----------------
## Inputs
## ----------------
## 
## INPUT:   C:\Users\xeo19\AppData\Local\Temp\Rtmpkf37V1\file1f54157824f7\file1f54f432848.gpkg
## OUTPUT:  C:\Users\xeo19\AppData\Local\Temp\Rtmpkf37V1/rivers_world_vertices.geojson
## 
## 
## 0...10...20...30...40...50...60...70...80...90...
## ----------------
## Results
## ----------------
## 
## OUTPUT:  C:\Users\xeo19\AppData\Local\Temp\Rtmpkf37V1/rivers_world_vertices.geojson&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;river_vertices &amp;lt;- st_read(qgis_output(river_vertices, &amp;quot;OUTPUT&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Reading layer `rivers_world_vertices&amp;#39; from data source 
##   `C:\Users\xeo19\AppData\Local\Temp\Rtmpkf37V1\rivers_world_vertices.geojson&amp;#39; 
##   using driver `GeoJSON&amp;#39;
## Simple feature collection with 339734 features and 12 fields
## Geometry type: POINT
## Dimension:     XY
## Bounding box:  xmin: -12117400 ymin: -3953778 xmax: 13751910 ymax: 7507359
## Geodetic CRS:  WGS 84&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Currently on Windows there seem to be problems with the &lt;em&gt;proj&lt;/em&gt; library. In principle, if the function ends up creating the &lt;code&gt;river_vertices&lt;/code&gt; object, you should not worry.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;selection&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Selection&lt;/h2&gt;
&lt;p&gt;Before continuing with the distribution estimation of the angles, we filter some rivers of interest. The functions of the &lt;code&gt;tidyverse&lt;/code&gt; collection are compatible with the &lt;code&gt;sf&lt;/code&gt; package. In the last post I made an introduction to &lt;code&gt;tidyverse&lt;/code&gt; &lt;a href=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;river_vertices &amp;lt;-  filter(river_vertices, 
                          NAME %in% c(&amp;quot;Mississippi&amp;quot;, &amp;quot;Colorado&amp;quot;, 
                                      &amp;quot;Amazon&amp;quot;, &amp;quot;Nile&amp;quot;, &amp;quot;Orange&amp;quot;, 
                                      &amp;quot;Ganges&amp;quot;, &amp;quot;Yangtze&amp;quot;, &amp;quot;Danube&amp;quot;,
                                      &amp;quot;Mackenzie&amp;quot;, &amp;quot;Lena&amp;quot;, &amp;quot;Murray&amp;quot;, 
                                      &amp;quot;Niger&amp;quot;)
                          ) 

river_vertices &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Simple feature collection with 94702 features and 12 fields
## Geometry type: POINT
## Dimension:     XY
## Bounding box:  xmin: -10377520 ymin: -3953778 xmax: 13124340 ymax: 7507359
## Geodetic CRS:  WGS 84
## First 10 features:
##    fid NAME SYSTEM name_alt scalerank rivernum Length_km vertex_index
## 1    6 Nile   &amp;lt;NA&amp;gt;     &amp;lt;NA&amp;gt;         1        4  3343.871            0
## 2    6 Nile   &amp;lt;NA&amp;gt;     &amp;lt;NA&amp;gt;         1        4  3343.871            1
## 3    6 Nile   &amp;lt;NA&amp;gt;     &amp;lt;NA&amp;gt;         1        4  3343.871            2
## 4    6 Nile   &amp;lt;NA&amp;gt;     &amp;lt;NA&amp;gt;         1        4  3343.871            3
## 5    6 Nile   &amp;lt;NA&amp;gt;     &amp;lt;NA&amp;gt;         1        4  3343.871            4
## 6    6 Nile   &amp;lt;NA&amp;gt;     &amp;lt;NA&amp;gt;         1        4  3343.871            5
## 7    6 Nile   &amp;lt;NA&amp;gt;     &amp;lt;NA&amp;gt;         1        4  3343.871            6
## 8    6 Nile   &amp;lt;NA&amp;gt;     &amp;lt;NA&amp;gt;         1        4  3343.871            7
## 9    6 Nile   &amp;lt;NA&amp;gt;     &amp;lt;NA&amp;gt;         1        4  3343.871            8
## 10   6 Nile   &amp;lt;NA&amp;gt;     &amp;lt;NA&amp;gt;         1        4  3343.871            9
##    vertex_part vertex_part_index  distance      angle                geometry
## 1            0                 0     0.000  31.096005 POINT (3037149 1672482)
## 2            0                 1  1208.130  22.456672 POINT (3037772 1673517)
## 3            0                 2  2324.160   8.602259 POINT (3038039 1674600)
## 4            0                 3  3656.452   8.573580 POINT (3038118 1675930)
## 5            0                 4  5735.538  24.406889 POINT (3038612 1677950)
## 6            0                 5  6758.322  25.134763 POINT (3039200 1678787)
## 7            0                 6 10432.834   6.998982 POINT (3040164 1682333)
## 8            0                 7 14865.136   4.239641 POINT (3040070 1686764)
## 9            0                 8 16563.207 358.730530 POINT (3040356 1688438)
## 10           0                 9 18376.526 347.480822 POINT (3039972 1690210)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;estimate-the-distribution&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Estimate the distribution&lt;/h1&gt;
&lt;p&gt;To visualize the distribution we can use either a histogram or a density graph. But in the case of estimating the probability density function, we find a mathematical problem when applying it to circular data. For circular data we should not use the &lt;code&gt;density()&lt;/code&gt; standard function of R since in our data a direction of 360º is the same at 0º, which would cause errors in this range of values. It is a general problem for different statistical metrics. More statistical details are explained in the &lt;code&gt;circular&lt;/code&gt; package. This package allows you to define the characteristics of circular data (unit, data type, rotation, etc.) as an object class in R.&lt;/p&gt;
&lt;p&gt;So what we do is to build a function that estimates the density and returns a table with the angles (x) and the density estimates (y). Since rivers have different lengths, and we want to see differences regardless of that, we normalize the estimates using the maximum value. Unlike the &lt;code&gt;density()&lt;/code&gt; function, in which the smoothing bandwidth &lt;code&gt;bw&lt;/code&gt; is optimized, here it is required to indicate it manually. It is similar to defining the bar width in a histogram. There is an optimization function for the bandwidth, &lt;code&gt;bw.nrd.circular()&lt;/code&gt; that could be used here.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dens_circ &amp;lt;- function(x){
  
  dens &amp;lt;- density.circular(circular(x$angle, units = &amp;quot;degrees&amp;quot;),
                                     bw = 70, kernel = &amp;quot;vonmises&amp;quot;,
                                     control.circular = list(units = &amp;quot;degrees&amp;quot;))
  
  df &amp;lt;- data.frame(x = dens$x, y = dens$y/max(dens$y))
  
  return(df)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we estimate the density of each river in our selection. We use the &lt;code&gt;split()&lt;/code&gt; function of R Base to get a table of each river in a list object. Then we apply our density estimation function to the list with the function &lt;code&gt;map_df()&lt;/code&gt; from the &lt;code&gt;purrr&lt;/code&gt; package. The suffix &lt;code&gt;_df&lt;/code&gt; allows us to get a joined table, instead of a list with the results of each river. However, it is necessary to indicate the name of the column with the argument &lt;code&gt;.id&lt;/code&gt;, which will contain the name of each river. Otherwise we would not know how to differentiate the results. Also here I recommend reading more details in the last post about &lt;code&gt;tidyverse&lt;/code&gt; &lt;a href=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dens_river &amp;lt;- split(river_vertices, river_vertices$NAME) %&amp;gt;% 
                  map_df(dens_circ, .id = &amp;quot;river&amp;quot;)

# results
head(dens_river)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    river        x         y
## 1 Amazon 0.000000 0.2399907
## 2 Amazon 0.704501 0.2492548
## 3 Amazon 1.409002 0.2585758
## 4 Amazon 2.113503 0.2679779
## 5 Amazon 2.818004 0.2774859
## 6 Amazon 3.522505 0.2871232&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;visualization&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Visualization&lt;/h1&gt;
&lt;p&gt;Now we only have to make the graph through the famous &lt;code&gt;ggplot&lt;/code&gt; package. First we add a new font &lt;em&gt;Montserrat&lt;/em&gt; for it use in this plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# font download
font_add_google(&amp;quot;Montserrat&amp;quot;, &amp;quot;Montserrat&amp;quot;)

# use of showtext
showtext_opts(dpi = 200)
showtext_auto() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the next step we create two objects with the title and the plot caption. In the title we are using an html code to color part of the text instead of a legend. You can use html very easily with the &lt;code&gt;ggtext&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# title with html
title &amp;lt;- &amp;quot;Relative distribution of river &amp;lt;span style=&amp;#39;color:#011FFD;&amp;#39;&amp;gt;&amp;lt;strong&amp;gt;flow direction&amp;lt;/strong&amp;gt;&amp;lt;/span&amp;gt; in the world&amp;quot;


caption &amp;lt;- &amp;quot;Based on data from Zeenatul Basher, 20180215&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The background grid that creates &lt;code&gt;ggplot&lt;/code&gt; by default for polar coordinates did not convince me, so we create a table with x axis background lines.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grid_x &amp;lt;- tibble(x = seq(0, 360 - 22.5, by = 22.5), 
                 y = rep(0, 16), 
                 xend = seq(0, 360 - 22.5, by = 22.5), 
                 yend = rep(Inf, 16))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next we define all the styles of the graph. The most important thing in this step is the &lt;code&gt;element_textbox()&lt;/code&gt; function of the &lt;code&gt;ggtext&lt;/code&gt; package to be able to interpret our html code incorporated into the title.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;theme_polar &amp;lt;- function(){
               theme_minimal() %+replace%
               theme(axis.title.y = element_blank(),
                     axis.text.y = element_blank(),
                     legend.title = element_blank(),
                     plot.title = element_textbox(family = &amp;quot;Montserrat&amp;quot;, 
                                                   hjust = 0.5, 
                                                   colour = &amp;quot;white&amp;quot;, 
                                                   size = 15),
                     plot.caption = element_text(family = &amp;quot;Montserrat&amp;quot;, 
                                                 colour = &amp;quot;white&amp;quot;),
                     axis.text.x = element_text(family = &amp;quot;Montserrat&amp;quot;, 
                                                 colour = &amp;quot;white&amp;quot;),
                     strip.text = element_text(family = &amp;quot;Montserrat&amp;quot;, 
                                               colour = &amp;quot;white&amp;quot;, 
                                               face = &amp;quot;bold&amp;quot;),
                     panel.background = element_rect(fill = &amp;quot;black&amp;quot;),
                     plot.background = element_rect(fill = &amp;quot;black&amp;quot;),
                     panel.grid = element_blank()
                    )
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally we build the graph: 1) We use the &lt;code&gt;geom_hline()&lt;/code&gt; function with different y intersection points to create the background grid. The &lt;code&gt;geom_segment()&lt;/code&gt; function creates the x grid. 2) We create the density area using the &lt;code&gt;geom_area()&lt;/code&gt; function. 3) In &lt;code&gt;scale_x_continous()&lt;/code&gt; we define a negative lower limit so that it does not collapse at a small point. The labels of the eight main directions are indicated in the &lt;code&gt;scale_y_continous()&lt;/code&gt; function, and 4) Finally, we change to a polar coordinate system and set the variable to create facets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot() +
  geom_hline(yintercept = c(0, .2, .4, .6, .8, 1), colour = &amp;quot;white&amp;quot;) +
  geom_segment(data = grid_x , 
               aes(x = x, y = y, xend = xend, yend = yend), 
               linetype = &amp;quot;dashed&amp;quot;, col = &amp;quot;white&amp;quot;) +
  geom_area(data = dens_river, 
            aes(x = x, y = y, ymin = 0, ymax = y), 
            alpha = .7, 
            colour = NA, 
            show.legend = FALSE,
            fill = &amp;quot;#011FFD&amp;quot;) + 
  scale_y_continuous(limits = c(-.2, 1), expand = c(0, 0)) +
  scale_x_continuous(limits = c(0, 360), 
                     breaks = seq(0, 360 - 22.5, by = 22.5),
                     minor_breaks = NULL,
                     labels = c(&amp;quot;N&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;NE&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;E&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;SE&amp;quot;, &amp;quot;&amp;quot;,
                                &amp;quot;S&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;SW&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;W&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;NW&amp;quot;, &amp;quot;&amp;quot;)) +
  coord_polar() + 
  facet_wrap(river ~ ., ncol = 4) +
  labs(title = title, caption = caption, x = &amp;quot;&amp;quot;) +
  theme_polar()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Ignoring unknown aesthetics: ymin, ymax&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/river-flow-directions/index.en_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/drxeo&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;41&#34; width=&#34;174&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A very short introduction to Tidyverse</title>
      <link>https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/</link>
      <pubDate>Sat, 06 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#tidyverse&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;1&lt;/span&gt; Tidyverse&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#style-guide&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2&lt;/span&gt; Style guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#pipe&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3&lt;/span&gt; Pipe %&amp;gt;%&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tidyverse-packages&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4&lt;/span&gt; Tidyverse packages&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#read-and-write-data&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.1&lt;/span&gt; Read and write data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#character-manipulations&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.2&lt;/span&gt; Character manipulations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#management-of-dates-and-times&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.3&lt;/span&gt; Management of dates and times&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#table-and-vector-manipulation&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.4&lt;/span&gt; Table and vector manipulation&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#select-and-rename&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.4.1&lt;/span&gt; Select and rename&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#filter-and-sort&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.4.2&lt;/span&gt; Filter and sort&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#group-and-summarize&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.4.3&lt;/span&gt; Group and summarize&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#join-tables&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.4.4&lt;/span&gt; Join tables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#long-and-wide-tables&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.4.5&lt;/span&gt; Long and wide tables&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#visualize-data&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.5&lt;/span&gt; Visualize data&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#line-and-scatter-plot&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.5.1&lt;/span&gt; Line and scatter plot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#boxplot&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.5.2&lt;/span&gt; Boxplot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#heatmap&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.5.3&lt;/span&gt; Heatmap&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#apply-functions-on-vectors-or-lists&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.6&lt;/span&gt; Apply functions on vectors or lists&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;tidyverse&#34; class=&#34;section level1&#34; number=&#34;1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Tidyverse&lt;/h1&gt;
&lt;p&gt;The &lt;code&gt;tidyverse&lt;/code&gt; universe of packages, a collection of packages specially focused on data science, marked a milestone in R programming. In this post I am going to summarize very briefly the most essential to start in this world. The tidyverse grammar follows a common structure in all functions. The most essential thing is that the first argument is the object and then come the rest of the arguments. In addition, a set of verbs is provided to facilitate the use of the functions. The &lt;code&gt;tidyverse&lt;/code&gt; philosophy and grammar of functions are also reflected in other packages that make its use compatible with the collection. For example, the &lt;code&gt;sf&lt;/code&gt; package (&lt;a href=&#34;https://r-spatial.github.io/sf/articles/sf1.html&#34;&gt;simple feature&lt;/a&gt;) is a standardized way to encode spatial vector data and allows the use of multiple functions that we can find in the &lt;code&gt;dplyr&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;The core of the &lt;code&gt;tidyverse&lt;/code&gt; collection is made up of the following packages:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Package&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ggplot2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Grammar for creating graphics&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;purrr&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;R functional programming&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tibble&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Modern and effective table system&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;dplyr&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Grammar for data manipulation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyr&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Set of functions to create tidy data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;stringr&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Function set to work with characters&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;readr&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;An easy and fast way to import data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;forcats&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Tools to easily work with factors&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;In addition to the mentioned packages, &lt;code&gt;lubridate&lt;/code&gt; is also used very frequently to work with dates and times, and also &lt;code&gt;readxl&lt;/code&gt; which allows us to import files in Excel format. To know all the available packages we can use the function &lt;code&gt;tidyverse_packages()&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;broom&amp;quot;         &amp;quot;cli&amp;quot;           &amp;quot;crayon&amp;quot;        &amp;quot;dbplyr&amp;quot;       
##  [5] &amp;quot;dplyr&amp;quot;         &amp;quot;dtplyr&amp;quot;        &amp;quot;forcats&amp;quot;       &amp;quot;googledrive&amp;quot;  
##  [9] &amp;quot;googlesheets4&amp;quot; &amp;quot;ggplot2&amp;quot;       &amp;quot;haven&amp;quot;         &amp;quot;hms&amp;quot;          
## [13] &amp;quot;httr&amp;quot;          &amp;quot;jsonlite&amp;quot;      &amp;quot;lubridate&amp;quot;     &amp;quot;magrittr&amp;quot;     
## [17] &amp;quot;modelr&amp;quot;        &amp;quot;pillar&amp;quot;        &amp;quot;purrr&amp;quot;         &amp;quot;readr&amp;quot;        
## [21] &amp;quot;readxl&amp;quot;        &amp;quot;reprex&amp;quot;        &amp;quot;rlang&amp;quot;         &amp;quot;rstudioapi&amp;quot;   
## [25] &amp;quot;rvest&amp;quot;         &amp;quot;stringr&amp;quot;       &amp;quot;tibble&amp;quot;        &amp;quot;tidyr&amp;quot;        
## [29] &amp;quot;xml2&amp;quot;          &amp;quot;tidyverse&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is very easy to get conflicts between functions, that is, that the same function name exists in several packages. To avoid this, we can write the name of the package in front of the function we want to use, separated by the colon symbol written twice (&lt;code&gt;package_name::function_name&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Before I get started with the packages, I hope it will be a really short introduction, some comments on the style when programming in R.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;style-guide&#34; class=&#34;section level1&#34; number=&#34;2&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; Style guide&lt;/h1&gt;
&lt;p&gt;In R there is no universal style guide, that is, in the R syntax it is not necessary to follow specific rules for our scripts. But it is recommended to work in a homogeneous, uniform, legible and clear way when writing scripts. The &lt;code&gt;tidyverse&lt;/code&gt; collection has its own guide (&lt;a href=&#34;https://style.tidyverse.org/&#34; class=&#34;uri&#34;&gt;https://style.tidyverse.org/&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The most important recommendations are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Avoid using more than 80 characters per line to allow reading the complete code.&lt;/li&gt;
&lt;li&gt;Always use a space after a comma, never before.&lt;/li&gt;
&lt;li&gt;The operators (==, +, -, &amp;lt;-,%&amp;gt;%, etc.) must have a space before and after.&lt;/li&gt;
&lt;li&gt;There is no space between the name of a function and the first parenthesis, nor between the last argument and the final parenthesis of a function.&lt;/li&gt;
&lt;li&gt;Avoid reusing names of functions and common variables (&lt;code&gt;c &amp;lt;- 5&lt;/code&gt; vs. &lt;code&gt;c()&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Sort the script separating the parts with the comment form &lt;code&gt;# Import data -----&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Avoid accent marks or special symbols in names, files, routes, etc.&lt;/li&gt;
&lt;li&gt;Object names must follow a constant structure: &lt;code&gt;day_one&lt;/code&gt;, &lt;code&gt;day_1&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is advisable to use a correct indentation for multiple arguments of a function or functions chained by the &lt;code&gt;pipe&lt;/code&gt; operator (&lt;code&gt;%&amp;gt;%&lt;/code&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;pipe&#34; class=&#34;section level1&#34; number=&#34;3&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; Pipe %&amp;gt;%&lt;/h1&gt;
&lt;p&gt;To facilitate working in data management, manipulation and visualization, the &lt;code&gt;magrittr&lt;/code&gt; package introduces the famous &lt;em&gt;pipe&lt;/em&gt; operator in the form &lt;code&gt;%&amp;gt;%&lt;/code&gt; with the aim of combining various functions without the need to assign the result to a new object. The &lt;em&gt;pipe&lt;/em&gt; operator passes the output of a function applied to the first argument of the next function. This way of combining functions allows you to chain several steps simultaneously, to perform sequential tasks. In the very simple example below, we pass the vector &lt;code&gt;1:5&lt;/code&gt; to the &lt;code&gt;mean()&lt;/code&gt; function to calculate the average. You should know that there are a couple of other pipe operators in the same package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;1:5 %&amp;gt;% mean()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;tidyverse-packages&#34; class=&#34;section level1&#34; number=&#34;4&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;4&lt;/span&gt; Tidyverse packages&lt;/h1&gt;
&lt;div id=&#34;read-and-write-data&#34; class=&#34;section level2&#34; number=&#34;4.1&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.1&lt;/span&gt; Read and write data&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;readr&lt;/code&gt; package makes it easy to read or write multiple file formats using functions that start with &lt;code&gt;read_*&lt;/code&gt; or &lt;code&gt;write_*&lt;/code&gt;.
In comparison to R Base, &lt;code&gt;readr&lt;/code&gt; functions are faster; they handle problematic column names, and dates are automatically converted. The imported tables are of class &lt;code&gt;tibble&lt;/code&gt; (&lt;em&gt;tbl_df&lt;/em&gt;), a modern version of &lt;code&gt;data.frame&lt;/code&gt; from the &lt;code&gt;tibble&lt;/code&gt; package. In the same sense, you can use the &lt;code&gt;read_excel()&lt;/code&gt; function of the &lt;code&gt;readxl&lt;/code&gt; package to import data from Excel sheets (more details also in this &lt;a href=&#34;https://dominicroye.github.io/en/2019/import-excel-sheets-with-r/&#34;&gt;blog post&lt;/a&gt;). In the following example, we import the mobility data registered by Google (&lt;a href=&#34;https://www.google.com/covid19/mobility/&#34;&gt;link&lt;/a&gt;) during the last months of the COVID-19 pandemic (&lt;a href=&#34;https://dominicroye.github.io/files/Global_Mobility_Report.csv&#34;&gt;download&lt;/a&gt;).&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Function&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;read_csv() o read_csv2()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;coma or semicolon (CSV)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;read_delim()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;general separator&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;read_table()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;whitespace-separated&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# load package
library(tidyverse)

google_mobility &amp;lt;- read_csv(&amp;quot;Global_Mobility_Report.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 516697 Columns: 13
## -- Column specification --------------------------------------------------------
## Delimiter: &amp;quot;,&amp;quot;
## chr  (6): country_region_code, country_region, sub_region_1, sub_region_2, i...
## dbl  (6): retail_and_recreation_percent_change_from_baseline, grocery_and_ph...
## date (1): date
## 
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;google_mobility&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 516,697 x 13
##    country_region_code country_region  sub_region_1 sub_region_2 iso_3166_2_code
##    &amp;lt;chr&amp;gt;               &amp;lt;chr&amp;gt;           &amp;lt;chr&amp;gt;        &amp;lt;chr&amp;gt;        &amp;lt;chr&amp;gt;          
##  1 AE                  United Arab Em~ &amp;lt;NA&amp;gt;         &amp;lt;NA&amp;gt;         &amp;lt;NA&amp;gt;           
##  2 AE                  United Arab Em~ &amp;lt;NA&amp;gt;         &amp;lt;NA&amp;gt;         &amp;lt;NA&amp;gt;           
##  3 AE                  United Arab Em~ &amp;lt;NA&amp;gt;         &amp;lt;NA&amp;gt;         &amp;lt;NA&amp;gt;           
##  4 AE                  United Arab Em~ &amp;lt;NA&amp;gt;         &amp;lt;NA&amp;gt;         &amp;lt;NA&amp;gt;           
##  5 AE                  United Arab Em~ &amp;lt;NA&amp;gt;         &amp;lt;NA&amp;gt;         &amp;lt;NA&amp;gt;           
##  6 AE                  United Arab Em~ &amp;lt;NA&amp;gt;         &amp;lt;NA&amp;gt;         &amp;lt;NA&amp;gt;           
##  7 AE                  United Arab Em~ &amp;lt;NA&amp;gt;         &amp;lt;NA&amp;gt;         &amp;lt;NA&amp;gt;           
##  8 AE                  United Arab Em~ &amp;lt;NA&amp;gt;         &amp;lt;NA&amp;gt;         &amp;lt;NA&amp;gt;           
##  9 AE                  United Arab Em~ &amp;lt;NA&amp;gt;         &amp;lt;NA&amp;gt;         &amp;lt;NA&amp;gt;           
## 10 AE                  United Arab Em~ &amp;lt;NA&amp;gt;         &amp;lt;NA&amp;gt;         &amp;lt;NA&amp;gt;           
## # ... with 516,687 more rows, and 8 more variables: census_fips_code &amp;lt;chr&amp;gt;,
## #   date &amp;lt;date&amp;gt;, retail_and_recreation_percent_change_from_baseline &amp;lt;dbl&amp;gt;,
## #   grocery_and_pharmacy_percent_change_from_baseline &amp;lt;dbl&amp;gt;,
## #   parks_percent_change_from_baseline &amp;lt;dbl&amp;gt;,
## #   transit_stations_percent_change_from_baseline &amp;lt;dbl&amp;gt;,
## #   workplaces_percent_change_from_baseline &amp;lt;dbl&amp;gt;,
## #   residential_percent_change_from_baseline &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Important is to take a look at the argument names, since they change in the &lt;code&gt;readr&lt;/code&gt; functions. For example, the well-known &lt;code&gt;header = TRUE&lt;/code&gt; argument of &lt;code&gt;read.csv()&lt;/code&gt; is in this case &lt;code&gt;col_names = TRUE&lt;/code&gt;. More details can be found in the &lt;a href=&#34;https://github.com/rstudio/cheatsheets/raw/master/data-import.pdf&#34;&gt;Cheat-Sheet&lt;/a&gt; of &lt;code&gt;readr&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;character-manipulations&#34; class=&#34;section level2&#34; number=&#34;4.2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.2&lt;/span&gt; Character manipulations&lt;/h2&gt;
&lt;p&gt;For working with strings we use the &lt;code&gt;stringr&lt;/code&gt; package, whose functions always start with &lt;code&gt;str_*&lt;/code&gt; followed by a verb and the first argument.&lt;/p&gt;
&lt;p&gt;Some of these functions are as follows:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Function&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;str_replace()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;replace patterns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;str_c()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;combine characters&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;str_detect()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;detect patterns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;str_extract()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;extract patterns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;str_sub()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;extract by position&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;str_length()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;length of string&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Regular expressions are often used for character patterns. For example, the regular expression &lt;code&gt;[aeiou]&lt;/code&gt; matches any single character that is a vowel. The use of square brackets &lt;code&gt;[]&lt;/code&gt; corresponds to character classes. For example, &lt;code&gt;[abc]&lt;/code&gt; corresponds to each letter regardless of its position. &lt;code&gt;[a-z]&lt;/code&gt;, &lt;code&gt;[A-Z]&lt;/code&gt; or &lt;code&gt;[0-9]&lt;/code&gt; each between a and z or 0 and 9. And finally, &lt;code&gt;[:punct:]&lt;/code&gt; punctuation, etc. With curly braces “{}” we can indicate the number of the previous element, &lt;code&gt;{2}&lt;/code&gt; would be twice, {1,2} between one and two, etc. Also with &lt;code&gt;$&lt;/code&gt; or &lt;code&gt;^&lt;/code&gt; we can indicate if the pattern starts at the beginning or ends at the end. More details and patterns can be found in the &lt;a href=&#34;https://github.com/rstudio/cheatsheets/raw/master/strings.pdf&#34;&gt;Cheat-Sheet&lt;/a&gt; of &lt;code&gt;stringr&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# replace &amp;#39;er&amp;#39; at the end with empty space

str_replace(month.name, &amp;quot;er$&amp;quot;, &amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;January&amp;quot;  &amp;quot;February&amp;quot; &amp;quot;March&amp;quot;    &amp;quot;April&amp;quot;    &amp;quot;May&amp;quot;      &amp;quot;June&amp;quot;    
##  [7] &amp;quot;July&amp;quot;     &amp;quot;August&amp;quot;   &amp;quot;Septemb&amp;quot;  &amp;quot;Octob&amp;quot;    &amp;quot;Novemb&amp;quot;   &amp;quot;Decemb&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_replace(month.name, &amp;quot;^Ma&amp;quot;, &amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;January&amp;quot;   &amp;quot;February&amp;quot;  &amp;quot;rch&amp;quot;       &amp;quot;April&amp;quot;     &amp;quot;y&amp;quot;         &amp;quot;June&amp;quot;     
##  [7] &amp;quot;July&amp;quot;      &amp;quot;August&amp;quot;    &amp;quot;September&amp;quot; &amp;quot;October&amp;quot;   &amp;quot;November&amp;quot;  &amp;quot;December&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# combine characters

a &amp;lt;- str_c(month.name, 1:12, sep = &amp;quot;_&amp;quot;)
a&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;January_1&amp;quot;   &amp;quot;February_2&amp;quot;  &amp;quot;March_3&amp;quot;     &amp;quot;April_4&amp;quot;     &amp;quot;May_5&amp;quot;      
##  [6] &amp;quot;June_6&amp;quot;      &amp;quot;July_7&amp;quot;      &amp;quot;August_8&amp;quot;    &amp;quot;September_9&amp;quot; &amp;quot;October_10&amp;quot; 
## [11] &amp;quot;November_11&amp;quot; &amp;quot;December_12&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# collapse combination

str_c(month.name, collapse = &amp;quot;, &amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;January, February, March, April, May, June, July, August, September, October, November, December&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# detect patterns

str_detect(a, &amp;quot;_[1-5]{1}&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract patterns

str_extract(a, &amp;quot;_[1-9]{1,2}&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;_1&amp;quot;  &amp;quot;_2&amp;quot;  &amp;quot;_3&amp;quot;  &amp;quot;_4&amp;quot;  &amp;quot;_5&amp;quot;  &amp;quot;_6&amp;quot;  &amp;quot;_7&amp;quot;  &amp;quot;_8&amp;quot;  &amp;quot;_9&amp;quot;  &amp;quot;_1&amp;quot;  &amp;quot;_11&amp;quot; &amp;quot;_12&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract the characters between position 1 and 2

str_sub(month.name, 1, 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Ja&amp;quot; &amp;quot;Fe&amp;quot; &amp;quot;Ma&amp;quot; &amp;quot;Ap&amp;quot; &amp;quot;Ma&amp;quot; &amp;quot;Ju&amp;quot; &amp;quot;Ju&amp;quot; &amp;quot;Au&amp;quot; &amp;quot;Se&amp;quot; &amp;quot;Oc&amp;quot; &amp;quot;No&amp;quot; &amp;quot;De&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# string length of each month

str_length(month.name)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 7 8 5 5 3 4 4 6 9 7 8 8&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the &amp;#39;.&amp;#39; represents the object passed by the pipe operator %&amp;gt;%
str_length(month.name) %&amp;gt;% 
   str_c(month.name, ., sep = &amp;quot;.&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;January.7&amp;quot;   &amp;quot;February.8&amp;quot;  &amp;quot;March.5&amp;quot;     &amp;quot;April.5&amp;quot;     &amp;quot;May.3&amp;quot;      
##  [6] &amp;quot;June.4&amp;quot;      &amp;quot;July.4&amp;quot;      &amp;quot;August.6&amp;quot;    &amp;quot;September.9&amp;quot; &amp;quot;October.7&amp;quot;  
## [11] &amp;quot;November.8&amp;quot;  &amp;quot;December.8&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A very useful function is &lt;code&gt;str_glue()&lt;/code&gt; to interpolate characters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;name &amp;lt;- c(&amp;quot;Juan&amp;quot;, &amp;quot;Michael&amp;quot;)
age &amp;lt;- c(50, 80) 
date_today &amp;lt;- Sys.Date()

str_glue(
  &amp;quot;My name is {name}, &amp;quot;,
  &amp;quot;I&amp;#39;am {age}, &amp;quot;,
  &amp;quot;and my birth year is {format(date_today-age*365, &amp;#39;%Y&amp;#39;)}.&amp;quot;
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## My name is Juan, I&amp;#39;am 50, and my birth year is 1972.
## My name is Michael, I&amp;#39;am 80, and my birth year is 1942.&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;management-of-dates-and-times&#34; class=&#34;section level2&#34; number=&#34;4.3&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.3&lt;/span&gt; Management of dates and times&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;lubridate&lt;/code&gt; package is very powerful in handling dates and times. It allows us to create R recognized objects with functions (like &lt;code&gt;ymd()&lt;/code&gt; or &lt;code&gt;ymd_hms()&lt;/code&gt;) and we can even make calculations.&lt;/p&gt;
&lt;p&gt;We only must know the following abbreviations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ymd&lt;/code&gt;: represents &lt;code&gt;y:year&lt;/code&gt;, &lt;code&gt;m: month&lt;/code&gt;, &lt;code&gt;d:day&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hms&lt;/code&gt;: represents &lt;code&gt;h:hour&lt;/code&gt;, &lt;code&gt;m:minutes&lt;/code&gt;, &lt;code&gt;s:seconds&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# load package
library(lubridate)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;lubridate&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:base&amp;#39;:
## 
##     date, intersect, setdiff, union&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# date vector
dat &amp;lt;- c(&amp;quot;1999/12/31&amp;quot;, &amp;quot;2000/01/07&amp;quot;, &amp;quot;2005/05/20&amp;quot;,&amp;quot;2010/03/25&amp;quot;)

# date-time vector
dat_time &amp;lt;- c(&amp;quot;1988-08-01 05:00&amp;quot;, &amp;quot;2000-02-01 22:00&amp;quot;)

# convert to date class
dat &amp;lt;- ymd(dat) 
dat&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;1999-12-31&amp;quot; &amp;quot;2000-01-07&amp;quot; &amp;quot;2005-05-20&amp;quot; &amp;quot;2010-03-25&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# other date formats
dmy(&amp;quot;05-02-2000&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2000-02-05&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ymd(&amp;quot;20000506&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2000-05-06&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# convert to POSIXct
dat_time &amp;lt;- ymd_hm(dat_time)
dat_time&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;1988-08-01 05:00:00 UTC&amp;quot; &amp;quot;2000-02-01 22:00:00 UTC&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# different date formats
dat_mix &amp;lt;- c(&amp;quot;1999/12/05&amp;quot;, &amp;quot;05-09-2008&amp;quot;, &amp;quot;2000/08/09&amp;quot;, &amp;quot;25-10-2019&amp;quot;)

# mixted formats with known convention found in ?strptime
parse_date_time(dat_mix, order = c(&amp;quot;%Y/%m/%d&amp;quot;, &amp;quot;%d-%m-%Y&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;1999-12-05 UTC&amp;quot; &amp;quot;2008-09-05 UTC&amp;quot; &amp;quot;2000-08-09 UTC&amp;quot; &amp;quot;2019-10-25 UTC&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;More useful functions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract the year
year(dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1999 2000 2005 2010&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the month
month(dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 12  1  5  3&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;month(dat, label = TRUE) # as label&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] dic ene may mar
## 12 Levels: ene &amp;lt; feb &amp;lt; mar &amp;lt; abr &amp;lt; may &amp;lt; jun &amp;lt; jul &amp;lt; ago &amp;lt; sep &amp;lt; ... &amp;lt; dic&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the day of the week
wday(dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 6 6 6 5&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;wday(dat, label = TRUE) # as label&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] vi\\. vi\\. vi\\. ju\\.
## Levels: do\\. &amp;lt; lu\\. &amp;lt; ma\\. &amp;lt; mi\\. &amp;lt; ju\\. &amp;lt; vi\\. &amp;lt; sá\\.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the hour
hour(dat_time)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  5 22&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# add 10 days
dat + days(10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2000-01-10&amp;quot; &amp;quot;2000-01-17&amp;quot; &amp;quot;2005-05-30&amp;quot; &amp;quot;2010-04-04&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# add 1 month
dat + months(1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2000-01-31&amp;quot; &amp;quot;2000-02-07&amp;quot; &amp;quot;2005-06-20&amp;quot; &amp;quot;2010-04-25&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, the &lt;code&gt;make_date()&lt;/code&gt; function is very useful to create dates from different date parts, such as the year, month, etc.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create date from its elements, here with year and month
make_date(2000, 5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2000-05-01&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create date with time
make_datetime(2005, 5, 23, 5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2005-05-23 05:00:00 UTC&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;More details can be found in the &lt;a href=&#34;https://github.com/rstudio/cheatsheets/raw/master/lubridate.pdf&#34;&gt;Cheat-Sheet&lt;/a&gt; of &lt;code&gt;lubridate&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;table-and-vector-manipulation&#34; class=&#34;section level2&#34; number=&#34;4.4&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.4&lt;/span&gt; Table and vector manipulation&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;dplyr&lt;/code&gt; and &lt;code&gt;tidyr&lt;/code&gt; packages provide us with a data manipulation grammar, a set of useful verbs to solve common problems. The most important functions are:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Function&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mutate()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;add new variables or modify existing ones&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;select()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;select variables&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;filter()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;filter&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;summarise()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;summarize/reduce&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;arrange()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;sort&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;group_by()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;group&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;rename()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;rename columns&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;In case you haven’t done it before, we import the mobility data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;google_mobility &amp;lt;- read_csv(&amp;quot;Global_Mobility_Report.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 516697 Columns: 13
## -- Column specification --------------------------------------------------------
## Delimiter: &amp;quot;,&amp;quot;
## chr  (6): country_region_code, country_region, sub_region_1, sub_region_2, i...
## dbl  (6): retail_and_recreation_percent_change_from_baseline, grocery_and_ph...
## date (1): date
## 
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;select-and-rename&#34; class=&#34;section level3&#34; number=&#34;4.4.1&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.4.1&lt;/span&gt; Select and rename&lt;/h3&gt;
&lt;p&gt;We can select or remove columns with the &lt;code&gt;select()&lt;/code&gt; function, using the name or index of the column. To delete columns we make use of the negative sign. The &lt;code&gt;rename&lt;/code&gt; function helps in renaming columns with either the same name or their index.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;residential_mobility &amp;lt;- select(google_mobility, 
                               country_region_code:sub_region_1, 
                               date, 
                               residential_percent_change_from_baseline) %&amp;gt;% 
                        rename(resi = 5)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;filter-and-sort&#34; class=&#34;section level3&#34; number=&#34;4.4.2&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.4.2&lt;/span&gt; Filter and sort&lt;/h3&gt;
&lt;p&gt;To filter data, we use &lt;code&gt;filter()&lt;/code&gt; with logical operators (&lt;code&gt;|&lt;/code&gt;, &lt;code&gt;==&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;, etc) or functions that return a logical value (&lt;code&gt;str_detect()&lt;/code&gt;, &lt;code&gt;is.na()&lt;/code&gt; , etc.). The &lt;code&gt;arrange()&lt;/code&gt; function sorts from least to greatest for one or multiple variables (with the negative sign &lt;code&gt;-&lt;/code&gt; the order is reversed from greatest to least).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(residential_mobility, 
       country_region_code == &amp;quot;US&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 304,648 x 5
##    country_region_code country_region sub_region_1 date        resi
##    &amp;lt;chr&amp;gt;               &amp;lt;chr&amp;gt;          &amp;lt;chr&amp;gt;        &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt;
##  1 US                  United States  &amp;lt;NA&amp;gt;         2020-02-15    -1
##  2 US                  United States  &amp;lt;NA&amp;gt;         2020-02-16    -1
##  3 US                  United States  &amp;lt;NA&amp;gt;         2020-02-17     5
##  4 US                  United States  &amp;lt;NA&amp;gt;         2020-02-18     1
##  5 US                  United States  &amp;lt;NA&amp;gt;         2020-02-19     0
##  6 US                  United States  &amp;lt;NA&amp;gt;         2020-02-20     1
##  7 US                  United States  &amp;lt;NA&amp;gt;         2020-02-21     0
##  8 US                  United States  &amp;lt;NA&amp;gt;         2020-02-22    -1
##  9 US                  United States  &amp;lt;NA&amp;gt;         2020-02-23    -1
## 10 US                  United States  &amp;lt;NA&amp;gt;         2020-02-24     0
## # ... with 304,638 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(residential_mobility, 
       country_region_code == &amp;quot;US&amp;quot;, 
       sub_region_1 == &amp;quot;New York&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 7,068 x 5
##    country_region_code country_region sub_region_1 date        resi
##    &amp;lt;chr&amp;gt;               &amp;lt;chr&amp;gt;          &amp;lt;chr&amp;gt;        &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt;
##  1 US                  United States  New York     2020-02-15     0
##  2 US                  United States  New York     2020-02-16    -1
##  3 US                  United States  New York     2020-02-17     9
##  4 US                  United States  New York     2020-02-18     3
##  5 US                  United States  New York     2020-02-19     2
##  6 US                  United States  New York     2020-02-20     2
##  7 US                  United States  New York     2020-02-21     3
##  8 US                  United States  New York     2020-02-22    -1
##  9 US                  United States  New York     2020-02-23    -1
## 10 US                  United States  New York     2020-02-24     0
## # ... with 7,058 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(residential_mobility, 
       resi &amp;gt; 50) %&amp;gt;% 
          arrange(-resi)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 32 x 5
##    country_region_code country_region sub_region_1              date        resi
##    &amp;lt;chr&amp;gt;               &amp;lt;chr&amp;gt;          &amp;lt;chr&amp;gt;                     &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt;
##  1 KW                  Kuwait         Al Farwaniyah Governorate 2020-05-14    56
##  2 KW                  Kuwait         Al Farwaniyah Governorate 2020-05-21    55
##  3 SG                  Singapore      &amp;lt;NA&amp;gt;                      2020-05-01    55
##  4 KW                  Kuwait         Al Farwaniyah Governorate 2020-05-28    54
##  5 PE                  Peru           Metropolitan Municipalit~ 2020-04-10    54
##  6 EC                  Ecuador        Pichincha                 2020-03-27    53
##  7 KW                  Kuwait         Al Farwaniyah Governorate 2020-05-11    53
##  8 KW                  Kuwait         Al Farwaniyah Governorate 2020-05-13    53
##  9 KW                  Kuwait         Al Farwaniyah Governorate 2020-05-20    53
## 10 SG                  Singapore      &amp;lt;NA&amp;gt;                      2020-04-10    53
## # ... with 22 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;group-and-summarize&#34; class=&#34;section level3&#34; number=&#34;4.4.3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.4.3&lt;/span&gt; Group and summarize&lt;/h3&gt;
&lt;p&gt;Where do we find greater variability between regions in each country on April 1, 2020?&lt;/p&gt;
&lt;p&gt;To answer this question, we first filter the data and then we group by the country column. When we use the &lt;code&gt;summarize()&lt;/code&gt; function after grouping, it allows us to summarize by these groups. Moreover, combining &lt;code&gt;group_by()&lt;/code&gt; with the &lt;code&gt;mutate()&lt;/code&gt; function modifies columns in each group separately. In &lt;code&gt;summarize()&lt;/code&gt; we calculate the maximum, minimum value and the difference between both extremes creating new columns.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;resi_variability &amp;lt;- residential_mobility %&amp;gt;% 
                        filter(date == ymd(&amp;quot;2020-04-01&amp;quot;),
                               !is.na(sub_region_1)) %&amp;gt;% 
                          group_by(country_region) %&amp;gt;% 
                           summarise(mx = max(resi, na.rm = TRUE), 
                                    min = min(resi, na.rm = TRUE),
                                    range = abs(mx)-abs(min))

arrange(resi_variability, -range)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 94 x 4
##    country_region    mx   min range
##    &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 Nigeria           43     6    37
##  2 United States     35     6    29
##  3 India             36    15    21
##  4 Malaysia          45    26    19
##  5 Philippines       40    21    19
##  6 Vietnam           28     9    19
##  7 Colombia          41    24    17
##  8 Ecuador           44    27    17
##  9 Argentina         35    19    16
## 10 Chile             30    14    16
## # ... with 84 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;join-tables&#34; class=&#34;section level3&#34; number=&#34;4.4.4&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.4.4&lt;/span&gt; Join tables&lt;/h3&gt;
&lt;p&gt;How can we filter the data to get a subset of Europe?&lt;/p&gt;
&lt;p&gt;To do this, we import a spatial dataset with the country code and a column of regions. Detailed explanations about the &lt;code&gt;sf&lt;/code&gt; (&lt;em&gt;simple feature&lt;/em&gt;) package, I’ll leave for another post.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rnaturalearth) # package of spatial vectorial data

# world limits
wld &amp;lt;- ne_countries(returnclass = &amp;quot;sf&amp;quot;)

# filter the countries with iso code and select the two columns of interest
wld &amp;lt;- filter(wld, !is.na(iso_a2)) %&amp;gt;% select(iso_a2, subregion)

# plot
plot(wld)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/index.en_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Other &lt;code&gt;dplyr&lt;/code&gt; functions allow us to join tables: &lt;code&gt;*_join ()&lt;/code&gt;. Depending on which table (left or right) you want to join, the functions change: &lt;code&gt;left_join()&lt;/code&gt;, &lt;code&gt;right_join()&lt;/code&gt; or even &lt;code&gt;full_join()&lt;/code&gt;. The &lt;code&gt;by&lt;/code&gt; argument is not necessary as long as both tables have a column in common. However, in this case the variable names are different, so we use the following way: &lt;code&gt;c(&#34;country_region_code&#34;=&#34;iso_a2&#34;)&lt;/code&gt;. The &lt;code&gt;forcats&lt;/code&gt; package of &lt;code&gt;tidyverse&lt;/code&gt; has many useful functions for handling categorical variables (&lt;code&gt;factors&lt;/code&gt;), variables that have a fixed and known set of possible values. All &lt;code&gt;forcats&lt;/code&gt; functions have the prefix &lt;code&gt;fct_*&lt;/code&gt;. For example, in this case we use &lt;code&gt;fct_reorder()&lt;/code&gt; to reorder the country labels in order of the maximum based on the residential mobility records. Finally, we create a new column &lt;code&gt;&#34;resi_real&#34;&lt;/code&gt; to change the reference value, the average or baseline, from 0 to 100.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;subset_europe &amp;lt;- filter(residential_mobility, 
                        is.na(sub_region_1),
                        !is.na(resi)) %&amp;gt;%
                 left_join(wld, by = c(&amp;quot;country_region_code&amp;quot;=&amp;quot;iso_a2&amp;quot;)) %&amp;gt;% 
                 filter(subregion %in% c(&amp;quot;Northern Europe&amp;quot;,
                                         &amp;quot;Southern Europe&amp;quot;,
                                          &amp;quot;Western Europe&amp;quot;,
                                          &amp;quot;Eastern Europe&amp;quot;)) %&amp;gt;%
                 mutate(resi_real = resi + 100,
                        region = fct_reorder(country_region, 
                                             resi, 
                                            .fun = &amp;quot;max&amp;quot;, 
                                            .desc = FALSE)) %&amp;gt;% 
                select(-geometry, -sub_region_1)

str(subset_europe)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## tibble [3,988 x 7] (S3: tbl_df/tbl/data.frame)
##  $ country_region_code: chr [1:3988] &amp;quot;AT&amp;quot; &amp;quot;AT&amp;quot; &amp;quot;AT&amp;quot; &amp;quot;AT&amp;quot; ...
##  $ country_region     : chr [1:3988] &amp;quot;Austria&amp;quot; &amp;quot;Austria&amp;quot; &amp;quot;Austria&amp;quot; &amp;quot;Austria&amp;quot; ...
##  $ date               : Date[1:3988], format: &amp;quot;2020-02-15&amp;quot; &amp;quot;2020-02-16&amp;quot; ...
##  $ resi               : num [1:3988] -2 -2 0 0 1 0 1 -2 0 -1 ...
##  $ subregion          : chr [1:3988] &amp;quot;Western Europe&amp;quot; &amp;quot;Western Europe&amp;quot; &amp;quot;Western Europe&amp;quot; &amp;quot;Western Europe&amp;quot; ...
##  $ resi_real          : num [1:3988] 98 98 100 100 101 100 101 98 100 99 ...
##  $ region             : Factor w/ 35 levels &amp;quot;Belarus&amp;quot;,&amp;quot;Ukraine&amp;quot;,..: 18 18 18 18 18 18 18 18 18 18 ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;long-and-wide-tables&#34; class=&#34;section level3&#34; number=&#34;4.4.5&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.4.5&lt;/span&gt; Long and wide tables&lt;/h3&gt;
&lt;p&gt;Before we go to create graphics with &lt;code&gt;ggplot2&lt;/code&gt;, it is very common to modify the table between two main formats, long and wide. A table is tidy when 1) each variable is a column 2) each observation/case is a row and 3) each type of observational unit forms a table.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# subset
mobility_selection &amp;lt;- select(subset_europe, country_region_code, date:resi)
mobility_selection&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3,988 x 3
##    country_region_code date        resi
##    &amp;lt;chr&amp;gt;               &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt;
##  1 AT                  2020-02-15    -2
##  2 AT                  2020-02-16    -2
##  3 AT                  2020-02-17     0
##  4 AT                  2020-02-18     0
##  5 AT                  2020-02-19     1
##  6 AT                  2020-02-20     0
##  7 AT                  2020-02-21     1
##  8 AT                  2020-02-22    -2
##  9 AT                  2020-02-23     0
## 10 AT                  2020-02-24    -1
## # ... with 3,978 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# wide table
mobi_wide &amp;lt;- pivot_wider(mobility_selection, 
                         names_from = country_region_code,
                         values_from = resi)
mobi_wide&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 114 x 36
##    date          AT    BA    BE    BG    BY    CH    CZ    DE    DK    EE    ES
##    &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 2020-02-15    -2    -1    -1     0    -1    -1    -2    -1     0     0    -2
##  2 2020-02-16    -2    -1     1    -3     0    -1    -1     0     1     0    -2
##  3 2020-02-17     0    -1     0    -2     0     1     0     0     1     1    -1
##  4 2020-02-18     0    -1     0    -2     0     1     0     1     1     1     0
##  5 2020-02-19     1    -1     0    -1    -1     1     0     1     1     0    -1
##  6 2020-02-20     0    -1     0     0    -1     0     0     1     1     0    -1
##  7 2020-02-21     1    -2     0    -1    -1     1     0     2     1     1    -2
##  8 2020-02-22    -2    -1     0     0    -2    -2    -3     0     1     0    -2
##  9 2020-02-23     0    -1     0    -3    -1    -1     0     0     0    -2    -3
## 10 2020-02-24    -1    -1     4    -1     0     0     0     4     0    16     0
## # ... with 104 more rows, and 24 more variables: FI &amp;lt;dbl&amp;gt;, FR &amp;lt;dbl&amp;gt;, GB &amp;lt;dbl&amp;gt;,
## #   GR &amp;lt;dbl&amp;gt;, HR &amp;lt;dbl&amp;gt;, HU &amp;lt;dbl&amp;gt;, IE &amp;lt;dbl&amp;gt;, IT &amp;lt;dbl&amp;gt;, LT &amp;lt;dbl&amp;gt;, LU &amp;lt;dbl&amp;gt;,
## #   LV &amp;lt;dbl&amp;gt;, MD &amp;lt;dbl&amp;gt;, MK &amp;lt;dbl&amp;gt;, NL &amp;lt;dbl&amp;gt;, NO &amp;lt;dbl&amp;gt;, PL &amp;lt;dbl&amp;gt;, PT &amp;lt;dbl&amp;gt;,
## #   RO &amp;lt;dbl&amp;gt;, RS &amp;lt;dbl&amp;gt;, RU &amp;lt;dbl&amp;gt;, SE &amp;lt;dbl&amp;gt;, SI &amp;lt;dbl&amp;gt;, SK &amp;lt;dbl&amp;gt;, UA &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# back to long table
pivot_longer(mobi_wide,
             2:36,
             names_to = &amp;quot;country_code&amp;quot;,
             values_to = &amp;quot;resi&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3,990 x 3
##    date       country_code  resi
##    &amp;lt;date&amp;gt;     &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt;
##  1 2020-02-15 AT              -2
##  2 2020-02-15 BA              -1
##  3 2020-02-15 BE              -1
##  4 2020-02-15 BG               0
##  5 2020-02-15 BY              -1
##  6 2020-02-15 CH              -1
##  7 2020-02-15 CZ              -2
##  8 2020-02-15 DE              -1
##  9 2020-02-15 DK               0
## 10 2020-02-15 EE               0
## # ... with 3,980 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another group of functions you should take a look at are: &lt;code&gt;separate()&lt;/code&gt;, &lt;code&gt;case_when()&lt;/code&gt;, &lt;code&gt;complete()&lt;/code&gt;. More details can be found in the &lt;a href=&#34;https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf&#34;&gt;Cheat-Sheet&lt;/a&gt; of &lt;code&gt;dplyr&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;visualize-data&#34; class=&#34;section level2&#34; number=&#34;4.5&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.5&lt;/span&gt; Visualize data&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;ggplot2&lt;/code&gt; is a modern system for data visualization with a huge variety of options. Unlike the R Base graphic system, in &lt;code&gt;ggplot2&lt;/code&gt; a different grammar is used. The grammar of graphics (gg) consists of the sum of several independent layers or objects that are combined using &lt;code&gt;+&lt;/code&gt; to construct the final graph. &lt;code&gt;ggplot&lt;/code&gt; differentiates between data, what is displayed and how it is displayed.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;data&lt;/em&gt;: our dataset (&lt;code&gt;data.frame&lt;/code&gt; or &lt;code&gt;tibble&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;aesthetics&lt;/em&gt;: with the &lt;code&gt;aes()&lt;/code&gt; function we indicate the variables that correspond to the x, y, z, … axes, or when it is intended to apply graphic parameters (color, size, shape) according to a variable. It is possible to include &lt;code&gt;aes()&lt;/code&gt; in &lt;code&gt;ggplot()&lt;/code&gt; or in the corresponding function to a geometry &lt;code&gt;geom_ *&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;geometries&lt;/em&gt;: are &lt;code&gt;geom_ *&lt;/code&gt; objects that indicate the geometry to be used, (eg: &lt;code&gt;geom_point()&lt;/code&gt;, &lt;code&gt;geom_line()&lt;/code&gt;, &lt;code&gt;geom_boxplot()&lt;/code&gt;, etc.).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;scales&lt;/em&gt;: are objects of type &lt;code&gt;scales_ *&lt;/code&gt; (eg, &lt;code&gt;scale_x_continous()&lt;/code&gt;, &lt;code&gt;scale_colour_manual()&lt;/code&gt;) to manipulate axes, define colors, etc.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;statistics&lt;/em&gt;: are &lt;code&gt;stat_ *&lt;/code&gt; objects (eg, &lt;code&gt;stat_density()&lt;/code&gt;) that allow to apply statistical transformations.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;More details can be found in the &lt;a href=&#34;https://github.com/rstudio/cheatsheets/raw/master/data-visualization-2.1.pdf&#34;&gt;Cheat-Sheet&lt;/a&gt; of &lt;code&gt;ggplot2&lt;/code&gt;. &lt;code&gt;ggplot&lt;/code&gt; is constantly supplemented by extensions for geometries or other graphical options (see &lt;a href=&#34;https://exts.ggplot2.tidyverse.org/ggiraph.html&#34; class=&#34;uri&#34;&gt;https://exts.ggplot2.tidyverse.org/ggiraph.html&lt;/a&gt;), for graphical ideas have a look a the R Graph Gallery (&lt;a href=&#34;https://www.r-graph-gallery.com/&#34; class=&#34;uri&#34;&gt;https://www.r-graph-gallery.com/&lt;/a&gt;).&lt;/p&gt;
&lt;div id=&#34;line-and-scatter-plot&#34; class=&#34;section level3&#34; number=&#34;4.5.1&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.5.1&lt;/span&gt; Line and scatter plot&lt;/h3&gt;
&lt;p&gt;We create a subset of our mobility data for residences and parks, filtering the records for Italian regions. In addition, we divide the mobility values in percentage by 100 to obtain the fraction, since &lt;code&gt;ggplot2&lt;/code&gt; allows us to indicate the unit of percentage in the label argument (see last plot in this section).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create subset
it &amp;lt;- filter(google_mobility, 
             country_region == &amp;quot;Italy&amp;quot;, 
             is.na(sub_region_1)) %&amp;gt;% 
      mutate(resi = residential_percent_change_from_baseline/100,   
             parks = parks_percent_change_from_baseline/100)


# line plot
ggplot(it, 
       aes(date, resi)) + 
  geom_line()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/index.en_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;2100&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# scatter plot
ggplot(it, 
       aes(parks, resi)) + 
  geom_point() +
  geom_smooth(method = &amp;quot;lm&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/index.en_files/figure-html/unnamed-chunk-20-2.png&#34; width=&#34;2100&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To modify the axes, we use the different &lt;code&gt;scale_*&lt;/code&gt; functions that we must adapt to the scales of measurement (date, discrete, continuous, etc.). The &lt;code&gt;labs()&lt;/code&gt; function helps us define the axis, legend and plot titles. Finally, we add the style of the graph with &lt;code&gt;theme_light()&lt;/code&gt; (others are &lt;code&gt;theme_bw()&lt;/code&gt;, &lt;code&gt;theme_minimal()&lt;/code&gt;, etc.). We could also make changes to all graphic elements through &lt;code&gt;theme()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# time serie plot
ggplot(it, 
       aes(date, resi)) + 
  geom_line(colour = &amp;quot;#560A86&amp;quot;, size = 0.8) +
  scale_x_date(date_breaks = &amp;quot;10 days&amp;quot;, 
               date_labels = &amp;quot;%d %b&amp;quot;) +
  scale_y_continuous(breaks = seq(-0.1, 1, 0.1), 
                     labels = scales::percent) +
  labs(x = &amp;quot;&amp;quot;, 
       y = &amp;quot;Residential mobility&amp;quot;,
       title = &amp;quot;Mobility during COVID-19&amp;quot;) +
  theme_light()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/index.en_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;2100&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# scatter plot
ggplot(it, 
       aes(parks, resi)) + 
  geom_point(alpha = .4, size = 2) +
  geom_smooth(method = &amp;quot;lm&amp;quot;) +
  scale_x_continuous(breaks = seq(-1, 1.4, 0.2), 
                     labels = scales::percent) +
  scale_y_continuous(breaks = seq(-1, 1, 0.1), 
                     labels = scales::percent) +
  labs(x = &amp;quot;Park mobility&amp;quot;, 
       y = &amp;quot;Residential mobility&amp;quot;,
       title = &amp;quot;Mobility during COVID-19&amp;quot;) +
  theme_light()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/index.en_files/figure-html/unnamed-chunk-21-2.png&#34; width=&#34;2100&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;boxplot&#34; class=&#34;section level3&#34; number=&#34;4.5.2&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.5.2&lt;/span&gt; Boxplot&lt;/h3&gt;
&lt;p&gt;We can visualize different aspects of the mobility with other geometries. Here we will create boxplots for each European country representing the variability of mobility between and within countries during the COVID-19 pandemic.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# subset
subset_europe_reg &amp;lt;- filter(residential_mobility, 
                           !is.na(sub_region_1),
                           !is.na(resi)) %&amp;gt;%
                     left_join(wld, by = c(&amp;quot;country_region_code&amp;quot;=&amp;quot;iso_a2&amp;quot;)) %&amp;gt;% 
                     filter(subregion %in% c(&amp;quot;Northern Europe&amp;quot;,
                                         &amp;quot;Southern Europe&amp;quot;,
                                          &amp;quot;Western Europe&amp;quot;,
                                          &amp;quot;Eastern Europe&amp;quot;)) %&amp;gt;% 
                     mutate(resi = resi/100, 
                            country_region = fct_reorder(country_region, resi))

# boxplot
ggplot(subset_europe_reg, 
       aes(country_region, resi, fill = subregion)) + 
  geom_boxplot() +
  scale_y_continuous(breaks = seq(-0.1, 1, 0.1), labels = scales::percent) +
  scale_fill_brewer(palette = &amp;quot;Set1&amp;quot;) +
  coord_flip() +
   labs(x = &amp;quot;&amp;quot;, 
       y = &amp;quot;Residential mobility&amp;quot;,
       title = &amp;quot;Mobility during COVID-19&amp;quot;, 
       fill = &amp;quot;&amp;quot;) +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/index.en_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;2100&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;heatmap&#34; class=&#34;section level3&#34; number=&#34;4.5.3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.5.3&lt;/span&gt; Heatmap&lt;/h3&gt;
&lt;p&gt;To visualize the mobility trend of all European countries it is recommended to use a heatmap instead of a bundle of lines. Before building the graph, we will create a vector of Sundays for the x-axis labels in the observation period.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# sequence of dates
df &amp;lt;- data.frame(d = seq(ymd(&amp;quot;2020-02-15&amp;quot;), ymd(&amp;quot;2020-06-07&amp;quot;), &amp;quot;day&amp;quot;))

# filter on Sundays 
sundays &amp;lt;- df %&amp;gt;% 
            mutate(wd = wday(d, week_start = 1)) %&amp;gt;% 
             filter(wd == 7) %&amp;gt;% 
              pull(d)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To difference between European regions, we will use a color fill for the boxplots. We can set the color type with &lt;code&gt;scale_fill_*&lt;/code&gt;, in this case, from the viridis scheme. In addition, the &lt;code&gt;guides()&lt;/code&gt; function can modify the color bar of the legend. Finally, here we see the use of &lt;code&gt;theme()&lt;/code&gt; with additional changes to &lt;code&gt;theme_minimal()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# headmap
ggplot(subset_europe, 
       aes(date, region, fill = resi_real)) +
  geom_tile() +
  scale_x_date(breaks = sundays,
               date_labels = &amp;quot;%d %b&amp;quot;) +
  scale_fill_viridis_c(option = &amp;quot;A&amp;quot;, 
                       breaks = c(91, 146),
                       labels = c(&amp;quot;Less&amp;quot;, &amp;quot;More&amp;quot;), 
                       direction = -1) +
  theme_minimal() +
  theme(legend.position = &amp;quot;top&amp;quot;, 
        title = element_text(size = 14),
        panel.grid.major.x = element_line(colour = &amp;quot;white&amp;quot;, linetype = &amp;quot;dashed&amp;quot;),
        panel.grid.minor.x = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.ontop = TRUE,
        plot.margin = margin(r = 1, unit = &amp;quot;cm&amp;quot;)) +
  labs(y = &amp;quot;&amp;quot;, 
       x = &amp;quot;&amp;quot;, 
       fill = &amp;quot;&amp;quot;, 
       title = &amp;quot;Mobility trends for places of residence&amp;quot;,
       caption = &amp;quot;Data: google.com/covid19/mobility/&amp;quot;) +
  guides(fill = guide_colorbar(barwidth = 10, 
                               barheight = .5,
                               label.position = &amp;quot;top&amp;quot;, 
                               ticks = FALSE)) +
  coord_cartesian(expand = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/index.en_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;3675&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;apply-functions-on-vectors-or-lists&#34; class=&#34;section level2&#34; number=&#34;4.6&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.6&lt;/span&gt; Apply functions on vectors or lists&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;purrr&lt;/code&gt; package contains a set of advanced functional programming functions for working with functions and vectors. The known &lt;code&gt;lapply()&lt;/code&gt; family of R Base corresponds to the &lt;code&gt;map()&lt;/code&gt; functions in this package. One of the biggest advantages is being able to reduce the use of loops (&lt;code&gt;for&lt;/code&gt;, etc.).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# list of two vectors
vec_list &amp;lt;- list(x = 1:10, y = 50:70)

# calculate the average for each one
map(vec_list, mean)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $x
## [1] 5.5
## 
## $y
## [1] 60&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# change the output type map_* (dbl, chr, lgl, etc.)
map_dbl(vec_list, mean)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    x    y 
##  5.5 60.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, a more complex example. We calculate the correlation coefficient between residential and park mobility in all European countries. To get a tidy summary of a model or test we use the &lt;code&gt;tidy()&lt;/code&gt; function of the &lt;code&gt;broom&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(broom) # tidy outputs

# custom function
cor_test &amp;lt;- function(x, formula) { 
  
df &amp;lt;- cor.test(as.formula(formula), data = x) %&amp;gt;% tidy()

return(df)
  
}

# prepare the data
europe_reg &amp;lt;- filter(google_mobility, 
                           !is.na(sub_region_1),
                           !is.na(residential_percent_change_from_baseline)) %&amp;gt;%
                     left_join(wld, by = c(&amp;quot;country_region_code&amp;quot;=&amp;quot;iso_a2&amp;quot;)) %&amp;gt;% 
                     filter(subregion %in% c(&amp;quot;Northern Europe&amp;quot;,
                                         &amp;quot;Southern Europe&amp;quot;,
                                          &amp;quot;Western Europe&amp;quot;,
                                          &amp;quot;Eastern Europe&amp;quot;))

# apply the function to each country creating a list
cor_mobility &amp;lt;- europe_reg %&amp;gt;%
                 split(.$country_region_code) %&amp;gt;% 
                   map(cor_test, formula = &amp;quot;~ residential_percent_change_from_baseline + parks_percent_change_from_baseline&amp;quot;)  

cor_mobility[1:5]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $AT
## # A tibble: 1 x 8
##   estimate statistic  p.value parameter conf.low conf.high method    alternative
##      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;int&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;      
## 1   -0.360     -12.3 2.68e-32      1009   -0.413    -0.305 Pearson&amp;#39;~ two.sided  
## 
## $BE
## # A tibble: 1 x 8
##   estimate statistic     p.value parameter conf.low conf.high method alternative
##      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;int&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;      
## 1   -0.312     -6.06     3.67e-9       340   -0.405    -0.213 Pears~ two.sided  
## 
## $BG
## # A tibble: 1 x 8
##   estimate statistic   p.value parameter conf.low conf.high method   alternative
##      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;int&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;      
## 1   -0.677     -37.8 1.47e-227      1694   -0.702    -0.650 Pearson~ two.sided  
## 
## $CH
## # A tibble: 1 x 8
##   estimate statistic p.value parameter conf.low conf.high method     alternative
##      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;     &amp;lt;int&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;      
## 1  -0.0786     -2.91 0.00370      1360   -0.131   -0.0256 Pearson&amp;#39;s~ two.sided  
## 
## $CZ
## # A tibble: 1 x 8
##   estimate statistic  p.value parameter conf.low conf.high method    alternative
##      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;int&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;      
## 1  -0.0837     -3.35 0.000824      1593   -0.132   -0.0347 Pearson&amp;#39;~ two.sided&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we’ve seen before, there are subfunctions of &lt;code&gt;map_*&lt;/code&gt; to get an object of another class instead of a list, here for a bind &lt;code&gt;data.frame&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor_mobility &amp;lt;- europe_reg %&amp;gt;%
                  split(.$country_region_code) %&amp;gt;% 
                     map_df(cor_test, 
                            formula = &amp;quot;~ residential_percent_change_from_baseline + parks_percent_change_from_baseline&amp;quot;, 
                            .id = &amp;quot;country_code&amp;quot;)

arrange(cor_mobility, estimate)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 27 x 9
##    country_code estimate statistic   p.value parameter conf.low conf.high method
##    &amp;lt;chr&amp;gt;           &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;int&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; 
##  1 IT             -0.831    -71.0  0              2250   -0.844    -0.818 Pears~
##  2 ES             -0.825    -65.4  0              2005   -0.839    -0.811 Pears~
##  3 PT             -0.729    -46.9  2.12e-321      1938   -0.749    -0.707 Pears~
##  4 FR             -0.698    -37.4  3.29e-216      1474   -0.723    -0.671 Pears~
##  5 GR             -0.692    -27.0  1.03e-114       796   -0.726    -0.654 Pears~
##  6 BG             -0.677    -37.8  1.47e-227      1694   -0.702    -0.650 Pears~
##  7 RO             -0.640    -56.0  0              4517   -0.657    -0.623 Pears~
##  8 SI             -0.627    -11.4  1.98e- 23       200   -0.704    -0.535 Pears~
##  9 HR             -0.579    -21.9  9.32e- 87       954   -0.620    -0.536 Pears~
## 10 LV             -0.544     -6.87 3.84e- 10       112   -0.662    -0.401 Pears~
## # ... with 17 more rows, and 1 more variable: alternative &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Other practical examples here in this &lt;a href=&#34;https://dominicroye.github.io/en/2019/import-excel-sheets-with-r/&#34;&gt;post&lt;/a&gt; or this &lt;a href=&#34;https://dominicroye.github.io/en/2019/tidy-correlation-tests-in-r/&#34;&gt;other&lt;/a&gt;. More details can be found in the &lt;a href=&#34;https://github.com/rstudio/cheatsheets/raw/master/purrr.pdf&#34;&gt;Cheat-Sheet&lt;/a&gt; of &lt;code&gt;purrr&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/drxeo&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;41&#34; width=&#34;174&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Visualize climate anomalies</title>
      <link>https://dominicroye.github.io/en/2020/visualize-climate-anomalies/</link>
      <pubDate>Sun, 29 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://dominicroye.github.io/en/2020/visualize-climate-anomalies/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2020/visualize-climate-anomalies/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;When we visualize precipitation and temperature anomalies, we simply use time series as bar graph indicating negative and positive values in red and blue. However, in order to have a better overview we need both anomalies in a single graph. In this way we could more easly answer the question of whether a particular season or month was dry-warm or wet-cold, and even compare these anomalies in the context of previous years.&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Packages&lt;/h2&gt;
&lt;p&gt;In this post we will use the following packages:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;10%&#34; /&gt;
&lt;col width=&#34;89%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Package&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lubridate&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Easy manipulation of dates and times&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ggrepel&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Repel overlapping text labels in ggplot2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#we install the packages if necessary
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;ggrepel&amp;quot;)) install.packages(&amp;quot;ggrepel&amp;quot;)
if(!require(&amp;quot;lubridate&amp;quot;)) install.packages(&amp;quot;lubridate&amp;quot;)

#packages
library(tidyverse)
library(lubridate)
library(ggrepel)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;preparing-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Preparing the data&lt;/h2&gt;
&lt;p&gt;First we import the daily precipitation and temperature data from the selected weather station (&lt;a href=&#34;https://dominicroye.github.io/files/meteo_tenerife.csv&#34;&gt;download&lt;/a&gt;). We will use the data from Tenerife South (Spain) [1981-2020] accessible through &lt;a href=&#34;https://opendata.aemet.es/&#34;&gt;Open Data AEMET&lt;/a&gt;. In R there is a package called &lt;a href=&#34;https://vegmod.ctfc.cat/software/meteoland/&#34;&gt;&lt;code&gt;meteoland&lt;/code&gt;&lt;/a&gt; that facilitates the download with specific functions to access data from AEMET (Spanish State Meteorological Agency), Meteogalicia (Galician Meteorological Service) and Meteocat (Catalan Meteorological Service).&lt;/p&gt;
&lt;div id=&#34;step-1-import-the-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Step 1: import the data&lt;/h3&gt;
&lt;p&gt;We import the data in &lt;em&gt;csv&lt;/em&gt; format, the first column is the date, the second column the precipitation (pr) and the last column the average daily temperature (ta).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- read_csv(&amp;quot;meteo_tenerife.csv&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 14303 Columns: 3
## -- Column specification --------------------------------------------------------
## Delimiter: &amp;quot;,&amp;quot;
## dbl  (2): pr, ta
## date (1): date
## 
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 14,303 x 3
##    date          pr    ta
##    &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 1981-01-02   0    17.6
##  2 1981-01-03   0    16.8
##  3 1981-01-04   0    17.4
##  4 1981-01-05   0    17.6
##  5 1981-01-06   0    17  
##  6 1981-01-07   0    17.6
##  7 1981-01-08   0    18.6
##  8 1981-01-09   0    19.8
##  9 1981-01-10   0    21.5
## 10 1981-01-11   3.8  17.6
## # ... with 14,293 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-2-preparing-the-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Step 2: preparing the data&lt;/h3&gt;
&lt;p&gt;In the second step we prepare the data to calculate the anomalies. To do this, we create three new columns: the month, the year, and the season of the year. Since our objective is to analyse winter anomalies, we cannot use the calendar year, because winter includes the month of December of one year and the months of January and February of the following. The custom function &lt;code&gt;meteo_yr()&lt;/code&gt; extracts the year from a date indicating the starting month. The concept is similar to the hydrological year in which it starts on October 1.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meteo_yr &amp;lt;- function(dates, start_month = NULL) {
  # convert to POSIXlt
  dates.posix &amp;lt;- as.POSIXlt(dates)
  # year offset
  offset &amp;lt;- ifelse(dates.posix$mon &amp;gt;= start_month - 1, 1, 0)
  # new year
  adj.year = dates.posix$year + 1900 + offset
  return(adj.year)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will use many functions of the package collection &lt;code&gt;tidyverse&lt;/code&gt; (&lt;a href=&#34;https://www.tidyverse.org/&#34; class=&#34;uri&#34;&gt;https://www.tidyverse.org/&lt;/a&gt;). The &lt;code&gt;mutate()&lt;/code&gt; function helps to add new columns or change existing ones. To define the seasons, we use the &lt;code&gt;case_when()&lt;/code&gt; function from the &lt;code&gt;dplyr&lt;/code&gt; package, which has many advantages compared to a chain of &lt;code&gt;ifelse()&lt;/code&gt;. In &lt;code&gt;case_when()&lt;/code&gt; we use two-side formulas, on the one hand the condition and on the other the action when that condition is met. A two-sided formula in R consists of the operator &lt;code&gt;~&lt;/code&gt;. The binary operator &lt;code&gt;%in%&lt;/code&gt; allows us to filter several values in a greater set.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- mutate(data, 
               winter_yr = meteo_yr(date, 12),
               month = month(date), 
               season = case_when(month %in% c(12,1:2) ~ &amp;quot;Winter&amp;quot;,
                                  month %in% 3:5 ~ &amp;quot;Spring&amp;quot;,
                                  month %in% 6:8 ~ &amp;quot;Summer&amp;quot;,
                                  month %in% 9:11 ~ &amp;quot;Autum&amp;quot;))

data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 14,303 x 6
##    date          pr    ta winter_yr month season
##    &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; 
##  1 1981-01-02   0    17.6      1981     1 Winter
##  2 1981-01-03   0    16.8      1981     1 Winter
##  3 1981-01-04   0    17.4      1981     1 Winter
##  4 1981-01-05   0    17.6      1981     1 Winter
##  5 1981-01-06   0    17        1981     1 Winter
##  6 1981-01-07   0    17.6      1981     1 Winter
##  7 1981-01-08   0    18.6      1981     1 Winter
##  8 1981-01-09   0    19.8      1981     1 Winter
##  9 1981-01-10   0    21.5      1981     1 Winter
## 10 1981-01-11   3.8  17.6      1981     1 Winter
## # ... with 14,293 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-3-estimate-winter-anomalies&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Step 3: estimate winter anomalies&lt;/h3&gt;
&lt;p&gt;In the next step we create a subset of the winter months. Then we group by the defined meteorological year and calculate the sum and average for precipitation and temperature, respectively. To facilitate the work, the &lt;code&gt;magrittr&lt;/code&gt; package introduces the operator called &lt;em&gt;pipe&lt;/em&gt; in the form &lt;code&gt;%&amp;gt;%&lt;/code&gt; with the aim of combining several functions without the need to assign the result to a new object. The &lt;em&gt;pipe&lt;/em&gt; operator passes the output of a function applied to the first argument of the next function. This way of combining functions allows you to chain several steps simultaneously. The &lt;code&gt;%&amp;gt;%&lt;/code&gt; must be understood and pronounced as &lt;em&gt;then&lt;/em&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_inv &amp;lt;- filter(data, 
                   season == &amp;quot;Winter&amp;quot;) %&amp;gt;% 
              group_by(winter_yr) %&amp;gt;%
                  summarise(pr = sum(pr, na.rm = TRUE),
                            ta = mean(ta, na.rm = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we only have to calculate the anomalies of precipitation and temperature. The columns &lt;code&gt;pr_mean&lt;/code&gt; and &lt;code&gt;ta_mean&lt;/code&gt; will contain the climate average, the reference for the anomalies with respect to the normal period 1981-2010. Therefore, we need to filter the values to the period before 2010, which we will do in the usual way of filtering vectors in R. Once we have the references we estimate the anomalies &lt;code&gt;pr_anom&lt;/code&gt; and &lt;code&gt;ta_anom&lt;/code&gt;. To facilitate the interpretation, in the case of precipitation we express the anomalies as percentage, with the average set at 0% instead of 100%.&lt;/p&gt;
&lt;p&gt;In addition, we add three required columns with information for the creation of the graph: 1) &lt;code&gt;labyr&lt;/code&gt; contains the year of each anomaly as long as it has been greater/less than -+10% or -+0.5ºC, respectively (this is for reducing the number of labels), 2) &lt;code&gt;symb_point&lt;/code&gt; is a dummy variable in order to be able to create different symbols between the cases of (1), and 3) &lt;code&gt;lab_font&lt;/code&gt; for highlighting in bold the year 2020.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_inv &amp;lt;-  mutate(data_inv, pr_mean = mean(pr[winter_yr &amp;lt;= 2010]), 
                              ta_mean = mean(ta[winter_yr &amp;lt;= 2010]),
                              pr_anom = (pr*100/pr_mean)-100, 
                              ta_anom = ta-ta_mean,
                              
                              labyr = case_when(pr_anom &amp;lt; -10 &amp;amp; ta_anom &amp;lt; -.5 ~ winter_yr,
                                                pr_anom &amp;lt; -10 &amp;amp; ta_anom &amp;gt; .5 ~ winter_yr,
                                                pr_anom &amp;gt; 10 &amp;amp; ta_anom &amp;lt; -.5 ~ winter_yr,
                                                pr_anom &amp;gt; 10 &amp;amp; ta_anom &amp;gt; .5 ~ winter_yr),
                              symb_point = ifelse(!is.na(labyr), &amp;quot;yes&amp;quot;, &amp;quot;no&amp;quot;),
                              lab_font = ifelse(labyr == 2020, &amp;quot;bold&amp;quot;, &amp;quot;plain&amp;quot;)
                    )&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-the-graph&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Creating the graph&lt;/h2&gt;
&lt;p&gt;We will build the chart adding layer by layer the distinctive elements: 1) the background with the different grids (Dry-Warm, Dry-Cold, etc.), 2) the points and labels, and 3) the style adjustments.&lt;/p&gt;
&lt;div id=&#34;part-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Part 1&lt;/h3&gt;
&lt;p&gt;The idea is that the points with dry-warm anomalies are located in quadrant I (top-right) and those with wet-cold in quadrant III (bottom-left). Therefore, we must invert the sign in the precipitation anomalies. Then we create a &lt;code&gt;data.frame&lt;/code&gt; with the label positions of the four quadrants. For the positions in &lt;em&gt;x&lt;/em&gt; and &lt;em&gt;y&lt;/em&gt; &lt;code&gt;Inf&lt;/code&gt; and &lt;code&gt;-Inf&lt;/code&gt; are used, which is equivalent to the maximum panel sides with respect to the data. However, it is necessary to adjust the position towards the extreme points within the panel with the known arguments of &lt;code&gt;ggplot2&lt;/code&gt;: &lt;em&gt;hjust&lt;/em&gt; and &lt;em&gt;vjust&lt;/em&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_inv_p &amp;lt;- mutate(data_inv, pr_anom = pr_anom * -1)

bglab &amp;lt;- data.frame(x = c(-Inf, Inf, -Inf, Inf), 
                    y = c(Inf, Inf, -Inf, -Inf),
                    hjust = c(1, 1, 0, 0), 
                    vjust = c(1, 0, 1, 0),
                    lab = c(&amp;quot;Wet-Warm&amp;quot;, &amp;quot;Dry-Warm&amp;quot;,
                              &amp;quot;Wet-Cold&amp;quot;, &amp;quot;Dry-Cold&amp;quot;))

  
bglab&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      x    y hjust vjust      lab
## 1 -Inf  Inf     1     1 Wet-Warm
## 2  Inf  Inf     1     0 Dry-Warm
## 3 -Inf -Inf     0     1 Wet-Cold
## 4  Inf -Inf     0     0 Dry-Cold&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;part-2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Part 2&lt;/h3&gt;
&lt;p&gt;In the second part we can start building the chart by adding all graphical elements. First we create the background with different colors of each quadrant. The function &lt;code&gt;annotate()&lt;/code&gt; allows adding geometry layers without the use of variables within &lt;code&gt;data.frames&lt;/code&gt;. With the &lt;code&gt;geom_hline()&lt;/code&gt; and &lt;code&gt;geom_vline()&lt;/code&gt; function we mark the quadrants horizontally and vertically using a dashed line. Finally, we draw the labels of each quadrant, using the function &lt;code&gt;geom_text()&lt;/code&gt;. When we use other data sources than the main one used in &lt;code&gt;ggplot()&lt;/code&gt;, we must indicate it with the argument &lt;code&gt;data&lt;/code&gt; in the corresponding geometry function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;g1 &amp;lt;- ggplot(data_inv_p, 
             aes(pr_anom, ta_anom)) +
         annotate(&amp;quot;rect&amp;quot;, xmin = -Inf, xmax = 0, ymin = 0, ymax = Inf, fill = &amp;quot;#fc9272&amp;quot;, alpha = .6) + #wet-warm
         annotate(&amp;quot;rect&amp;quot;, xmin = 0, xmax = Inf, ymin = 0, ymax = Inf, fill = &amp;quot;#cb181d&amp;quot;, alpha = .6) + #dry-warm
         annotate(&amp;quot;rect&amp;quot;, xmin = -Inf, xmax = 0, ymin = -Inf, ymax = 0, fill = &amp;quot;#2171b5&amp;quot;, alpha = .6) + #wet-cold
         annotate(&amp;quot;rect&amp;quot;, xmin = 0, xmax = Inf, ymin = -Inf, ymax = 0, fill = &amp;quot;#c6dbef&amp;quot;, alpha = .6) + #dry-cold
       geom_hline(yintercept = 0,
                  linetype = &amp;quot;dashed&amp;quot;) +
       geom_vline(xintercept = 0,
                  linetype = &amp;quot;dashed&amp;quot;) +
       geom_text(data = bglab, 
                     aes(x, y, label = lab, hjust = hjust, vjust = vjust),
                     fontface = &amp;quot;italic&amp;quot;, size = 5, 
                     angle = 90, colour = &amp;quot;white&amp;quot;)

g1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/visualize-climate-anomalies/index.en_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;3507&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;part-3&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Part 3&lt;/h3&gt;
&lt;p&gt;In the third part we simply add the points of the anomalies and the labels of the years. The &lt;code&gt;geom_text_repel()&lt;/code&gt; function is similar to the one known by default in &lt;code&gt;ggplot2&lt;/code&gt;, &lt;code&gt;geom_text()&lt;/code&gt;, but it repels overlapping text labels away from each other.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;g2 &amp;lt;- g1 + geom_point(aes(fill = symb_point, colour = symb_point),
                      size = 2.8, shape = 21, show.legend = FALSE) +
           geom_text_repel(aes(label = labyr, fontface = lab_font),
                           max.iter = 5000, 
                           size = 3.5) 
g2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 25 rows containing missing values (geom_text_repel).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/visualize-climate-anomalies/index.en_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;3507&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;part-4&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Part 4&lt;/h3&gt;
&lt;p&gt;In the last part we adjust, in addition to the general style, the axes, the color type and the (sub)title. Remember that we changed the sign on precipitation anomalies. Hence, we must use the arguments &lt;code&gt;breaks&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt; in the function &lt;code&gt;scale_x_continouous()&lt;/code&gt; to reverse the sign in the labels corresponding to the breaks.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;g3 &amp;lt;- g2 + scale_x_continuous(&amp;quot;Precipitation anomaly in %&amp;quot;,
                              breaks = seq(-100, 250, 10) * -1,
                              labels = seq(-100, 250, 10),
                              limits = c(min(data_inv_p$pr_anom), 100)) +
           scale_y_continuous(&amp;quot;Mean temperature anomaly in ºC&amp;quot;,
                              breaks = seq(-2, 2, 0.5)) +
           scale_fill_manual(values = c(&amp;quot;black&amp;quot;, &amp;quot;white&amp;quot;)) +
           scale_colour_manual(values = rev(c(&amp;quot;black&amp;quot;, &amp;quot;white&amp;quot;))) +
           labs(title = &amp;quot;Winter anomalies in Tenerife South&amp;quot;, 
                caption = &amp;quot;Data: AEMET\nNormal period 1981-2010&amp;quot;) +
           theme_bw()

g3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 25 rows containing missing values (geom_text_repel).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/visualize-climate-anomalies/index.en_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;3507&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/drxeo&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;41&#34; width=&#34;174&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Geographic distance</title>
      <link>https://dominicroye.github.io/en/2020/geographic-distance/</link>
      <pubDate>Sun, 19 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://dominicroye.github.io/en/2020/geographic-distance/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2020/geographic-distance/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;The first post of this year 2020, I will dedicate to a question that I was recently asked. The question was how to calculate the shortest distance between different points and how to know which is the closest point. When we work with spatial data in R, currently the easiest thing is to use the &lt;code&gt;sf&lt;/code&gt; package in combination with the &lt;code&gt;tidyverse&lt;/code&gt; collection of packages. We also use the &lt;code&gt;units&lt;/code&gt; package which is very useful for working with units of measurement.&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Packages&lt;/h2&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;12%&#34; /&gt;
&lt;col width=&#34;87%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Package&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Simple Feature: import, export and manipulate vector data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;units&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Support for measurement units in R vectors, matrices and arrays: propagation, conversion, derivation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;maps&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Draw geographical maps&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;rnaturalearth&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Hold and facilitate interaction with Natural Earth map data&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install the necessary packages
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;units&amp;quot;)) install.packages(&amp;quot;units&amp;quot;)
if(!require(&amp;quot;sf&amp;quot;)) install.packages(&amp;quot;sf&amp;quot;)
if(!require(&amp;quot;maps&amp;quot;)) install.packages(&amp;quot;maps&amp;quot;)
if(!require(&amp;quot;rnaturalearth&amp;quot;)) install.packages(&amp;quot;rnaturalearth&amp;quot;)

# load packages
library(maps)
library(sf) 
library(tidyverse)
library(units)
library(rnaturalearth)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;measurement-units&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Measurement units&lt;/h2&gt;
&lt;p&gt;The use of vectors and matrices with the &lt;code&gt;units&lt;/code&gt; class allows us to calculate and transform units of measurement.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# length
l &amp;lt;- set_units(1:10, m)
l&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Units: [m]
##  [1]  1  2  3  4  5  6  7  8  9 10&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# convert units
set_units(l, cm)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Units: [cm]
##  [1]  100  200  300  400  500  600  700  800  900 1000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# sum different units
set_units(l, cm) + l&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Units: [cm]
##  [1]  200  400  600  800 1000 1200 1400 1600 1800 2000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# area
a &amp;lt;- set_units(355, ha)
set_units(a, km2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 3.55 [km2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# velocity
vel &amp;lt;- set_units(seq(20, 50, 10), km/h)
set_units(vel, m/s)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Units: [m/s]
## [1]  5.555556  8.333333 11.111111 13.888889&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;capital-cities-of-the-world&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Capital cities of the world&lt;/h2&gt;
&lt;p&gt;We will use the capital cities of the whole world with the objective of calculating the distance to the nearest capital city and indicating the name/country.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# set of world cities with coordinates
head(world.cities) # from the maps package&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                 name country.etc   pop   lat  long capital
## 1 &amp;#39;Abasan al-Jadidah   Palestine  5629 31.31 34.34       0
## 2 &amp;#39;Abasan al-Kabirah   Palestine 18999 31.32 34.35       0
## 3       &amp;#39;Abdul Hakim    Pakistan 47788 30.55 72.11       0
## 4 &amp;#39;Abdullah-as-Salam      Kuwait 21817 29.36 47.98       0
## 5              &amp;#39;Abud   Palestine  2456 32.03 35.07       0
## 6            &amp;#39;Abwein   Palestine  3434 32.03 35.20       0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To convert points with longitude and latitude into a spatial object of class &lt;code&gt;sf&lt;/code&gt;, we use the function &lt;code&gt;st_as_sf()&lt;/code&gt;, indicating the coordinate columns and the coordinate reference system (WSG84, epsg: 4326).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# convert the points into an sf object with CRS WSG84
cities &amp;lt;- st_as_sf(world.cities, coords = c(&amp;quot;long&amp;quot;, &amp;quot;lat&amp;quot;), crs = 4326)
cities&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Simple feature collection with 43645 features and 4 fields
## Geometry type: POINT
## Dimension:     XY
## Bounding box:  xmin: -178.8 ymin: -54.79 xmax: 179.81 ymax: 78.93
## Geodetic CRS:  WGS 84
## First 10 features:
##                  name  country.etc   pop capital            geometry
## 1  &amp;#39;Abasan al-Jadidah    Palestine  5629       0 POINT (34.34 31.31)
## 2  &amp;#39;Abasan al-Kabirah    Palestine 18999       0 POINT (34.35 31.32)
## 3        &amp;#39;Abdul Hakim     Pakistan 47788       0 POINT (72.11 30.55)
## 4  &amp;#39;Abdullah-as-Salam       Kuwait 21817       0 POINT (47.98 29.36)
## 5               &amp;#39;Abud    Palestine  2456       0 POINT (35.07 32.03)
## 6             &amp;#39;Abwein    Palestine  3434       0  POINT (35.2 32.03)
## 7            &amp;#39;Adadlay      Somalia  9198       0  POINT (44.65 9.77)
## 8              &amp;#39;Adale      Somalia  5492       0   POINT (46.3 2.75)
## 9               &amp;#39;Afak         Iraq 22706       0 POINT (45.26 32.07)
## 10              &amp;#39;Afif Saudi Arabia 41731       0 POINT (42.93 23.92)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the next step, we filter by the capital cities encoded in the column &lt;em&gt;capital&lt;/em&gt; with 1. The advantage of the &lt;code&gt;sf&lt;/code&gt; package is the possibility of applying functions of the &lt;code&gt;tidyverse&lt;/code&gt; collection to manipulate the attributes. In addition, we add a column with new labels using the &lt;code&gt;str_c()&lt;/code&gt; function of the &lt;code&gt;stringr&lt;/code&gt; package, which is similar to that of &lt;em&gt;R Base&lt;/em&gt; &lt;code&gt;paste()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# filter the capital cities
capitals &amp;lt;- filter(cities, capital == 1)

# create a new label combining name and country
capitals &amp;lt;- mutate(capitals, city_country = str_c(name, &amp;quot; (&amp;quot;, country.etc, &amp;quot;)&amp;quot;))

capitals &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Simple feature collection with 230 features and 5 fields
## Geometry type: POINT
## Dimension:     XY
## Bounding box:  xmin: -176.13 ymin: -51.7 xmax: 179.2 ymax: 78.21
## Geodetic CRS:  WGS 84
## First 10 features:
##           name          country.etc     pop capital               geometry
## 1       &amp;#39;Amman               Jordan 1303197       1    POINT (35.93 31.95)
## 2    Abu Dhabi United Arab Emirates  619316       1    POINT (54.37 24.48)
## 3        Abuja              Nigeria  178462       1      POINT (7.17 9.18)
## 4        Accra                Ghana 2029143       1      POINT (-0.2 5.56)
## 5    Adamstown             Pitcairn      51       1  POINT (-130.1 -25.05)
## 6  Addis Abeba             Ethiopia 2823167       1     POINT (38.74 9.03)
## 7        Agana                 Guam    1041       1   POINT (144.75 13.47)
## 8      Algiers              Algeria 2029936       1     POINT (3.04 36.77)
## 9        Alofi                 Niue     627       1 POINT (-169.92 -19.05)
## 10   Amsterdam          Netherlands  744159       1     POINT (4.89 52.37)
##                        city_country
## 1                   &amp;#39;Amman (Jordan)
## 2  Abu Dhabi (United Arab Emirates)
## 3                   Abuja (Nigeria)
## 4                     Accra (Ghana)
## 5              Adamstown (Pitcairn)
## 6            Addis Abeba (Ethiopia)
## 7                      Agana (Guam)
## 8                 Algiers (Algeria)
## 9                      Alofi (Niue)
## 10          Amsterdam (Netherlands)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;calculate-distances&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Calculate distances&lt;/h2&gt;
&lt;p&gt;Geographical distance (Euclidean or greater circle) is calculated with the &lt;code&gt;st_distance()&lt;/code&gt; function, either between two points, between one point and others or between all points. In the latter case we obtain a symmetric matrix of distances (NxN), taken pairwise between the elements of the capital city set. In the diagonal we find the combinations between the same points giving all null values.&lt;/p&gt;
&lt;table&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;B&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;C&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;255&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;345&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;B&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;255&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;142&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;345&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;142&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;For instance, when we want to know the distance from Amsterdam to Abu Dhabi, Washington and Tokyo we pass two spatial objects.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# calculate distance
dist_amsterdam &amp;lt;- st_distance(slice(capitals, 10), 
                              slice(capitals, c(2, 220, 205)))

dist_amsterdam # distance in meters&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Units: [m]
##         [,1]    [,2]    [,3]
## [1,] 5163124 6187634 9293710&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The result is a matrix with a single row or column (depending on the order of the spatial objects) with a class of &lt;code&gt;units&lt;/code&gt;. Thus it is possible to convert easily to another unit of measure. If we want to obtain a vector without class &lt;code&gt;units&lt;/code&gt;, we only have to apply the function &lt;code&gt;as.vector()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# change from m to km
set_units(dist_amsterdam, &amp;quot;km&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Units: [km]
##          [,1]     [,2]    [,3]
## [1,] 5163.124 6187.634 9293.71&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# units class to vector
as.vector(dist_amsterdam)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 5163124 6187634 9293710&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the second step, we estimate the distance matrix between all the capital cities. It is important to convert the null values to &lt;code&gt;NA&lt;/code&gt; to subsequently obtain the correct matrix index.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# calculate distance
m_distance &amp;lt;- st_distance(capitals)

# matrix
dim(m_distance)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 230 230&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# change m to km
m_distance_km &amp;lt;- set_units(m_distance, km)

# replace the distance of 0 m with NA
m_distance_km[m_distance_km == set_units(0, km)] &amp;lt;- NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    When the result is of the &lt;code&gt;units&lt;/code&gt; class, it is necessary to use the same class to be able to make logical queries. For example, &lt;code&gt;set_units(1, m) == set_units(1, m)&lt;/code&gt; vs. &lt;code&gt;set_units(1, m) == 1&lt;/code&gt;.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;To obtain the shortest distance, in addition to its position, we use the &lt;code&gt;apply ()&lt;/code&gt; function which in turn allows us to apply the function &lt;code&gt;which.min()&lt;/code&gt; and &lt;code&gt;min()&lt;/code&gt; on each row. It would also be possible to use the function on columns giving the same result. Finally, we add the results as new columns with the &lt;code&gt;mutate()&lt;/code&gt; function. The indices in &lt;em&gt;pos&lt;/em&gt; allow us to obtain the names of the nearest cities.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get the index (position) of the city and the distance
pos &amp;lt;- apply(m_distance_km, 1, which.min)
dist &amp;lt;- apply(m_distance_km, 1, min, na.rm = TRUE)

# add the distance and get the name of the city
capitals &amp;lt;- mutate(capitals, nearest_city =  city_country[pos], 
                             geometry_nearest = geometry[pos],
                             distance_city = dist)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;map-of-distances-to-the-next-capital-city&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Map of distances to the next capital city&lt;/h2&gt;
&lt;p&gt;Finally, we build a map representing the distance in proportional circles. To do this, we use the usual grammar of &lt;code&gt;ggplot()&lt;/code&gt; by adding the geometry &lt;code&gt;geom_sf()&lt;/code&gt;, first for the world map as background and then for the cities. In &lt;code&gt;aes()&lt;/code&gt; we indicate, with the argument &lt;code&gt;size = distance_city&lt;/code&gt;, the variable which we want to map proportionally. The &lt;code&gt;theme_void()&lt;/code&gt; function removes all style elements. In addition, we define with the function &lt;code&gt;coord_sf()&lt;/code&gt; a new projection indicating the &lt;em&gt;proj4&lt;/em&gt; format.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# world map
world &amp;lt;- ne_countries(scale = 10, returnclass = &amp;quot;sf&amp;quot;)

# map
ggplot(world) +
   geom_sf(fill = &amp;quot;black&amp;quot;, colour = &amp;quot;white&amp;quot;) +
   geom_sf(data = capitals, 
           aes(size = distance_city),
           alpha = 0.7,
           fill = &amp;quot;#bd0026&amp;quot;,
           shape = 21,
           show.legend = &amp;#39;point&amp;#39;) +
   coord_sf(crs = &amp;quot;+proj=robin +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs&amp;quot;) +
  labs(size = &amp;quot;Distance (km)&amp;quot;, title = &amp;quot;Distance to the next capital city&amp;quot;) +
  theme_void()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/geographic-distance/index.en_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/drxeo&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;41&#34; width=&#34;174&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Visualize urban growth</title>
      <link>https://dominicroye.github.io/en/2019/visualize-urban-growth/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://dominicroye.github.io/en/2019/visualize-urban-growth/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2019/visualize-urban-growth/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;The General Directorate for the Cadastre of Spain has spatial information of the all buildings except for the Basque Country and Navarra. This data set is part of the implementation of &lt;a href=&#34;https://inspire.ec.europa.eu/&#34;&gt;INSPIRE&lt;/a&gt;, the Space Information Infrastructure in Europe. More information can be found &lt;a href=&#34;http://www.catastro.meh.es/webinspire/index.html&#34;&gt;here&lt;/a&gt;. We will use the links (&lt;em&gt;urls&lt;/em&gt;) in &lt;em&gt;ATOM&lt;/em&gt; format, which is an RSS type for web feeds, allowing us to obtain the download link for each municipality.&lt;/p&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    This blog post is a reduced version of the case study that you can find in our recent publication - &lt;a href=&#34;https://dominicroye.github.io/es/publication/manual_rgis_2019/&#34;&gt;Introduction to GIS with R&lt;/a&gt; - published by Dominic Royé and Roberto Serrano-Notivoli (in Spanish).
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Packages&lt;/h2&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;10%&#34; /&gt;
&lt;col width=&#34;89%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Package&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Simple Feature: import, export and manipulate vector data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;fs&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Provides a cross-platform, uniform interface to file system operations&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lubridate&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Easy manipulation of dates and times&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;feedeR&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Import feeds RSS or ATOM&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tmap&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Easy creation of thematic maps&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;classInt&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Create univariate class intervals&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sysfonts&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Loading system fonts and Google Fonts&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;showtext&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Using fonts more easily in R graphs&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install the packages if necessary
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;feedeR&amp;quot;)) install.packages(&amp;quot;feedeR&amp;quot;)
if(!require(&amp;quot;fs&amp;quot;)) install.packages(&amp;quot;fs&amp;quot;)
if(!require(&amp;quot;lubridate&amp;quot;)) install.packages(&amp;quot;lubridate&amp;quot;)
if(!require(&amp;quot;fs&amp;quot;)) install.packages(&amp;quot;fs&amp;quot;)
if(!require(&amp;quot;tmap&amp;quot;)) install.packages(&amp;quot;tmap&amp;quot;)
if(!require(&amp;quot;classInt&amp;quot;)) install.packages(&amp;quot;classInt&amp;quot;)
if(!require(&amp;quot;showtext&amp;quot;)) install.packages(&amp;quot;showtext&amp;quot;)
if(!require(&amp;quot;sysfonts&amp;quot;)) install.packages(&amp;quot;sysfonts&amp;quot;)
if(!require(&amp;quot;rvest&amp;quot;)) install.packages(&amp;quot;rvest&amp;quot;)

# load packages
library(feedeR)
library(sf) 
library(fs)
library(tidyverse)
library(lubridate)
library(classInt)
library(tmap)
library(rvest)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;download-links&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Download links&lt;/h2&gt;
&lt;p&gt;The first &lt;em&gt;url&lt;/em&gt; will give us access to a list of provinces, territorial headquarters (they do not always coincide with the oficial province), with new RSS links, which include the final download link for each municipality. In this case, we will download the buildings of Valencia. Cadastre data is updated every six months.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;url &amp;lt;- &amp;quot;http://www.catastro.minhap.es/INSPIRE/buildings/ES.SDGC.bu.atom.xml&amp;quot;

# import RSS feed with provincial links
prov_enlaces &amp;lt;- feed.extract(url)
str(prov_enlaces) # object is a list&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 4
##  $ title  : chr &amp;quot;Download service of Buildings. Territorial Office&amp;quot;
##  $ link   : chr &amp;quot;http://www.catastro.minhap.es/INSPIRE/buildings/ES.SDGC.BU.atom.xml&amp;quot;
##  $ updated: POSIXct[1:1], format: &amp;quot;2022-03-14&amp;quot;
##  $ items  : tibble [52 x 5] (S3: tbl_df/tbl/data.frame)
##   ..$ title      : chr [1:52] &amp;quot;Territorial office 02 Albacete&amp;quot; &amp;quot;Territorial office 03 Alicante&amp;quot; &amp;quot;Territorial office 04 Almería&amp;quot; &amp;quot;Territorial office 05 Avila&amp;quot; ...
##   ..$ date       : POSIXct[1:52], format: &amp;quot;2022-03-14&amp;quot; &amp;quot;2022-03-14&amp;quot; ...
##   ..$ link       : chr [1:52] &amp;quot;http://www.catastro.minhap.es/INSPIRE/buildings/02/ES.SDGC.bu.atom_02.xml&amp;quot; &amp;quot;http://www.catastro.minhap.es/INSPIRE/buildings/03/ES.SDGC.bu.atom_03.xml&amp;quot; &amp;quot;http://www.catastro.minhap.es/INSPIRE/buildings/04/ES.SDGC.bu.atom_04.xml&amp;quot; &amp;quot;http://www.catastro.minhap.es/INSPIRE/buildings/05/ES.SDGC.bu.atom_05.xml&amp;quot; ...
##   ..$ description: chr [1:52] &amp;quot;\n\n\t\t  &amp;quot; &amp;quot;\n\n\t\t  &amp;quot; &amp;quot;\n\n\t\t  &amp;quot; &amp;quot;\n\n\t\t  &amp;quot; ...
##   ..$ hash       : chr [1:52] &amp;quot;d21ebb7975e59937&amp;quot; &amp;quot;bdba5e149f09e9d8&amp;quot; &amp;quot;03bcbcc7c5be2e17&amp;quot; &amp;quot;8a154202dd778143&amp;quot; ...&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract the table with the links
prov_enlaces_tab &amp;lt;- as_tibble(prov_enlaces$items) %&amp;gt;% 
                       mutate(title = repair_encoding(title))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `html_encoding_repair()` was deprecated in rvest 1.0.0.
## Instead, re-load using the `encoding` argument of `read_html()`
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Best guess: UTF-8 (100% confident)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prov_enlaces_tab&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 52 x 5
##    title                             date                link  description hash 
##    &amp;lt;chr&amp;gt;                             &amp;lt;dttm&amp;gt;              &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt;
##  1 &amp;quot;Territorial office 02 Albacete&amp;quot;  2022-03-14 00:00:00 http~ &amp;quot;\n\n\t\t ~ d21e~
##  2 &amp;quot;Territorial office 03 Alicante&amp;quot;  2022-03-14 00:00:00 http~ &amp;quot;\n\n\t\t ~ bdba~
##  3 &amp;quot;Territorial office 04 Almería&amp;quot;   2022-03-14 00:00:00 http~ &amp;quot;\n\n\t\t ~ 03bc~
##  4 &amp;quot;Territorial office 05 Avila&amp;quot;     2022-03-14 00:00:00 http~ &amp;quot;\n\n\t\t ~ 8a15~
##  5 &amp;quot;Territorial office 06 Badajoz&amp;quot;   2022-03-14 00:00:00 http~ &amp;quot;\n\n\t\t ~ 7d3f~
##  6 &amp;quot;Territorial office 07 Baleares &amp;quot; 2022-03-14 00:00:00 http~ &amp;quot;\n\n\t\t ~ 9c08~
##  7 &amp;quot;Territorial office 08 Barcelona&amp;quot; 2022-03-14 00:00:00 http~ &amp;quot;\n\n\t\t ~ ff72~
##  8 &amp;quot;Territorial office 09 Burgos &amp;quot;   2022-03-14 00:00:00 http~ &amp;quot;\n\n\t\t ~ b431~
##  9 &amp;quot;Territorial office 10 Cáceres &amp;quot;  2022-03-14 00:00:00 http~ &amp;quot;\n\n\t\t ~ f79c~
## 10 &amp;quot;Territorial office 11 Cádiz &amp;quot;    2022-03-14 00:00:00 http~ &amp;quot;\n\n\t\t ~ d702~
## # ... with 42 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we access and download the data from Valencia. To filter the final download link we use the &lt;code&gt;filter()&lt;/code&gt; function of the &lt;code&gt;dplyr&lt;/code&gt; package, searching for the name of the territorial headquarter and then the name of the municipality in capital letters with the &lt;code&gt;str_detect()&lt;/code&gt; function of &lt;code&gt;stringr&lt;/code&gt;. The &lt;code&gt;pull()&lt;/code&gt; function allows us to extract a column from a &lt;code&gt;data.frame&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Currently the &lt;code&gt;feed.extract()&lt;/code&gt; function does not import correctly in the encoding UTF-8 under Windows. For this reason, in some cities a bad codification of special characters may appear “CÃ¡diz”. To solve this problem we apply the &lt;code&gt;repair_encoding()&lt;/code&gt; function of the &lt;code&gt;rvest&lt;/code&gt; package. Nevertheless, problems can arise that have to be corrected manually.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# filter the province and get the RSS link
val_atom &amp;lt;- filter(prov_enlaces_tab, str_detect(title, &amp;quot;Valencia&amp;quot;)) %&amp;gt;% pull(link)

# import the RSS
val_enlaces &amp;lt;- feed.extract(val_atom)

# get the table with the download links
val_enlaces_tab &amp;lt;- val_enlaces$items
val_enlaces_tab &amp;lt;- mutate(val_enlaces_tab, title = repair_encoding(title),
                          link = repair_encoding(link)) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Best guess: UTF-8 (80% confident)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in stringi::stri_conv(x, from): the Unicode code point \U0000fffd cannot
## be converted to destination encoding

## Warning in stringi::stri_conv(x, from): the Unicode code point \U0000fffd cannot
## be converted to destination encoding&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Best guess: UTF-8 (80% confident)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in stringi::stri_conv(x, from): the Unicode code point \U0000fffd cannot
## be converted to destination encoding

## Warning in stringi::stri_conv(x, from): the Unicode code point \U0000fffd cannot
## be converted to destination encoding&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#  filter the table with the name of the city
val_link &amp;lt;- filter(val_enlaces_tab, str_detect(title, &amp;quot;VALENCIA&amp;quot;)) %&amp;gt;% pull(link)
val_link&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;http://www.catastro.minhap.es/INSPIRE/Buildings/46/46900-VALENCIA/A.ES.SDGC.BU.46900.zip&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data-download&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data download&lt;/h2&gt;
&lt;p&gt;The download is done with the &lt;code&gt;download.file()&lt;/code&gt; function that only has two main arguments, the download link and the path with the file name. In this case, we use the &lt;code&gt;tempfile()&lt;/code&gt; function, which is useful for creating temporary files, that is, files that only exist in the memory for a certain time.
The file we download has the extension &lt;code&gt;*.zip&lt;/code&gt;, so we must unzip it with another function (&lt;code&gt;unzip()&lt;/code&gt;), which requires the name of the file and the name of the folder, where we want to unzip it. Finally, the &lt;code&gt;URLencode()&lt;/code&gt; function encodes an &lt;em&gt;URL&lt;/em&gt; address that contains special characters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create a temporary file
temp &amp;lt;- tempfile()

# download the data
download.file(URLencode(val_link), temp)

# unzip to a folder called buildings
unzip(temp, exdir = &amp;quot;buildings_valencia&amp;quot;) # change the name according to the city&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;import-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Import the data&lt;/h2&gt;
&lt;p&gt;To import the data we use the &lt;code&gt;dir_ls()&lt;/code&gt; function of the &lt;code&gt;fs&lt;/code&gt; package, which can obtain the files and folders of a specific path while filtering through a text pattern (&lt;em&gt;regexp &lt;/em&gt;: regular expression). We apply the &lt;code&gt;st_read()&lt;/code&gt; function of the &lt;code&gt;sf&lt;/code&gt; package to the &lt;em&gt;Geography Markup Language&lt;/em&gt; (GML) file.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get the path with the file
file_val &amp;lt;- dir_ls(&amp;quot;buildings_valencia&amp;quot;, regexp = &amp;quot;building.gml&amp;quot;) # change the folder if needed

# import the data
buildings_val &amp;lt;- st_read(file_val)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Reading layer `Building&amp;#39; from data source 
##   `E:\GitHub\blog_update_2021\content\en\post\2019-11-01-visualize-urban-growth\buildings_valencia\A.ES.SDGC.BU.46900.building.gml&amp;#39; 
##   using driver `GML&amp;#39;
## Simple feature collection with 36284 features and 24 fields
## Geometry type: MULTIPOLYGON
## Dimension:     XY
## Bounding box:  xmin: 720570.9 ymin: 4351286 xmax: 734981.9 ymax: 4382906
## Projected CRS: ETRS89 / UTM zone 30N&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data-preparation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data preparation&lt;/h2&gt;
&lt;p&gt;We only have to convert the column of the construction year (beginning) into a &lt;code&gt;Date&lt;/code&gt; class. The date column contains some dates in &lt;code&gt;--01-01&lt;/code&gt; format, which does not correspond to any recognizable date. Therefore, we replace the first &lt;code&gt;-&lt;/code&gt; with &lt;code&gt;0000&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;buildings_val &amp;lt;- mutate(buildings_val, 
               beginning = str_replace(beginning, &amp;quot;^-&amp;quot;, &amp;quot;0000&amp;quot;) %&amp;gt;% 
                            ymd_hms() %&amp;gt;% as_date()
               )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: 4 failed to parse.&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;distribution-chart&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Distribution chart&lt;/h2&gt;
&lt;p&gt;Before creating the maps of the construction years, which will reflect urban growth, we will make a graph of distribution of the beginning variable. We can clearly identify periods of urban expansion. We will use the &lt;code&gt;ggplot2&lt;/code&gt; package with the geometry of &lt;code&gt;geom_density()&lt;/code&gt; for this purpose. The &lt;code&gt;font_add_google()&lt;/code&gt; function of the &lt;code&gt;sysfonts&lt;/code&gt; package allows us to download and include font families from Google.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#font download
sysfonts::font_add_google(&amp;quot;Montserrat&amp;quot;, &amp;quot;Montserrat&amp;quot;)

#use showtext for fonts
showtext::showtext_auto() &lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# limit the period after 1750
filter(buildings_val, beginning &amp;gt;= &amp;quot;1750-01-01&amp;quot;) %&amp;gt;%
 ggplot(aes(beginning)) + 
    geom_density(fill = &amp;quot;#2166ac&amp;quot;, alpha = 0.7) +
  scale_x_date(date_breaks = &amp;quot;20 year&amp;quot;, 
               date_labels = &amp;quot;%Y&amp;quot;) +
  theme_minimal(base_family = &amp;quot;Montserrat&amp;quot;) +
  labs(y = &amp;quot;&amp;quot;,x = &amp;quot;&amp;quot;, title = &amp;quot;Evolution of urban development&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-urban-growth/index.en_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;buffer-of-25-km-for-valencia&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Buffer of 2,5 km for Valencia&lt;/h2&gt;
&lt;p&gt;To visualize better the distribution of urban growth, we limit the map to a radius of 2.5 km from the city center. Therefore, we use the &lt;code&gt;geocode_OSM()&lt;/code&gt; function of the &lt;code&gt;tmaptools&lt;/code&gt; package to obtain the coordinates of Valencia in class &lt;code&gt;sf&lt;/code&gt;. Then we project the points to the system we use for the buildings (EPSG: 25830). The &lt;code&gt;st_crs()&lt;/code&gt; function returns the coordinate system of a spatial object &lt;code&gt;sf&lt;/code&gt;. Finally, we create with the function &lt;code&gt;st_buffer()&lt;/code&gt; a buffer with 2500 m and the intersection with our building data. It is also possible to create a buffer in the form of a rectangle indicating the style with the argument &lt;code&gt;endCapStyle =&#34; SQUARE &#34;&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get the coordinates of Valencia
ciudad_point &amp;lt;- tmaptools::geocode_OSM(&amp;quot;Valencia&amp;quot;, 
                                      as.sf = TRUE)

#  project the points
ciudad_point &amp;lt;- st_transform(ciudad_point, st_crs(buildings_val))

# create the buffer
point_bf &amp;lt;- st_buffer(ciudad_point, 2500) # radius of 2500 m


# get the intersection between the buffer and the building
buildings_val25 &amp;lt;- st_intersection(buildings_val, point_bf)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: attribute variables are assumed to be spatially constant throughout all
## geometries&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;prepare-data-for-mapping&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Prepare data for mapping&lt;/h2&gt;
&lt;p&gt;We categorize the year into 15 groups using quartiles. It is also possible to modify the number of classes or the applied method (eg jenks, fisher, etc), you can find more details in the help &lt;code&gt;?classIntervals&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# find 15 classes
br &amp;lt;- classIntervals(year(buildings_val25$beginning), 15, &amp;quot;quantile&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in classIntervals(year(buildings_val25$beginning), 15, &amp;quot;quantile&amp;quot;): var
## has missing values, omitted in finding classes&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create labels
lab &amp;lt;- names(print(br, under = &amp;quot;&amp;lt;&amp;quot;, over = &amp;quot;&amp;gt;&amp;quot;, cutlabels = FALSE))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## style: quantile
##      &amp;lt; 1890 1890 - 1912 1912 - 1925 1925 - 1930 1930 - 1940 1940 - 1950 
##         932        1350         947         594        1703        1054 
## 1950 - 1958 1958 - 1962 1962 - 1966 1966 - 1970 1970 - 1973 1973 - 1978 
##        1453        1029        1223        1158        1155        1190 
## 1978 - 1988 1988 - 1999      &amp;gt; 1999 
##        1149        1111        1244&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# categorize the year
buildings_val25 &amp;lt;- mutate(buildings_val25, 
                          yr_cl = cut(year(beginning), 
                                       br$brks, 
                                       labels = lab, 
                                       include.lowest = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;map-of-valencia&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Map of Valencia&lt;/h2&gt;
&lt;p&gt;For the mapping, we will use the &lt;code&gt;tmap&lt;/code&gt; package. It is an interesting alternative to &lt;code&gt;ggplot2&lt;/code&gt;. It is a package of functions specialized in creating thematic maps. The philosophy of the package follows the same as in &lt;code&gt;ggplot2&lt;/code&gt;, creating multiple layers with different functions, which always start with &lt;code&gt;tm_ *&lt;/code&gt;and combine with &lt;code&gt;+&lt;/code&gt;. Building a map with &lt;em&gt;tmap&lt;/em&gt; always starts with &lt;em&gt;tm_shape()&lt;/em&gt;, where the data, we want to draw, is defined. Then we add the corresponding geometry to the data type (&lt;code&gt;tm_polygon()&lt;/code&gt;, &lt;code&gt;tm_border()&lt;/code&gt;, &lt;code&gt;tm_dots()&lt;/code&gt; or even &lt;code&gt;tm_raster()&lt;/code&gt;). The &lt;code&gt;tm_layout()&lt;/code&gt; function help us to configure the map style.&lt;/p&gt;
&lt;p&gt;When we need more colors than the maximum allowed by &lt;code&gt;RColorBrewer&lt;/code&gt;, we can pass the colors to the &lt;code&gt;colorRampPalette()&lt;/code&gt; function. This function interpolates a set of given colors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# colours
col_spec &amp;lt;- RColorBrewer::brewer.pal(11, &amp;quot;Spectral&amp;quot;)

# colour ramp function
col_spec_fun &amp;lt;- colorRampPalette(col_spec)


# create the final map
tm_shape(buildings_val25) +
  tm_polygons(&amp;quot;yr_cl&amp;quot;, 
              border.col = &amp;quot;transparent&amp;quot;,
              palette = col_spec_fun(15), # adapt to the number of classes
              textNA = &amp;quot;Without data&amp;quot;,
              title = &amp;quot;&amp;quot;) +
 tm_layout(bg.color = &amp;quot;black&amp;quot;,
           outer.bg.color = &amp;quot;black&amp;quot;,
           legend.outside = TRUE,
           legend.text.color = &amp;quot;white&amp;quot;,
           legend.text.fontfamily = &amp;quot;Montserrat&amp;quot;, 
            panel.label.fontfamily = &amp;quot;Montserrat&amp;quot;,
            panel.label.color = &amp;quot;white&amp;quot;,
            panel.label.bg.color = &amp;quot;black&amp;quot;,
            panel.label.size = 5,
            panel.label.fontface = &amp;quot;bold&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-urban-growth/index.en_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can export our map using the function &lt;code&gt;tmap_save(&#34;name.png&#34;, dpi = 300)&lt;/code&gt;. I recommend using the &lt;code&gt;dpi = 300&lt;/code&gt; argument for a good image quality.&lt;/p&gt;
&lt;p&gt;An alternative way to the &lt;code&gt;tmap&lt;/code&gt; package is &lt;code&gt;ggplot2&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create the final map
ggplot(buildings_val25) +
     geom_sf(aes(fill = yr_cl), colour = &amp;quot;transparent&amp;quot;) +
  scale_fill_manual(values = col_spec_fun(15)) + # adapt to the number of classes
    labs(title = &amp;quot;VALÈNCIA&amp;quot;, fill = &amp;quot;&amp;quot;) +
  guides(fill = guide_legend(keywidth = .7, keyheight = 2.7)) +
theme_void(base_family = &amp;quot;Montserrat&amp;quot;) +
theme(panel.background = element_rect(fill = &amp;quot;black&amp;quot;),
      plot.background = element_rect(fill = &amp;quot;black&amp;quot;),
      legend.justification = .5,
      legend.text = element_text(colour = &amp;quot;white&amp;quot;, size = 12),
      plot.title = element_text(colour = &amp;quot;white&amp;quot;, hjust = .5, size = 60,
      margin = margin(t = 30)),
      plot.caption = element_text(colour = &amp;quot;white&amp;quot;,
      margin = margin(b = 20), hjust = .5, size = 16),
      plot.margin = margin(r = 40, l = 40))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-urban-growth/index.en_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;1536&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To export the result of ggplot we can use the function &lt;code&gt;ggsave(&#34;name.png&#34;)&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;dynamic-map-with-leaflet&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Dynamic map with leaflet&lt;/h2&gt;
&lt;p&gt;A very interesting advantage is the &lt;code&gt;tmap_leaflet()&lt;/code&gt; function of the &lt;code&gt;tmap&lt;/code&gt; package to easily pass a map created in the same frame to &lt;code&gt;leaflet&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# tmap object
m &amp;lt;-   tm_shape(buildings_val25) +
          tm_polygons(&amp;quot;yr_cl&amp;quot;, 
              border.col = &amp;quot;transparent&amp;quot;,
              palette = col_spec_fun(15), # adapt to the number of classes
              textNA = &amp;quot;Without data&amp;quot;,
              title = &amp;quot;&amp;quot;)


# dynamic map
tmap_leaflet(m)&lt;/code&gt;&lt;/pre&gt;
&lt;iframe src=&#34;https://dominicroye.github.io/files/urban_growth_leaflet.html&#34; width=&#34;672&#34; height=&#34;500px&#34; data-external=&#34;1&#34;&gt;
&lt;/iframe&gt;
&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/drxeo&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;41&#34; width=&#34;174&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Visualize monthly precipitation anomalies</title>
      <link>https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/</link>
      <pubDate>Sun, 07 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Normally when we visualize monthly precipitation anomalies, we simply use a bar graph indicating negative and positive values with red and blue. However, it does not explain the general context of these anomalies. For example, what was the highest or lowest anomaly in each month? In principle, we could use a &lt;em&gt;boxplot&lt;/em&gt; to visualize the distribution of the anomalies, but in this particular case they would not fit aesthetically, so we should look for an alternative. Here I present a very useful graphic form.&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Packages&lt;/h2&gt;
&lt;p&gt;In this post we will use the following packages:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;10%&#34; /&gt;
&lt;col width=&#34;89%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Package&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;readr&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Import data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ggthemes&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Themes for ggplot2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lubridate&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Easy manipulation of dates and times&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;cowplot&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Easy creation of multiple graphics with ggplot2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#we install the packages if necessary
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;ggthemes&amp;quot;)) install.packages(&amp;quot;broom&amp;quot;)
if(!require(&amp;quot;cowplot&amp;quot;)) install.packages(&amp;quot;cowplot&amp;quot;)
if(!require(&amp;quot;lubridate&amp;quot;)) install.packages(&amp;quot;lubridate&amp;quot;)

#packages
library(tidyverse) #include readr
library(ggthemes)
library(cowplot)
library(lubridate)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;preparing-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Preparing the data&lt;/h2&gt;
&lt;p&gt;First we import the daily precipitation of the selected weather station (&lt;a href=&#34;https://dominicroye.github.io/files/RR_STAID001394.txt&#34;&gt;download&lt;/a&gt;). We will use data from Santiago de Compostela (Spain) accessible through &lt;a href=&#34;https://eca.knmi.nl&#34;&gt;ECA&amp;amp;D&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;step-1-import-the-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Step 1: import the data&lt;/h3&gt;
&lt;p&gt;We not only import the data in &lt;em&gt;csv&lt;/em&gt; format, but we also make the first changes. We skip the first 21 rows that contain information about the weather station. In addition, we convert the date to the &lt;code&gt;date&lt;/code&gt; class and replace missing values (-9999) with &lt;code&gt;NA&lt;/code&gt;. The precipitation is given in 0.1 mm, therefore, we must divide the values by 10. Then we select the columns &lt;em&gt;DATE&lt;/em&gt; and &lt;em&gt;RR&lt;/em&gt;, and rename them.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- read_csv(&amp;quot;RR_STAID001394.txt&amp;quot;, skip = 21) %&amp;gt;%
             mutate(DATE = ymd(DATE), RR = ifelse(RR == -9999, NA, RR/10)) %&amp;gt;%
               select(DATE:RR) %&amp;gt;% 
             rename(date = DATE, pr = RR)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 27606 Columns: 5
## -- Column specification --------------------------------------------------------
## Delimiter: &amp;quot;,&amp;quot;
## dbl (5): STAID, SOUID, DATE, RR, Q_RR
## 
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 27,606 x 2
##    date          pr
##    &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt;
##  1 1943-11-01   0.6
##  2 1943-11-02   0  
##  3 1943-11-03   0  
##  4 1943-11-04   0  
##  5 1943-11-05   0  
##  6 1943-11-06   0  
##  7 1943-11-07   0  
##  8 1943-11-08   0  
##  9 1943-11-09   0  
## 10 1943-11-10   0  
## # ... with 27,596 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-2-creating-monthly-values&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Step 2: creating monthly values&lt;/h3&gt;
&lt;p&gt;In the second step we calculate the monthly amounts of precipitation. To do this, a) we limit the period to the years after 1950, b) we add the month with its labels and the year as variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- mutate(data, mo = month(date, label = TRUE), yr = year(date)) %&amp;gt;%
            filter(date &amp;gt;= &amp;quot;1950-01-01&amp;quot;) %&amp;gt;%
                group_by(yr, mo) %&amp;gt;% 
                   summarise(prs = sum(pr, na.rm = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;yr&amp;#39;. You can override using the `.groups`
## argument.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 833 x 3
## # Groups:   yr [70]
##       yr mo      prs
##    &amp;lt;dbl&amp;gt; &amp;lt;ord&amp;gt; &amp;lt;dbl&amp;gt;
##  1  1950 Jan    55.6
##  2  1950 Feb   349. 
##  3  1950 Mar    85.8
##  4  1950 Apr    33.4
##  5  1950 May   272. 
##  6  1950 Jun   111. 
##  7  1950 Jul    35.4
##  8  1950 Aug    76.4
##  9  1950 Sep    85  
## 10  1950 Oct    53  
## # ... with 823 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-3-estimating-anomalies&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Step 3: estimating anomalies&lt;/h3&gt;
&lt;p&gt;Now we must estimate the normals of each month and join this table to our main data in order to calculate the monthly anomaly. We express the anomalies in percentage and subtract 100 to set the average to 0. In addition, we create a variable which indicates if the anomaly is negative or positive, and another with the date.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pr_ref &amp;lt;- filter(data, yr &amp;gt; 1981, yr &amp;lt;= 2010) %&amp;gt;%
                   group_by(mo) %&amp;gt;%
                      summarise(pr_ref = mean(prs))

data &amp;lt;- left_join(data, pr_ref, by = &amp;quot;mo&amp;quot;)

data &amp;lt;- mutate(data, 
               anom = (prs*100/pr_ref)-100, 
               date = str_c(yr, as.numeric(mo), 1, sep = &amp;quot;-&amp;quot;) %&amp;gt;% ymd(),
               sign= ifelse(anom &amp;gt; 0, &amp;quot;pos&amp;quot;, &amp;quot;neg&amp;quot;) %&amp;gt;% factor(c(&amp;quot;pos&amp;quot;, &amp;quot;neg&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can do a first test graph of anomalies (the classic one), for that we filter the year 2018. In this case we use a bar graph, remember that by default the function &lt;code&gt;geom_bar()&lt;/code&gt; applies the counting of the variable. However, in this case we know &lt;code&gt;y&lt;/code&gt;, hence we indicate with the argument &lt;code&gt;stat = &#34;identity&#34;&lt;/code&gt; that it should use the given value in &lt;code&gt;aes()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(data, yr == 2018) %&amp;gt;%
   ggplot(aes(date, anom, fill = sign)) + 
       geom_bar(stat = &amp;quot;identity&amp;quot;, show.legend = FALSE) + 
    scale_x_date(date_breaks = &amp;quot;month&amp;quot;, date_labels = &amp;quot;%b&amp;quot;) +
    scale_y_continuous(breaks = seq(-100, 100, 20)) +
    scale_fill_manual(values = c(&amp;quot;#99000d&amp;quot;, &amp;quot;#034e7b&amp;quot;)) +
         labs(y = &amp;quot;Precipitation anomaly (%)&amp;quot;, x = &amp;quot;&amp;quot;) +
          theme_hc()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-4-calculating-the-statistical-metrics&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Step 4: calculating the statistical metrics&lt;/h3&gt;
&lt;p&gt;In this last step we estimate the maximum, minimum value, the 25%/75% quantiles and the interquartile range per month of the entire time series.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_norm &amp;lt;-     group_by(data, mo) %&amp;gt;%
                     summarise(mx = max(anom),
                               min = min(anom),
                               q25 = quantile(anom, .25),
                               q75 = quantile(anom, .75),
                               iqr = q75-q25)
data_norm&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 12 x 6
##    mo       mx    min   q25   q75   iqr
##    &amp;lt;ord&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 Jan    193.  -89.6 -43.6 56.3   99.9
##  2 Feb    320.  -96.5 -51.2 77.7  129. 
##  3 Mar    381. -100   -40.6 88.2  129. 
##  4 Apr    198.  -93.6 -51.2 17.1   68.3
##  5 May    141.  -90.1 -45.2 17.0   62.2
##  6 Jun    419.  -99.3 -58.2 50.0  108. 
##  7 Jul    311.  -98.2 -77.3 27.1  104. 
##  8 Aug    264. -100   -68.2 39.8  108. 
##  9 Sep    241.  -99.2 -64.9 48.6  113. 
## 10 Oct    220.  -99.0 -54.5  4.69  59.2
## 11 Nov    137.  -98.8 -44.0 39.7   83.7
## 12 Dec    245.  -91.8 -49.8 36.0   85.8&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-the-graph&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Creating the graph&lt;/h2&gt;
&lt;p&gt;To create the anomaly graph with legend it is necessary to separate the main graph from the legends.&lt;/p&gt;
&lt;div id=&#34;part-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Part 1&lt;/h3&gt;
&lt;p&gt;In this first part we are adding layer by layer the different elements: 1) the range of anomalies maximum-minimum 2) the interquartile range and 3) the anomalies of the year 2018.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#range of anomalies maximum-minimum
g1.1 &amp;lt;- ggplot(data_norm)+
           geom_crossbar(aes(x = mo, y = 0, ymin = min, ymax = mx),
                        fatten = 0, fill = &amp;quot;grey90&amp;quot;, colour = &amp;quot;NA&amp;quot;)

g1.1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#adding interquartile range
g1.2 &amp;lt;- g1.1 + geom_crossbar(aes(x = mo, y = 0, ymin = q25, ymax = q75),
                              fatten = 0, fill = &amp;quot;grey70&amp;quot;)

g1.2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-9-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#adding anomalies of the year 2018 

g1.3 &amp;lt;- g1.2 + geom_crossbar(data = filter(data, yr == 2018),
                aes(x = mo, y = 0, ymin = 0, ymax = anom, fill = sign),
                fatten = 0, width = 0.7, alpha = .7, colour = &amp;quot;NA&amp;quot;,
                show.legend = FALSE)
g1.3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-9-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Finally we change some last style settings.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;g1 &amp;lt;- g1.3 + geom_hline(yintercept = 0)+
               scale_fill_manual(values=c(&amp;quot;#99000d&amp;quot;,&amp;quot;#034e7b&amp;quot;))+
               scale_y_continuous(&amp;quot;Precipitation anomaly (%)&amp;quot;,
                                   breaks = seq(-100, 500, 25),
                                   expand = c(0, 5))+
            labs(x = &amp;quot;&amp;quot;,
                 title = &amp;quot;Precipitation anomaly in Santiago de Compostela 2018&amp;quot;,
                 caption=&amp;quot;Dominic Royé (@dr_xeo) | Data: eca.knmi.nl&amp;quot;)+
            theme_hc()
g1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;part-2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Part 2&lt;/h3&gt;
&lt;p&gt;We still need a legend. First we create it for the normals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#legend data
legend &amp;lt;- filter(data_norm, mo == &amp;quot;Jan&amp;quot;)

legend_lab &amp;lt;- gather(legend, stat, y, mx:q75) %&amp;gt;%
                 mutate(stat = factor(stat, stat, c(&amp;quot;maximum&amp;quot;,
                                                   &amp;quot;minimum&amp;quot;,
                                                   &amp;quot;Quantile 25%&amp;quot;,
                                                   &amp;quot;Quantile 75%&amp;quot;)) %&amp;gt;%
                                            as.character())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: attributes are not identical across measure variables;
## they will be dropped&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#legend graph
g2 &amp;lt;- legend %&amp;gt;% ggplot()+
                  geom_crossbar(aes(x = mo, y = 0, ymin = min, ymax = mx),
                                fatten = 0, fill = &amp;quot;grey90&amp;quot;, colour = &amp;quot;NA&amp;quot;, width = 0.2) +
                  geom_crossbar(aes(x = mo, y = 0, ymin = q25, ymax = q75),
                                fatten = 0, fill = &amp;quot;grey70&amp;quot;, width = 0.2) +
                  geom_text(data = legend_lab, 
                            aes(x = mo, y = y+c(12,-8,-10,12), label = stat), 
                            fontface = &amp;quot;bold&amp;quot;, size = 2) +
                   annotate(&amp;quot;text&amp;quot;, x = 1.18, y = 40, 
                            label = &amp;quot;Period 1950-2018&amp;quot;, angle = 90, size = 3) +
              theme_void() + 
                theme(plot.margin = unit(c(0, 0, 0, 0), &amp;quot;cm&amp;quot;))

g2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Second, we create another legend for the current anomalies.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#legend data
legend2 &amp;lt;- filter(data, yr == 1950, mo %in% c(&amp;quot;Jan&amp;quot;,&amp;quot;Feb&amp;quot;)) %&amp;gt;% 
              ungroup() %&amp;gt;% 
            select(mo, anom, sign)

legend2[2,1] &amp;lt;- &amp;quot;Jan&amp;quot;

legend_lab2 &amp;lt;- data.frame(mo = rep(&amp;quot;Jan&amp;quot;, 3), 
                          anom= c(110, 3, -70), 
                          label = c(&amp;quot;Positive anomaly&amp;quot;, &amp;quot;Average&amp;quot;, &amp;quot;Negative anomaly&amp;quot;))

#legend graph
g3 &amp;lt;-  ggplot() + 
         geom_bar(data = legend2,
                aes(x = mo, y = anom, fill = sign),
                   alpha = .6, colour = &amp;quot;NA&amp;quot;, stat = &amp;quot;identity&amp;quot;, show.legend = FALSE, width = 0.2) +
         geom_segment(aes(x = .85, y = 0, xend = 1.15, yend = 0), linetype = &amp;quot;dashed&amp;quot;) +
         geom_text(data = legend_lab2, 
                   aes(x = mo, y = anom+c(10,5,-13), label = label), 
                   fontface = &amp;quot;bold&amp;quot;, size = 2) +
         annotate(&amp;quot;text&amp;quot;, x = 1.25, y = 20, 
                  label =&amp;quot;Reference 1971-2010&amp;quot;, angle = 90, size = 3) +
         scale_fill_manual(values = c(&amp;quot;#99000d&amp;quot;, &amp;quot;#034e7b&amp;quot;)) +
        theme_void() +
         theme(plot.margin = unit(c(0, 0, 0, 0), &amp;quot;cm&amp;quot;))

g3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;part-3&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Part 3&lt;/h3&gt;
&lt;p&gt;Finally, we only have to join the graph and the legends with the help of the &lt;code&gt;cowplot&lt;/code&gt; package. The main function of &lt;code&gt;cowplot&lt;/code&gt; is &lt;code&gt;plot_grid()&lt;/code&gt; which is used for combining different graphs. However, in this case it is necessary to use more flexible functions to create less common formats. The &lt;code&gt;ggdraw()&lt;/code&gt; function configures the basic layer of the graph, and the functions that are intended to operate on this layer start with &lt;code&gt;draw_*&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- ggdraw() +
       draw_plot(g1, x = 0, y = .3, width = 1, height = 0.6) +
       draw_plot(g2, x = 0, y = .15, width = .2, height = .15) +
       draw_plot(g3, x = 0.08, y = .15, width = .2, height = .15)

p&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;3729&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;save_plot(&amp;quot;pr_anomaly2016_scq.png&amp;quot;, p, dpi = 300, base_width = 12.43, base_height = 8.42)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;multiple-facets&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Multiple facets&lt;/h2&gt;
&lt;p&gt;In this section we will make the same graph as in the previous one, but for several years.&lt;/p&gt;
&lt;div id=&#34;part-1-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Part 1&lt;/h3&gt;
&lt;p&gt;First we need to filter again by set of years, in this case from 2016 to 2018, using the operator &lt;code&gt;%in%&lt;/code&gt;, we also add the function &lt;code&gt;facet_grid()&lt;/code&gt; to &lt;code&gt;ggplot&lt;/code&gt;, which allows us to plot the graph according to a variable. The formula used for the facet function is similar to the use in models: &lt;code&gt;variable_by_row ~ variable_by_column&lt;/code&gt;. When we do not have a variable in the column, we should use the &lt;code&gt;.&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#range of anomalies maximum-minimum
g1.1 &amp;lt;- ggplot(data_norm)+
           geom_crossbar(aes(x = mo, y = 0, ymin = min, ymax = mx),
                        fatten = 0, fill = &amp;quot;grey90&amp;quot;, colour = &amp;quot;NA&amp;quot;)

g1.1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#adding the interquartile range
g1.2 &amp;lt;- g1.1 + geom_crossbar(aes(x = mo, y = 0, ymin = q25, ymax = q75),
                              fatten = 0, fill = &amp;quot;grey70&amp;quot;)

g1.2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-14-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#adding the anomalies of the year 2016-2018

g1.3 &amp;lt;- g1.2 + geom_crossbar(data = filter(data, yr %in% 2016:2018),
                aes(x = mo, y = 0, ymin = 0, ymax = anom, fill = sign),
                fatten = 0, width = 0.7, alpha = .7, colour = &amp;quot;NA&amp;quot;,
                show.legend = FALSE) +
               facet_grid(yr ~ .)
g1.3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-14-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Finally we change some last style settings.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;g1 &amp;lt;- g1.3 + geom_hline(yintercept = 0)+
               scale_fill_manual(values=c(&amp;quot;#99000d&amp;quot;,&amp;quot;#034e7b&amp;quot;))+
               scale_y_continuous(&amp;quot;Anomalía de precipitación (%)&amp;quot;,
                                   breaks = seq(-100, 500, 50),
                                   expand = c(0, 5))+
            labs(x = &amp;quot;&amp;quot;,
                 title = &amp;quot;Anomalía de precipitación en Santiago de Compostela&amp;quot;,
                 caption=&amp;quot;Dominic Royé (@dr_xeo) | Datos: eca.knmi.nl&amp;quot;)+
            theme_hc()
g1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;3729&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We use the same legend created for the previous graph.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;part-2-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part 2&lt;/h2&gt;
&lt;p&gt;Finally, we join the graph and the legends with the help of the &lt;code&gt;cowplot&lt;/code&gt; package. The only thing we must adjust here are the arguments in the &lt;code&gt;draw_plot()&lt;/code&gt; function to correctly place the different parts.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- ggdraw() +
       draw_plot(g1, x = 0, y = .18, width = 1, height = 0.8) +
       draw_plot(g2, x = 0, y = .08, width = .2, height = .15) +
       draw_plot(g3, x = 0.08, y = .08, width = .2, height = .15)

p&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;3729&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;save_plot(&amp;quot;pr_anomaly20162018_scq.png&amp;quot;, p, dpi = 300, base_width = 12.43, base_height = 8.42)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/drxeo&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;41&#34; width=&#34;174&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Tidy correlation tests in R</title>
      <link>https://dominicroye.github.io/en/2019/tidy-correlation-tests-in-r/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://dominicroye.github.io/en/2019/tidy-correlation-tests-in-r/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2019/tidy-correlation-tests-in-r/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;When we try to estimate the correlation coefficient between multiple variables, the task is more complicated in order to obtain a simple and tidy result. A simple solution is to use the &lt;code&gt;tidy()&lt;/code&gt; function from the &lt;em&gt;{broom}&lt;/em&gt; package. In this post we are going to estimate the correlation coefficients between the annual precipitation of several Spanish cities and climate teleconnections indices: &lt;a href=&#34;https://dominicroye.github.io/files/teleconnections_indices.zip&#34;&gt;download&lt;/a&gt;. The data of the teleconnections are preprocessed, but can be downloaded directly from &lt;a href=&#34;https://crudata.uea.ac.uk/cru/data/pci.htm&#34;&gt;crudata.uea.ac.uk&lt;/a&gt;. The daily precipitation data comes from &lt;a href=&#34;https://www.ecad.eu//dailydata/index.php&#34;&gt;ECA&amp;amp;D&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Packages&lt;/h2&gt;
&lt;p&gt;In this post we will use the following packages:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;10%&#34; /&gt;
&lt;col width=&#34;89%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Package&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;broom&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Convert results of statistical functions (lm, t.test, cor.test, etc.) into tidy tables&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;fs&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Provides a cross-platform, uniform interface to file system operations&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lubridate&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Easy manipulation of dates and times&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install the packages if necessary
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;broom&amp;quot;)) install.packages(&amp;quot;broom&amp;quot;)
if(!require(&amp;quot;fs&amp;quot;)) install.packages(&amp;quot;fs&amp;quot;)
if(!require(&amp;quot;lubridate&amp;quot;)) install.packages(&amp;quot;lubridate&amp;quot;)

#load packages
library(tidyverse)
library(broom)
library(fs)
library(lubridate)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;import-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Import data&lt;/h2&gt;
&lt;p&gt;First we have to import the daily precipitation of the selected weather stations.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Create a vector with all precipitation files using the function &lt;code&gt;dir_ls()&lt;/code&gt; of the &lt;em&gt;{fs}&lt;/em&gt; package.&lt;/li&gt;
&lt;li&gt;Import the data using the &lt;code&gt;map_df()&lt;/code&gt; function of the &lt;em&gt;{purrr}&lt;/em&gt; package that applies another function to a vector or list, and joins them together in a single &lt;em&gt;data.frame&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;Select the columns that interest us, b) Convert the date string into a date object using the &lt;code&gt;ymd()&lt;/code&gt; function of the &lt;em&gt;{lubridate}&lt;/em&gt; package, c) Create a new column &lt;em&gt;yr&lt;/em&gt; with the years, d) Divide the precipitation values by 10 and reclassify absent values -9999 by NA, e) Finally, reclassify the ID of each weather station creating a factor with new labels.&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;More details about the use of the &lt;code&gt;dir_ls()&lt;/code&gt; and &lt;code&gt;map_df()&lt;/code&gt; functions can be found in this previous &lt;a href=&#34;https://dominicroye.github.io/en/2019/import-excel-sheets-%20with-r%20/&#34;&gt;post&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#precipitation files
files &amp;lt;- dir_ls(regexp = &amp;quot;txt&amp;quot;)
files&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## RR_STAID001393.txt RR_STAID001394.txt RR_STAID002969.txt RR_STAID003946.txt 
## RR_STAID003969.txt&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#import all files and join them together
pr &amp;lt;- files %&amp;gt;% map_df(read_csv, skip = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 26329 Columns: 5
## -- Column specification --------------------------------------------------------
## Delimiter: &amp;quot;,&amp;quot;
## dbl (5): STAID, SOUID, DATE, RR, Q_RR
## 
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.
## Rows: 27545 Columns: 5
## -- Column specification --------------------------------------------------------
## Delimiter: &amp;quot;,&amp;quot;
## dbl (5): STAID, SOUID, DATE, RR, Q_RR
## 
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.
## Rows: 34729 Columns: 5
## -- Column specification --------------------------------------------------------
## Delimiter: &amp;quot;,&amp;quot;
## dbl (5): STAID, SOUID, DATE, RR, Q_RR
## 
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.
## Rows: 24927 Columns: 5
## -- Column specification --------------------------------------------------------
## Delimiter: &amp;quot;,&amp;quot;
## dbl (5): STAID, SOUID, DATE, RR, Q_RR
## 
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.
## Rows: 19813 Columns: 5
## -- Column specification --------------------------------------------------------
## Delimiter: &amp;quot;,&amp;quot;
## dbl (5): STAID, SOUID, DATE, RR, Q_RR
## 
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pr&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 133,343 x 5
##    STAID SOUID     DATE    RR  Q_RR
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1  1393 20611 19470301     0     0
##  2  1393 20611 19470302     5     0
##  3  1393 20611 19470303     0     0
##  4  1393 20611 19470304    33     0
##  5  1393 20611 19470305    15     0
##  6  1393 20611 19470306     0     0
##  7  1393 20611 19470307    85     0
##  8  1393 20611 19470308     3     0
##  9  1393 20611 19470309     0     0
## 10  1393 20611 19470310     0     0
## # ... with 133,333 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#create levels for the factor 
id &amp;lt;- unique(pr$STAID)

#the corresponding labels
lab &amp;lt;- c(&amp;quot;Bilbao&amp;quot;, &amp;quot;Santiago&amp;quot;, &amp;quot;Barcelona&amp;quot;, &amp;quot;Madrid&amp;quot;, &amp;quot;Valencia&amp;quot;)

#first changes
pr &amp;lt;- select(pr, STAID, DATE, RR) %&amp;gt;% 
        mutate(DATE = ymd(DATE), 
               RR = ifelse(RR == -9999, NA, RR/10), 
               STAID = factor(STAID, id, lab), 
               yr = year(DATE)) 
pr&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 133,343 x 4
##    STAID  DATE          RR    yr
##    &amp;lt;fct&amp;gt;  &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 Bilbao 1947-03-01   0    1947
##  2 Bilbao 1947-03-02   0.5  1947
##  3 Bilbao 1947-03-03   0    1947
##  4 Bilbao 1947-03-04   3.3  1947
##  5 Bilbao 1947-03-05   1.5  1947
##  6 Bilbao 1947-03-06   0    1947
##  7 Bilbao 1947-03-07   8.5  1947
##  8 Bilbao 1947-03-08   0.3  1947
##  9 Bilbao 1947-03-09   0    1947
## 10 Bilbao 1947-03-10   0    1947
## # ... with 133,333 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We still need to filter and calculate the annual amount of precipitation. Actually, it is not correct to sum up precipitation without taking into account that there are missing values, but it should be enough for this practice. Then, we change the table format with the &lt;code&gt;spread()&lt;/code&gt; function, passing from a long to a wide table, that is, we want to obtain one column per weather station.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pr_yr &amp;lt;- filter(pr, DATE &amp;gt;= &amp;quot;1950-01-01&amp;quot;, DATE &amp;lt; &amp;quot;2018-01-01&amp;quot;) %&amp;gt;%
           group_by(STAID, yr)%&amp;gt;%
             summarise(pr = sum(RR, na.rm = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;STAID&amp;#39;. You can override using the
## `.groups` argument.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pr_yr&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 324 x 3
## # Groups:   STAID [5]
##    STAID     yr    pr
##    &amp;lt;fct&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 Bilbao  1950 1342 
##  2 Bilbao  1951 1306.
##  3 Bilbao  1952 1355.
##  4 Bilbao  1953 1372.
##  5 Bilbao  1954 1428.
##  6 Bilbao  1955 1062.
##  7 Bilbao  1956 1254.
##  8 Bilbao  1957  968.
##  9 Bilbao  1958 1272.
## 10 Bilbao  1959 1450.
## # ... with 314 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pr_yr &amp;lt;- spread(pr_yr, STAID, pr)
pr_yr&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 68 x 6
##       yr Bilbao Santiago Barcelona Madrid Valencia
##    &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
##  1  1950  1342     1800.      345     NA        NA
##  2  1951  1306.    2344.     1072.   798.       NA
##  3  1952  1355.    1973.      415.   524.       NA
##  4  1953  1372.     973.      683.   365.       NA
##  5  1954  1428.    1348.      581.   246.       NA
##  6  1955  1062.    1769.      530.   473.       NA
##  7  1956  1254.    1533.      695.   480.       NA
##  8  1957   968.    1599.      635.   424.       NA
##  9  1958  1272.    2658.      479.   482.       NA
## 10  1959  1450.    2847.     1006    665.       NA
## # ... with 58 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The next step is to import the climate teleconnection indices.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#teleconnections
telecon &amp;lt;- read_csv(&amp;quot;teleconnections_indices.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 68 Columns: 9
## -- Column specification --------------------------------------------------------
## Delimiter: &amp;quot;,&amp;quot;
## dbl (9): yr, NAO, WeMO, EA, POL-EUAS, EATL/WRUS, MO, SCAND, AO
## 
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;telecon&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 68 x 9
##       yr   NAO   WeMO     EA `POL-EUAS` `EATL/WRUS`    MO    SCAND        AO
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
##  1  1950  0.49  0.555 -0.332     0.0217     -0.0567 0.335  0.301   -0.199   
##  2  1951 -0.07  0.379 -0.372     0.402      -0.419  0.149 -0.00667 -0.365   
##  3  1952 -0.37  0.693 -0.688    -0.0117     -0.711  0.282  0.0642  -0.675   
##  4  1953  0.4  -0.213 -0.727    -0.0567     -0.0508 0.216  0.0233  -0.0164  
##  5  1954  0.51  1.20  -0.912     0.142      -0.318  0.386  0.458   -0.000583
##  6  1955 -0.64  0.138 -0.824    -0.0267      0.154  0.134  0.0392  -0.362   
##  7  1956  0.17  0.617 -1.29     -0.197       0.0617 0.256  0.302   -0.163   
##  8  1957 -0.02  0.321 -0.952    -0.638      -0.167  0.322 -0.134   -0.342   
##  9  1958  0.12  0.941 -0.243     0.138       0.661  0.296  0.279   -0.868   
## 10  1959  0.49 -0.055 -0.23     -0.0142      0.631  0.316  0.725   -0.0762  
## # ... with 58 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally we need to join both tables by year.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_all &amp;lt;- left_join(pr_yr, telecon, by = &amp;quot;yr&amp;quot;)
data_all&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 68 x 14
##       yr Bilbao Santiago Barcelona Madrid Valencia   NAO   WeMO     EA
##    &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
##  1  1950  1342     1800.      345     NA        NA  0.49  0.555 -0.332
##  2  1951  1306.    2344.     1072.   798.       NA -0.07  0.379 -0.372
##  3  1952  1355.    1973.      415.   524.       NA -0.37  0.693 -0.688
##  4  1953  1372.     973.      683.   365.       NA  0.4  -0.213 -0.727
##  5  1954  1428.    1348.      581.   246.       NA  0.51  1.20  -0.912
##  6  1955  1062.    1769.      530.   473.       NA -0.64  0.138 -0.824
##  7  1956  1254.    1533.      695.   480.       NA  0.17  0.617 -1.29 
##  8  1957   968.    1599.      635.   424.       NA -0.02  0.321 -0.952
##  9  1958  1272.    2658.      479.   482.       NA  0.12  0.941 -0.243
## 10  1959  1450.    2847.     1006    665.       NA  0.49 -0.055 -0.23 
## # ... with 58 more rows, and 5 more variables: `POL-EUAS` &amp;lt;dbl&amp;gt;,
## #   `EATL/WRUS` &amp;lt;dbl&amp;gt;, MO &amp;lt;dbl&amp;gt;, SCAND &amp;lt;dbl&amp;gt;, AO &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;correlation-test&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Correlation test&lt;/h2&gt;
&lt;p&gt;A correlation test between paired samples can be done with the &lt;code&gt;cor.test()&lt;/code&gt; function of R Base. In this case between the annual precipitation of Bilbao and the NAO index.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor_nao_bil &amp;lt;- cor.test(data_all$Bilbao, data_all$NAO,
                        method = &amp;quot;spearman&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in cor.test.default(data_all$Bilbao, data_all$NAO, method = &amp;quot;spearman&amp;quot;):
## Cannot compute exact p-value with ties&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor_nao_bil&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Spearman&amp;#39;s rank correlation rho
## 
## data:  data_all$Bilbao and data_all$NAO
## S = 44372, p-value = 0.2126
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##       rho 
## 0.1531149&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(cor_nao_bil)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 8
##  $ statistic  : Named num 44372
##   ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##  $ parameter  : NULL
##  $ p.value    : num 0.213
##  $ estimate   : Named num 0.153
##   ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##  $ null.value : Named num 0
##   ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##  $ alternative: chr &amp;quot;two.sided&amp;quot;
##  $ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##  $ data.name  : chr &amp;quot;data_all$Bilbao and data_all$NAO&amp;quot;
##  - attr(*, &amp;quot;class&amp;quot;)= chr &amp;quot;htest&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that the result is in an unmanageable and untidy format. It is a console summary of the correlation with all the statistical parameters necessary to get a conclusion about the relationship. The orginal structure is a list of vectors. However, the &lt;code&gt;tidy()&lt;/code&gt; function of the &lt;em&gt;{broom}&lt;/em&gt; package allows us to convert the result into a table format.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy(cor_nao_bil)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 5
##   estimate statistic p.value method                          alternative
##      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;                           &amp;lt;chr&amp;gt;      
## 1    0.153    44372.   0.213 Spearman&amp;#39;s rank correlation rho two.sided&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;apply-the-correlation-test-to-multiple-variables&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Apply the correlation test to multiple variables&lt;/h2&gt;
&lt;p&gt;The objective is to apply the correlation test to all weather stations and climate teleconnection indices.&lt;/p&gt;
&lt;p&gt;First, we must pass the table to the long format, that is, create a column/variable for the city and for the value of the corresponding precipitation. Then we repeat the same for the teleconnections indices.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- gather(data_all, city, pr, Bilbao:Valencia)%&amp;gt;%
                     gather(telecon, index, NAO:AO)
data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2,720 x 5
##       yr city      pr telecon index
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt;
##  1  1950 Bilbao 1342  NAO      0.49
##  2  1951 Bilbao 1306. NAO     -0.07
##  3  1952 Bilbao 1355. NAO     -0.37
##  4  1953 Bilbao 1372. NAO      0.4 
##  5  1954 Bilbao 1428. NAO      0.51
##  6  1955 Bilbao 1062. NAO     -0.64
##  7  1956 Bilbao 1254. NAO      0.17
##  8  1957 Bilbao  968. NAO     -0.02
##  9  1958 Bilbao 1272. NAO      0.12
## 10  1959 Bilbao 1450. NAO      0.49
## # ... with 2,710 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To apply the test to all cities, we need the corresponding groupings. Therefore, we use the &lt;code&gt;group_by()&lt;/code&gt; function for indicating the two groups: &lt;em&gt;city&lt;/em&gt; and &lt;em&gt;telecon&lt;/em&gt;. In addition, we apply the &lt;code&gt;nest()&lt;/code&gt; function of the &lt;em&gt;{tidyr}&lt;/em&gt; package (&lt;em&gt;{tidyverse}&lt;/em&gt; collection) with the aim of creating lists of tables nested per row. In other words, in each row of each city and teleconnection index we will have a new table that contains the year, the precipitation value and the value of each teleconection, correspondingly.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_nest &amp;lt;- group_by(data, city, telecon) %&amp;gt;% nest()
head(data_nest)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 3
## # Groups:   city, telecon [6]
##   city      telecon data             
##   &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;   &amp;lt;list&amp;gt;           
## 1 Bilbao    NAO     &amp;lt;tibble [68 x 3]&amp;gt;
## 2 Santiago  NAO     &amp;lt;tibble [68 x 3]&amp;gt;
## 3 Barcelona NAO     &amp;lt;tibble [68 x 3]&amp;gt;
## 4 Madrid    NAO     &amp;lt;tibble [68 x 3]&amp;gt;
## 5 Valencia  NAO     &amp;lt;tibble [68 x 3]&amp;gt;
## 6 Bilbao    WeMO    &amp;lt;tibble [68 x 3]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(head(slice(data_nest, 1)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## grouped_df [6 x 3] (S3: grouped_df/tbl_df/tbl/data.frame)
##  $ city   : chr [1:6] &amp;quot;Barcelona&amp;quot; &amp;quot;Barcelona&amp;quot; &amp;quot;Barcelona&amp;quot; &amp;quot;Barcelona&amp;quot; ...
##  $ telecon: chr [1:6] &amp;quot;AO&amp;quot; &amp;quot;EA&amp;quot; &amp;quot;EATL/WRUS&amp;quot; &amp;quot;MO&amp;quot; ...
##  $ data   :List of 6
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] -0.199333 -0.364667 -0.674917 -0.016417 -0.000583 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] -0.333 -0.372 -0.688 -0.727 -0.912 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] -0.0567 -0.4192 -0.7108 -0.0508 -0.3175 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] 0.335 0.149 0.282 0.216 0.386 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] 0.49 -0.07 -0.37 0.4 0.51 -0.64 0.17 -0.02 0.12 0.49 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] 0.0217 0.4025 -0.0117 -0.0567 0.1425 ...
##  - attr(*, &amp;quot;groups&amp;quot;)= tibble [6 x 3] (S3: tbl_df/tbl/data.frame)
##   ..$ city   : chr [1:6] &amp;quot;Barcelona&amp;quot; &amp;quot;Barcelona&amp;quot; &amp;quot;Barcelona&amp;quot; &amp;quot;Barcelona&amp;quot; ...
##   ..$ telecon: chr [1:6] &amp;quot;AO&amp;quot; &amp;quot;EA&amp;quot; &amp;quot;EATL/WRUS&amp;quot; &amp;quot;MO&amp;quot; ...
##   ..$ .rows  : list&amp;lt;int&amp;gt; [1:6] 
##   .. ..$ : int 1
##   .. ..$ : int 2
##   .. ..$ : int 3
##   .. ..$ : int 4
##   .. ..$ : int 5
##   .. ..$ : int 6
##   .. ..@ ptype: int(0) 
##   ..- attr(*, &amp;quot;.drop&amp;quot;)= logi TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The next step is to create a function, in which we define the correlation test and pass it to the clean format using the &lt;code&gt;tidy()&lt;/code&gt; function, which we apply to each groupings.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor_fun &amp;lt;- function(df) cor.test(df$pr, df$index, method = &amp;quot;spearman&amp;quot;) %&amp;gt;% tidy()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we only have to apply our function to the column that contains the tables for each combination between city and teleconnection. To do this, we use the &lt;code&gt;map()&lt;/code&gt; function that applies another function to a vector or list. What we do is create a new column that contains the result, a statistical summary table, for each combination.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_nest &amp;lt;- mutate(data_nest, model = map(data, cor_fun))
head(data_nest)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 4
## # Groups:   city, telecon [6]
##   city      telecon data              model           
##   &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;   &amp;lt;list&amp;gt;            &amp;lt;list&amp;gt;          
## 1 Bilbao    NAO     &amp;lt;tibble [68 x 3]&amp;gt; &amp;lt;tibble [1 x 5]&amp;gt;
## 2 Santiago  NAO     &amp;lt;tibble [68 x 3]&amp;gt; &amp;lt;tibble [1 x 5]&amp;gt;
## 3 Barcelona NAO     &amp;lt;tibble [68 x 3]&amp;gt; &amp;lt;tibble [1 x 5]&amp;gt;
## 4 Madrid    NAO     &amp;lt;tibble [68 x 3]&amp;gt; &amp;lt;tibble [1 x 5]&amp;gt;
## 5 Valencia  NAO     &amp;lt;tibble [68 x 3]&amp;gt; &amp;lt;tibble [1 x 5]&amp;gt;
## 6 Bilbao    WeMO    &amp;lt;tibble [68 x 3]&amp;gt; &amp;lt;tibble [1 x 5]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(head(slice(data_nest, 1)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## grouped_df [6 x 4] (S3: grouped_df/tbl_df/tbl/data.frame)
##  $ city   : chr [1:6] &amp;quot;Barcelona&amp;quot; &amp;quot;Barcelona&amp;quot; &amp;quot;Barcelona&amp;quot; &amp;quot;Barcelona&amp;quot; ...
##  $ telecon: chr [1:6] &amp;quot;AO&amp;quot; &amp;quot;EA&amp;quot; &amp;quot;EATL/WRUS&amp;quot; &amp;quot;MO&amp;quot; ...
##  $ data   :List of 6
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] -0.199333 -0.364667 -0.674917 -0.016417 -0.000583 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] -0.333 -0.372 -0.688 -0.727 -0.912 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] -0.0567 -0.4192 -0.7108 -0.0508 -0.3175 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] 0.335 0.149 0.282 0.216 0.386 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] 0.49 -0.07 -0.37 0.4 0.51 -0.64 0.17 -0.02 0.12 0.49 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] 0.0217 0.4025 -0.0117 -0.0567 0.1425 ...
##  $ model  :List of 6
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num -0.00989
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 52912
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.936
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num -0.295
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 67832
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.0147
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num 0.161
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 43966
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.19
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num -0.255
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 65754
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.0361
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num -0.0203
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 53460
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.869
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num 0.178
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 43082
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.147
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##  - attr(*, &amp;quot;groups&amp;quot;)= tibble [6 x 3] (S3: tbl_df/tbl/data.frame)
##   ..$ city   : chr [1:6] &amp;quot;Barcelona&amp;quot; &amp;quot;Barcelona&amp;quot; &amp;quot;Barcelona&amp;quot; &amp;quot;Barcelona&amp;quot; ...
##   ..$ telecon: chr [1:6] &amp;quot;AO&amp;quot; &amp;quot;EA&amp;quot; &amp;quot;EATL/WRUS&amp;quot; &amp;quot;MO&amp;quot; ...
##   ..$ .rows  : list&amp;lt;int&amp;gt; [1:6] 
##   .. ..$ : int 1
##   .. ..$ : int 2
##   .. ..$ : int 3
##   .. ..$ : int 4
##   .. ..$ : int 5
##   .. ..$ : int 6
##   .. ..@ ptype: int(0) 
##   ..- attr(*, &amp;quot;.drop&amp;quot;)= logi TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;How can we undo the list of tables in each row of our table?&lt;/p&gt;
&lt;p&gt;First we eliminate the column with the data and then simply we can apply the &lt;code&gt;unnest()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corr_pr &amp;lt;- select(data_nest, -data) %&amp;gt;% unnest()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `cols` is now required when using unnest().
## Please use `cols = c(model)`&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corr_pr&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 40 x 7
## # Groups:   city, telecon [40]
##    city      telecon estimate statistic  p.value method              alternative
##    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;               &amp;lt;chr&amp;gt;      
##  1 Bilbao    NAO       0.153     44372. 0.213    Spearman&amp;#39;s rank co~ two.sided  
##  2 Santiago  NAO      -0.181     61902. 0.139    Spearman&amp;#39;s rank co~ two.sided  
##  3 Barcelona NAO      -0.0203    53460. 0.869    Spearman&amp;#39;s rank co~ two.sided  
##  4 Madrid    NAO      -0.291     64692. 0.0169   Spearman&amp;#39;s rank co~ two.sided  
##  5 Valencia  NAO      -0.113     27600. 0.422    Spearman&amp;#39;s rank co~ two.sided  
##  6 Bilbao    WeMO      0.404     31242  0.000706 Spearman&amp;#39;s rank co~ two.sided  
##  7 Santiago  WeMO      0.332     35014  0.00594  Spearman&amp;#39;s rank co~ two.sided  
##  8 Barcelona WeMO      0.0292    50862  0.813    Spearman&amp;#39;s rank co~ two.sided  
##  9 Madrid    WeMO      0.109     44660  0.380    Spearman&amp;#39;s rank co~ two.sided  
## 10 Valencia  WeMO     -0.252     31056  0.0688   Spearman&amp;#39;s rank co~ two.sided  
## # ... with 30 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The result is a table in which we can see the correlations and their statistical significance for each city and teleconnection index.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;heatmap-of-the-results&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Heatmap of the results&lt;/h2&gt;
&lt;p&gt;Finally, we make a heatmap of the obtained result. But, previously we create a column that indicates whether the correlation is significant with p-value less than 0.05.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corr_pr &amp;lt;- mutate(corr_pr, sig = ifelse(p.value &amp;lt;0.05, &amp;quot;Sig.&amp;quot;, &amp;quot;Non Sig.&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot()+
  geom_tile(data = corr_pr,
            aes(city, telecon, fill = estimate),
            size = 1,
            colour = &amp;quot;white&amp;quot;)+
  geom_tile(data = filter(corr_pr, sig == &amp;quot;Sig.&amp;quot;),
            aes(city, telecon),
            size = 1,
            colour = &amp;quot;black&amp;quot;,
            fill = &amp;quot;transparent&amp;quot;)+
  geom_text(data = corr_pr,
            aes(city, telecon, label = round(estimate, 2),
            fontface = ifelse(sig == &amp;quot;Sig.&amp;quot;, &amp;quot;bold&amp;quot;, &amp;quot;plain&amp;quot;)))+
  scale_fill_gradient2(breaks = seq(-1, 1, 0.2))+
  labs(x = &amp;quot;&amp;quot;, y = &amp;quot;&amp;quot;, fill = &amp;quot;&amp;quot;, p.value = &amp;quot;&amp;quot;)+
  theme_minimal()+
  theme(panel.grid.major = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.ticks = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/tidy-correlation-tests-in-r/index.en_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;2100&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/drxeo&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;41&#34; width=&#34;174&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Import Excel sheets with R</title>
      <link>https://dominicroye.github.io/en/2019/import-excel-sheets-with-r/</link>
      <pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://dominicroye.github.io/en/2019/import-excel-sheets-with-r/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2019/import-excel-sheets-with-r/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;We usually work with different data sources, and sometimes we can find tables distributed over several Excel sheets. In this post we are going to import the average daily temperature of Madrid and Berlin which is found in two Excel files with sheets for each year between 2000 and 2005: &lt;a href=&#34;https://dominicroye.github.io/files/Data_Excel.zip&#34;&gt;download&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Packages&lt;/h2&gt;
&lt;p&gt;In this post we will use the following packages:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;10%&#34; /&gt;
&lt;col width=&#34;89%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Packages&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;fs&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Provides a cross-platform, uniform interface to file system operations&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;readxl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Import Excel files&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install the packages if necessary
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;fs&amp;quot;)) install.packages(&amp;quot;fs&amp;quot;)
if(!require(&amp;quot;readxl&amp;quot;)) install.packages(&amp;quot;readxl&amp;quot;)


#load packages
library(tidyverse)
library(fs)
library(readxl)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By default, the &lt;code&gt;read_excel()&lt;/code&gt; function imports the first sheet. To import a different sheet it is necessary to indicate the number or name with the argument &lt;em&gt;sheet&lt;/em&gt; (second argument).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#import first sheet
read_excel(&amp;quot;madrid_temp.xlsx&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 366 x 3
##    date                   ta    yr
##    &amp;lt;dttm&amp;gt;              &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 2000-01-01 00:00:00   5.4  2000
##  2 2000-01-02 00:00:00   5    2000
##  3 2000-01-03 00:00:00   3.5  2000
##  4 2000-01-04 00:00:00   4.3  2000
##  5 2000-01-05 00:00:00   0.6  2000
##  6 2000-01-06 00:00:00   3.8  2000
##  7 2000-01-07 00:00:00   6.2  2000
##  8 2000-01-08 00:00:00   5.4  2000
##  9 2000-01-09 00:00:00   5.5  2000
## 10 2000-01-10 00:00:00   4.8  2000
## # ... with 356 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#import third sheet
read_excel(&amp;quot;madrid_temp.xlsx&amp;quot;, 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 365 x 3
##    date                   ta    yr
##    &amp;lt;dttm&amp;gt;              &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 2002-01-01 00:00:00   8.7  2002
##  2 2002-01-02 00:00:00   7.4  2002
##  3 2002-01-03 00:00:00   8.5  2002
##  4 2002-01-04 00:00:00   9.2  2002
##  5 2002-01-05 00:00:00   9.3  2002
##  6 2002-01-06 00:00:00   7.3  2002
##  7 2002-01-07 00:00:00   5.4  2002
##  8 2002-01-08 00:00:00   5.6  2002
##  9 2002-01-09 00:00:00   6.8  2002
## 10 2002-01-10 00:00:00   6.1  2002
## # ... with 355 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;excel_sheets()&lt;/code&gt; function can extract the names of the sheets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;path &amp;lt;- &amp;quot;madrid_temp.xlsx&amp;quot;

path %&amp;gt;%
  excel_sheets()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2000&amp;quot; &amp;quot;2001&amp;quot; &amp;quot;2002&amp;quot; &amp;quot;2003&amp;quot; &amp;quot;2004&amp;quot; &amp;quot;2005&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The results are the sheet names and we find the years from 2000 to 2005. The most important function to read multiple sheets is &lt;code&gt;map()&lt;/code&gt; of the &lt;em&gt;{purrr}&lt;/em&gt; package, which is part of the &lt;em&gt;{tidyverse]&lt;/em&gt; collection. &lt;code&gt;map()&lt;/code&gt; allows you to apply a function to each element of a vector or list.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;path &amp;lt;- &amp;quot;madrid_temp.xlsx&amp;quot;

mad &amp;lt;- path %&amp;gt;%
        excel_sheets() %&amp;gt;%
        set_names() %&amp;gt;%
       map(read_excel,
           path = path)
        
str(mad)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 6
##  $ 2000: tibble [366 x 3] (S3: tbl_df/tbl/data.frame)
##   ..$ date: POSIXct[1:366], format: &amp;quot;2000-01-01&amp;quot; &amp;quot;2000-01-02&amp;quot; ...
##   ..$ ta  : num [1:366] 5.4 5 3.5 4.3 0.6 3.8 6.2 5.4 5.5 4.8 ...
##   ..$ yr  : num [1:366] 2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...
##  $ 2001: tibble [365 x 3] (S3: tbl_df/tbl/data.frame)
##   ..$ date: POSIXct[1:365], format: &amp;quot;2001-01-01&amp;quot; &amp;quot;2001-01-02&amp;quot; ...
##   ..$ ta  : num [1:365] 8.2 8.8 7.5 9.2 10 9 5.5 4.6 3 7.9 ...
##   ..$ yr  : num [1:365] 2001 2001 2001 2001 2001 ...
##  $ 2002: tibble [365 x 3] (S3: tbl_df/tbl/data.frame)
##   ..$ date: POSIXct[1:365], format: &amp;quot;2002-01-01&amp;quot; &amp;quot;2002-01-02&amp;quot; ...
##   ..$ ta  : num [1:365] 8.7 7.4 8.5 9.2 9.3 7.3 5.4 5.6 6.8 6.1 ...
##   ..$ yr  : num [1:365] 2002 2002 2002 2002 2002 ...
##  $ 2003: tibble [365 x 3] (S3: tbl_df/tbl/data.frame)
##   ..$ date: POSIXct[1:365], format: &amp;quot;2003-01-01&amp;quot; &amp;quot;2003-01-02&amp;quot; ...
##   ..$ ta  : num [1:365] 9.4 10.8 9.7 9.2 6.3 6.6 3.8 6.4 4.3 3.4 ...
##   ..$ yr  : num [1:365] 2003 2003 2003 2003 2003 ...
##  $ 2004: tibble [366 x 3] (S3: tbl_df/tbl/data.frame)
##   ..$ date: POSIXct[1:366], format: &amp;quot;2004-01-01&amp;quot; &amp;quot;2004-01-02&amp;quot; ...
##   ..$ ta  : num [1:366] 6.6 5.9 7.8 8.1 6.4 5.7 5.2 6.9 11.8 12.2 ...
##   ..$ yr  : num [1:366] 2004 2004 2004 2004 2004 ...
##  $ 2005: tibble [365 x 3] (S3: tbl_df/tbl/data.frame)
##   ..$ date: POSIXct[1:365], format: &amp;quot;2005-01-01&amp;quot; &amp;quot;2005-01-02&amp;quot; ...
##   ..$ ta  : num [1:365] 7.1 7.8 6.4 5.6 4.4 6.8 7.4 6 5.2 4.2 ...
##   ..$ yr  : num [1:365] 2005 2005 2005 2005 2005 ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The result is a named list with the name of each sheet that contains the data.frame. Since it is the same table in all sheets, we could use the function &lt;code&gt;bind_rows()&lt;/code&gt;, however, there is a variant of &lt;code&gt;map()&lt;/code&gt; that directly joins all the tables by row: &lt;code&gt;map_df()&lt;/code&gt;. If it were necessary to join by column, &lt;code&gt;map_dfc()&lt;/code&gt; could be used.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;path &amp;lt;- &amp;quot;madrid_temp.xlsx&amp;quot;

mad &amp;lt;- path %&amp;gt;%
        excel_sheets() %&amp;gt;%
        set_names() %&amp;gt;%
       map_df(read_excel,
           path = path)

mad&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2,192 x 3
##    date                   ta    yr
##    &amp;lt;dttm&amp;gt;              &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 2000-01-01 00:00:00   5.4  2000
##  2 2000-01-02 00:00:00   5    2000
##  3 2000-01-03 00:00:00   3.5  2000
##  4 2000-01-04 00:00:00   4.3  2000
##  5 2000-01-05 00:00:00   0.6  2000
##  6 2000-01-06 00:00:00   3.8  2000
##  7 2000-01-07 00:00:00   6.2  2000
##  8 2000-01-08 00:00:00   5.4  2000
##  9 2000-01-09 00:00:00   5.5  2000
## 10 2000-01-10 00:00:00   4.8  2000
## # ... with 2,182 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In our case we have a column in each sheet (year, but also the date) that differentiates each table. If it were not the case, we should use the name of the sheets as a new column when joining all of them. In &lt;code&gt;bind_rows()&lt;/code&gt; it can be done with the &lt;em&gt;.id&lt;/em&gt; argument by assigning a name for the column. The same works for &lt;code&gt;map_df()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;path &amp;lt;- &amp;quot;madrid_temp.xlsx&amp;quot;

mad &amp;lt;- path %&amp;gt;%
        excel_sheets() %&amp;gt;%
        set_names() %&amp;gt;%
       map_df(read_excel,
           path = path,
           .id = &amp;quot;yr2&amp;quot;)

str(mad)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## tibble [2,192 x 4] (S3: tbl_df/tbl/data.frame)
##  $ yr2 : chr [1:2192] &amp;quot;2000&amp;quot; &amp;quot;2000&amp;quot; &amp;quot;2000&amp;quot; &amp;quot;2000&amp;quot; ...
##  $ date: POSIXct[1:2192], format: &amp;quot;2000-01-01&amp;quot; &amp;quot;2000-01-02&amp;quot; ...
##  $ ta  : num [1:2192] 5.4 5 3.5 4.3 0.6 3.8 6.2 5.4 5.5 4.8 ...
##  $ yr  : num [1:2192] 2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But how do we import multiple Excel files?&lt;/p&gt;
&lt;p&gt;To do this, first we must know the &lt;code&gt;dir_ls()&lt;/code&gt; function from the &lt;a href=&#34;https://github.com/r-lib/fs&#34;&gt;&lt;em&gt;{fs}&lt;/em&gt;&lt;/a&gt; package. Indeed, there is the &lt;code&gt;dir()&lt;/code&gt; function of &lt;em&gt;R Base&lt;/em&gt;, but the advantages of the recent package are several, especially the compatibility with the &lt;em&gt;{tidyverse}&lt;/em&gt; collection.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dir_ls()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## berlin_temp.xlsx   featured.png       index.en.html      index.en.Rmd       
## index.en.Rmd.lock~ index.en_files     madrid_temp.xlsx&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#we can filter the files that we want
dir_ls(regexp = &amp;quot;xlsx&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## berlin_temp.xlsx madrid_temp.xlsx&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We import the two Excel files.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#without joining
dir_ls(regexp = &amp;quot;xlsx&amp;quot;) %&amp;gt;%
  map(read_excel)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $berlin_temp.xlsx
## # A tibble: 366 x 3
##    date                   ta    yr
##    &amp;lt;dttm&amp;gt;              &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 2000-01-01 00:00:00   1.2  2000
##  2 2000-01-02 00:00:00   3.6  2000
##  3 2000-01-03 00:00:00   5.7  2000
##  4 2000-01-04 00:00:00   5.1  2000
##  5 2000-01-05 00:00:00   2.2  2000
##  6 2000-01-06 00:00:00   1.8  2000
##  7 2000-01-07 00:00:00   4.2  2000
##  8 2000-01-08 00:00:00   4.2  2000
##  9 2000-01-09 00:00:00   4.2  2000
## 10 2000-01-10 00:00:00   1.7  2000
## # ... with 356 more rows
## 
## $madrid_temp.xlsx
## # A tibble: 366 x 3
##    date                   ta    yr
##    &amp;lt;dttm&amp;gt;              &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 2000-01-01 00:00:00   5.4  2000
##  2 2000-01-02 00:00:00   5    2000
##  3 2000-01-03 00:00:00   3.5  2000
##  4 2000-01-04 00:00:00   4.3  2000
##  5 2000-01-05 00:00:00   0.6  2000
##  6 2000-01-06 00:00:00   3.8  2000
##  7 2000-01-07 00:00:00   6.2  2000
##  8 2000-01-08 00:00:00   5.4  2000
##  9 2000-01-09 00:00:00   5.5  2000
## 10 2000-01-10 00:00:00   4.8  2000
## # ... with 356 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#joining with a new id column
dir_ls(regexp = &amp;quot;xlsx&amp;quot;) %&amp;gt;%
  map_df(read_excel, .id = &amp;quot;city&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 732 x 4
##    city             date                   ta    yr
##    &amp;lt;chr&amp;gt;            &amp;lt;dttm&amp;gt;              &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 berlin_temp.xlsx 2000-01-01 00:00:00   1.2  2000
##  2 berlin_temp.xlsx 2000-01-02 00:00:00   3.6  2000
##  3 berlin_temp.xlsx 2000-01-03 00:00:00   5.7  2000
##  4 berlin_temp.xlsx 2000-01-04 00:00:00   5.1  2000
##  5 berlin_temp.xlsx 2000-01-05 00:00:00   2.2  2000
##  6 berlin_temp.xlsx 2000-01-06 00:00:00   1.8  2000
##  7 berlin_temp.xlsx 2000-01-07 00:00:00   4.2  2000
##  8 berlin_temp.xlsx 2000-01-08 00:00:00   4.2  2000
##  9 berlin_temp.xlsx 2000-01-09 00:00:00   4.2  2000
## 10 berlin_temp.xlsx 2000-01-10 00:00:00   1.7  2000
## # ... with 722 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, in this case we only import the first sheet of each Excel file. To solve this problem, we must create our own function. In this function we do what we previously did individually.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;read_multiple_excel &amp;lt;- function(path) {
  path %&amp;gt;%
    excel_sheets() %&amp;gt;% 
    set_names() %&amp;gt;% 
  map_df(read_excel, path = path)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We apply our created function to import multiple sheets of several Excel files.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#separately
data &amp;lt;- dir_ls(regexp = &amp;quot;xlsx&amp;quot;) %&amp;gt;% 
           map(read_multiple_excel)

str(data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 2
##  $ berlin_temp.xlsx: tibble [2,192 x 3] (S3: tbl_df/tbl/data.frame)
##   ..$ date: POSIXct[1:2192], format: &amp;quot;2000-01-01&amp;quot; &amp;quot;2000-01-02&amp;quot; ...
##   ..$ ta  : num [1:2192] 1.2 3.6 5.7 5.1 2.2 1.8 4.2 4.2 4.2 1.7 ...
##   ..$ yr  : num [1:2192] 2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...
##  $ madrid_temp.xlsx: tibble [2,192 x 3] (S3: tbl_df/tbl/data.frame)
##   ..$ date: POSIXct[1:2192], format: &amp;quot;2000-01-01&amp;quot; &amp;quot;2000-01-02&amp;quot; ...
##   ..$ ta  : num [1:2192] 5.4 5 3.5 4.3 0.6 3.8 6.2 5.4 5.5 4.8 ...
##   ..$ yr  : num [1:2192] 2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#joining all data.frames
data_df &amp;lt;- dir_ls(regexp = &amp;quot;xlsx&amp;quot;) %&amp;gt;% 
           map_df(read_multiple_excel,
                  .id = &amp;quot;city&amp;quot;)

str(data_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## tibble [4,384 x 4] (S3: tbl_df/tbl/data.frame)
##  $ city: chr [1:4384] &amp;quot;berlin_temp.xlsx&amp;quot; &amp;quot;berlin_temp.xlsx&amp;quot; &amp;quot;berlin_temp.xlsx&amp;quot; &amp;quot;berlin_temp.xlsx&amp;quot; ...
##  $ date: POSIXct[1:4384], format: &amp;quot;2000-01-01&amp;quot; &amp;quot;2000-01-02&amp;quot; ...
##  $ ta  : num [1:4384] 1.2 3.6 5.7 5.1 2.2 1.8 4.2 4.2 4.2 1.7 ...
##  $ yr  : num [1:4384] 2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/drxeo&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;41&#34; width=&#34;174&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Calculating the distance to the sea in R</title>
      <link>https://dominicroye.github.io/en/2019/calculating-the-distance-to-the-sea-in-r/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://dominicroye.github.io/en/2019/calculating-the-distance-to-the-sea-in-r/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2019/calculating-the-distance-to-the-sea-in-r/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;The distance to the sea is a fundamental variable in geography, especially relevant when it comes to modeling. For example, in interpolations of air temperature, the distance to the sea is usually used as a predictor variable, since there is a casual relationship between the two that explains the spatial variation. How can we estimate the (shortest) distance to the coast in R?&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Packages&lt;/h2&gt;
&lt;p&gt;In this post we will use the following libraries:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;15%&#34; /&gt;
&lt;col width=&#34;84%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Library&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Simple Feature: import, export and manipulate vector data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;raster&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Import, export and manipulate raster&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;rnaturalearth&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Set of vector maps ‘natural earth’&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;RColorBrewer&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Color palettes&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install the libraries if necessary
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;sf&amp;quot;)) install.packages(&amp;quot;sf&amp;quot;)
if(!require(&amp;quot;raster&amp;quot;)) install.packages(&amp;quot;raster&amp;quot;)
if(!require(&amp;quot;rnaturalearth&amp;quot;)) install.packages(&amp;quot;rnaturalearth&amp;quot;)

#packages
library(rnaturalearth)
library(sf)
library(raster)
library(tidyverse)
library(RColorBrewer)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-coast-of-iceland-as-an-example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The coast of Iceland as an example&lt;/h2&gt;
&lt;p&gt;Our example in this post will be Iceland, and, as it is an island territory it will facilitate the tutorial showing the process in a simple manner. The &lt;em&gt;rnaturalearth&lt;/em&gt; package allows you to import the boundaries of countries (with different administrative levels) from around the world. The data comes from the platform &lt;a href=&#34;http://www.naturalearthdata.com/&#34;&gt;naturalearthdata.com&lt;/a&gt;. I recommend exploring the package, more info &lt;a href=&#34;https://github.com/ropensci/rnaturalearth&#34;&gt;here&lt;/a&gt;. The &lt;code&gt;ne_countries( )&lt;/code&gt; function imports the country boundaries. In this case we indicate with the argument &lt;em&gt;scale&lt;/em&gt; the resolution (10, 50 or 110m), with &lt;em&gt;country&lt;/em&gt; we indicate the specific country of interest and with &lt;em&gt;returnclass&lt;/em&gt; we determine which class we want (&lt;em&gt;sf&lt;/em&gt; or &lt;em&gt;sp&lt;/em&gt;), in our case &lt;em&gt;sf&lt;/em&gt; (simple feature).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;world &amp;lt;- ne_countries(scale = 50) #world map with 50m resolution

plot(world) #sp class by default&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/calculating-the-distance-to-the-sea-in-r/index.en_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#import the limits of Iceland
iceland &amp;lt;- ne_countries(scale = 10, country = &amp;quot;Iceland&amp;quot;, returnclass = &amp;quot;sf&amp;quot;)

#info of our spatial vector object
iceland&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Simple feature collection with 1 feature and 94 fields
## Geometry type: MULTIPOLYGON
## Dimension:     XY
## Bounding box:  xmin: -24.53991 ymin: 63.39671 xmax: -13.50292 ymax: 66.56415
## CRS:           +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0
##          featurecla scalerank labelrank sovereignt sov_a3 adm0_dif level
## 188 Admin-0 country         0         3    Iceland    ISL        0     2
##                  type   admin adm0_a3 geou_dif geounit gu_a3 su_dif subunit
## 188 Sovereign country Iceland     ISL        0 Iceland   ISL      0 Iceland
##     su_a3 brk_diff    name name_long brk_a3 brk_name brk_group  abbrev postal
## 188   ISL        0 Iceland   Iceland    ISL  Iceland      &amp;lt;NA&amp;gt; Iceland     IS
##               formal_en formal_fr name_ciawf note_adm0 note_brk name_sort
## 188 Republic of Iceland      &amp;lt;NA&amp;gt;    Iceland      &amp;lt;NA&amp;gt;     &amp;lt;NA&amp;gt;   Iceland
##     name_alt mapcolor7 mapcolor8 mapcolor9 mapcolor13 pop_est pop_rank
## 188     &amp;lt;NA&amp;gt;         1         4         4          9  339747       10
##     gdp_md_est pop_year lastcensus gdp_year                    economy
## 188      16150     2017         NA     2016 2. Developed region: nonG7
##               income_grp wikipedia fips_10_ iso_a2 iso_a3 iso_a3_eh iso_n3
## 188 1. High income: OECD        NA       IC     IS    ISL       ISL    352
##     un_a3 wb_a2 wb_a3   woe_id woe_id_eh                   woe_note adm0_a3_is
## 188   352    IS   ISL 23424845  23424845 Exact WOE match as country        ISL
##     adm0_a3_us adm0_a3_un adm0_a3_wb continent region_un       subregion
## 188        ISL         NA         NA    Europe    Europe Northern Europe
##                 region_wb name_len long_len abbrev_len tiny homepart min_zoom
## 188 Europe &amp;amp; Central Asia        7        7          7   NA        1        0
##     min_label max_label      ne_id wikidataid name_ar name_bn name_de name_en
## 188         2         7 1159320917       Q189    &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;  Island Iceland
##      name_es name_fr name_el name_hi name_hu  name_id name_it name_ja name_ko
## 188 Islandia Islande    &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;  Izland Islandia Islanda    &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;
##     name_nl  name_pl  name_pt name_ru name_sv name_tr name_vi name_zh
## 188 IJsland Islandia Islândia    &amp;lt;NA&amp;gt;  Island Izlanda Iceland    &amp;lt;NA&amp;gt;
##                           geometry
## 188 MULTIPOLYGON (((-14.56363 6...&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#here Iceland
plot(iceland)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/calculating-the-distance-to-the-sea-in-r/index.en_files/figure-html/unnamed-chunk-3-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;By default, the &lt;code&gt;plot( )&lt;/code&gt; function with the class &lt;em&gt;sf&lt;/em&gt; creates as many facets of the map as there are variables in it. To limit this behavior we can use either a variable name &lt;code&gt;plot(iceland[&#34;admin&#34;])&lt;/code&gt; or the limit argument &lt;code&gt;plot(iceland, max.plot = 1)&lt;/code&gt;. With the argument &lt;em&gt;max.plot = 1&lt;/em&gt; the function uses the first available variable of the map.&lt;/p&gt;
&lt;p&gt;In addition, we see in the information of the object &lt;em&gt;sf&lt;/em&gt; that the projection is WGS84 with decimal degrees (EPSG code: 4326). For the calculation of distances it is more convenient to use meters instead of degrees. Because of this, the first thing we do is to transform the map of Iceland to UTM Zone 27 (EPSG code: 3055). More information about EPSG and projections &lt;a href=&#34;http://spatialreference.org/ref/epsg/wgs-84/&#34;&gt;here&lt;/a&gt;. For that purpose, we use the &lt;code&gt;st_transform( )&lt;/code&gt; function. We simply indicate the map and the EPSG code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#transform to UTM
iceland &amp;lt;- st_transform(iceland, 3055)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;create-a-fishnet-of-points&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Create a fishnet of points&lt;/h2&gt;
&lt;p&gt;We still need the points where we want to know the distance. In our case it will be a regular fishnet of points in Iceland with a resolution of 5km. We do this with the function &lt;code&gt;st_make_grid( )&lt;/code&gt;, indicating the resolution in the unit of the coordinate system (meters in our case) with the argument &lt;em&gt;cellsize&lt;/em&gt;, and what geometry we would like to create &lt;em&gt;what&lt;/em&gt; (polygons, centers or corners).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#create the fishnet
grid &amp;lt;- st_make_grid(iceland, cellsize = 5000, what = &amp;quot;centers&amp;quot;)

#our fishnet with the extension of Iceland
plot(grid)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/calculating-the-distance-to-the-sea-in-r/index.en_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#only extract the points in the limits of Iceland
grid &amp;lt;- st_intersection(grid, iceland)   

#our fishnet now
plot(grid)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/calculating-the-distance-to-the-sea-in-r/index.en_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;calculating-the-distance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Calculating the distance&lt;/h2&gt;
&lt;p&gt;To estimate the distance we use the &lt;code&gt;st_distance( )&lt;/code&gt; function that returns a vector of distances for all our points in the fishnet. But first it is necessary to transform the map of Iceland from a polygon shape (MULTIPOLYGON) to a line (MULTILINESTRING). More details with &lt;code&gt;?st_cast&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#transform Iceland from polygon shape to line
iceland &amp;lt;- st_cast(iceland, &amp;quot;MULTILINESTRING&amp;quot;)

#calculation of the distance between the coast and our points
dist &amp;lt;- st_distance(iceland, grid)

#distance with unit in meters
head(dist[1,])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Units: [m]
## [1]  790.7906 1151.4360 1270.7603 3128.9057 2428.5677 4197.7472&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;plotting-the-calculated-distance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plotting the calculated distance&lt;/h2&gt;
&lt;p&gt;Once obtained the distance for our points, we can combine them with the coordinates and plot them in &lt;em&gt;ggplot2&lt;/em&gt;. For this, we create a &lt;em&gt;data.frame&lt;/em&gt;. The object &lt;em&gt;dist&lt;/em&gt; is a matrix of one column, so we have to convert it to a vector with the function &lt;code&gt;as.vector( )&lt;/code&gt;. In addition, we divide by 1000 to convert the distance in meters to km. The &lt;code&gt;st_coordinates( )&lt;/code&gt; function extracts the coordinates of our points. For the final visualization we use a vector of colors with the RdGy palette (more &lt;a href=&#34;http://colorbrewer2.org&#34;&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#create a data.frame with the distance and the coordinates of the points
df &amp;lt;- data.frame(dist = as.vector(dist)/1000,
                    st_coordinates(grid))

#structure
str(df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;data.frame&amp;#39;:    4104 obs. of  3 variables:
##  $ dist: num  0.791 1.151 1.271 3.129 2.429 ...
##  $ X   : num  608796 613796 583796 588796 593796 ...
##  $ Y   : num  7033371 7033371 7038371 7038371 7038371 ...&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#colors 
col_dist &amp;lt;- brewer.pal(11, &amp;quot;RdGy&amp;quot;)


ggplot(df, aes(X, Y, fill = dist))+ #variables
         geom_tile()+ #geometry
           scale_fill_gradientn(colours = rev(col_dist))+ #colors for plotting the distance
             labs(fill = &amp;quot;Distance (km)&amp;quot;)+ #legend name
             theme_void()+ #map theme
              theme(legend.position = &amp;quot;bottom&amp;quot;) #legend position&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/calculating-the-distance-to-the-sea-in-r/index.en_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;export-the-distance-as-a-raster&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Export the distance as a raster&lt;/h2&gt;
&lt;p&gt;To be able to export the estimated distance to the sea of Iceland, we need to use the &lt;code&gt;rasterize( )&lt;/code&gt; function of the library &lt;em&gt;raster&lt;/em&gt;.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;First, it is necessary to create an empty raster. In this raster we have to indicate the resolution, in our case it is of 5000m, the projection and the extension of the raster.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;p&gt;We can extract the projection from the information of the map of Iceland.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The extension can be extracted from our &lt;em&gt;grid&lt;/em&gt; points with the function &lt;code&gt;extent( )&lt;/code&gt;. However, this last function needs the class &lt;em&gt;sp&lt;/em&gt;, so we pass the object &lt;em&gt;grid&lt;/em&gt; in &lt;em&gt;sf&lt;/em&gt; format, only for this time, to the class &lt;em&gt;sp&lt;/em&gt; using the function &lt;code&gt;as( )&lt;/code&gt; and the argument “Spatial”.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In addition to the above, the &lt;em&gt;data.frame&lt;/em&gt; &lt;strong&gt;df&lt;/strong&gt;, that we created earlier, has to be converted into the &lt;em&gt;sf&lt;/em&gt; class. Therefore, we apply the function &lt;code&gt;st_as_sf( )&lt;/code&gt; with the argument &lt;em&gt;coords&lt;/em&gt; indicating the names of the coordinates. Additionally, we also define the coordinate system that we know.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#get the extension
ext &amp;lt;- extent(as(grid, &amp;quot;Spatial&amp;quot;))

#extent object
ext&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class      : Extent 
## xmin       : 338795.6 
## xmax       : 848795.6 
## ymin       : 7033371 
## ymax       : 7383371&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#raster destination
r &amp;lt;- raster(resolution = 5000, ext = ext, crs = &amp;quot;+proj=utm +zone=27 +ellps=intl +towgs84=-73,47,-83,0,0,0,0 +units=m +no_defs&amp;quot;)

#convert the points to a spatial object class sf
dist_sf &amp;lt;- st_as_sf(df, coords = c(&amp;quot;X&amp;quot;, &amp;quot;Y&amp;quot;)) %&amp;gt;%
                      st_set_crs(3055)

#create the distance raster
dist_raster &amp;lt;- rasterize(dist_sf, r, &amp;quot;dist&amp;quot;, fun = mean)

#raster
dist_raster&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class      : RasterLayer 
## dimensions : 70, 102, 7140  (nrow, ncol, ncell)
## resolution : 5000, 5000  (x, y)
## extent     : 338795.6, 848795.6, 7033371, 7383371  (xmin, xmax, ymin, ymax)
## crs        : +proj=utm +zone=27 +ellps=intl +units=m +no_defs 
## source     : memory
## names      : layer 
## values     : 0.006124901, 115.1712  (min, max)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#plot the raster
plot(dist_raster)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/calculating-the-distance-to-the-sea-in-r/index.en_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#export the raster
writeRaster(dist_raster, file = &amp;quot;dist_islandia.tif&amp;quot;, format = &amp;quot;GTiff&amp;quot;, overwrite = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;rasterize( )&lt;/code&gt; function is designed to create rasters from an irregular grid. In case we have a regular grid, like this one, we can use an easier alternative way. The &lt;code&gt;rasterFromXYZ( )&lt;/code&gt; function converts a &lt;em&gt;data.frame&lt;/em&gt; with longitude, latitude and the variable &lt;em&gt;Z&lt;/em&gt; into a raster object. It is important that the order should be longitude, latitude, variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r &amp;lt;- rasterFromXYZ(df[, c(2:3, 1)], crs = &amp;quot;+proj=utm +zone=27 +ellps=intl +towgs84=-73,47,-83,0,0,0,0 +units=m +no_defs&amp;quot;)

plot(r)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/calculating-the-distance-to-the-sea-in-r/index.en_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;With the calculation of distance we can create art, as seen in the header of this post, which includes a world map only with the distance to the sea of all continents. A different perspective to our world (&lt;a href=&#34;https://www.geografiainfinita.com/2017/06/una-radiografia-del-mundo-a-traves-de-la-distancia-al-mar/&#34;&gt;here more (spanish)&lt;/a&gt;) .&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/drxeo&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;41&#34; width=&#34;174&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How to create &#39;Warming Stripes&#39; in R</title>
      <link>https://dominicroye.github.io/en/2018/how-to-create-warming-stripes-in-r/</link>
      <pubDate>Wed, 05 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://dominicroye.github.io/en/2018/how-to-create-warming-stripes-in-r/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2018/how-to-create-warming-stripes-in-r/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This year, the so-called &lt;em&gt;warming stripes&lt;/em&gt;, which were created by the scientist &lt;a href=&#34;https://twitter.com/ed_hawkins?lang=es&#34;&gt;Ed Hawkins&lt;/a&gt; of the University of Reading, became very famous all over the world. These graphs represent and communicate climate change in a very illustrative and effective way.&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Visualising global temperature change since records began in 1850. Versions for USA, central England &amp;amp; Toronto available too: &lt;a href=&#34;https://t.co/H5Hv9YgZ7v&#34;&gt;https://t.co/H5Hv9YgZ7v&lt;/a&gt; &lt;a href=&#34;https://t.co/YMzdySrr3A&#34;&gt;pic.twitter.com/YMzdySrr3A&lt;/a&gt;&lt;/p&gt;&amp;mdash; Ed Hawkins (@ed_hawkins) &lt;a href=&#34;https://twitter.com/ed_hawkins/status/999242147135188993?ref_src=twsrc%5Etfw&#34;&gt;May 23, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/p&gt;
&lt;p&gt;From his idea, I created strips for examples of Spain, like the next one in Madrid.&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;es&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://twitter.com/hashtag/Temperatura?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Temperatura&lt;/a&gt; anual en &lt;a href=&#34;https://twitter.com/hashtag/MadridRetiro?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#MadridRetiro&lt;/a&gt; desde 1920 a 2017.  &lt;a href=&#34;https://twitter.com/hashtag/CambioClimatico?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#CambioClimatico&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/dataviz?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#dataviz&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/ggplot2?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#ggplot2&lt;/a&gt; (idea de &lt;a href=&#34;https://twitter.com/ed_hawkins?ref_src=twsrc%5Etfw&#34;&gt;@ed_hawkins&lt;/a&gt; 🙏) &lt;a href=&#34;https://twitter.com/Divulgameteo?ref_src=twsrc%5Etfw&#34;&gt;@Divulgameteo&lt;/a&gt; &lt;a href=&#34;https://twitter.com/edupenabad?ref_src=twsrc%5Etfw&#34;&gt;@edupenabad&lt;/a&gt; &lt;a href=&#34;https://twitter.com/climayagua?ref_src=twsrc%5Etfw&#34;&gt;@climayagua&lt;/a&gt; &lt;a href=&#34;https://twitter.com/ClimaGroupUB?ref_src=twsrc%5Etfw&#34;&gt;@ClimaGroupUB&lt;/a&gt; &lt;a href=&#34;https://twitter.com/4gotas_com?ref_src=twsrc%5Etfw&#34;&gt;@4gotas_com&lt;/a&gt; &lt;a href=&#34;https://t.co/wmLb5uczpT&#34;&gt;pic.twitter.com/wmLb5uczpT&lt;/a&gt;&lt;/p&gt;&amp;mdash; Dr. Dominic Royé (@dr_xeo) &lt;a href=&#34;https://twitter.com/dr_xeo/status/1002954473927561217?ref_src=twsrc%5Etfw&#34;&gt;June 2, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/p&gt;
&lt;p&gt;In this post I will show how you can create these strips in R with the library &lt;em&gt;ggplot2&lt;/em&gt;. Although I must say that there are many ways in R that can lead us to the same result or to a similar one, even within &lt;em&gt;ggplot2&lt;/em&gt;.&lt;/p&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;In this case we will use the annual temperatures of Lisbon
&lt;a href=&#34;https://data.giss.nasa.gov/gistemp/stdata/&#34;&gt;GISS Surface Temperature Analysis&lt;/a&gt;, homogenized time series, comprising the period from 1880 to 2018. Monthly temperatures or other time series could also be used. The file can be downloaded &lt;a href=&#34;https://dominicroye.github.io/files/temp_lisboa.csv&#34;&gt;here&lt;/a&gt;. First, we should, as long as we have not done it, install the collection of &lt;em&gt;tidyverse&lt;/em&gt; libraries that also include &lt;em&gt;ggplot2&lt;/em&gt;. In addition, we will need the library &lt;em&gt;lubridate&lt;/em&gt; for the treatment of dates. Then, we import the data of Lisbon in csv format.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install the lubridate and tidyverse libraries
if(!require(&amp;quot;lubridate&amp;quot;)) install.packages(&amp;quot;lubridate&amp;quot;)
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)

#packages
library(tidyverse)
library(lubridate)
library(RColorBrewer)

#import the annual temperatures
temp_lisboa &amp;lt;- read_csv(&amp;quot;temp_lisboa.csv&amp;quot;)

str(temp_lisboa)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## spec_tbl_df [139 x 18] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
##  $ YEAR  : num [1:139] 1880 1881 1882 1883 1884 ...
##  $ JAN   : num [1:139] 9.17 11.37 10.07 10.86 11.16 ...
##  $ FEB   : num [1:139] 12 11.8 11.9 11.5 10.6 ...
##  $ MAR   : num [1:139] 13.6 14.1 13.5 10.5 12.4 ...
##  $ APR   : num [1:139] 13.1 14.4 14 13.8 12.2 ...
##  $ MAY   : num [1:139] 15.7 17.3 15.6 14.6 16.4 ...
##  $ JUN   : num [1:139] 17 19.2 17.9 17.2 19.1 ...
##  $ JUL   : num [1:139] 19.1 21.8 20.3 19.5 21.4 ...
##  $ AUG   : num [1:139] 20.6 23.5 21 21.6 22.4 ...
##  $ SEP   : num [1:139] 20.7 20 18 18.8 19.5 ...
##  $ OCT   : num [1:139] 17.9 16.3 16.4 15.8 16.4 ...
##  $ NOV   : num [1:139] 12.5 14.7 13.7 13.5 12.5 ...
##  $ DEC   : num [1:139] 11.07 9.97 10.66 9.46 10.25 ...
##  $ D-J-F : num [1:139] 10.7 11.4 10.6 11 10.4 ...
##  $ M-A-M : num [1:139] 14.1 15.2 14.3 12.9 13.6 ...
##  $ J-J-A : num [1:139] 18.9 21.5 19.7 19.4 20.9 ...
##  $ S-O-N : num [1:139] 17 17 16 16 16.1 ...
##  $ metANN: num [1:139] 15.2 16.3 15.2 14.8 15.3 ...
##  - attr(*, &amp;quot;spec&amp;quot;)=
##   .. cols(
##   ..   YEAR = col_double(),
##   ..   JAN = col_double(),
##   ..   FEB = col_double(),
##   ..   MAR = col_double(),
##   ..   APR = col_double(),
##   ..   MAY = col_double(),
##   ..   JUN = col_double(),
##   ..   JUL = col_double(),
##   ..   AUG = col_double(),
##   ..   SEP = col_double(),
##   ..   OCT = col_double(),
##   ..   NOV = col_double(),
##   ..   DEC = col_double(),
##   ..   `D-J-F` = col_double(),
##   ..   `M-A-M` = col_double(),
##   ..   `J-J-A` = col_double(),
##   ..   `S-O-N` = col_double(),
##   ..   metANN = col_double()
##   .. )
##  - attr(*, &amp;quot;problems&amp;quot;)=&amp;lt;externalptr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see in the columns that we have monthly and seasonal values, and the annual temperature value. But before proceeding to visualize the annual temperature, we must replace the missing values &lt;em&gt;999.9&lt;/em&gt; with &lt;code&gt;NA&lt;/code&gt;, using the &lt;code&gt;ifelse( )&lt;/code&gt; function that evaluates a condition and perform the given argument corresponding to true and false.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#select only the annual temperature and year column
temp_lisboa_yr &amp;lt;- select(temp_lisboa, YEAR, metANN)

#rename the temperature column
temp_lisboa_yr &amp;lt;- rename(temp_lisboa_yr, ta = metANN)

#missing values 999.9
summary(temp_lisboa_yr) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       YEAR            ta        
##  Min.   :1880   Min.   : 14.53  
##  1st Qu.:1914   1st Qu.: 15.65  
##  Median :1949   Median : 16.11  
##  Mean   :1949   Mean   : 37.38  
##  3rd Qu.:1984   3rd Qu.: 16.70  
##  Max.   :2018   Max.   :999.90&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;temp_lisboa_yr &amp;lt;- mutate(temp_lisboa_yr, ta = ifelse(ta == 999.9, NA, ta))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When we use the year as a variable, we do not usually convert it into a date object, however it is advisable. This allows us to use the date functions of the library &lt;em&gt;lubridate&lt;/em&gt; and the support functions inside of &lt;em&gt;ggplot2&lt;/em&gt;. The &lt;code&gt;str_c( )&lt;/code&gt; function of the library &lt;em&gt;stringr&lt;/em&gt;, part of the collection of &lt;em&gt;tidyverse&lt;/em&gt;, is similar to &lt;code&gt;paste( )&lt;/code&gt; of R Base that allows us to combine characters by specifying a separator (sep = “-”). The &lt;code&gt;ymd( )&lt;/code&gt; (year month day) function of the &lt;em&gt;lubridate&lt;/em&gt; library converts a date character into a &lt;em&gt;Date&lt;/em&gt; object. It is possible to combine several functions
using the &lt;em&gt;pipe operator&lt;/em&gt; &lt;code&gt;%&amp;gt;%&lt;/code&gt; that helps to chain without assigning the result to a new object. Its use is very extended especially with the library &lt;em&gt;tidyverse&lt;/em&gt;. If you want to know more about its use, &lt;a href=&#34;https://www.datacamp.com/community/tutorials/pipe-r-tutorial&#34;&gt;here&lt;/a&gt; you have a tutorial.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;temp_lisboa_yr &amp;lt;- mutate(temp_lisboa_yr, date = str_c(YEAR, &amp;quot;01-01&amp;quot;, sep = &amp;quot;-&amp;quot;) %&amp;gt;% ymd())&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-the-strips&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Creating the strips&lt;/h2&gt;
&lt;p&gt;First, we create the style of the graph, specifying all the arguments of the theme we want to adjust. We start with the default style of &lt;code&gt;theme_minimal( )&lt;/code&gt;. In addition, we assign
the colors from &lt;em&gt;RColorBrewer&lt;/em&gt; to an object &lt;em&gt;col_srip&lt;/em&gt;. More information about the colors used &lt;a href=&#34;http://colorbrewer2.org&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;theme_strip &amp;lt;- theme_minimal()+
                 theme(axis.text.y = element_blank(),
                       axis.line.y = element_blank(),
                       axis.title = element_blank(),
                       panel.grid.major = element_blank(),
                       legend.title = element_blank(),
                       axis.text.x = element_text(vjust = 3),
                       panel.grid.minor = element_blank(),
                        plot.title = element_text(size = 14, face = &amp;quot;bold&amp;quot;)
                       )


col_strip &amp;lt;- brewer.pal(11, &amp;quot;RdBu&amp;quot;)

brewer.pal.info&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          maxcolors category colorblind
## BrBG            11      div       TRUE
## PiYG            11      div       TRUE
## PRGn            11      div       TRUE
## PuOr            11      div       TRUE
## RdBu            11      div       TRUE
## RdGy            11      div      FALSE
## RdYlBu          11      div       TRUE
## RdYlGn          11      div      FALSE
## Spectral        11      div      FALSE
## Accent           8     qual      FALSE
## Dark2            8     qual       TRUE
## Paired          12     qual       TRUE
## Pastel1          9     qual      FALSE
## Pastel2          8     qual      FALSE
## Set1             9     qual      FALSE
## Set2             8     qual       TRUE
## Set3            12     qual      FALSE
## Blues            9      seq       TRUE
## BuGn             9      seq       TRUE
## BuPu             9      seq       TRUE
## GnBu             9      seq       TRUE
## Greens           9      seq       TRUE
## Greys            9      seq       TRUE
## Oranges          9      seq       TRUE
## OrRd             9      seq       TRUE
## PuBu             9      seq       TRUE
## PuBuGn           9      seq       TRUE
## PuRd             9      seq       TRUE
## Purples          9      seq       TRUE
## RdPu             9      seq       TRUE
## Reds             9      seq       TRUE
## YlGn             9      seq       TRUE
## YlGnBu           9      seq       TRUE
## YlOrBr           9      seq       TRUE
## YlOrRd           9      seq       TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the final graphic we use the geometry &lt;code&gt;geom_tile( )&lt;/code&gt;. Since the data does not have a specific value for the Y axis, we need a &lt;em&gt;dummy&lt;/em&gt; value, here I used 1. Also, I adjust the width of the color bar in the legend.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;     ggplot(temp_lisboa_yr,
             aes(x = date, y = 1, fill = ta))+
        geom_tile()+
           scale_x_date(date_breaks = &amp;quot;6 years&amp;quot;,
                     date_labels = &amp;quot;%Y&amp;quot;,
                     expand = c(0, 0))+
           scale_y_continuous(expand = c(0, 0))+
           scale_fill_gradientn(colors = rev(col_strip))+
             guides(fill = guide_colorbar(barwidth = 1))+
            labs(title = &amp;quot;LISBOA 1880-2018&amp;quot;,
                caption = &amp;quot;Datos: GISS Surface Temperature Analysis&amp;quot;)+
              theme_strip&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2018/how-to-create-warming-stripes-in-r/index.en_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In case we want to get only the strips, we can use &lt;code&gt;theme_void( )&lt;/code&gt; and the argument &lt;em&gt;show.legend = FALSE&lt;/em&gt; in &lt;code&gt;geom_tile( )&lt;/code&gt; to remove all style elements. We can also change the color for the &lt;code&gt;NA&lt;/code&gt; values, including the argument &lt;em&gt;na.value = “gray70”&lt;/em&gt; in the &lt;code&gt;scale_fill_gradientn( )&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;     ggplot(temp_lisboa_yr,
             aes(x = date, y = 1, fill = ta))+
        geom_tile(show.legend = FALSE)+
           scale_x_date(date_breaks = &amp;quot;6 years&amp;quot;,
                     date_labels = &amp;quot;%Y&amp;quot;,
                     expand = c(0, 0))+
           scale_y_discrete(expand = c(0, 0))+
           scale_fill_gradientn(colors = rev(col_strip))+
             theme_void()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2018/how-to-create-warming-stripes-in-r/index.en_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/drxeo&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;41&#34; width=&#34;174&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Accessing OpenStreetMap data with R</title>
      <link>https://dominicroye.github.io/en/2018/accessing-openstreetmap-data-with-r/</link>
      <pubDate>Sat, 03 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://dominicroye.github.io/en/2018/accessing-openstreetmap-data-with-r/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2018/accessing-openstreetmap-data-with-r/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;the-database-of-open-street-maps&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The database of Open Street Maps&lt;/h2&gt;
&lt;p&gt;Recently I created a map of the distribution of gas stations and electric charging stations in Europe.&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Population density through the number of gas stations in Europe. &lt;a href=&#34;https://twitter.com/hashtag/dataviz?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#dataviz&lt;/a&gt; &lt;a href=&#34;https://twitter.com/AGE_Oficial?ref_src=twsrc%5Etfw&#34;&gt;@AGE_Oficial&lt;/a&gt; &lt;a href=&#34;https://twitter.com/mipazos?ref_src=twsrc%5Etfw&#34;&gt;@mipazos&lt;/a&gt; &lt;a href=&#34;https://twitter.com/simongerman600?ref_src=twsrc%5Etfw&#34;&gt;@simongerman600&lt;/a&gt; &lt;a href=&#34;https://twitter.com/openstreetmap?ref_src=twsrc%5Etfw&#34;&gt;@openstreetmap&lt;/a&gt; &lt;a href=&#34;https://t.co/eIUx2yn7ej&#34;&gt;pic.twitter.com/eIUx2yn7ej&lt;/a&gt;&lt;/p&gt;&amp;mdash; Dr. Dominic Royé (@dr_xeo) &lt;a href=&#34;https://twitter.com/dr_xeo/status/967811548646379521?ref_src=twsrc%5Etfw&#34;&gt;February 25, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/p&gt;
&lt;p&gt;How can you obtain this data?&lt;/p&gt;
&lt;p&gt;Well, in this case I used points of interest (POIs) from the database of &lt;em&gt;Open Street Maps&lt;/em&gt; (OSM). Obviously OSM not only contains streets and highways, but also information that can be useful when we use a map such as locations of hospitals or gas stations. To avoid downloading the entire OSM and extracting the required information, you can use an &lt;em&gt;overpass API&lt;/em&gt;, which allows us to query the OSM database with our own criteria.&lt;/p&gt;
&lt;p&gt;An easy way to access an &lt;em&gt;overpass API&lt;/em&gt; is through &lt;a href=&#34;http://overpass-turbo.eu&#34;&gt;overpass-turbo.eu&lt;/a&gt;, which even includes a wizard to build a query and display the results on a interactive map. A detailed explanation of the previous web can be found &lt;a href=&#34;https://wiki.openstreetmap.org/wiki/ES:Overpass_turbo&#34;&gt;here&lt;/a&gt;.
However, we have at our disposal a package &lt;em&gt;osmdata&lt;/em&gt; that allows us to create and make queries directly from the R environment. Nevertheless, the use of the &lt;em&gt;overpass-turbo.eu&lt;/em&gt; can be useful when we are not sure what we are looking for or when we have some difficulty in building the query.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;accessing-the-overpass-api-from-r&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Accessing the overpass API from R&lt;/h2&gt;
&lt;p&gt;The first step is to install several packages, in case they are not installed. In almost all my scripts I use &lt;a href=&#34;https://www.tidyverse.org/&#34;&gt;&lt;em&gt;tidyverse&lt;/em&gt;&lt;/a&gt; which is a fundamental collection of different packages, including &lt;em&gt;dplyr&lt;/em&gt; (data manipulation), &lt;em&gt;ggplot2&lt;/em&gt; (visualization), etc. The &lt;a href=&#34;https://r-spatial.github.io/sf/articles/sf1.html&#34;&gt;&lt;em&gt;sf&lt;/em&gt;&lt;/a&gt; package is the new standard for working with spatial data and is compatible with &lt;em&gt;ggplot2&lt;/em&gt; and &lt;em&gt;dplyr&lt;/em&gt;. Finally, &lt;a href=&#34;http://stat405.had.co.nz/ggmap.pdf&#34;&gt;&lt;em&gt;ggmap&lt;/em&gt;&lt;/a&gt; makes it easier for us to create maps.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install the osmdata, sf, tidyverse and ggmap package
if(!require(&amp;quot;osmdata&amp;quot;)) install.packages(&amp;quot;osmdata&amp;quot;)
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;sf&amp;quot;)) install.packages(&amp;quot;sf&amp;quot;)
if(!require(&amp;quot;ggmap&amp;quot;)) install.packages(&amp;quot;ggmap&amp;quot;)

#load packages
library(tidyverse)
library(osmdata)
library(sf)
library(ggmap)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;build-a-query&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Build a query&lt;/h2&gt;
&lt;p&gt;Before creating a query, we need to know what we can filter. The &lt;code&gt;available_features( )&lt;/code&gt; function returns a list of available OSM features that have different tags. More details are available in the OSM &lt;em&gt;wiki&lt;/em&gt; &lt;a href=&#34;https://wiki.openstreetmap.org/wiki/Map_Features&#34;&gt;here&lt;/a&gt;.
For example, the feature &lt;em&gt;shop&lt;/em&gt; contains several tags among others &lt;em&gt;supermarket&lt;/em&gt;, &lt;em&gt;fishing&lt;/em&gt;, &lt;em&gt;books&lt;/em&gt;, etc.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#the first five features
head(available_features())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;4wd_only&amp;quot;  &amp;quot;abandoned&amp;quot; &amp;quot;abutters&amp;quot;  &amp;quot;access&amp;quot;    &amp;quot;addr&amp;quot;      &amp;quot;addr:city&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#amenities
head(available_tags(&amp;quot;amenity&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;animal_boarding&amp;quot; &amp;quot;animal_breeding&amp;quot; &amp;quot;animal_shelter&amp;quot;  &amp;quot;arts_centre&amp;quot;    
## [5] &amp;quot;atm&amp;quot;             &amp;quot;baby_hatch&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#shops
head(available_tags(&amp;quot;shop&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;agrarian&amp;quot;  &amp;quot;alcohol&amp;quot;   &amp;quot;anime&amp;quot;     &amp;quot;antiques&amp;quot;  &amp;quot;appliance&amp;quot; &amp;quot;art&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;the-first-query-where-are-cinemas-in-madrid&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The first query: Where are cinemas in Madrid?&lt;/h3&gt;
&lt;p&gt;To build the query, we use the &lt;em&gt;pipe operator&lt;/em&gt; &lt;code&gt;%&amp;gt;%&lt;/code&gt;, which helps to chain several functions without assigning the result to a new object. Its use is very extended especially within the &lt;em&gt;tidyverse&lt;/em&gt; package collection. If you want to know more about its use, you can find &lt;a href=&#34;https://www.datacamp.com/community/tutorials/pipe-r-tutorial&#34;&gt;here&lt;/a&gt; a tutorial.&lt;/p&gt;
&lt;p&gt;In the first part of the query we need to indicate the place where we want to extract the information. The &lt;code&gt;getbb( )&lt;/code&gt; function creates a boundering box for a given place, looking for the name. The main function is &lt;code&gt;opq( )&lt;/code&gt; which build the final query. We add our filter criteria with the &lt;code&gt;add_osm_feature( )&lt;/code&gt; function. In this first query we will look for cinemas in Madrid. That’s why we use as key &lt;em&gt;amenity&lt;/em&gt; and &lt;em&gt;cinema&lt;/em&gt; as tag. There are several formats to obtain the resulting spatial data of the query. The &lt;code&gt;osmdata_*( )&lt;/code&gt; function sends the query to the server and, depending on the suffix * sf/sp/xml, returns a &lt;em&gt;simple feature&lt;/em&gt;, &lt;em&gt;spatial&lt;/em&gt; or &lt;em&gt;XML&lt;/em&gt; format.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#building the query
q &amp;lt;- getbb(&amp;quot;Madrid&amp;quot;) %&amp;gt;%
      opq() %&amp;gt;%
       add_osm_feature(&amp;quot;amenity&amp;quot;, &amp;quot;cinema&amp;quot;)

str(q) #query structure&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 4
##  $ bbox    : chr &amp;quot;40.3119774,-3.8889539,40.6437293,-3.5179163&amp;quot;
##  $ prefix  : chr &amp;quot;[out:xml][timeout:25];\n(\n&amp;quot;
##  $ suffix  : chr &amp;quot;);\n(._;&amp;gt;;);\nout body;&amp;quot;
##  $ features: chr &amp;quot; [\&amp;quot;amenity\&amp;quot;=\&amp;quot;cinema\&amp;quot;]&amp;quot;
##  - attr(*, &amp;quot;class&amp;quot;)= chr [1:2] &amp;quot;list&amp;quot; &amp;quot;overpass_query&amp;quot;
##  - attr(*, &amp;quot;nodes_only&amp;quot;)= logi FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cinema &amp;lt;- osmdata_sf(q)
cinema&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Object of class &amp;#39;osmdata&amp;#39; with:
##                  $bbox : 40.3119774,-3.8889539,40.6437293,-3.5179163
##         $overpass_call : The call submitted to the overpass API
##                  $meta : metadata including timestamp and version numbers
##            $osm_points : &amp;#39;sf&amp;#39; Simple Features Collection with 220 points
##             $osm_lines : NULL
##          $osm_polygons : &amp;#39;sf&amp;#39; Simple Features Collection with 12 polygons
##        $osm_multilines : NULL
##     $osm_multipolygons : NULL&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that the result is a list of different spatial objects. In our case, we are only interested in &lt;em&gt;osm_points&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;How can we visulise these points?&lt;/p&gt;
&lt;p&gt;The advantage of &lt;em&gt;sf&lt;/em&gt; objects is that for &lt;em&gt;ggplot2&lt;/em&gt; already exists a geometry function &lt;code&gt;geom_sf( )&lt;/code&gt;. Furthermore, we can include a background map using &lt;em&gt;ggmap&lt;/em&gt;. The &lt;code&gt;get_map( )&lt;/code&gt; function downloads the map for a given place. Alternatively, it can be an address, latitude/longitude or a bounding box. The &lt;em&gt;maptype&lt;/em&gt; argument allows us to indicate the style or type of map. You can find more details in the help of the &lt;code&gt;?get_map&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;When we build a graph with &lt;em&gt;ggplot&lt;/em&gt; we usually start with &lt;code&gt;ggplot( )&lt;/code&gt;. In this case, we start with &lt;code&gt;ggmap( )&lt;/code&gt; that includes the object with our background map. Then we add with &lt;code&gt;geom_sf( )&lt;/code&gt; the points of the cinemas in Madrid. It is important to indicate with the argument &lt;em&gt;inherit.aes = FALSE&lt;/em&gt; that it has to use the &lt;em&gt;aesthetic mappings&lt;/em&gt; of the spatial object &lt;em&gt;osm_points&lt;/em&gt;. In addition, we change the color, fill, transparency (&lt;em&gt;alpha&lt;/em&gt;), type and size of the circles.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#our background map
mad_map &amp;lt;- get_map(getbb(&amp;quot;Madrid&amp;quot;), maptype = &amp;quot;toner-background&amp;quot;)

#final map
ggmap(mad_map)+
  geom_sf(data = cinema$osm_points,
          inherit.aes = FALSE,
          colour = &amp;quot;#238443&amp;quot;,
          fill = &amp;quot;#004529&amp;quot;,
          alpha = .5,
          size = 4,
          shape = 21)+
  labs(x = &amp;quot;&amp;quot;, y = &amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2018/accessing-openstreetmap-data-with-r/index.en_files/figure-html/fig.width==5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;where-can-we-find-mercadona-supermarkets&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Where can we find Mercadona supermarkets?&lt;/h3&gt;
&lt;p&gt;Instead of obtaining a bounding box with the function &lt;em&gt;getbb( )&lt;/em&gt; we can build our own box. To do this, we create a vector of four elements, the order has to be West/South/East/North. In the query we use two features: &lt;em&gt;name&lt;/em&gt; and &lt;em&gt;shop&lt;/em&gt; to filter supermarkets that are of this particular brand. Depending on the area or volume of the query, it is necessary to extend the waiting time. By default, the limit is set at 25 seconds (&lt;em&gt;timeout&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;The map, we create in this case, consists only of the supermarket points. Therefore, we use the usual grammar by adding the geometry &lt;code&gt;geom_sf( )&lt;/code&gt;. The &lt;code&gt;theme_void( )&lt;/code&gt; function removes everything except for the points.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#bounding box for the Iberian Peninsula
m &amp;lt;- c(-10, 30, 5, 46)

#building the query
q &amp;lt;- m %&amp;gt;% 
      opq (timeout = 25*100) %&amp;gt;%
         add_osm_feature(&amp;quot;name&amp;quot;, &amp;quot;Mercadona&amp;quot;) %&amp;gt;%
         add_osm_feature(&amp;quot;shop&amp;quot;, &amp;quot;supermarket&amp;quot;)

#query
mercadona &amp;lt;- osmdata_sf(q)

#final map
ggplot(mercadona$osm_points)+
  geom_sf(colour = &amp;quot;#08519c&amp;quot;,
          fill = &amp;quot;#08306b&amp;quot;,
          alpha = .5,
          size = 1,
          shape = 21)+
  theme_void()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2018/accessing-openstreetmap-data-with-r/index.en_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/drxeo&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;41&#34; width=&#34;174&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Access to climate reanalysis data from R</title>
      <link>https://dominicroye.github.io/en/2018/access-to-climate-reanalysis-data-from-r/</link>
      <pubDate>Sat, 15 Sep 2018 10:59:44 +0100</pubDate>
      <guid>https://dominicroye.github.io/en/2018/access-to-climate-reanalysis-data-from-r/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2018/access-to-climate-reanalysis-data-from-r/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;1&lt;/span&gt; Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ncep&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2&lt;/span&gt; NCEP&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#packages&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.1&lt;/span&gt; Packages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-download&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.2&lt;/span&gt; Data download&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#monthly-average&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.3&lt;/span&gt; Monthly average&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#visualization&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.4&lt;/span&gt; Visualization&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#era-interim&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3&lt;/span&gt; ERA-Interim&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#installation&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.1&lt;/span&gt; Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#connection-and-download-with-the-ecmwf-api&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.2&lt;/span&gt; Connection and download with the ECMWF API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#processing-ncdf&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.3&lt;/span&gt; Processing ncdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#update-for-accessing-era-5&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4&lt;/span&gt; Update for accessing ERA-5&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;A friend advised me to introduce R levels as categories. An idea that I now add to each blog post. There are three levels: elementary, intermediate, and advanced. I hope it will help the reader and the R user.&lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34; number=&#34;1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Introduction&lt;/h1&gt;
&lt;p&gt;In this post, I will show how we can download and work directly with data from climatic reanalysis in R. These kind of datasets are a combination of forcast models and data assimilation systems, which allows us to create corrected global grids of recent history of the atmosphere, land surface, and oceans. The two most used reanalyses are &lt;a href=&#34;https://climatedataguide.ucar.edu/climate-data/ncep-reanalysis-r2&#34;&gt;NCEP-DO&lt;/a&gt; (Reanalysis II) from the &lt;em&gt;NOAA/OAR/ESRL&lt;/em&gt;, an improved version of &lt;em&gt;NCEP-NCAR&lt;/em&gt; (Reanalysis I), and &lt;em&gt;ERA-Interim&lt;/em&gt; from the &lt;a href=&#34;https://www.ecmwf.int/en/research/climate-reanalysis&#34;&gt;&lt;em&gt;ECMWF&lt;/em&gt;&lt;/a&gt;. Since &lt;em&gt;NCEP-DO&lt;/em&gt; is the first generation, it is recommended to use third-generation climate reanalysis, especially &lt;em&gt;ERA-Interim&lt;/em&gt;. An overview of the current atmospheric reanalysis can be found &lt;a href=&#34;https://reanalyses.org/index.php/atmosphere/overview-current-atmospheric-reanalyses&#34;&gt;here&lt;/a&gt;. First, let’s see how to access the &lt;em&gt;NCEP&lt;/em&gt; data through an R library on &lt;em&gt;CRAN&lt;/em&gt; that facilitates the download and handling of the data. Then we will do the same with the &lt;em&gt;ERA-Interim&lt;/em&gt;, however, to access this last reanalysis dataset it is necessary to use &lt;em&gt;python&lt;/em&gt; and the corresponding API of the &lt;em&gt;ECMWF&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ncep&#34; class=&#34;section level1&#34; number=&#34;2&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; NCEP&lt;/h1&gt;
&lt;p&gt;To access the &lt;em&gt;NCEP&lt;/em&gt; reanalysis it is required to install the corresponding package &lt;em&gt;RNCEP&lt;/em&gt;. The main function is &lt;code&gt;NCEP.gather( )&lt;/code&gt;. The resolution of the &lt;em&gt;NCEP&lt;/em&gt; reanalysis is 2.5º X 2.5º.&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level2&#34; number=&#34;2.1&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.1&lt;/span&gt; Packages&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install the RNCEP, lubridate and tidyverse packages
if(!require(&amp;quot;RNCEP&amp;quot;)) install.packages(&amp;quot;RNCEP&amp;quot;)
if(!require(&amp;quot;lubridate&amp;quot;)) install.packages(&amp;quot;lubridate&amp;quot;)
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;sf&amp;quot;)) install.packages(&amp;quot;sf&amp;quot;)

#load the packages
library(RNCEP)
library(lubridate) #date and time manipulation
library(tidyverse) #data manipulation and visualization
library(RColorBrewer) #color schemes
library(sf) #to import a spatial object and to work with geom_sf in ggplot2&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data-download&#34; class=&#34;section level2&#34; number=&#34;2.2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.2&lt;/span&gt; Data download&lt;/h2&gt;
&lt;p&gt;We will download the air temperature of the 850haPa pressure level for the year 2016. The variables and pressure levels can be found in the details of the function &lt;code&gt;?NCEP.gather&lt;/code&gt;. The &lt;em&gt;reanalysis2&lt;/em&gt; argument allows us to download both version I and version II, being by default &lt;em&gt;FALSE&lt;/em&gt;, that is, we access reanalysis I. In all the requests we will obtain data of every 6 hours (00:00, 06:00, 12:00 and 18:00). This supposes a total of 1464 values for the year 2016.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#define the necessary arguments
month_range &amp;lt;- c(1,12)     #period of months
year_range &amp;lt;- c(2016,2016) #period of years

lat_range &amp;lt;- c(30,60)      #latitude range
lon_range &amp;lt;- c(-30,50)     #longitude range
 

data &amp;lt;- NCEP.gather(&amp;quot;air&amp;quot;,    #name of the variable
                    850, #pressure level 850hPa
                    month_range,year_range,
                    lat_range,lon_range,
                    return.units = TRUE,
                    reanalysis2=TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] Units of variable &amp;#39;air&amp;#39; are degK
## [1] Units of variable &amp;#39;air&amp;#39; are degK&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#dimensions                    
dim(data) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]   13   33 1464&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#we find lon, lat and time with dimnames()
#date and time
date_time &amp;lt;- dimnames(data)[[3]]
date_time &amp;lt;- ymd_h(date_time)
head(date_time)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2016-01-01 00:00:00 UTC&amp;quot; &amp;quot;2016-01-01 06:00:00 UTC&amp;quot;
## [3] &amp;quot;2016-01-01 12:00:00 UTC&amp;quot; &amp;quot;2016-01-01 18:00:00 UTC&amp;quot;
## [5] &amp;quot;2016-01-02 00:00:00 UTC&amp;quot; &amp;quot;2016-01-02 06:00:00 UTC&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#longitude and latitude
lat &amp;lt;- dimnames(data)[[1]]
lon &amp;lt;- dimnames(data)[[2]]
head(lon);head(lat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;-30&amp;quot;   &amp;quot;-27.5&amp;quot; &amp;quot;-25&amp;quot;   &amp;quot;-22.5&amp;quot; &amp;quot;-20&amp;quot;   &amp;quot;-17.5&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;60&amp;quot;   &amp;quot;57.5&amp;quot; &amp;quot;55&amp;quot;   &amp;quot;52.5&amp;quot; &amp;quot;50&amp;quot;   &amp;quot;47.5&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;monthly-average&#34; class=&#34;section level2&#34; number=&#34;2.3&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.3&lt;/span&gt; Monthly average&lt;/h2&gt;
&lt;p&gt;We see that the downloaded data is an &lt;em&gt;array&lt;/em&gt; of three dimensions with [lat, lon, time]. As above mentioned, we extracted latitude, longitude and time. The temperature is given in Kelvin. The objective in the next section will be to show two maps comparing January and July.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#create our grouping variable
group &amp;lt;- month(date_time) 

#estimate the average temperature by month 
data_month &amp;lt;- aperm(
  apply(
    data, #our data
    c(1,2), #apply to each time series 1:row, 2:column a the mean( ) function
    by, #group by
    group, #months
    function(x)ifelse(all(is.na(x)),NA,mean(x))),
  c(2,3,1)) #reorder to get an array like the original

dim(data_month) #850haPa temperature per month January to December&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 13 33 12&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;visualization&#34; class=&#34;section level2&#34; number=&#34;2.4&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.4&lt;/span&gt; Visualization&lt;/h2&gt;
&lt;p&gt;Once we got here, we can visualize the 850hPa temperature of January and July with &lt;em&gt;ggplot2&lt;/em&gt;. In this example, I use &lt;code&gt;geom_sf( )&lt;/code&gt; from the library &lt;a href=&#34;https://github.com/r-spatial/sf&#34;&gt;&lt;em&gt;sf&lt;/em&gt;&lt;/a&gt;, which makes the work easier to visualize spatial objects in &lt;em&gt;ggplot&lt;/em&gt; (in the near future I will make a post about &lt;em&gt;sf&lt;/em&gt; and &lt;em&gt;ggplot&lt;/em&gt;). In the dimension of latitude and longitude we saw that it only indicates a value for each row and column. But we need the coordinates of all the cells in the matrix. To create all combinations between two variables we can use the &lt;code&gt;expand.grid( )&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#first we create all the combinations of lon-lat
lonlat &amp;lt;- expand.grid(lon=lon,lat=lat)

#as lonlat was a row/column name, it is character, that&amp;#39;s why we convert it into numeric
lonlat &amp;lt;- apply(lonlat,2,as.numeric)

#lon and lat are not in the order as we expect
#row=lon; column=lat
data_month &amp;lt;- aperm(data_month,c(2,1,3))

#subtract 273.15K to convert K to ºC.
df &amp;lt;- data.frame(lonlat,
                 Ta01=as.vector(data_month[,,1])-273.15,
                 Ta07=as.vector(data_month[,,7])-273.15)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before we can make the map with &lt;em&gt;ggplot2&lt;/em&gt;, we have to adapt the table. The shapefile with the countries limits can be downloaded &lt;a href=&#34;https://dominicroye.github.io/files/CNTR_RG_03M_2014.zip&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#convert the wide table into a long one
df &amp;lt;- gather(df,month,Ta,Ta01:Ta07)%&amp;gt;%
             mutate(month=factor(month,unique(month),c(&amp;quot;Jan&amp;quot;,&amp;quot;Jul&amp;quot;)))

#import the countries limits
limit &amp;lt;- st_read(&amp;quot;CNTR_RG_03M_2014.shp&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Reading layer `CNTR_RG_03M_2014&amp;#39; from data source 
##   `E:\GitHub\blog_update_2021\content\en\post\2018-09-15-access-to-climate-reanalysis-data-from-r\CNTR_RG_03M_2014.shp&amp;#39; 
##   using driver `ESRI Shapefile&amp;#39;
## Simple feature collection with 256 features and 3 fields
## Geometry type: MULTIPOLYGON
## Dimension:     XY
## Bounding box:  xmin: -180 ymin: -90 xmax: 180 ymax: 83.66068
## Geodetic CRS:  ETRS89&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#color scheme
colbr &amp;lt;- brewer.pal(11,&amp;quot;RdBu&amp;quot;)

ggplot(df)+
      geom_tile(aes(lon,lat,fill=Ta))+ #temperature data
      geom_sf(data=limit,fill=NA,size=.5)+ #limits 
        scale_fill_gradientn(colours=rev(colbr))+
          coord_sf(ylim=c(30,60),xlim=c(-30,50))+
          scale_x_continuous(breaks=seq(-30,50,10),expand=c(0,0))+
          scale_y_continuous(breaks=seq(30,60,5),expand=c(0,0))+
          labs(x=&amp;quot;&amp;quot;,y=&amp;quot;&amp;quot;,fill=&amp;quot;Ta 850hPa (ºC)&amp;quot;)+
           facet_grid(month~.)+ #plot panels by month
             theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2018/access-to-climate-reanalysis-data-from-r/index.en_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;era-interim&#34; class=&#34;section level1&#34; number=&#34;3&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; ERA-Interim&lt;/h1&gt;
&lt;p&gt;The &lt;em&gt;ECMWF&lt;/em&gt; offers access to its public databases from a &lt;a href=&#34;https://confluence.ecmwf.int//display/WEBAPI/Access+ECMWF+Public+Datasets&#34;&gt;&lt;em&gt;pyhton-API&lt;/em&gt;&lt;/a&gt;. It is required to be registered on the &lt;em&gt;ECMWF&lt;/em&gt; website. You can register &lt;a href=&#34;https://apps.ecmwf.int/registration/&#34;&gt;here&lt;/a&gt;. When dealing with another programming language, in R we have to use an interface between both which allows the library &lt;a href=&#34;https://github.com/rstudio/reticulate&#34;&gt;&lt;em&gt;reticulate&lt;/em&gt;&lt;/a&gt;. We must also have installed a pyhton distribution (version 2.x or 3.x). In the case of Windows we can use &lt;a href=&#34;https://www.anaconda.com/download/&#34;&gt;anaconda&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Recently a new package called &lt;code&gt;ecmwfr&lt;/code&gt; has been published that facilitates accessing the Copernicus and ECMWF APIs. The major advantage is that it is not necessary to install &lt;code&gt;python&lt;/code&gt;. More details &lt;a href=&#34;https://github.com/khufkens/ecmwfr&#34;&gt;here&lt;/a&gt;. I wrote a more updated version in 2022.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;div id=&#34;installation&#34; class=&#34;section level2&#34; number=&#34;3.1&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.1&lt;/span&gt; Installation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if(!require(&amp;quot;reticulate&amp;quot;)) install.packages(&amp;quot;reticulate&amp;quot;)
if(!require(&amp;quot;ncdf4&amp;quot;)) install.packages(&amp;quot;ncdf4&amp;quot;) #to manage netCDF format

#load packages
library(reticulate)
library(ncdf4)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once we have installed &lt;em&gt;anaconda&lt;/em&gt; and the package &lt;em&gt;reticulate&lt;/em&gt;, we can install the library &lt;em&gt;python ecmwfapi&lt;/em&gt;. We can carry out the installation, or through the Windows CMD using the command &lt;em&gt;conda install -c conda-forge ecmwf-api-client&lt;/em&gt;, or with the R function &lt;code&gt;py_install( )&lt;/code&gt; from the &lt;em&gt;reticulate&lt;/em&gt; package. The same function allows us to install any &lt;em&gt;python&lt;/em&gt; library from R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install the python ECMWF API
py_install(&amp;quot;ecmwf-api-client&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;connection-and-download-with-the-ecmwf-api&#34; class=&#34;section level2&#34; number=&#34;3.2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.2&lt;/span&gt; Connection and download with the ECMWF API&lt;/h2&gt;
&lt;p&gt;In order to access the API, it is required to create a file with the user’s information.&lt;/p&gt;
&lt;p&gt;The “.ecmwfapirc” file must contain the following information:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
    &amp;quot;url&amp;quot;   : &amp;quot;https://api.ecmwf.int/v1&amp;quot;,
    &amp;quot;key&amp;quot;   : &amp;quot;XXXXXXXXXXXXXXXXXXXXXX&amp;quot;,
    &amp;quot;email&amp;quot; : &amp;quot;john.smith@example.com&amp;quot;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The key can be obtained with the user account &lt;a href=&#34;https://api.ecmwf.int/v1/key/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The file can be created with the Windows notebook.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;We create a document “ecmwfapirc.txt”.&lt;/li&gt;
&lt;li&gt;Rename this file to “.ecmwfapirc.”&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The last point disappears automatically. Then we save this file in “C:/USERNAME/.ecmwfapirc” or “C:/USERNAME/Documents/.ecmwfapirc”.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#import the python library ecmwfapi
ecmwf &amp;lt;- import(&amp;#39;ecmwfapi&amp;#39;)

#for this step there must exist the file .ecmwfapirc
server = ecmwf$ECMWFDataServer() #start the connection&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One we get here, how do we create a query? The easiest thing is to go to the website of &lt;a href=&#34;http://apps.ecmwf.int/datasets/data/interim-full-daily/levtype=sfc/&#34;&gt;&lt;em&gt;ECMWF&lt;/em&gt;&lt;/a&gt;, where we choose the database, in this case &lt;em&gt;ERA-Interim&lt;/em&gt; surface, to create a script with all the necessary data. More details about the syntax can be found &lt;a href=&#34;https://confluence.ecmwf.int/display/WEBAPI/Brief+request+syntax&#34;&gt;here&lt;/a&gt;. When we proceed on the website, we only have to click on “View MARS Request”. This step takes us to the script in &lt;em&gt;python&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;erainterim1.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;erainterim2.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;With the syntax of the script from the &lt;em&gt;MARS Request&lt;/em&gt;, we can create the query in R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#we create the query
query &amp;lt;-r_to_py(list(
  class=&amp;#39;ei&amp;#39;,
  dataset= &amp;quot;interim&amp;quot;, #dataset
  date= &amp;quot;2017-01-01/to/2017-12-31&amp;quot;, #time period
  expver= &amp;quot;1&amp;quot;,
  grid= &amp;quot;0.125/0.125&amp;quot;, #resolution
  levtype=&amp;quot;sfc&amp;quot;,
  param= &amp;quot;167.128&amp;quot;, # air temperature (2m)
  area=&amp;quot;45/-10/30/5&amp;quot;, #N/W/S/E
  step= &amp;quot;0&amp;quot;,
  stream=&amp;quot;oper&amp;quot;,
  time=&amp;quot;00:00:00/06:00:00/12:00:00/18:00:00&amp;quot;, #hours
  type=&amp;quot;an&amp;quot;,
  format= &amp;quot;netcdf&amp;quot;, #format
  target=&amp;#39;ta2017.nc&amp;#39; #file name
))

#query to get the ncdf
server$retrieve(query)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The result is a netCDF file that we can process with the library &lt;em&gt;ncdf4&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;processing-ncdf&#34; class=&#34;section level2&#34; number=&#34;3.3&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.3&lt;/span&gt; Processing ncdf&lt;/h2&gt;
&lt;p&gt;In the next section, the objective will be the extraction of a time serie from the closest coordinate to a given one. We will use the coordinates of Madrid (40.418889, -3.691944).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#load packages
library(sf)
library(ncdf4)
library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#open the connection with the ncdf file
nc &amp;lt;- nc_open(&amp;quot;ta2017.nc&amp;quot;)

#extract lon and lat
lat &amp;lt;- ncvar_get(nc,&amp;#39;latitude&amp;#39;)
lon &amp;lt;- ncvar_get(nc,&amp;#39;longitude&amp;#39;)
dim(lat);dim(lon)

#extract the time
t &amp;lt;- ncvar_get(nc, &amp;quot;time&amp;quot;)

#time unit: hours since 1900-01-01
ncatt_get(nc,&amp;#39;time&amp;#39;)

#convert the hours into date + hour
#as_datetime() function of the lubridate package needs seconds
timestamp &amp;lt;- as_datetime(c(t*60*60),origin=&amp;quot;1900-01-01&amp;quot;)

#import the data
data &amp;lt;- ncvar_get(nc,&amp;quot;t2m&amp;quot;)

#close the conection with the ncdf file
nc_close(nc)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this next section we use the &lt;em&gt;sf&lt;/em&gt; package, which is replacing the well known &lt;em&gt;sp&lt;/em&gt; and &lt;em&gt;rgdal&lt;/em&gt; packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#create all the combinations of lon-lat
lonlat &amp;lt;- expand.grid(lon=lon,lat=lat)

#we must convert the coordinates in a spatial object sf
#we also indicate the coordinate system in EPSG code
coord &amp;lt;- st_as_sf(lonlat,coords=c(&amp;quot;lon&amp;quot;,&amp;quot;lat&amp;quot;))%&amp;gt;%
                    st_set_crs(4326)

#we do the same with our coordinate of Madrid
psj &amp;lt;- st_point(c(-3.691944,40.418889))%&amp;gt;%
                   st_sfc()%&amp;gt;%
                     st_set_crs(4326)

#plot all points
plot(st_geometry(coord))
plot(psj,add=TRUE,pch = 3, col = &amp;#39;red&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the next steps we calculate the distance of our reference point to all the grid points. Then we look for the one with less distance.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#add the distance to the points
coord &amp;lt;- mutate(coord,dist=st_distance(coord,psj))

#create a distance matrix with the same dimensions as our data
dist_mat &amp;lt;- matrix(coord$dist,dim(data)[-3])

#the arrayInd function is useful to obtain the row and column indexes
mat_index &amp;lt;- as.vector(arrayInd(which.min(dist_mat), dim(dist_mat)))

#we extract the time serie and change the unit from K to ºC
#we convert the time in date + hour
df &amp;lt;- data.frame(ta=data[mat_index[1],mat_index[2],],time=timestamp)%&amp;gt;%
        mutate(ta=ta-273.15,time=ymd_hms(time))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we visualize our time series.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(df,
       aes(time,ta))+
    geom_line()+
    labs(y=&amp;quot;Temperature (ºC)&amp;quot;,
             x=&amp;quot;&amp;quot;)+
    theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;update-for-accessing-era-5&#34; class=&#34;section level1&#34; number=&#34;4&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;4&lt;/span&gt; Update for accessing ERA-5&lt;/h1&gt;
&lt;p&gt;Recently the new reanalysis ERA-5 with &lt;a href=&#34;https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=overview&#34;&gt;single level&lt;/a&gt; or &lt;a href=&#34;https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-pressure-levels?tab=overview&#34;&gt;pressure level&lt;/a&gt; was made available to users. It is the fifth generation of the European Center for Medium-Range Weather Forecasts (ECMWF) and accessible through a new Copernicus API. The ERA-5 reanalysis has a temporary coverage from 1950 to the present at a horizontal resolution of 30km worldwide, with 137 levels from the surface to a height of 80km. An important difference with respect to the previous ERA-Interim is the temporal resolution with hourly data.&lt;/p&gt;
&lt;p&gt;The access changes to the Climate Data Store (CDS) infrastructure with its own API. It is possible to download directly from the web or using the Python API in a similar way to the one already presented in this post. However, there are slight differences which I will explain below.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;It is necessary to have a Copernicus CDS account &lt;a href=&#34;https://cds.climate.copernicus.eu/user/register&#34;&gt;link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Again, you need a account key &lt;a href=&#34;https://cds.climate.copernicus.eu/api-how-to&#34;&gt;link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;There are changes in the Python library and in some arguments of the query.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#load libraries 
library(sf)
library(ncdf4)
library(tidyverse)
library(reticulate)

#install the CDS API
conda_install(&amp;quot;r-reticulate&amp;quot;,&amp;quot;cdsapi&amp;quot;, pip=TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To be able to access the API, a requirement is to create a file with the user’s information.&lt;/p&gt;
&lt;p&gt;The “.cdsapirc” file must contain the following information:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
url: https://cds.climate.copernicus.eu/api/v2
key: {uid}:{api-key}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The key can be obtained with the user account in the &lt;em&gt;User profile&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The file can be created in the same way as it has been explained for ERA-Interim.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#import python CDS-API
cdsapi &amp;lt;- import(&amp;#39;cdsapi&amp;#39;)

#for this step there must exist the file .cdsapirc
server = cdsapi$Client() #start the connection&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the syntax of the script from the &lt;em&gt;Show API request&lt;/em&gt; &lt;a href=&#34;https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=overview&#34;&gt;single level&lt;/a&gt;, we can create the query in R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#we create the query
query &amp;lt;- r_to_py(list(
    variable= &amp;quot;2m_temperature&amp;quot;,
    product_type= &amp;quot;reanalysis&amp;quot;,
    year= &amp;quot;2018&amp;quot;,
    month= &amp;quot;07&amp;quot;, #formato: &amp;quot;01&amp;quot;,&amp;quot;01&amp;quot;, etc.
    day= str_pad(1:31,2,&amp;quot;left&amp;quot;,&amp;quot;0&amp;quot;),   
    time= str_c(0:23,&amp;quot;00&amp;quot;,sep=&amp;quot;:&amp;quot;)%&amp;gt;%str_pad(5,&amp;quot;left&amp;quot;,&amp;quot;0&amp;quot;),
    format= &amp;quot;netcdf&amp;quot;,
    area = &amp;quot;45/-20/35/5&amp;quot; # North, West, South, East
  ))

#query to get the ncdf
server$retrieve(&amp;quot;reanalysis-era5-single-levels&amp;quot;,
                  query,
                 &amp;quot;era5_ta_2018.nc&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is possible that the first time an error message is received, given that the required terms and conditions have not yet been accepted. Simply, the indicated link should be followed.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Error in py_call_impl(callable, dots$args, dots$keywords) : 
  Exception: Client has not agreed to the required terms and conditions.. To access this resource, you first need to accept the termsof &amp;#39;Licence to Use Copernicus Products&amp;#39; at https://cds.climate.copernicus.eu/cdsapp/#!/terms/licence-to-use-copernicus-products&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From here we can follow the same steps as with ERA-Interim.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#open the connection with the file
nc &amp;lt;- nc_open(&amp;quot;era5_ta_2018.nc&amp;quot;)

#extract lon, lat
lat &amp;lt;- ncvar_get(nc,&amp;#39;latitude&amp;#39;)
lon &amp;lt;- ncvar_get(nc,&amp;#39;longitude&amp;#39;)
dim(lat);dim(lon)

#extract time
t &amp;lt;- ncvar_get(nc, &amp;quot;time&amp;quot;)

#time unit: hours from 1900-01-01
ncatt_get(nc,&amp;#39;time&amp;#39;)

#we convert the hours into date+time 
#as_datetime from lubridate needs seconds
timestamp &amp;lt;- as_datetime(c(t*60*60),origin=&amp;quot;1900-01-01&amp;quot;)

#temperatures in K from july 2018
head(timestamp)

#import temperature data
data &amp;lt;- ncvar_get(nc,&amp;quot;t2m&amp;quot;)

#plot 2018-07-01
filled.contour(data[,,1])

#time serie plot for a pixel
plot(data.frame(date=timestamp,
                ta=data[1,5,]),
     type=&amp;quot;l&amp;quot;)

#close the conection with the ncdf file
nc_close(nc)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/drxeo&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;41&#34; width=&#34;174&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>the pie chart</title>
      <link>https://dominicroye.github.io/en/2018/the-pie-chart/</link>
      <pubDate>Wed, 22 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://dominicroye.github.io/en/2018/the-pie-chart/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2018/the-pie-chart/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Welcome to my blog! I am Dominic Royé, researcher and lecturer of physical geography at the University of Santiago de Compostela. One of my passions is R programming to visualize and analyze any type of data. Hence, my idea of this blog has its origin in my datavis publications I have been cooking in the last year on Twitter on different topics describing the world. In addition, I would like to take advantage of the blog and publish short introductions and explanation on data visualization, management and manipulation in R. I hope you like it. Any suggestion or ideas are welcomed.&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;background&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;I have always wanted to write about the use of the pie chart. The pie chart is widely used in research, teaching, journalism or technical reports. I do not know if it is due to Excel, but even worse than the pie chart itself, is its 3D version (the same for the bar chart). About the 3D versions, I only want to say that they are not recommended, since in these cases the third dimension does not contain any information and therefore it does not help to correctly read the information of the graphic. Regarding the pie chart, among many experts its use is not advised. But why?&lt;/p&gt;
&lt;p&gt;Already in a study conducted by Simkin (1987) they found that the interpretation and processing of angles is more difficult than that of linear forms. Mostly it is easier to read a bar chart than a pie chart. A problem that becomes very visible when we have; 1) too many categories 2) few differences between categories 3) a misuse of colors as legend or 4) comparisons between various pie charts.&lt;/p&gt;
&lt;p&gt;In general, to decide what possible graphic representations exist for our data, I recommend using the website &lt;a href=&#34;https://www.data-to-viz.com&#34;&gt;www.data-to-viz.com&lt;/a&gt; or the &lt;em&gt;Financial Times Visual Vocabulary&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/ft-interactive/chart-doctor/tree/master/visual-vocabulary&#34;&gt;&lt;img src=&#34;https://dominicroye.github.io/img/poster_piepost.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Well, now what alternative ways can we use in R?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;alternatives-to-the-pie-chart&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Alternatives to the pie chart&lt;/h2&gt;
&lt;p&gt;The dataset we will use about the vaccination status of &lt;strong&gt;measles&lt;/strong&gt; correspond to June 2018 in Europe and come from the &lt;a href=&#34;https://ecdc.europa.eu/en/surveillance-atlas-infectious-diseases&#34;&gt;ECDC&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#packages
library(tidyverse)
library(scales)
library(RColorBrewer)

#data
measles &amp;lt;- data.frame(
          vacc_status=c(&amp;quot;Unvaccinated&amp;quot;,&amp;quot;1 Dose&amp;quot;,
                        &amp;quot;&amp;gt;= 2 Dose&amp;quot;,&amp;quot;Unkown Dose&amp;quot;,&amp;quot;Unkown&amp;quot;),
          prop=c(0.75,0.091,0.05,0.012,0.096)
          )

#we order from the highest to the lowest and fix it with a factor

measles &amp;lt;- arrange(measles,
                   desc(prop))%&amp;gt;%
              mutate(vacc_status=factor(vacc_status,vacc_status))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;vacc_status&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;prop&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Unvaccinated&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.750&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Unkown&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.096&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;1 Dose&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.091&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt;= 2 Dose&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.050&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Unkown Dose&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.012&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;bar-plot-or-similar&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Bar plot or similar&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(measles,aes(vacc_status,prop))+
            geom_bar(stat=&amp;quot;identity&amp;quot;)+
             scale_y_continuous(breaks=seq(0,1,.1),
                                labels=percent,    #convert to %
                                limits=c(0,1))+
            labs(x=&amp;quot;&amp;quot;,y=&amp;quot;&amp;quot;)+
            theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2018/the-pie-chart/index.en_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(measles,aes(x=vacc_status,prop,ymin=0,ymax=prop))+
            geom_pointrange()+
             scale_y_continuous(breaks=seq(0,1,.1),
                                labels=percent,    #convert to %
                                limits=c(0,1))+
            labs(x=&amp;quot;&amp;quot;,y=&amp;quot;&amp;quot;)+
            theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2018/the-pie-chart/index.en_files/figure-html/unnamed-chunk-3-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#custom themes definitions
theme_singlebar &amp;lt;- theme_bw()+
  theme(
    legend.position = &amp;quot;bottom&amp;quot;,
    axis.title = element_blank(),
    axis.ticks.y = element_blank(),
    axis.text.y = element_blank(),
    panel.border = element_blank(),
    panel.grid=element_blank(),
    plot.title=element_text(size=14, face=&amp;quot;bold&amp;quot;)
  )

#plot
mutate(measles,
       vacc_status=factor(vacc_status,               #we change the order of the categories
                          rev(levels(vacc_status))))%&amp;gt;%
ggplot(aes(1,prop,fill=vacc_status))+  #we put 1 in x to create a single bar
         geom_bar(stat=&amp;quot;identity&amp;quot;)+
          scale_y_continuous(breaks=seq(0,1,.1),
                             labels=percent,
                             limits=c(0,1),
                             expand=c(.01,.01))+
          scale_x_continuous(expand=c(0,0))+
              scale_fill_brewer(&amp;quot;&amp;quot;,palette=&amp;quot;Set1&amp;quot;)+
                coord_flip()+
                  theme_singlebar&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2018/the-pie-chart/index.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#we expand our data with numbers from Italy
measles2 &amp;lt;- mutate(measles,
                  italy=c(0.826,0.081,0.053,0.013,0.027),
                  vacc_status=factor(vacc_status,rev(levels(vacc_status))))%&amp;gt;%
                rename(europe=&amp;quot;prop&amp;quot;)%&amp;gt;%
                gather(region,prop,europe:italy)

#plot
ggplot(measles2,aes(region,prop,fill=vacc_status))+
            geom_bar(stat=&amp;quot;identity&amp;quot;,position=&amp;quot;stack&amp;quot;)+ #stack bar
             scale_y_continuous(breaks=seq(0,1,.1),
                                labels=percent,    #convert to %
                                limits=c(0,1),
                                expand=c(0,0))+
            scale_fill_brewer(palette = &amp;quot;Set1&amp;quot;)+
            labs(x=&amp;quot;&amp;quot;,y=&amp;quot;&amp;quot;,fill=&amp;quot;Vaccination Status&amp;quot;)+
            theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2018/the-pie-chart/index.en_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;waffle-plot&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Waffle plot&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#package
library(waffle)

#the waffle function uses a vector with names
val_measles &amp;lt;- round(measles$prop*100)
names(val_measles) &amp;lt;- measles$vacc_status

#plot
waffle(val_measles, #data
        colors=brewer.pal(5,&amp;quot;Set1&amp;quot;), #colors
        rows=5) #row number &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2018/the-pie-chart/index.en_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The Waffle chart seems very interesting to me when we want to show a proportion of an individual category.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#data
medida &amp;lt;- c(41,59) #data from the OECD 2015
names(medida) &amp;lt;- c(&amp;quot;Estudios Superiores&amp;quot;,&amp;quot;Otros estudios&amp;quot;)

#plot
waffle(medida,
       colors=c(&amp;quot;#377eb8&amp;quot;,&amp;quot;#bdbdbd&amp;quot;),
       rows=5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2018/the-pie-chart/index.en_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;treemap&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Treemap&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#package
library(treemap)

#plot
treemap(measles,
index=&amp;quot;vacc_status&amp;quot;, #variable with categories
vSize=&amp;quot;prop&amp;quot;,        #values
type=&amp;quot;index&amp;quot;,        #style more in ?treemap
title=&amp;quot;&amp;quot;,            
palette = brewer.pal(5,&amp;quot;Set1&amp;quot;) #colors
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2018/the-pie-chart/index.en_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Personally, I think that all types of graphic representations have their advantages and disadvantages. However, we currently have a huge variety of alternatives to avoid using the pie chart. If you still want to make a pie chart, which I would not rule out either, I recommend following certain rules, which you can find very well summarized in a recent &lt;a href=&#34;https://academy.datawrapper.de/article/127-what-to-consider-when-creating-a-pie-chart&#34;&gt;post&lt;/a&gt; by &lt;a href=&#34;https://twitter.com/lisacrost&#34;&gt;Lisa Charlotte Rost&lt;/a&gt;. For example, you should order from the highest to the lowest unless there is a natural order or use a maximum of five categories. Finally, I leave you a link to a &lt;a href=&#34;https://policyviz.com/2018/08/07/dataviz-cheatsheet/&#34;&gt;cheat sheet&lt;/a&gt; from &lt;em&gt;policyviz&lt;/em&gt; with basic rules of data visualization. A good reference on graphics using different programs from Excel to R can be found in the book &lt;em&gt;Creating More Effective Graphs&lt;/em&gt; (Robbins 2013).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
