<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on Dominic Royé</title>
    <link>https://dominicroye.github.io/en/categories/r/</link>
    <description>Recent content in R on Dominic Royé</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>&amp;copy; 2018-2021 Dominic Royé. All rights reserved.</copyright>
    <lastBuildDate>Tue, 01 Jun 2021 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://dominicroye.github.io/en/categories/r/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Firefly cartography</title>
      <link>https://dominicroye.github.io/en/2021/firefly-cartography/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://dominicroye.github.io/en/2021/firefly-cartography/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2021/firefly-cartography/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;cartography-firefly&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Cartography &lt;em&gt;firefly&lt;/em&gt;&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;Firefly&lt;/em&gt; maps are promoted and described by
&lt;a href=&#34;https://twitter.com/John_M_Nelson&#34;&gt;John Nelson&lt;/a&gt; who published a &lt;a href=&#34;https://adventuresinmapping.com/2016/10/17/firefly-cartography/&#34;&gt;post&lt;/a&gt; in 2016 about its characteristics. However, these types of maps are linked to ArcGIS, which has led me to try to recreate them in R. The recent &lt;code&gt;ggplot2&lt;/code&gt; extension &lt;a href=&#34;https://github.com/marcmenem/ggshadow&#34;&gt;&lt;code&gt;ggshadow&lt;/code&gt;&lt;/a&gt; facilitates the creation of this cartographic style. It is characterized by three elements 1) a dark and unsaturated basemap (eg satellite imagery) 2) a masked vignette and highlighted area and 3) a single bright thematic layer. The essential are the colors and the brightness that is achieved with cold colors, usually neon colors. John Nelson explains more details in this &lt;a href=&#34;https://www.esri.com/arcgis-blog/products/mapping/mapping/steal-this-firefly-style-please/&#34;&gt;post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;What is the &lt;em&gt;firefly&lt;/em&gt; style for? In the words of &lt;a href=&#34;https://www.esri.com/arcgis-blog/products/mapping/mapping/steal-this-firefly-style-please/&#34;&gt;John Nelson&lt;/a&gt;: “the map style that captures our attention and dutifully honors the First Law of Geography”. John refers to what was said by Waldo Tobler
“everything is related to everything else, but near things are more related than distant things” (Tobler 1970).&lt;/p&gt;
&lt;p&gt;In this post we will visualize all earthquakes recorded in southwestern Europe with a magnitude greater than 3.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Packages&lt;/h1&gt;
&lt;p&gt;We will use the following packages:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;14%&#34; /&gt;
&lt;col width=&#34;85%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Package&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;plotwidgets&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Contains functions for color conversion (RGB, HSL)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;terra&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Import, export and manipulate raster (raster successor package)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;raster&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Import, export and manipulate raster&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Simple Feature: import, export and manipulate vector data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ggshadow&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ggplot2 extension for shaded and glow geometries&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ggspatial&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ggplot2 extension for spatial objects&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ggnewscale&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ggplot2 extension to create multiple scales&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;janitor&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Simple functions to examine and clean data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;rnaturalearth&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Vector maps of the world ‘Natural Earth’&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install the packages if necessary

if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;sf&amp;quot;)) install.packages(&amp;quot;sf&amp;quot;)
if(!require(&amp;quot;terra&amp;quot;)) install.packages(&amp;quot;terra&amp;quot;)
if(!require(&amp;quot;raster&amp;quot;)) install.packages(&amp;quot;raster&amp;quot;)
if(!require(&amp;quot;plotwidgets&amp;quot;)) install.packages(&amp;quot;plotwidgets&amp;quot;)
if(!require(&amp;quot;ggshadow&amp;quot;)) install.packages(&amp;quot;ggshadow&amp;quot;)
if(!require(&amp;quot;ggspatial&amp;quot;)) install.packages(&amp;quot;ggspatial&amp;quot;)
if(!require(&amp;quot;ggnewscale&amp;quot;)) install.packages(&amp;quot;ggnewscale&amp;quot;)
if(!require(&amp;quot;janitor&amp;quot;)) install.packages(&amp;quot;janitor&amp;quot;)
if(!require(&amp;quot;rnaturalearth&amp;quot;)) install.packages(&amp;quot;rnaturalearth&amp;quot;)

# load packages

library(raster)
library(terra)
library(sf)
library(tidyverse)
library(plotwidgets)
library(ggshadow)
library(ggspatial)
library(ggnewscale)
library(janitor)
library(rnaturalearth)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;preparation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Preparation&lt;/h1&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;First we download all the necessary data. For the base map we will use the Blue Marble imagery via the access to worldview.earthdata.nasa.gov where I have downloaded a selection of the area of interest in geoTiff format with a resolution of 1 km. It is important to adjust the resolution to the necessary detail of the map.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Blue Marble selection via &lt;a href=&#34;worldview.earthdata.nasa.gov&#34;&gt;worldview.earthdata.nasa.gov&lt;/a&gt; ( ~ 66 MB) &lt;a href=&#34;https://www.dropbox.com/s/bt8qfkzw339q13l/snapshot-2017-11-30T00_00_00Z.tiff?dl=0&#34;&gt;download&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Records of historical earthquakes in southwestern Europe from &lt;a href=&#34;https://www.ign.es/web/ign/portal/sis-catalogo-earthquakes&#34;&gt;IGN&lt;/a&gt; &lt;a href=&#34;https://dominicroye.github.io/files/catalogoComunSV_1621713848556.csv&#34;&gt;download&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;import&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Import&lt;/h2&gt;
&lt;p&gt;The first thing we do is to import the RGB &lt;em&gt;Blue Marble&lt;/em&gt; raster and the earthquake data. To import the raster I use the new package &lt;a href=&#34;https://rspatial.org/terra/pkg/index.html&#34;&gt;&lt;code&gt;terra&lt;/code&gt;&lt;/a&gt; which is the successor of the &lt;code&gt;raster&lt;/code&gt; package. You can find a recent comparison &lt;a href=&#34;https://www.r-bloggers.com/2021/05/a-comparison-of-terra-and-raster-packages/&#34;&gt;here&lt;/a&gt;. Not all packages are yet compatible with the new &lt;code&gt;SpatRaster&lt;/code&gt; class, so we also need the &lt;code&gt;raster&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# earthquakes

earthquakes &amp;lt;- read.csv2(&amp;quot;catalogoComunSV_1621713848556.csv&amp;quot;)
str(earthquakes)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;data.frame&amp;#39;:    149724 obs. of  10 variables:
##  $ Evento       : chr  &amp;quot;          33&amp;quot; &amp;quot;          34&amp;quot; &amp;quot;          35&amp;quot; &amp;quot;          36&amp;quot; ...
##  $ Fecha        : chr  &amp;quot;  02/03/1373&amp;quot; &amp;quot;  03/03/1373&amp;quot; &amp;quot;  08/03/1373&amp;quot; &amp;quot;  19/03/1373&amp;quot; ...
##  $ Hora         : chr  &amp;quot;    00:00:00&amp;quot; &amp;quot;    00:00:00&amp;quot; &amp;quot;    00:00:00&amp;quot; &amp;quot;    00:00:00&amp;quot; ...
##  $ Latitud      : chr  &amp;quot;     42.5000&amp;quot; &amp;quot;     42.5000&amp;quot; &amp;quot;     42.5000&amp;quot; &amp;quot;     42.5000&amp;quot; ...
##  $ Longitud     : chr  &amp;quot;      0.7500&amp;quot; &amp;quot;      0.7500&amp;quot; &amp;quot;      0.7500&amp;quot; &amp;quot;      0.7500&amp;quot; ...
##  $ Prof...Km.   : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ Inten.       : chr  &amp;quot;     VIII-IX&amp;quot; &amp;quot;            &amp;quot; &amp;quot;            &amp;quot; &amp;quot;            &amp;quot; ...
##  $ Mag.         : chr  &amp;quot;            &amp;quot; &amp;quot;            &amp;quot; &amp;quot;            &amp;quot; &amp;quot;            &amp;quot; ...
##  $ Tipo.Mag.    : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ LocalizaciÃ³n: chr  &amp;quot;RibagorÃ§a.L&amp;quot; &amp;quot;RibagorÃ§a.L&amp;quot; &amp;quot;RibagorÃ§a.L&amp;quot; &amp;quot;RibagorÃ§a.L&amp;quot; ...&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Blue Marble RGB raster

bm &amp;lt;- rast(&amp;quot;snapshot-2017-11-30T00_00_00Z.tiff&amp;quot;)
bm # contains three layers (red, green, blue)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class       : SpatRaster 
## dimensions  : 7156, 7156, 3  (nrow, ncol, nlyr)
## resolution  : 0.008789272, 0.008789272  (x, y)
## extent      : -33.49823, 29.39781, 15.77547, 78.67151  (xmin, xmax, ymin, ymax)
## coord. ref. : +proj=longlat +datum=WGS84 +no_defs 
## source      : snapshot-2017-11-30T00_00_00Z.tiff 
## red-grn-blue: 1, 2, 3 
## names       : sna_1, sna_2, sna_3&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# plot

plotRGB(bm)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2021/firefly-cartography/index.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;2100&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# country boundaries

limits &amp;lt;- ne_countries(scale = 50, returnclass = &amp;quot;sf&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;earthquakes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Earthquakes&lt;/h2&gt;
&lt;p&gt;In this step we clean the imported earthquakes data. 1) We convert longitude, latitude and magnitude into numeric using the &lt;code&gt;parse_number()&lt;/code&gt; function and clean the column names with the &lt;code&gt;clean_names()&lt;/code&gt; function, 2) We create a spatial object &lt;code&gt;sf&lt;/code&gt; and project it using the EPSG:3035 corresponding to ETRS89-extended/LAEA Europe.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# we clean the data and create an sf object

earthquakes &amp;lt;-  earthquakes %&amp;gt;% clean_names() %&amp;gt;%
                  mutate(across(c(mag, latitud, longitud),                                                                                                 parse_number)) %&amp;gt;%
                 st_as_sf(coords = c(&amp;quot;longitud&amp;quot;, &amp;quot;latitud&amp;quot;), 
                       crs = 4326) %&amp;gt;% 
                 st_transform(3035) # project to Laea&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;blue-marble-background-map&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Blue Marble background Map&lt;/h2&gt;
&lt;p&gt;We cropped the background map to a smaller extent, but we still haven’t limited to the final area yet.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# clip to the desired area

bm &amp;lt;- crop(bm, extent(-20, 10, 30, 50)) # W, E, S, N&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To obtain an unsaturated version of the Blue Marble RGB raster, we must apply a function created for this purpose. In this, we use the &lt;code&gt;rgb2hsl()&lt;/code&gt; function from the &lt;code&gt;plotwidgets&lt;/code&gt; package, which helps us converting RGB to HSL and vice versa. The HSL model is defined by Hue, Saturation, Lightness. The last two parameters are expressed in ratio or percentage. The hue is defined on a color wheel from 0 to 360º. 0 is red, 120 is green, 240 is blue. To change the saturation we only have to reduce the value of S.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# function to change saturation from RGB

saturation &amp;lt;- function(rgb, s = .5){
  
  hsl &amp;lt;- rgb2hsl(as.matrix(rgb))
  hsl[2, ] &amp;lt;- s
  
  rgb_new &amp;lt;- as.vector(t(hsl2rgb(hsl)))
  
  return(rgb_new)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We employ our &lt;code&gt;saturation()&lt;/code&gt; function using the &lt;code&gt;app()&lt;/code&gt; function that applies it to each pixel with the three RGB layers. We add the argument &lt;code&gt;s&lt;/code&gt;, which defines the desired saturation level. This step may take several minutes. Then we project our RGB image.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# apply the function to unsaturate with 5%

bm_desat &amp;lt;- app(bm, saturation, s = .05)

# plot new RGB image

plotRGB(bm_desat)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2021/firefly-cartography/index.en_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;2100&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# project 

bm_desat &amp;lt;- terra::project(bm_desat, &amp;quot;epsg:3035&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;firefly-map-construction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;em&gt;Firefly&lt;/em&gt; map construction&lt;/h1&gt;
&lt;div id=&#34;boundaries-and-graticules&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Boundaries and graticules&lt;/h2&gt;
&lt;p&gt;Before starting to build the map, we create graticules and set the final map limits.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# define the final map extent

bx &amp;lt;- tibble(x = c(-13, 6.7), y = c(31, 47)) %&amp;gt;% 
       st_as_sf(coords = c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;), crs = 4326) %&amp;gt;%
        st_transform(3035) %&amp;gt;% 
         st_bbox()

# create map graticules

grid &amp;lt;- st_graticule(earthquakes) &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;map-with-image-background&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Map with image background&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;layer_spatial()&lt;/code&gt; function of &lt;code&gt;ggspatial&lt;/code&gt; allows us to add an RGB raster without major problems, however, it still does not support the new&lt;code&gt;SpatRaster&lt;/code&gt; class. Therefore, we must convert it to the &lt;code&gt;stack&lt;/code&gt; class with the &lt;code&gt;stack()&lt;/code&gt; function. It is also possible to use instead of &lt;code&gt;geom_sf()&lt;/code&gt;, the &lt;code&gt;layer_spatial()&lt;/code&gt; function for vector objects of class &lt;code&gt;sf&lt;/code&gt; or&lt;code&gt;sp&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot() +
  layer_spatial(data = stack(bm_desat)) + # blue marble background map
  geom_sf(data = limits, fill = NA, size = .3, colour = &amp;quot;white&amp;quot;) + # country boundaries
  coord_sf(xlim = bx[c(1, 3)], 
           ylim = bx[c(2, 4)], 
           crs = 3035,
           expand = FALSE) +
  theme_void()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2021/firefly-cartography/index.en_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;4500&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;map-with-background-and-earthquakes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Map with background and earthquakes&lt;/h2&gt;
&lt;p&gt;To create the glow effect on &lt;em&gt;firefly&lt;/em&gt; maps, we use the &lt;code&gt;geom_glowpoint()&lt;/code&gt; function from the &lt;code&gt;ggshadow&lt;/code&gt; package. There is also the same function for lines. Since our data is of spatial class &lt;code&gt;sf&lt;/code&gt; and the geometry &lt;code&gt;sf&lt;/code&gt; is not directly supported, we must indicate as an argument &lt;code&gt;stats = &#34;sf_coordinates&#34;&lt;/code&gt; and inside &lt;code&gt;aes()&lt;/code&gt; indicate &lt;code&gt;geometry = geometry&lt;/code&gt;. We will map the size of the points as a function of magnitude. In addition, we filter those earthquakes with a magnitude greater than 3.&lt;/p&gt;
&lt;p&gt;Inside the &lt;code&gt;geom_glowpoint()&lt;/code&gt; function, 1) we define the desired color for the point and the glow effect, 2) the degree of transparency with &lt;code&gt;alpha&lt;/code&gt; either for the point or for the glow. Finally, in the &lt;code&gt;scale_size()&lt;/code&gt; function we set the range (minimum, maximum) of the size that the points will have.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot() +
  layer_spatial(data = stack(bm_desat)) +
  geom_sf(data = limits, fill = NA, size = .3, colour = &amp;quot;white&amp;quot;) +
  geom_sf(data = grid, colour = &amp;quot;white&amp;quot;, size = .1, alpha = .5) +
  geom_glowpoint(data = filter(earthquakes, mag &amp;gt; 3),
                 aes(geometry = geometry, size = mag), 
                   alpha = .8,
                   color = &amp;quot;#6bb857&amp;quot;,
                   shadowcolour = &amp;quot;#6bb857&amp;quot;,
                   shadowalpha = .1,
                   stat = &amp;quot;sf_coordinates&amp;quot;,
                   show.legend = FALSE) +
  scale_size(range = c(.1, 1.5)) +
  coord_sf(xlim = bx[c(1, 3)], 
           ylim = bx[c(2, 4)], 
           crs = 3035,
           expand = FALSE) +
  theme_void()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2021/firefly-cartography/index.en_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;4500&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;final-map&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Final map&lt;/h2&gt;
&lt;p&gt;The glow effect of &lt;em&gt;firefly&lt;/em&gt; maps is characterized by having a white tone or a lighter tone in the center of the points. To achieve this, we must duplicate the previous created layer, changing only the color and make the glow points smaller.&lt;/p&gt;
&lt;p&gt;By default, &lt;code&gt;ggplot2&lt;/code&gt; does not allow to use multiple scales for the same characteristic (size, color, etc) of different layers. But the &lt;code&gt;ggnewscale&lt;/code&gt; package gives us the ability to incorporate multiple scales of a feature from different layers. The only important thing to achieve this is the order in which each layer (geom) and scale is added. First we must add the geometry and then its corresponding scale. We indicate with &lt;code&gt;new_scale(&#39;size&#39;)&lt;/code&gt; that the next layer and scale is a new one independent of the previous one. If we used &lt;code&gt;color&lt;/code&gt; or &lt;code&gt;fill&lt;/code&gt; it would be done with &lt;code&gt;new_scale_*()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot() +
  layer_spatial(data = stack(bm_desat)) +
  geom_sf(data = limits, fill = NA, size = .3, colour = &amp;quot;white&amp;quot;) +
  geom_sf(data = grid, colour = &amp;quot;white&amp;quot;, size = .1, alpha = .5) +
  geom_glowpoint(data = filter(earthquakes, mag &amp;gt; 3),
                   aes(geometry = geometry, size = mag), 
                   alpha = .8,
                   color = &amp;quot;#6bb857&amp;quot;,
                   shadowcolour = &amp;quot;#6bb857&amp;quot;,
                   shadowalpha = .1,
                   stat = &amp;quot;sf_coordinates&amp;quot;,
                   show.legend = FALSE) +
  scale_size(range = c(.1, 1.5)) +
  new_scale(&amp;quot;size&amp;quot;) +
  geom_glowpoint(data = filter(earthquakes, mag &amp;gt; 3),
                   aes(geometry = geometry, size = mag), 
                   alpha = .6,
                   shadowalpha = .05,
                   color = &amp;quot;#ffffff&amp;quot;,
                   stat = &amp;quot;sf_coordinates&amp;quot;,
                   show.legend = FALSE) +
  scale_size(range = c(.01, .7)) +
  labs(title = &amp;quot;EARTHQUAKES&amp;quot;) +
  coord_sf(xlim = bx[c(1, 3)], ylim = bx[c(2, 4)], crs = 3035,
           expand = FALSE) +
  theme_void() +
  theme(plot.title = element_text(size = 50, vjust = -5, colour = &amp;quot;white&amp;quot;, hjust = .95))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2021/firefly-cartography/index.en_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;4500&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggsave(&amp;quot;firefly_map.png&amp;quot;, width = 15, height = 15, units = &amp;quot;in&amp;quot;, dpi = 300)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
      
            <category>firefly</category>
      
            <category>map</category>
      
            <category>earthquake</category>
      
            <category>cartography</category>
      
      
            <category>gis</category>
      
            <category>R</category>
      
            <category>R:intermediate</category>
      
            <category>visualization</category>
      
    </item>
    
    <item>
      <title>Bivariate dasymetric map</title>
      <link>https://dominicroye.github.io/en/2021/bivariate-dasymetric-map/</link>
      <pubDate>Mon, 01 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://dominicroye.github.io/en/2021/bivariate-dasymetric-map/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2021/bivariate-dasymetric-map/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;initial-considerations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Initial considerations&lt;/h1&gt;
&lt;p&gt;A disadvantage of choropleth maps is that they tend to distort the relationship between the true underlying geography and the represented variable. It is because the administrative divisions do not usually coincide with the geographical reality where people live. Besides, large areas appear to have a weight that they do not really have because of sparsely populated regions. To better reflect reality, more realistic population distributions are used, such as land use. With Geographic Information Systems techniques, it is possible to redistribute the variable of interest as a function of a variable with a smaller spatial unit.&lt;/p&gt;
&lt;p&gt;With point data, the redistribution process is simply clipping points with population based on land use, usually classified as urban. We could also crop and mask with land use polygons when we have a vectorial polygon layer, but an interesting alternative is the same data in raster format. We will see how we can make a dasymetric map using raster data with a resolution of 100 m. This post will use data from census sections of the median income and the Gini index for Spain. We will make a dasymetric and bivariate map, representing both variables with two ranges of colours on the same map.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Packages&lt;/h1&gt;
&lt;p&gt;In this post we will use the following packages:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;10%&#34; /&gt;
&lt;col width=&#34;89%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Package&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;patchwork&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Simple grammar to combine separate ggplots into the same graphic&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;raster&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Import, export and manipulate raster&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Simple Feature: import, export and manipulate vector data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;biscale&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Tools and Palettes for Bivariate Thematic Mapping&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sysfonts&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Load fonts in R&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;showtext&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Use fonts more easily in R graphs&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install the packages if necessary
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;patchwork&amp;quot;)) install.packages(&amp;quot;patchwork&amp;quot;)
if(!require(&amp;quot;sf&amp;quot;)) install.packages(&amp;quot;sf&amp;quot;)
if(!require(&amp;quot;raster&amp;quot;)) install.packages(&amp;quot;raster&amp;quot;)
if(!require(&amp;quot;biscale&amp;quot;)) install.packages(&amp;quot;biscale&amp;quot;)
if(!require(&amp;quot;sysfonts&amp;quot;)) install.packages(&amp;quot;sysfonts&amp;quot;)
if(!require(&amp;quot;showtext&amp;quot;)) install.packages(&amp;quot;showtext&amp;quot;)

# packages
library(tidyverse)
library(sf)
library(readxl)
library(biscale)
library(patchwork)
library(raster)
library(sysfonts)
library(showtext)
library(raster)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;preparation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Preparation&lt;/h1&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;First we download all the necessary data. With the exception of the CORINE Land Cover (~ 200 MB), the data stored on this blog can be obtained directly via the indicated links.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CORINE Land Cover 2018 (geotiff): &lt;a href=&#34;https://land.copernicus.eu/pan-european/corine-land-cover/clc2018?tab=download&#34;&gt;COPERNICUS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Income data and Gini index (excel) [INE]: &lt;a href=&#34;https://dominicroye.github.io/files/renta.zip&#34;&gt;download&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Census limits of Spain (vectorial) [INE]: &lt;a href=&#34;https://dominicroye.github.io/files/SECC_CE_20200101.zip&#34;&gt;download&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;import&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Import&lt;/h2&gt;
&lt;p&gt;The first thing we do is to import the land use raster, the income and Gini index data, and the census boundaries.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# raster of CORINE LAND COVER 2018
urb &amp;lt;- raster(&amp;quot;U2018_CLC2018_V2020_20u1.tif&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in showSRID(uprojargs, format = &amp;quot;PROJ&amp;quot;, multiline = &amp;quot;NO&amp;quot;, prefer_proj
## = prefer_proj): Discarded datum Unknown based on GRS80 ellipsoid in Proj4
## definition&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# income data and Gini index
renta &amp;lt;- read_excel(&amp;quot;30824.xlsx&amp;quot;)
gini &amp;lt;- read_excel(&amp;quot;37677.xlsx&amp;quot;)

# census boundaries
limits &amp;lt;- read_sf(&amp;quot;SECC_CE_20200101.shp&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;land-uses&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Land uses&lt;/h2&gt;
&lt;p&gt;In this first step we filter the census sections to obtain those of the Autonomous Community of Madrid, and we create the municipal limits. To dissolve the polygons of census tracts we apply the function &lt;code&gt;group_by()&lt;/code&gt; in combination with &lt;code&gt;summarise()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# filter the Autonomous Community of Madrid
limits &amp;lt;- filter(limits, NCA == &amp;quot;Comunidad de Madrid&amp;quot;)

# obtain the municipal limits
mun_limit &amp;lt;- group_by(limits, CUMUN) %&amp;gt;% summarise()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the next step we cut the land use raster with the limits of Madrid. I recommend always using the &lt;code&gt;crop()&lt;/code&gt; function first and then &lt;code&gt;mask()&lt;/code&gt;, the first function crop to the required extent and the second mask the values. Subsequently, we remove all the cells that correspond to 1 or 2 (urban continuous, discontinuous). Finally, we project the raster.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# project the limits
limits_prj &amp;lt;- st_transform(limits, projection(urb))

# crop and mask 
urb_mad &amp;lt;- crop(urb, limits_prj) %&amp;gt;% 
              mask(limits_prj)

# remove non-urban pixels
urb_mad[!urb_mad %in% 1:2] &amp;lt;- NA 

# plot the raster
plot(urb_mad)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2021/bivariate-dasymetric-map/index.en_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;2100&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# project
urb_mad &amp;lt;- projectRaster(urb_mad, crs = CRS(&amp;quot;+proj=longlat +datum=WGS84 +no_defs&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this step, we convert the raster data into a point &lt;code&gt;sf&lt;/code&gt; object.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# transform the raster to xyz and a sf object
urb_mad &amp;lt;- as.data.frame(urb_mad, xy = TRUE, na.rm = TRUE) %&amp;gt;%
                st_as_sf(coords = c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;), crs = 4326)

# add the columns of the coordinates
urb_mad &amp;lt;- urb_mad %&amp;gt;% rename(urb = 1) %&amp;gt;% cbind(st_coordinates(urb_mad))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;income-data-and-gini-index&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Income data and Gini index&lt;/h2&gt;
&lt;p&gt;The format of the Excels does not coincide with the original of the INE, since I have cleaned the format before in order to make this post easier. What remains is to create a column with the codes of the census sections and exclude data that correspond to another administrative level.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## income and Gini index data

renta_sec &amp;lt;- mutate(renta, NATCODE = str_extract(CUSEC, &amp;quot;[0-9]{5,10}&amp;quot;), 
                nc_len = str_length(NATCODE),
                mun_name = str_remove(CUSEC, NATCODE) %&amp;gt;% str_trim()) %&amp;gt;%
             filter(nc_len &amp;gt; 5)

gini_sec &amp;lt;- mutate(gini, NATCODE = str_extract(CUSEC, &amp;quot;[0-9]{5,10}&amp;quot;), 
               nc_len = str_length(NATCODE),
               mun_name = str_remove(CUSEC, NATCODE) %&amp;gt;% str_trim()) %&amp;gt;%
             filter(nc_len &amp;gt; 5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the next step we join both tables with the census tracts using &lt;code&gt;left_join()&lt;/code&gt; and convert columns of interest in numerical mode.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# join both the income and Gini tables with the census limits
mad &amp;lt;- left_join(limits, renta_sec, by = c(&amp;quot;CUSEC&amp;quot;=&amp;quot;NATCODE&amp;quot;)) %&amp;gt;% 
          left_join(gini_sec, by = c(&amp;quot;CUSEC&amp;quot;=&amp;quot;NATCODE&amp;quot;))

# convert selected columns to numeric
mad &amp;lt;- mutate_at(mad, c(23:27, 30:31), as.numeric)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;bivariate-variable&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bivariate variable&lt;/h2&gt;
&lt;p&gt;To create a bivariate map we must construct a single variable that combines different classes of two variables. Usually we make three classes of each variable which leads to nine combinations; in our case, the average income and the Gini index. The &lt;code&gt;biscale&lt;/code&gt; package includes helper functions to carry out this process. With the &lt;code&gt;bi_class()&lt;/code&gt; function we create the classification variable using quantiles as algorithm. Since in both variables we find missing values, we correct those combinations between both variables where an &lt;code&gt;NA&lt;/code&gt; appears.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create bivariate classification
mapbivar &amp;lt;- bi_class(mad, GINI_2017, RNMP_2017, style = &amp;quot;quantile&amp;quot;, dim = 3) %&amp;gt;% 
             mutate(bi_class = ifelse(str_detect(bi_class, &amp;quot;NA&amp;quot;), NA, bi_class))

# results
head(dplyr::select(mapbivar, GINI_2017, RNMP_2017, bi_class))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Simple feature collection with 6 features and 3 fields
## geometry type:  MULTIPOLYGON
## dimension:      XY
## bbox:           xmin: 415538.9 ymin: 4451487 xmax: 469341.7 ymax: 4552422
## projected CRS:  ETRS89 / UTM zone 30N
## # A tibble: 6 x 4
##   GINI_2017 RNMP_2017 bi_class                                          geometry
##       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;                                   &amp;lt;MULTIPOLYGON [m]&amp;gt;
## 1      NA          NA &amp;lt;NA&amp;gt;     (((446007.9 4552348, 446133.7 4552288, 446207.8 ~
## 2      31       13581 2-2      (((460243.8 4487756, 460322.4 4487739, 460279 44~
## 3      30       12407 2-2      (((457392.5 4486262, 457391.6 4486269, 457391.1 ~
## 4      34.3     13779 3-2      (((468720.8 4481374, 468695.5 4481361, 468664.6 ~
## 5      33.5      9176 3-1      (((417140.2 4451736, 416867.5 4451737, 416436.8 ~
## 6      26.2     10879 1-1      (((469251.9 4480826, 469268.1 4480797, 469292.6 ~&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We finish by redistributing the inequality variable over the pixels of urban land use. The &lt;code&gt;st_join()&lt;/code&gt; function joins the data with the land use points.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# redistribute urban pixels to inequality
mapdasi &amp;lt;- st_join(urb_mad, st_transform(mapbivar, 4326))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;map-building&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Map building&lt;/h1&gt;
&lt;div id=&#34;legend-and-font&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Legend and font&lt;/h2&gt;
&lt;p&gt;Before constructing both maps we must create the legend using the &lt;code&gt;bi_legend()&lt;/code&gt; function. In the function we define the titles for each variable, the number of dimensions and the color scale. Finally, we add the Montserrat font for the final titles in the graphic.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# bivariate legend
legend2 &amp;lt;- bi_legend(pal = &amp;quot;DkViolet&amp;quot;,
                     dim = 3,
                     xlab = &amp;quot;Higher inequality&amp;quot;,
                     ylab = &amp;quot;Higher income&amp;quot;,
                     size = 9)


# download font
font_add_google(&amp;quot;Montserrat&amp;quot;, &amp;quot;Montserrat&amp;quot;)
showtext_auto()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;dasymetric-map&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Dasymetric map&lt;/h2&gt;
&lt;p&gt;We build this map using &lt;code&gt;geom_tile()&lt;/code&gt; for the pixels and &lt;code&gt;geom_sf()&lt;/code&gt; for the municipal boundaries. In addition, it will be the map on the right where we also place the legend. To add the legend we use the &lt;code&gt;annotation_custom()&lt;/code&gt; function indicating the position in the geographical coordinates of the map. The &lt;code&gt;biscale&lt;/code&gt; package also helps us with the color definition via the &lt;code&gt;bi_scale_fill()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p2 &amp;lt;- ggplot(mapdasi) + 
  geom_tile(aes(X, Y, 
                fill = bi_class), 
            show.legend = FALSE) +
  geom_sf(data = mun_limit,  
          color = &amp;quot;grey80&amp;quot;, 
          fill = NA, 
          size = 0.2) +
  annotation_custom(ggplotGrob(legend2), 
                    xmin = -3.25, xmax = -2.65,
                    ymin = 40.55, ymax = 40.95) +
  bi_scale_fill(pal = &amp;quot;DkViolet&amp;quot;, 
                dim = 3, 
                na.value = &amp;quot;grey90&amp;quot;) +
  labs(title = &amp;quot;dasymetric&amp;quot;, x = &amp;quot;&amp;quot;, y =&amp;quot;&amp;quot;) +
  bi_theme() +
  theme(plot.title = element_text(family = &amp;quot;Montserrat&amp;quot;, size = 30, face = &amp;quot;bold&amp;quot;)) +
  coord_sf(crs = 4326)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;choropleth-map&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Choropleth map&lt;/h2&gt;
&lt;p&gt;The choropleth map is built in a similar way to the previous map with the difference that we use &lt;code&gt;geom_sf()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1 &amp;lt;- ggplot(mapbivar) + 
  geom_sf(aes(fill = bi_class), 
          colour = NA, 
          size = .1, 
          show.legend = FALSE) +
  geom_sf(data = mun_limit,  
          color = &amp;quot;white&amp;quot;, 
          fill = NA, 
          size = 0.2) +
  bi_scale_fill(pal = &amp;quot;DkViolet&amp;quot;, 
                dim = 3, 
                na.value = &amp;quot;grey90&amp;quot;) +
  labs(title = &amp;quot;choropleth&amp;quot;,  x = &amp;quot;&amp;quot;, y =&amp;quot;&amp;quot;) +
  bi_theme() +
  theme(plot.title = element_text(family = &amp;quot;Montserrat&amp;quot;, size = 30, face = &amp;quot;bold&amp;quot;)) +
  coord_sf(crs = 4326)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;merge-both-maps&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Merge both maps&lt;/h2&gt;
&lt;p&gt;With the help of the &lt;code&gt;patchwork&lt;/code&gt; package, we combine both maps in a single row, first the choropleth map and on its right the dasymmetric map. More details of the grammar used for the combination of graphics &lt;a href=&#34;https://patchwork.data-imaginist.com/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# combine 
p &amp;lt;- p1 | p2

# final map
p&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2021/bivariate-dasymetric-map/index.en_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;3300&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
      
            <category>bivariate</category>
      
            <category>map</category>
      
            <category>inequality</category>
      
            <category>income</category>
      
            <category>Madrid</category>
      
            <category>urban</category>
      
      
            <category>gis</category>
      
            <category>R</category>
      
            <category>R:advanced</category>
      
            <category>visualization</category>
      
    </item>
    
    <item>
      <title>A heatmap as calendar</title>
      <link>https://dominicroye.github.io/en/2020/a-heatmap-as-calendar/</link>
      <pubDate>Sun, 20 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dominicroye.github.io/en/2020/a-heatmap-as-calendar/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2020/a-heatmap-as-calendar/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Recently I was looking for a visual representation to show the daily changes of temperature, precipitation and wind in an application &lt;a href=&#34;https://xeo81.shinyapps.io/MeteoExtremosGalicia/&#34;&gt;xeo81.shinyapps.io/MeteoExtremosGalicia&lt;/a&gt; (in Spanish), which led me to use a heatmap in the form of a calendar. The &lt;a href=&#34;https://shiny.rstudio.com/&#34;&gt;shiny&lt;/a&gt; application is updated every four hours with new data showing calendars for each weather station. The heatmap as a calendar allows you to visualize any variable with a daily time reference.&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Packages&lt;/h2&gt;
&lt;p&gt;In this post we will use the following packages:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;10%&#34; /&gt;
&lt;col width=&#34;89%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Package&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lubridate&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Easy manipulation of dates and times&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ragg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ragg provides a set of high quality and high performance raster devices&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# instalamos los paquetes si hace falta
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;ragg&amp;quot;)) install.packages(&amp;quot;ragg&amp;quot;)
if(!require(&amp;quot;lubridate&amp;quot;)) install.packages(&amp;quot;lubridate&amp;quot;)

# paquetes
library(tidyverse)
library(lubridate)
library(ragg)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For those with less experience with &lt;code&gt;tidyverse&lt;/code&gt;, I recommend the short introduction on this blog &lt;a href=&#34;https://dominicroye.github.io/es/2020/una-muy-breve-introducci%C3%B3n-a-tidyverse/&#34;&gt;post&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;In this example we will use the daily precipitation of Santiago de Compostela for this year 2020 (until December 20) &lt;a href=&#34;https://dominicroye.github.io/files/precipitation_santiago.csv&#34;&gt;download&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# import the data
dat_pr &amp;lt;- read_csv(&amp;quot;precipitation_santiago.csv&amp;quot;)
dat_pr&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 355 x 2
##    date          pr
##    &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt;
##  1 2020-01-01   0  
##  2 2020-01-02   0  
##  3 2020-01-03   5.4
##  4 2020-01-04   0  
##  5 2020-01-05   0  
##  6 2020-01-06   0  
##  7 2020-01-07   0  
##  8 2020-01-08   1  
##  9 2020-01-09   3.8
## 10 2020-01-10   0  
## # ... with 345 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;preparation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Preparation&lt;/h2&gt;
&lt;p&gt;In the first step we must 1) complement the time series from December 21 to December 31 with &lt;code&gt;NA&lt;/code&gt;, 2) add the day of the week, the month, the week number and the day. Depending on whether we want each week to start on Sunday or Monday, we indicate it in the &lt;code&gt;wday()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat_pr &amp;lt;- dat_pr %&amp;gt;% 
          complete(date = seq(ymd(&amp;quot;2020-01-01&amp;quot;), 
                              ymd(&amp;quot;2020-12-31&amp;quot;), 
                              &amp;quot;day&amp;quot;)) %&amp;gt;%
          mutate(weekday = wday(date, label = T, week_start = 1), 
                 month = month(date, label = T, abbr = F),
                 week = isoweek(date),
                 day = day(date))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the next step we need to make a change in the week of the year, which is because in certain years there may be, for example, a few days at the end of the year as the first week of the following year. We also create two new columns. On the one hand, we categorize precipitation into 14 classes and on the other, we define a white text color for darker tones in the heatmap.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat_pr &amp;lt;- mutate(dat_pr, 
                 week = case_when(month == &amp;quot;December&amp;quot; &amp;amp; week == 1 ~ 53,
                                  month == &amp;quot;January&amp;quot; &amp;amp; week %in% 52:53 ~ 0,
                                  TRUE ~ week),
                 pcat = cut(pr, c(-1, 0, .5, 1:5, 7, 9, 15, 20, 25, 30, 300)),
                 text_col = ifelse(pcat %in% c(&amp;quot;(15,20]&amp;quot;, &amp;quot;(20,25]&amp;quot;, &amp;quot;(25,30]&amp;quot;, &amp;quot;(30,300]&amp;quot;), 
                                   &amp;quot;white&amp;quot;, &amp;quot;black&amp;quot;)) 
      
dat_pr  &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 366 x 8
##    date          pr weekday month    week   day pcat    text_col
##    &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;ord&amp;gt;   &amp;lt;ord&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt;   &amp;lt;chr&amp;gt;   
##  1 2020-01-01   0   Wed     January     1     1 (-1,0]  black   
##  2 2020-01-02   0   Thu     January     1     2 (-1,0]  black   
##  3 2020-01-03   5.4 Fri     January     1     3 (5,7]   black   
##  4 2020-01-04   0   Sat     January     1     4 (-1,0]  black   
##  5 2020-01-05   0   Sun     January     1     5 (-1,0]  black   
##  6 2020-01-06   0   Mon     January     2     6 (-1,0]  black   
##  7 2020-01-07   0   Tue     January     2     7 (-1,0]  black   
##  8 2020-01-08   1   Wed     January     2     8 (0.5,1] black   
##  9 2020-01-09   3.8 Thu     January     2     9 (3,4]   black   
## 10 2020-01-10   0   Fri     January     2    10 (-1,0]  black   
## # ... with 356 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;visualization&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Visualization&lt;/h2&gt;
&lt;p&gt;First we create a color ramp from Brewer colors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# color ramp
pubu &amp;lt;- RColorBrewer::brewer.pal(9, &amp;quot;PuBu&amp;quot;)
col_p &amp;lt;- colorRampPalette(pubu)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Second, before building the chart, we define a custom theme as a function. To do this, we specify all the elements and their modifications with the help of the &lt;code&gt;theme()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;theme_calendar &amp;lt;- function(){

 theme(aspect.ratio = 1/2,
       
       axis.title = element_blank(),
       axis.ticks = element_blank(),
       axis.text.y = element_blank(),
       axis.text = element_text(family = &amp;quot;Montserrat&amp;quot;),
       
       panel.grid = element_blank(),
       panel.background = element_blank(),
       
       strip.background = element_blank(),
       strip.text = element_text(family = &amp;quot;Montserrat&amp;quot;, face = &amp;quot;bold&amp;quot;, size = 15),
       
       legend.position = &amp;quot;top&amp;quot;,
       legend.text = element_text(family = &amp;quot;Montserrat&amp;quot;, hjust = .5),
       legend.title = element_text(family = &amp;quot;Montserrat&amp;quot;, size = 9, hjust = 1),
       
       plot.caption =  element_text(family = &amp;quot;Montserrat&amp;quot;, hjust = 1, size = 8),
       panel.border = element_rect(colour = &amp;quot;grey&amp;quot;, fill=NA, size=1),
       plot.title = element_text(family = &amp;quot;Montserrat&amp;quot;, hjust = .5, size = 26, 
                                 face = &amp;quot;bold&amp;quot;, 
                                 margin = margin(0,0,0.5,0, unit = &amp;quot;cm&amp;quot;)),
       plot.subtitle = element_text(family = &amp;quot;Montserrat&amp;quot;, hjust = .5, size = 16)
  )
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we build the final chart using &lt;code&gt;geom_tile()&lt;/code&gt; and specify the day of the week as the X axis and the week number as the Y axis. As you can see in the variable of the week number (&lt;code&gt;-week&lt;/code&gt;), I change the sign so that the first day of each month is in the first row. With &lt;code&gt;geom_text()&lt;/code&gt; we add the number of each day with its color according to what we defined previously. In &lt;code&gt;guides&lt;/code&gt; we make the adjustments of the colorbar and in &lt;code&gt;scale_fill/colour_manual()&lt;/code&gt; we define the corresponding colors. An important step is found in &lt;code&gt;facet_wrap()&lt;/code&gt; where we specify the facets composition of each month. The facets should have free scales and the ideal would be a 4 x 3 facet distribution. It is possible to modify the position of the day number to another using the arguments &lt;code&gt;nudge_*&lt;/code&gt; in &lt;code&gt;geom_text()&lt;/code&gt; (eg bottom-right corner: nudge_x = .35, nudge_y = -.25).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;    ggplot(dat_pr, 
           aes(weekday, -week, fill = pcat)) +
      geom_tile(colour = &amp;quot;white&amp;quot;, size = .4)  + 
      geom_text(aes(label = day, colour = text_col), size = 2.5) +
      guides(fill = guide_colorsteps(barwidth = 25, 
                                     barheight = .4,
                                    title.position = &amp;quot;top&amp;quot;)) +
       scale_fill_manual(values = c(&amp;quot;white&amp;quot;, col_p(13)),
                         na.value = &amp;quot;grey90&amp;quot;, drop = FALSE) +
       scale_colour_manual(values = c(&amp;quot;black&amp;quot;, &amp;quot;white&amp;quot;), guide = FALSE) + 
       facet_wrap(~ month, nrow = 4, ncol = 3, scales = &amp;quot;free&amp;quot;) +
       labs(title = &amp;quot;How is 2020 being in Santiago?&amp;quot;, 
             subtitle = &amp;quot;Precipitation&amp;quot;,
             caption = &amp;quot;Data: Meteogalicia&amp;quot;,
             fill = &amp;quot;mm&amp;quot;) +
       theme_calendar()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/a-heatmap-as-calendar/index.en_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To export we will use the &lt;a href=&#34;https://github.com/r-lib/ragg&#34;&gt;&lt;code&gt;ragg&lt;/code&gt;&lt;/a&gt; package, which provides higher performance and quality than the standard raster devices provided by grDevices.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggsave(&amp;quot;pr_calendar.png&amp;quot;, height = 10, width = 8, device = agg_png())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In other heatmap calendars I have added the predominant wind direction of each day as an arrow using &lt;code&gt;geom_arrow()&lt;/code&gt; from the &lt;code&gt;metR&lt;/code&gt; package (it can be seen in the aforementioned application).&lt;/p&gt;
&lt;/div&gt;
</description>
      
            <category>calendar</category>
      
            <category>temperature</category>
      
            <category>climate</category>
      
            <category>heatmap</category>
      
      
            <category>visualization</category>
      
            <category>R</category>
      
            <category>R:intermediate</category>
      
    </item>
    
    <item>
      <title>Climate animation of maximum temperatures</title>
      <link>https://dominicroye.github.io/en/2020/climate-animation-of-maximum-temperatures/</link>
      <pubDate>Sun, 11 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dominicroye.github.io/en/2020/climate-animation-of-maximum-temperatures/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2020/climate-animation-of-maximum-temperatures/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;In the field of data visualization, the animation of spatial data in its temporal dimension can show fascinating changes and patterns. As a result of one of the last publications in the social networks that I have made, I was asked to make a post about how I created it. Well, here we go to start with an example of data from mainland Spain. You can find more animations in the graphics &lt;a href=&#34;https://dominicroye.github.io/en/graphs/climate/&#34;&gt;section&lt;/a&gt; of my blog.&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;I couldn&amp;#39;t resist to make another animation. Smoothed daily maximum temperature throughout the year in Europe. &lt;a href=&#34;https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rstats&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/ggplot2?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#ggplot2&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/dataviz?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#dataviz&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/climate?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#climate&lt;/a&gt; &lt;a href=&#34;https://t.co/ZC9L0vh3vR&#34;&gt;pic.twitter.com/ZC9L0vh3vR&lt;/a&gt;&lt;/p&gt;&amp;mdash; Dominic Royé (@dr_xeo) &lt;a href=&#34;https://twitter.com/dr_xeo/status/1259059168817930240?ref_src=twsrc%5Etfw&#34;&gt;May 9, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Packages&lt;/h2&gt;
&lt;p&gt;In this post we will use the following packages:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;14%&#34; /&gt;
&lt;col width=&#34;85%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Packages&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;rnaturalearth&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Vector maps of the world ‘Natural Earth’&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lubridate&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Easy manipulation of dates and times&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Simple Feature: import, export and manipulate vector data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;raster&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Import, export and manipulate raster&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ggthemes&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Themes for ggplot2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;gifski&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Create gifs&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;showtext&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Use fonts more easily in R graphs&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sysfonts&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Load fonts in R&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install the packages if necessary
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;rnaturalearth&amp;quot;)) install.packages(&amp;quot;rnaturalearth&amp;quot;)
if(!require(&amp;quot;lubridate&amp;quot;)) install.packages(&amp;quot;lubridate&amp;quot;)
if(!require(&amp;quot;sf&amp;quot;)) install.packages(&amp;quot;sf&amp;quot;)
if(!require(&amp;quot;ggthemes&amp;quot;)) install.packages(&amp;quot;ggthemes&amp;quot;)
if(!require(&amp;quot;gifski&amp;quot;)) install.packages(&amp;quot;gifski&amp;quot;)
if(!require(&amp;quot;raster&amp;quot;)) install.packages(&amp;quot;raster&amp;quot;)
if(!require(&amp;quot;sysfonts&amp;quot;)) install.packages(&amp;quot;sysfonts&amp;quot;)
if(!require(&amp;quot;showtext&amp;quot;)) install.packages(&amp;quot;showtext&amp;quot;)

# packages
library(raster)
library(tidyverse)
library(lubridate)
library(ggthemes)
library(sf)
library(rnaturalearth)
library(extrafont)
library(showtext)
library(RColorBrewer)
library(gifski)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For those with less experience with &lt;code&gt;tidyverse&lt;/code&gt;, I recommend the short introduction on this blog (&lt;a href=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/&#34;&gt;post&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;preparation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Preparation&lt;/h1&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;First, we need to download the STEAD dataset of the maximum temperature (&lt;em&gt;tmax_pen.nc&lt;/em&gt;) in &lt;em&gt;netCDF&lt;/em&gt; format from the CSIC repository &lt;a href=&#34;https://digital.csic.es/handle/10261/177655&#34;&gt;here&lt;/a&gt; (the size of the data is 2 GB). It is a set of data with a spatial resolution of 5 km and includes daily maximum temperatures from 1901 to 2014. In climatology and meteorology, a widely used format is that of &lt;em&gt;netCDF&lt;/em&gt; databases, which allow to obtain a multidimensional structure and to exchange data independently of the usued operating system. It is a space-time format with a regular or irregular grid. The multidimensional structure in the form of arrays or cubes can handle not only spatio-temporal data but also multivariate ones. In our dataset we will have an array of three dimensions: longitude, latitude and time of the maximum temperature.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://dominicroye.github.io/img/3d_ncdf.en.png&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Royé 2015. Sémata: Ciencias Sociais e Humanidades 27:11-37&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;import-the-dataset&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Import the dataset&lt;/h2&gt;
&lt;p&gt;The &lt;em&gt;netCDF&lt;/em&gt; format with &lt;em&gt;.nc&lt;/em&gt; extension can be imported via two main packages: 1) &lt;code&gt;ncdf4&lt;/code&gt; and 2) &lt;code&gt;raster&lt;/code&gt;. Actually, the &lt;code&gt;raster&lt;/code&gt; package use the first package to import the &lt;em&gt;netCDF&lt;/em&gt; datasets. In this post we will use the &lt;code&gt;raster&lt;/code&gt; package since it is somewhat easier, with some very useful and more universal functions for all types of &lt;em&gt;raster&lt;/em&gt; format. The main import functions are: &lt;code&gt;raster()&lt;/code&gt;, &lt;code&gt;stack()&lt;/code&gt; and &lt;code&gt;brick()&lt;/code&gt;. The first function only allows you to import a single layer, instead, the last two functions are used for multidimensional data. In our dataset we only have one variable, therefore it would not be necessary to use the &lt;code&gt;varname&lt;/code&gt; argument.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# import netCDF data
tmx &amp;lt;- brick(&amp;quot;tmax_pen.nc&amp;quot;, varname = &amp;quot;tx&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required namespace: ncdf4&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tmx # metadata&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class      : RasterBrick 
## dimensions : 190, 230, 43700, 41638  (nrow, ncol, ncell, nlayers)
## resolution : 0.0585, 0.045  (x, y)
## extent     : -9.701833, 3.753167, 35.64247, 44.19247  (xmin, xmax, ymin, ymax)
## crs        : +proj=longlat +datum=WGS84 +no_defs 
## source     : tmax_pen.nc 
## names      : X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14, X15, ... 
## Time (days since 1901-01-01): 1, 41638 (min, max)
## varname    : tx&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;RasterBrick&lt;/code&gt; object details show you all the necessary metadata: the resolution, the dimensions or the type of projection, or the name of the variable. It also tells us that it only points to the data source and has not imported them into the memory, which makes it easier to work with large datasets.&lt;/p&gt;
&lt;p&gt;To access any layer we use &lt;code&gt;[[ ]]&lt;/code&gt; with the corresponding index. So we can easily plot any day of the 41,638 days we have.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# map any day
plot(tmx[[200]], col = rev(heat.colors(7)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/climate-animation-of-maximum-temperatures/index.en_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;calculate-the-average-temperature&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Calculate the average temperature&lt;/h2&gt;
&lt;p&gt;In this step the objective is to calculate the average maximum temperature for each day of the year. Therefore, the first thing we do is to create a vector, indicating the day of the year for the entire time series. In the &lt;code&gt;raster&lt;/code&gt; package we have the &lt;code&gt;stackApply()&lt;/code&gt; function that allows us to apply another function on groups of layers, or rather, indexes. Since our dataset is large, we include this function in parallelization functions.&lt;/p&gt;
&lt;p&gt;For the parallelization we start and end always with the &lt;code&gt;beginClusterr()&lt;/code&gt; and &lt;code&gt;endCluster()&lt;/code&gt;. In the first function we must indicate the number of cores we want to use. In this case, I use 4 of 7 possible cores, however, the number must be changed according to the characteristics of each CPU, the general rule is n-1. So the &lt;code&gt;clusterR&lt;/code&gt; function execute a function in parallel with multiple cores. The first argument corresponds to the raster object, the second to the used function, and as list argument we pass the arguments of the &lt;code&gt;stackApply()&lt;/code&gt; function: the indexes that create the groups and the function used for each of the groups. Adding the argument &lt;code&gt;progress = &#39;text&#39;&lt;/code&gt; shows a progress bar of the calculation process.&lt;/p&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  
For the US dataset I did the preprocessing, the calculation of the average, in a cloud computing platform through &lt;a href=&#34;https://earthengine.google.com/&#34;&gt;Google Earth Engine&lt;/a&gt;, which makes the whole process faster. In the case of Australia the preprocessing was more complex as the dataset is separated in multiple &lt;em&gt;netCDF&lt;/em&gt; files for each year.

&lt;/div&gt;
&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# convert the dates between 1901 and 2014 to days of the year
time_days &amp;lt;- yday(seq(as_date(&amp;quot;1901-01-01&amp;quot;), as_date(&amp;quot;2014-12-31&amp;quot;), &amp;quot;day&amp;quot;))

# calculate the average
beginCluster(4)
tmx_mean &amp;lt;- clusterR(tmx, stackApply, args = list(indices = time_days, fun = mean))
endCluster()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;smooth-the-temperature-variability&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Smooth the temperature variability&lt;/h2&gt;
&lt;p&gt;Before we start to smooth the time series of our &lt;em&gt;RasterBrick&lt;/em&gt;, an example of why we do it. We extract a pixel from our dataset at coordinates -1º of longitude and 40º of latitude using the &lt;code&gt;extract()&lt;/code&gt; function. Since the function with the same name appears in several packages, we must change to the form &lt;code&gt;package_name::function_name&lt;/code&gt;. The result is a matrix with a single row corresponding to the pixel and 366 columns of the days of the year. The next step is to create a &lt;em&gt;data.frame&lt;/em&gt; with a &lt;em&gt;dummy&lt;/em&gt; date and the extracted maximum temperature.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract a pixel
point_ts &amp;lt;- raster::extract(tmx_mean, matrix(c(-1, 40), nrow = 1))
dim(point_ts) # dimensions&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]   1 366&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create a data.frame
df &amp;lt;- data.frame(date = seq(as_date(&amp;quot;2000-01-01&amp;quot;), as_date(&amp;quot;2000-12-31&amp;quot;), &amp;quot;day&amp;quot;),
                 tmx = point_ts[1,])

# visualize the maximum temperature
ggplot(df, 
       aes(date, tmx)) + 
     geom_line() + 
  scale_x_date(date_breaks = &amp;quot;month&amp;quot;, date_labels = &amp;quot;%b&amp;quot;) +
  scale_y_continuous(breaks = seq(5, 28, 2)) +
  labs(y = &amp;quot;maximum temperature&amp;quot;, x = &amp;quot;&amp;quot;, colour =  &amp;quot;&amp;quot;) +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/climate-animation-of-maximum-temperatures/index.en_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The graph clearly shows the still existing variability, which would cause an animation to fluctuate quite a bit. Therefore, we create a smoothing function based on a local polynomial regression fit (LOESS), more details can be found in the help of the &lt;code&gt;loess()&lt;/code&gt; function. The most important argument is &lt;code&gt;span&lt;/code&gt;, which determines the degree of smoothing, the smaller the value the less smooth the curve will be. I found the best result showed a value of 0.5.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;daily_smooth &amp;lt;- function(x, span = 0.5){
  
  if(all(is.na(x))){
   
    return(x) 
   
  } else {
    
  df &amp;lt;- data.frame(yd = 1:366, ta = x)
  m &amp;lt;- loess(ta ~ yd, span = span, data = df)
  est &amp;lt;- predict(m, 1:366)

  return(est)
  
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We apply our new smoothing function to the extracted time series and make some changes to be able to visualize the difference between the original and smoothed data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# smooth the temperature
df &amp;lt;- mutate(df, tmx_smoothed = daily_smooth(tmx)) %&amp;gt;% 
          pivot_longer(2:3, names_to = &amp;quot;var&amp;quot;, values_to = &amp;quot;temp&amp;quot;)

# visualize the difference
ggplot(df, 
       aes(date, temp, 
           colour = var)) + 
     geom_line() + 
  scale_x_date(date_breaks = &amp;quot;month&amp;quot;, date_labels = &amp;quot;%b&amp;quot;) +
  scale_y_continuous(breaks = seq(5, 28, 2)) +
  scale_colour_manual(values = c(&amp;quot;#f4a582&amp;quot;, &amp;quot;#b2182b&amp;quot;)) +
  labs(y = &amp;quot;maximum temperature&amp;quot;, x = &amp;quot;&amp;quot;, colour =  &amp;quot;&amp;quot;) +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/climate-animation-of-maximum-temperatures/index.en_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As we see in the graph, the smoothed curve follows the original curve very well. In the next step we apply our function to the &lt;em&gt;RasterBrick&lt;/em&gt; with the &lt;code&gt;calc()&lt;/code&gt; function. The function returns as many layers as those returned by the function used for each of the time series.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# smooth the RasterBrick
tmx_smooth &amp;lt;- calc(tmx_mean, fun = daily_smooth)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;visualization&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Visualization&lt;/h1&gt;
&lt;div id=&#34;preparation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Preparation&lt;/h2&gt;
&lt;p&gt;To visualize the maximum temperatures throughout the year, first, we convert the &lt;em&gt;RasterBrick&lt;/em&gt; to a &lt;em&gt;data.frame&lt;/em&gt;, including longitude and latitude, but removing all time series without values (&lt;code&gt;NA&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# convert to data.frame
tmx_mat &amp;lt;- as.data.frame(tmx_smooth, xy = TRUE, na.rm = TRUE)

# rename the columns 
tmx_mat &amp;lt;- set_names(tmx_mat, c(&amp;quot;lon&amp;quot;, &amp;quot;lat&amp;quot;, str_c(&amp;quot;D&amp;quot;, 1:366)))
str(tmx_mat[, 1:10])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;data.frame&amp;#39;:    20676 obs. of  10 variables:
##  $ lon: num  -8.03 -7.98 -7.92 -7.86 -7.8 ...
##  $ lat: num  43.8 43.8 43.8 43.8 43.8 ...
##  $ D1 : num  10.5 10.3 10 10.9 11.5 ...
##  $ D2 : num  10.5 10.3 10.1 10.9 11.5 ...
##  $ D3 : num  10.5 10.3 10.1 10.9 11.5 ...
##  $ D4 : num  10.6 10.4 10.1 10.9 11.5 ...
##  $ D5 : num  10.6 10.4 10.1 11 11.6 ...
##  $ D6 : num  10.6 10.4 10.1 11 11.6 ...
##  $ D7 : num  10.6 10.4 10.2 11 11.6 ...
##  $ D8 : num  10.6 10.4 10.2 11 11.6 ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Second, we import the administrative boundaries with the &lt;code&gt;ne_countries()&lt;/code&gt; function from the &lt;code&gt;rnaturalearth&lt;/code&gt; package, limiting the extension to the region of the Iberian Peninsula, southern France and northern Africa.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# import global boundaries
map &amp;lt;- ne_countries(scale = 10, returnclass = &amp;quot;sf&amp;quot;) %&amp;gt;% st_cast(&amp;quot;MULTILINESTRING&amp;quot;)

# limit the extension
map &amp;lt;- st_crop(map, xmin = -10, xmax = 5, ymin = 35, ymax = 44) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## although coordinates are longitude/latitude, st_intersection assumes that they are planar&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: attribute variables are assumed to be spatially constant throughout all
## geometries&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# map of boundaries
plot(map)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: plotting the first 9 out of 94 attributes; use max.plot = 94 to plot
## all&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/climate-animation-of-maximum-temperatures/index.en_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Third, we create a vector with the day of the year as labels in order to include them later in the animation. In addition, we define the break points for the maximum temperature, adapted to the distribution of our data, to obtain a categorization with a total of 20 classes.&lt;/p&gt;
&lt;p&gt;Fourth, we apply the &lt;code&gt;cut()&lt;/code&gt; function with the breaks to all the columns with temperature data of each day of the year.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# labels of day of the year
lab &amp;lt;- as_date(0:365, &amp;quot;2000-01-01&amp;quot;) %&amp;gt;% format(&amp;quot;%d %B&amp;quot;)

# breaks for the temperature data
ct &amp;lt;- c(-5, 0, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 40, 45)

# categorized data with fixed breaks
tmx_mat_cat &amp;lt;- mutate_at(tmx_mat, 3:368, cut, breaks = ct)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Fifth, we download the Montserrat font and define the colors corresponding to the created classes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# download font
font_add_google(&amp;quot;Montserrat&amp;quot;, &amp;quot;Montserrat&amp;quot;)

# use of showtext with 300 DPI
showtext_opts(dpi = 300)
showtext_auto()

# define the color ramp
col_spec &amp;lt;- colorRampPalette(rev(brewer.pal(11, &amp;quot;Spectral&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;static-map&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Static map&lt;/h2&gt;
&lt;p&gt;In this first plot we make a map of May 29 (day 150). I am not going to explain all the details of the construction with &lt;code&gt;ggplot2&lt;/code&gt;, however, it is important to note that I use the &lt;code&gt;aes_string()&lt;/code&gt; function instead of &lt;code&gt;aes()&lt;/code&gt; to use the column names in string format. With the &lt;code&gt;geom_raster()&lt;/code&gt; function we add the gridded temperature data as the first layer of the graph and with &lt;code&gt;geom_sf()&lt;/code&gt; the boundaries in &lt;code&gt;sf&lt;/code&gt; class. Finally, the &lt;code&gt;guide_colorsteps()&lt;/code&gt; function allows you to create a nice legend based on the classes created by the &lt;code&gt;cut()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(tmx_mat_cat) + 
         geom_raster(aes_string(&amp;quot;lon&amp;quot;, &amp;quot;lat&amp;quot;, fill = &amp;quot;D150&amp;quot;)) +
         geom_sf(data = map,
                 colour = &amp;quot;grey50&amp;quot;, size = 0.2) +
  coord_sf(expand = FALSE) +
  scale_fill_manual(values = col_spec(20), drop = FALSE) +
  guides(fill = guide_colorsteps(barwidth = 30, 
                                 barheight = 0.5,
                                 title.position = &amp;quot;right&amp;quot;,
                                 title.vjust = .1)) +
   theme_void() +
   theme(legend.position = &amp;quot;top&amp;quot;,
      legend.justification = 1,
      plot.caption = element_text(family = &amp;quot;Montserrat&amp;quot;, 
                                  margin = margin(b = 5, t = 10, unit = &amp;quot;pt&amp;quot;)),                
      plot.title = element_text(family = &amp;quot;Montserrat&amp;quot;, 
                                size = 16, face = &amp;quot;bold&amp;quot;, 
                                margin = margin(b = 2, t = 5, unit = &amp;quot;pt&amp;quot;)),
     legend.text = element_text(family = &amp;quot;Montserrat&amp;quot;),
     plot.subtitle = element_text(family = &amp;quot;Montserrat&amp;quot;, 
                                  size = 13, 
                                  margin = margin(b = 10, t = 5, unit = &amp;quot;pt&amp;quot;))) +
   labs(title = &amp;quot;Average maximum temperature during the year in Spain&amp;quot;, 
     subtitle = lab[150], 
     caption = &amp;quot;Reference period 1901-2014. Data: STEAD&amp;quot;,
     fill = &amp;quot;ºC&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/img/fig_1.en.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;animation-of-the-whole-year&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Animation of the whole year&lt;/h2&gt;
&lt;p&gt;The final animation consists of creating a gif from all the images of 366 days, in principle, the &lt;code&gt;gganimate&lt;/code&gt; package could be used, but in my experience it is slower, since it requires a &lt;code&gt;data.frame&lt;/code&gt; in long format. In this example a long table would have more than seven million rows. So what we do here is to use a loop over the columns and join all the created images with the &lt;code&gt;gifski&lt;/code&gt; package that also uses &lt;code&gt;gganimate&lt;/code&gt; for rendering.&lt;/p&gt;
&lt;p&gt;Before looping we create a vector with the time steps or names of the columns, and another vector with the name of the images, including the name of the folder. In order to obtain a list of images ordered by their number, we must maintain three figures, filling the positions on the left with zeros.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;time_step &amp;lt;- str_c(&amp;quot;D&amp;quot;, 1:366)

files &amp;lt;- str_c(&amp;quot;./ta_anima/D&amp;quot;, str_pad(1:366, 3, &amp;quot;left&amp;quot;, &amp;quot;0&amp;quot;), &amp;quot;.png&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Lastly, we include the above plot construction in a for loop.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;for(i in 1:366){

 ggplot(tmx_mat_cat) + 
         geom_raster(aes_string(&amp;quot;lon&amp;quot;, &amp;quot;lat&amp;quot;, fill = time_step[i])) +
         geom_sf(data = map,
                 colour = &amp;quot;grey50&amp;quot;, size = 0.2) +
  coord_sf(expand = FALSE) +
  scale_fill_manual(values = col_spec(20), drop = FALSE) +
  guides(fill = guide_colorsteps(barwidth = 30, 
                                 barheight = 0.5,
                                 title.position = &amp;quot;right&amp;quot;,
                                 title.vjust = .1)) +
   theme_void() +
   theme(legend.position = &amp;quot;top&amp;quot;,
      legend.justification = 1,
      plot.caption = element_text(family = &amp;quot;Montserrat&amp;quot;, 
                                  margin = margin(b = 5, t = 10, unit = &amp;quot;pt&amp;quot;)),                
      plot.title = element_text(family = &amp;quot;Montserrat&amp;quot;, 
                                size = 16, face = &amp;quot;bold&amp;quot;, 
                                margin = margin(b = 2, t = 5, unit = &amp;quot;pt&amp;quot;)),
     legend.text = element_text(family = &amp;quot;Montserrat&amp;quot;),
     plot.subtitle = element_text(family = &amp;quot;Montserrat&amp;quot;, 
                                  size = 13, 
                                  margin = margin(b = 10, t = 5, unit = &amp;quot;pt&amp;quot;))) +
   labs(title = &amp;quot;Average maximum temperature during the year in Spain&amp;quot;, 
     subtitle = lab[i], 
     caption = &amp;quot;Reference period 1901-2014. Data: STEAD&amp;quot;,
     fill = &amp;quot;ºC&amp;quot;)
  
  ggsave(files[i], width = 8.28, height = 7.33, type = &amp;quot;cairo&amp;quot;)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After having created images for each day of the year, we only have to create the gif.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gifski(files, &amp;quot;tmx_spain.gif&amp;quot;, width = 800, height = 700, loop = FALSE, delay = 0.05)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/img/tmx_spain.en.gif&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
      
            <category>animation</category>
      
            <category>temperature</category>
      
            <category>climte</category>
      
            <category>GIS</category>
      
      
            <category>visualization</category>
      
            <category>R</category>
      
            <category>R:advanced</category>
      
    </item>
    
    <item>
      <title>River flow directions</title>
      <link>https://dominicroye.github.io/en/2020/river-flow-directions/</link>
      <pubDate>Fri, 24 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dominicroye.github.io/en/2020/river-flow-directions/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2020/river-flow-directions/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I recently created a visualization of the distribution of river flow directions and also of coastal orientations. Following its publication in social networks (&lt;a href=&#34;%5Btweet%5D(https://twitter.com/dr_xeo/status/1277978724034465798?s=20)&#34;&gt;here&lt;/a&gt;), I was asked to make a post about how I did it. Well, here we go to start with an example of rivers, coastal orientation is somewhat more complex. I did the same for a selection of European rivers here in this &lt;a href=&#34;https://twitter.com/dr_xeo/status/1277243216828473345?s=20&#34;&gt;tweet&lt;/a&gt;. However, originally I started with the orientation of the European coasts.&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Have you ever wondered where the European &lt;a href=&#34;https://twitter.com/hashtag/coasts?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#coasts&lt;/a&gt; are oriented? &lt;a href=&#34;https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rstats&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/ggplot2?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#ggplot2&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/geography?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#geography&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/dataviz?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#dataviz&lt;/a&gt; &lt;a href=&#34;https://t.co/tpWVxSoHlw&#34;&gt;pic.twitter.com/tpWVxSoHlw&lt;/a&gt;&lt;/p&gt;&amp;mdash; Dominic Royé (@dr_xeo) &lt;a href=&#34;https://twitter.com/dr_xeo/status/1265286552525180929?ref_src=twsrc%5Etfw&#34;&gt;May 26, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Packages&lt;/h2&gt;
&lt;p&gt;In this post we will use the following packages:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;10%&#34; /&gt;
&lt;col width=&#34;89%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Packages&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;remotes&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Installation from remote repositories&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;RQGIS3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Interface between R and QGIS3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Simple Feature: import, export and manipulate vector data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ggtext&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Improved text rendering support for ggplot2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sysfonts&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Load fonts in R&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;showtext&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Use fonts more easily in R graphs&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;circular&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Functions for working with circular data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;geosphere&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Spherical trigonometry for geographic applications&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;In the case of the &lt;code&gt;RQGIS3&lt;/code&gt; package, it is necessary to install QGIS in OSGeo4W &lt;a href=&#34;https://www.qgis.org/es/site/forusers/download.html&#34;&gt;here&lt;/a&gt;. I will explain the reason for using QGIS later.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install the packages if necessary
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;remotes&amp;quot;)) install.packages(&amp;quot;remotes&amp;quot;)
if(!require(&amp;quot;RQGIS3&amp;quot;)) remotes::install_github(&amp;quot;jannes-m/RQGIS3&amp;quot;)
if(!require(&amp;quot;sf&amp;quot;)) install.packages(&amp;quot;sf&amp;quot;)
if(!require(&amp;quot;ggtext&amp;quot;)) install.packages(&amp;quot;ggtext&amp;quot;)
if(!require(&amp;quot;circular&amp;quot;)) install.packages(&amp;quot;circular&amp;quot;)
if(!require(&amp;quot;geosphere&amp;quot;)) install.packages(&amp;quot;geosphere&amp;quot;)
if(!require(&amp;quot;sysfonts&amp;quot;)) install.packages(&amp;quot;sysfonts&amp;quot;)
if(!require(&amp;quot;showtext&amp;quot;)) install.packages(&amp;quot;showtext&amp;quot;)

# packages
library(sf)
library(tidyverse)
library(ggtext)
library(circular)
library(geosphere)
library(RQGIS3)
library(showtext)
library(sysfonts)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;initial-considerations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Initial considerations&lt;/h1&gt;
&lt;p&gt;Angles in vectorial lines are based on the angle between two vertices, and the number of vertices depends on the complexity, and therefore the resolution, of the vector data. Consequently, there can be differences in using different resolutions of a spatial line, either from the coast or from the river as in this example. A straight line is simply constructed with two points of longitude and latitude.&lt;/p&gt;
&lt;p&gt;Related to this is fractality, an apparently irregular structure but that is repeated at different scales, known from coastlines or also from river. The most paradoxical feature is that the length of a coastline depends on the measurement scale, the smaller the measurement increment, the longer is the measured coastline.&lt;/p&gt;
&lt;p&gt;There are two possibilities of obtaining the vertice angles. In the first one we calculate the angle between all consecutive vertices.&lt;/p&gt;
&lt;p&gt;For example, imagine two points, Madrid (-3.71, 40.43) and Barcelona (2.14, 41.4).&lt;/p&gt;
&lt;p&gt;What is the angle of a straight line between both cities?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bearingRhumb(c(-3.71, 40.43), c(2.14, 41.4))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 77.62391&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that it is 77º, that is, northeast direction. But what if we go from Barcelona to Madrid?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bearingRhumb(c(2.14, 41.4), c(-3.71, 40.43))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 257.6239&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The angle is different because we &lt;em&gt;move&lt;/em&gt; from the northeast to the southwest. We can easily invert the direction to get the opposite angle.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# opposite angle of Barcelona -&amp;gt; Madrid
bearingRhumb(c(2.14, 41.4), c(-3.71, 40.43)) - 180&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 77.62391&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# opposite angle of Madrid -&amp;gt; Barcelona
bearingRhumb(c(-3.71, 40.43), c(2.14, 41.4)) + 180&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 257.6239&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The direction in which we calculate the angles is important. In the case of rivers, it is expected to be the direction of flow from origin to the mouth, however, a problem may be that the vertices, which build the lines, are not geographically ordered in the attribute table. Another problem may be that the vertices start at the mouth which would give the reverse angle as we have seen before.&lt;/p&gt;
&lt;p&gt;However, there is an easier way. We can take advantage of the attributes of projected coordinate systems (Robinson projection, etc.) that include the angle between the vertices. We will use this last approach in this post. Still, we must pay close attention to the results as stated above.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;preparation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Preparation&lt;/h1&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;We download the central lines of the largest rivers in the world (&lt;a href=&#34;https://dominicroye.github.io/files/RiverHRCenterlinesCombo.zip&#34;&gt;here&lt;/a&gt;), also accessible in &lt;a href=&#34;https://www.sciencebase.gov/catalog/item/5a145fdde4b09fc93dcfd36c&#34;&gt;Zeenatul Basher et al. 2018&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;import-and-project&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Import and project&lt;/h2&gt;
&lt;p&gt;The first thing we do is to import, project the spatial lines and delete the third dimension &lt;em&gt;Z&lt;/em&gt;, chaining the following functions: &lt;code&gt;st_read()&lt;/code&gt; helps us import any vector format, &lt;code&gt;st_zm()&lt;/code&gt; delete the dimension Z or M of a geometry and &lt;code&gt;st_transform()&lt;/code&gt; projects the vector data to the new projection in &lt;em&gt;proj4&lt;/em&gt; format. We combine the functions with the famous pipe (&lt;code&gt;%&amp;gt;%&lt;/code&gt;) that facilitates the application of a sequence of functions on a data set, more details in this &lt;a href=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/&#34;&gt;post&lt;/a&gt;. All functions in the &lt;code&gt;sf&lt;/code&gt; package start with &lt;code&gt;st_*&lt;/code&gt; with reference to the spatial character, similar to &lt;em&gt;PostGIS&lt;/em&gt;. In the same style as &lt;em&gt;PostGIS&lt;/em&gt;, verbs are used as function names.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;proj_rob &amp;lt;- &amp;quot;+proj=robin +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m no_defs&amp;quot;

river_line &amp;lt;- st_read(&amp;quot;RiverHRCenterlinesCombo.shp&amp;quot;) %&amp;gt;% 
                 st_zm() %&amp;gt;% 
                    st_transform(proj_rob)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Reading layer `RiverHRCenterlinesCombo&amp;#39; from data source `D:\OneDriveUSC\OneDrive - Universidade de Santiago de Compostela\Documentos\GitHub\blogR_update\content\post\en\2020-07-24-river-flow-directions\RiverHRCenterlinesCombo.shp&amp;#39; using driver `ESRI Shapefile&amp;#39;
## Simple feature collection with 78 features and 6 fields
## Geometry type: MULTILINESTRING
## Dimension:     XYZ
## Bounding box:  xmin: -164.7059 ymin: -36.97094 xmax: 151.5931 ymax: 72.64474
## z_range:       zmin: 0 zmax: 0
## Geodetic CRS:  WGS 84&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;extract-the-angles&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Extract the angles&lt;/h2&gt;
&lt;p&gt;In the next step we have to extract the vertice angles. Unfortunately, as far as I know, it is not possible to extract the attributes with some function from the &lt;code&gt;sf&lt;/code&gt; package. Although the function &lt;code&gt;st_coordinates()&lt;/code&gt; returns the coordinates, it does not include other attributes. Therefore, we must use another way, and that is the open software Quantum GIS in which we can find a tool to extract all the vertice attributes. We could import the vector data into QGIS Desktop and export the vertices from there, but it is also possible to access the QGIS tools from R directly.&lt;/p&gt;
&lt;p&gt;For this, we need to have QGIS installed in OSGeo4W. The &lt;code&gt;RQGIS3&lt;/code&gt; package allows us to use very easily all the tools of the software in R. First we use the &lt;code&gt;set_env()&lt;/code&gt; function to define all the necessary QGIS paths and start the API with &lt;code&gt;open_app()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# paths to QGIS
set_env()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Trying to find QGIS in C:/&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $root
## [1] &amp;quot;C:/Program Files/QGIS 3.18&amp;quot;
## 
## $qgis_prefix_path
## [1] &amp;quot;C:/Program Files/QGIS 3.18/apps/qgis&amp;quot;
## 
## $python_plugins
## [1] &amp;quot;C:/Program Files/QGIS 3.18/apps/qgis/python/plugins&amp;quot;
## 
## $platform
## [1] &amp;quot;Windows&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# start of QGIS Python
open_app()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in check_for_server(): Hey there! According to our internal checks, you are trying to run RQGIS3 on a Windows server.
## Please note that this is only possible if you imitate a x-display.
## QGIS needs this in the background to be able to execute its processing modules.
## Note that you need to start the x-display with admin rights&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;find_algorithms()&lt;/code&gt; function helps us to search for different QGIS tools. In addition the &lt;code&gt;get_usage()&lt;/code&gt; function specifies the way of usage with all the required parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# search tools
find_algorithms(search_term = &amp;quot;vertices&amp;quot;, name_only = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;native:exportmeshvertices&amp;quot;              
## [2] &amp;quot;native:extractspecificvertices&amp;quot;         
## [3] &amp;quot;native:extractvertices&amp;quot;                 
## [4] &amp;quot;native:filterverticesbym&amp;quot;               
## [5] &amp;quot;native:filterverticesbyz&amp;quot;               
## [6] &amp;quot;native:removeduplicatevertices&amp;quot;         
## [7] &amp;quot;saga:convertpolygonlineverticestopoints&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# usage of tool
get_usage(alg = &amp;quot;native:extractvertices&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Extract vertices (native:extractvertices)
## 
## This algorithm takes a line or polygon layer and generates a point layer with points representing the vertices in the input lines or polygons. The attributes associated to each point are the same ones associated to the line or polygon that the point belongs to.
## 
## Additional fields are added to the point indicating the vertex index (beginning at 0)
## the vertex’s part and its index within the part (as well as its ring for polygons)
## distance along original geometry and bisector angle of vertex for original geometry.
## 
## 
## ----------------
## Input parameters
## ----------------
## 
## INPUT: Input layer
## 
##  Parameter type: QgsProcessingParameterFeatureSource
## 
##  Accepted data types:
##      - str: layer ID
##      - str: layer name
##      - str: layer source
##      - QgsProcessingFeatureSourceDefinition
##      - QgsProperty
##      - QgsVectorLayer
## 
## OUTPUT: Vertices
## 
##  Parameter type: QgsProcessingParameterFeatureSink
## 
##  Accepted data types:
##      - str: destination vector file
## e.g. d:/test.shp
##      - str: memory: to store result in temporary memory layer
##      - str: using vector provider ID prefix and destination URI
## e.g. postgres:… to store result in PostGIS table
##      - QgsProcessingOutputLayerDefinition
##      - QgsProperty
## 
## ----------------
## Outputs
## ----------------
## 
## OUTPUT:  &amp;lt;QgsProcessingOutputVectorLayer&amp;gt;
##  Vertices&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In our case the tool to extract the vertices is simple and only has one input and one output. The function &lt;code&gt;run_qgis()&lt;/code&gt; executes a QGIS tool indicating the algorithm and its arguments. The advantage of using the algorithm directly from R is that we can pass objects of class &lt;code&gt;sf&lt;/code&gt; (or &lt;code&gt;sp&lt;/code&gt;) and &lt;code&gt;raster&lt;/code&gt; that we have imported or created in R. As output we create a &lt;code&gt;geojson&lt;/code&gt;, it could also be of another vector format, and we save it in a temporary folder. At the same time we indicate to import the result directly into R (&lt;code&gt;load_output = TRUE&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;river_vertices &amp;lt;- run_qgis(alg = &amp;quot;native:extractvertices&amp;quot;,
               INPUT = river_line,
               OUTPUT = file.path(tempdir(), &amp;quot;rivers_world_vertices.geojson&amp;quot;),
               load_output = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $OUTPUT
## [1] &amp;quot;C:/Users/xeo19/AppData/Local/Temp/RtmpigHIXu/rivers_world_vertices.geojson&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  
Currently on Windows there seem to be problems with the &lt;em&gt;proj&lt;/em&gt; library. In principle, if the function ends up creating the &lt;code&gt;river_vertices&lt;/code&gt; object, you should not worry. Otherwise, I recommend looking at the discussion in the issue opened at &lt;a href=&#34;https://github.com/r-spatial/RQGIS3/issues/20&#34;&gt;gitbub&lt;/a&gt;.

&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;selection&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Selection&lt;/h2&gt;
&lt;p&gt;Before continuing with the distribution estimation of the angles, we filter some rivers of interest. The functions of the &lt;code&gt;tidyverse&lt;/code&gt; collection are compatible with the &lt;code&gt;sf&lt;/code&gt; package. In the last post I made an introduction to &lt;code&gt;tidyverse&lt;/code&gt; &lt;a href=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;river_vertices &amp;lt;-  filter(river_vertices, 
                          NAME %in% c(&amp;quot;Mississippi&amp;quot;, &amp;quot;Colorado&amp;quot;, 
                                      &amp;quot;Amazon&amp;quot;, &amp;quot;Nile&amp;quot;, &amp;quot;Orange&amp;quot;, 
                                      &amp;quot;Ganges&amp;quot;, &amp;quot;Yangtze&amp;quot;, &amp;quot;Danube&amp;quot;,
                                      &amp;quot;Mackenzie&amp;quot;, &amp;quot;Lena&amp;quot;, &amp;quot;Murray&amp;quot;, 
                                      &amp;quot;Niger&amp;quot;)
                          ) 

river_vertices &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Simple feature collection with 94702 features and 11 fields
## Geometry type: POINT
## Dimension:     XY
## Bounding box:  xmin: -10377520 ymin: -3953778 xmax: 13124340 ymax: 7507359
## Geodetic CRS:  WGS 84
## # A tibble: 94,702 x 12
##    NAME  SYSTEM name_alt scalerank rivernum Length_km vertex_index vertex_part
##  * &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;        &amp;lt;int&amp;gt;       &amp;lt;int&amp;gt;
##  1 Nile  &amp;lt;NA&amp;gt;   &amp;lt;NA&amp;gt;             1        4     3344.            0           0
##  2 Nile  &amp;lt;NA&amp;gt;   &amp;lt;NA&amp;gt;             1        4     3344.            1           0
##  3 Nile  &amp;lt;NA&amp;gt;   &amp;lt;NA&amp;gt;             1        4     3344.            2           0
##  4 Nile  &amp;lt;NA&amp;gt;   &amp;lt;NA&amp;gt;             1        4     3344.            3           0
##  5 Nile  &amp;lt;NA&amp;gt;   &amp;lt;NA&amp;gt;             1        4     3344.            4           0
##  6 Nile  &amp;lt;NA&amp;gt;   &amp;lt;NA&amp;gt;             1        4     3344.            5           0
##  7 Nile  &amp;lt;NA&amp;gt;   &amp;lt;NA&amp;gt;             1        4     3344.            6           0
##  8 Nile  &amp;lt;NA&amp;gt;   &amp;lt;NA&amp;gt;             1        4     3344.            7           0
##  9 Nile  &amp;lt;NA&amp;gt;   &amp;lt;NA&amp;gt;             1        4     3344.            8           0
## 10 Nile  &amp;lt;NA&amp;gt;   &amp;lt;NA&amp;gt;             1        4     3344.            9           0
## # ... with 94,692 more rows, and 4 more variables: vertex_part_index &amp;lt;int&amp;gt;,
## #   distance &amp;lt;dbl&amp;gt;, angle &amp;lt;dbl&amp;gt;, geometry &amp;lt;POINT [°]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;estimate-the-distribution&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Estimate the distribution&lt;/h1&gt;
&lt;p&gt;To visualize the distribution we can use either a histogram or a density graph. But in the case of estimating the probability density function, we find a mathematical problem when applying it to circular data. For circular data we should not use the &lt;code&gt;density()&lt;/code&gt; standard function of R since in our data a direction of 360º is the same at 0º, which would cause errors in this range of values. It is a general problem for different statistical metrics. More statistical details are explained in the &lt;code&gt;circular&lt;/code&gt; package. This package allows you to define the characteristics of circular data (unit, data type, rotation, etc.) as an object class in R.&lt;/p&gt;
&lt;p&gt;So what we do is to build a function that estimates the density and returns a table with the angles (x) and the density estimates (y). Since rivers have different lengths, and we want to see differences regardless of that, we normalize the estimates using the maximum value. Unlike the &lt;code&gt;density()&lt;/code&gt; function, in which the smoothing bandwidth &lt;code&gt;bw&lt;/code&gt; is optimized, here it is required to indicate it manually. It is similar to defining the bar width in a histogram. There is an optimization function for the bandwidth, &lt;code&gt;bw.nrd.circular()&lt;/code&gt; that could be used here.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dens_circ &amp;lt;- function(x){
  
  dens &amp;lt;- density.circular(circular(x$angle, units = &amp;quot;degrees&amp;quot;),
                                     bw = 70, kernel = &amp;quot;vonmises&amp;quot;,
                                     control.circular = list(units = &amp;quot;degrees&amp;quot;))
  
  df &amp;lt;- data.frame(x = dens$x, y = dens$y/max(dens$y))
  
  return(df)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we estimate the density of each river in our selection. We use the &lt;code&gt;split()&lt;/code&gt; function of R Base to get a table of each river in a list object. Then we apply our density estimation function to the list with the function &lt;code&gt;map_df()&lt;/code&gt; from the &lt;code&gt;purrr&lt;/code&gt; package. The suffix &lt;code&gt;_df&lt;/code&gt; allows us to get a joined table, instead of a list with the results of each river. However, it is necessary to indicate the name of the column with the argument &lt;code&gt;.id&lt;/code&gt;, which will contain the name of each river. Otherwise we would not know how to differentiate the results. Also here I recommend reading more details in the last post about &lt;code&gt;tidyverse&lt;/code&gt; &lt;a href=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dens_river &amp;lt;- split(river_vertices, river_vertices$NAME) %&amp;gt;% 
                  map_df(dens_circ, .id = &amp;quot;river&amp;quot;)

# results
head(dens_river)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    river        x         y
## 1 Amazon 0.000000 0.2399907
## 2 Amazon 0.704501 0.2492548
## 3 Amazon 1.409002 0.2585758
## 4 Amazon 2.113503 0.2679779
## 5 Amazon 2.818004 0.2774859
## 6 Amazon 3.522505 0.2871232&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;visualization&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Visualization&lt;/h1&gt;
&lt;p&gt;Now we only have to make the graph through the famous &lt;code&gt;ggplot&lt;/code&gt; package. First we add a new font &lt;em&gt;Montserrat&lt;/em&gt; for it use in this plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# font download
font_add_google(&amp;quot;Montserrat&amp;quot;, &amp;quot;Montserrat&amp;quot;)

# use of showtext
showtext_opts(dpi = 200)
showtext_auto() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the next step we create two objects with the title and the plot caption. In the title we are using an html code to color part of the text instead of a legend. You can use html very easily with the &lt;code&gt;ggtext&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# title with html
title &amp;lt;- &amp;quot;Relative distribution of river &amp;lt;span style=&amp;#39;color:#011FFD;&amp;#39;&amp;gt;&amp;lt;strong&amp;gt;flow direction&amp;lt;/strong&amp;gt;&amp;lt;/span&amp;gt; in the world&amp;quot;


caption &amp;lt;- &amp;quot;Based on data from Zeenatul Basher, 20180215&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The background grid that creates &lt;code&gt;ggplot&lt;/code&gt; by default for polar coordinates did not convince me, so we create a table with x axis background lines.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grid_x &amp;lt;- tibble(x = seq(0, 360 - 22.5, by = 22.5), 
                 y = rep(0, 16), 
                 xend = seq(0, 360 - 22.5, by = 22.5), 
                 yend = rep(Inf, 16))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next we define all the styles of the graph. The most important thing in this step is the &lt;code&gt;element_textbox()&lt;/code&gt; function of the &lt;code&gt;ggtext&lt;/code&gt; package to be able to interpret our html code incorporated into the title.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;theme_polar &amp;lt;- theme_minimal() +
               theme(axis.title.y = element_blank(),
                     axis.text.y = element_blank(),
                     legend.title = element_blank(),
                     plot.title = element_textbox(family = &amp;quot;Montserrat&amp;quot;, 
                                                   hjust = 0.5, 
                                                   colour = &amp;quot;white&amp;quot;, 
                                                   size = 15),
                     plot.caption = element_text(family = &amp;quot;Montserrat&amp;quot;, 
                                                 colour = &amp;quot;white&amp;quot;),
                     axis.text.x = element_text(family = &amp;quot;Montserrat&amp;quot;, 
                                                 colour = &amp;quot;white&amp;quot;),
                     strip.text = element_text(family = &amp;quot;Montserrat&amp;quot;, 
                                               colour = &amp;quot;white&amp;quot;, 
                                               face = &amp;quot;bold&amp;quot;),
                     panel.background = element_rect(fill = &amp;quot;black&amp;quot;),
                     plot.background = element_rect(fill = &amp;quot;black&amp;quot;),
                     panel.grid = element_blank()
                    )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally we build the graph: 1) We use the &lt;code&gt;geom_hline()&lt;/code&gt; function with different y intersection points to create the background grid. The &lt;code&gt;geom_segment()&lt;/code&gt; function creates the x grid. 2) We create the density area using the &lt;code&gt;geom_area()&lt;/code&gt; function. 3) In &lt;code&gt;scale_x_continous()&lt;/code&gt; we define a negative lower limit so that it does not collapse at a small point. The labels of the eight main directions are indicated in the &lt;code&gt;scale_y_continous()&lt;/code&gt; function, and 4) Finally, we change to a polar coordinate system and set the variable to create facets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot() +
  geom_hline(yintercept = c(0, .2, .6, .8, 1), colour = &amp;quot;white&amp;quot;) +
  geom_segment(data = grid_x , 
               aes(x = x, y = y, xend = xend, yend = yend), 
               linetype = &amp;quot;dashed&amp;quot;, col = &amp;quot;white&amp;quot;) +
  geom_area(data = dens_river, 
            aes(x = x, y = y, ymin = 0, ymax = y), 
            alpha = .7, 
            colour = NA, 
            show.legend = FALSE,
            fill = &amp;quot;#011FFD&amp;quot;) + 
  scale_y_continuous(limits = c(-.2, 1), expand = c(0, 0)) +
  scale_x_continuous(limits = c(0, 360), 
                     breaks = seq(0, 360 - 22.5, by = 22.5),
                     minor_breaks = NULL,
                     labels = c(&amp;quot;N&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;NE&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;E&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;SE&amp;quot;, &amp;quot;&amp;quot;,
                                &amp;quot;S&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;SW&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;W&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;NW&amp;quot;, &amp;quot;&amp;quot;)) +
  coord_polar() + 
  facet_wrap(river ~ ., ncol = 4) +
  labs(title = title, caption = caption, x = &amp;quot;&amp;quot;) +
  theme_polar&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/river-flow-directions/index.en_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
      
            <category>directions</category>
      
            <category>river</category>
      
            <category>fluvial</category>
      
            <category>orientation</category>
      
            <category>distribution</category>
      
      
            <category>gis</category>
      
            <category>R</category>
      
            <category>R:advanced</category>
      
    </item>
    
    <item>
      <title>A very short introduction to Tidyverse</title>
      <link>https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/</link>
      <pubDate>Sat, 06 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#tidyverse&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;1&lt;/span&gt; Tidyverse&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#style-guide&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2&lt;/span&gt; Style guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#pipe&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3&lt;/span&gt; Pipe %&amp;gt;%&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tidyverse-packages&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4&lt;/span&gt; Tidyverse packages&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#read-and-write-data&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.1&lt;/span&gt; Read and write data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#character-manipulations&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.2&lt;/span&gt; Character manipulations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#management-of-dates-and-times&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.3&lt;/span&gt; Management of dates and times&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#table-and-vector-manipulation&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.4&lt;/span&gt; Table and vector manipulation&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#select-and-rename&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.4.1&lt;/span&gt; Select and rename&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#filter-and-sort&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.4.2&lt;/span&gt; Filter and sort&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#group-and-summarize&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.4.3&lt;/span&gt; Group and summarize&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#join-tables&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.4.4&lt;/span&gt; Join tables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#long-and-wide-tables&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.4.5&lt;/span&gt; Long and wide tables&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#visualize-data&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.5&lt;/span&gt; Visualize data&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#line-and-scatter-plot&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.5.1&lt;/span&gt; Line and scatter plot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#boxplot&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.5.2&lt;/span&gt; Boxplot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#heatmap&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.5.3&lt;/span&gt; Heatmap&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#apply-functions-on-vectors-or-lists&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.6&lt;/span&gt; Apply functions on vectors or lists&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;tidyverse&#34; class=&#34;section level1&#34; number=&#34;1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Tidyverse&lt;/h1&gt;
&lt;p&gt;The &lt;code&gt;tidyverse&lt;/code&gt; universe of packages, a collection of packages specially focused on data science, marked a milestone in R programming. In this post I am going to summarize very briefly the most essential to start in this world. The tidyverse grammar follows a common structure in all functions. The most essential thing is that the first argument is the object and then come the rest of the arguments. In addition, a set of verbs is provided to facilitate the use of the functions. The &lt;code&gt;tidyverse&lt;/code&gt; philosophy and grammar of functions are also reflected in other packages that make its use compatible with the collection. For example, the &lt;code&gt;sf&lt;/code&gt; package (&lt;a href=&#34;https://r-spatial.github.io/sf/articles/sf1.html&#34;&gt;simple feature&lt;/a&gt;) is a standardized way to encode spatial vector data and allows the use of multiple functions that we can find in the &lt;code&gt;dplyr&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;The core of the &lt;code&gt;tidyverse&lt;/code&gt; collection is made up of the following packages:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Package&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ggplot2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Grammar for creating graphics&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;purrr&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;R functional programming&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tibble&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Modern and effective table system&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;dplyr&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Grammar for data manipulation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyr&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Set of functions to create tidy data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;stringr&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Function set to work with characters&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;readr&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;An easy and fast way to import data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;forcats&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Tools to easily work with factors&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;In addition to the mentioned packages, &lt;code&gt;lubridate&lt;/code&gt; is also used very frequently to work with dates and times, and also &lt;code&gt;readxl&lt;/code&gt; which allows us to import files in Excel format. To know all the available packages we can use the function &lt;code&gt;tidyverse_packages()&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;broom&amp;quot;         &amp;quot;cli&amp;quot;           &amp;quot;crayon&amp;quot;        &amp;quot;dbplyr&amp;quot;       
##  [5] &amp;quot;dplyr&amp;quot;         &amp;quot;dtplyr&amp;quot;        &amp;quot;forcats&amp;quot;       &amp;quot;googledrive&amp;quot;  
##  [9] &amp;quot;googlesheets4&amp;quot; &amp;quot;ggplot2&amp;quot;       &amp;quot;haven&amp;quot;         &amp;quot;hms&amp;quot;          
## [13] &amp;quot;httr&amp;quot;          &amp;quot;jsonlite&amp;quot;      &amp;quot;lubridate&amp;quot;     &amp;quot;magrittr&amp;quot;     
## [17] &amp;quot;modelr&amp;quot;        &amp;quot;pillar&amp;quot;        &amp;quot;purrr&amp;quot;         &amp;quot;readr&amp;quot;        
## [21] &amp;quot;readxl&amp;quot;        &amp;quot;reprex&amp;quot;        &amp;quot;rlang&amp;quot;         &amp;quot;rstudioapi&amp;quot;   
## [25] &amp;quot;rvest&amp;quot;         &amp;quot;stringr&amp;quot;       &amp;quot;tibble&amp;quot;        &amp;quot;tidyr&amp;quot;        
## [29] &amp;quot;xml2&amp;quot;          &amp;quot;tidyverse&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is very easy to get conflicts between functions, that is, that the same function name exists in several packages. To avoid this, we can write the name of the package in front of the function we want to use, separated by the colon symbol written twice (&lt;code&gt;package_name::function_name&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Before I get started with the packages, I hope it will be a really short introduction, some comments on the style when programming in R.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;style-guide&#34; class=&#34;section level1&#34; number=&#34;2&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; Style guide&lt;/h1&gt;
&lt;p&gt;In R there is no universal style guide, that is, in the R syntax it is not necessary to follow specific rules for our scripts. But it is recommended to work in a homogeneous, uniform, legible and clear way when writing scripts. The &lt;code&gt;tidyverse&lt;/code&gt; collection has its own guide (&lt;a href=&#34;https://style.tidyverse.org/&#34; class=&#34;uri&#34;&gt;https://style.tidyverse.org/&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The most important recommendations are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Avoid using more than 80 characters per line to allow reading the complete code.&lt;/li&gt;
&lt;li&gt;Always use a space after a comma, never before.&lt;/li&gt;
&lt;li&gt;The operators (==, +, -, &amp;lt;-,%&amp;gt;%, etc.) must have a space before and after.&lt;/li&gt;
&lt;li&gt;There is no space between the name of a function and the first parenthesis, nor between the last argument and the final parenthesis of a function.&lt;/li&gt;
&lt;li&gt;Avoid reusing names of functions and common variables (&lt;code&gt;c &amp;lt;- 5&lt;/code&gt; vs. &lt;code&gt;c()&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Sort the script separating the parts with the comment form &lt;code&gt;# Import data -----&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Avoid accent marks or special symbols in names, files, routes, etc.&lt;/li&gt;
&lt;li&gt;Object names must follow a constant structure: &lt;code&gt;day_one&lt;/code&gt;, &lt;code&gt;day_1&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is advisable to use a correct indentation for multiple arguments of a function or functions chained by the &lt;code&gt;pipe&lt;/code&gt; operator (&lt;code&gt;%&amp;gt;%&lt;/code&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;pipe&#34; class=&#34;section level1&#34; number=&#34;3&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; Pipe %&amp;gt;%&lt;/h1&gt;
&lt;p&gt;To facilitate working in data management, manipulation and visualization, the &lt;code&gt;magrittr&lt;/code&gt; package introduces the famous &lt;em&gt;pipe&lt;/em&gt; operator in the form &lt;code&gt;%&amp;gt;%&lt;/code&gt; with the aim of combining various functions without the need to assign the result to a new object. The &lt;em&gt;pipe&lt;/em&gt; operator passes the output of a function applied to the first argument of the next function. This way of combining functions allows you to chain several steps simultaneously, to perform sequential tasks. In the very simple example below, we pass the vector &lt;code&gt;1:5&lt;/code&gt; to the &lt;code&gt;mean()&lt;/code&gt; function to calculate the average. You should know that there are a couple of other pipe operators in the same package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;1:5 %&amp;gt;% mean()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;tidyverse-packages&#34; class=&#34;section level1&#34; number=&#34;4&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;4&lt;/span&gt; Tidyverse packages&lt;/h1&gt;
&lt;div id=&#34;read-and-write-data&#34; class=&#34;section level2&#34; number=&#34;4.1&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.1&lt;/span&gt; Read and write data&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;readr&lt;/code&gt; package makes it easy to read or write multiple file formats using functions that start with &lt;code&gt;read_*&lt;/code&gt; or &lt;code&gt;write_*&lt;/code&gt;.
In comparison to R Base, &lt;code&gt;readr&lt;/code&gt; functions are faster; they handle problematic column names, and dates are automatically converted. The imported tables are of class &lt;code&gt;tibble&lt;/code&gt; (&lt;em&gt;tbl_df&lt;/em&gt;), a modern version of &lt;code&gt;data.frame&lt;/code&gt; from the &lt;code&gt;tibble&lt;/code&gt; package. In the same sense, you can use the &lt;code&gt;read_excel()&lt;/code&gt; function of the &lt;code&gt;readxl&lt;/code&gt; package to import data from Excel sheets (more details also in this &lt;a href=&#34;https://dominicroye.github.io/en/2019/import-excel-sheets-with-r/&#34;&gt;blog post&lt;/a&gt;). In the following example, we import the mobility data registered by Google (&lt;a href=&#34;https://www.google.com/covid19/mobility/&#34;&gt;link&lt;/a&gt;) during the last months of the COVID-19 pandemic (&lt;a href=&#34;https://dominicroye.github.io/files/Global_Mobility_Report.csv&#34;&gt;download&lt;/a&gt;).&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Function&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;read_csv() o read_csv2()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;coma or semicolon (CSV)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;read_delim()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;general separator&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;read_table()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;whitespace-separated&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# load package
library(tidyverse)

google_mobility &amp;lt;- read_csv(&amp;quot;Global_Mobility_Report.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## -- Column specification --------------------------------------------------------
## cols(
##   country_region_code = col_character(),
##   country_region = col_character(),
##   sub_region_1 = col_character(),
##   sub_region_2 = col_logical(),
##   iso_3166_2_code = col_character(),
##   census_fips_code = col_logical(),
##   date = col_date(format = &amp;quot;&amp;quot;),
##   retail_and_recreation_percent_change_from_baseline = col_double(),
##   grocery_and_pharmacy_percent_change_from_baseline = col_double(),
##   parks_percent_change_from_baseline = col_double(),
##   transit_stations_percent_change_from_baseline = col_double(),
##   workplaces_percent_change_from_baseline = col_double(),
##   residential_percent_change_from_baseline = col_double()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: 597554 parsing failures.
##    row              col           expected         actual                         file
## 200119 sub_region_2     1/0/T/F/TRUE/FALSE Autauga County &amp;#39;Global_Mobility_Report.csv&amp;#39;
## 200119 census_fips_code 1/0/T/F/TRUE/FALSE 01001          &amp;#39;Global_Mobility_Report.csv&amp;#39;
## 200120 sub_region_2     1/0/T/F/TRUE/FALSE Autauga County &amp;#39;Global_Mobility_Report.csv&amp;#39;
## 200120 census_fips_code 1/0/T/F/TRUE/FALSE 01001          &amp;#39;Global_Mobility_Report.csv&amp;#39;
## 200121 sub_region_2     1/0/T/F/TRUE/FALSE Autauga County &amp;#39;Global_Mobility_Report.csv&amp;#39;
## ...... ................ .................. .............. ............................
## See problems(...) for more details.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;google_mobility&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 516,697 x 13
##    country_region_co~ country_region   sub_region_1 sub_region_2 iso_3166_2_code
##    &amp;lt;chr&amp;gt;              &amp;lt;chr&amp;gt;            &amp;lt;chr&amp;gt;        &amp;lt;lgl&amp;gt;        &amp;lt;chr&amp;gt;          
##  1 AE                 United Arab Emi~ &amp;lt;NA&amp;gt;         NA           &amp;lt;NA&amp;gt;           
##  2 AE                 United Arab Emi~ &amp;lt;NA&amp;gt;         NA           &amp;lt;NA&amp;gt;           
##  3 AE                 United Arab Emi~ &amp;lt;NA&amp;gt;         NA           &amp;lt;NA&amp;gt;           
##  4 AE                 United Arab Emi~ &amp;lt;NA&amp;gt;         NA           &amp;lt;NA&amp;gt;           
##  5 AE                 United Arab Emi~ &amp;lt;NA&amp;gt;         NA           &amp;lt;NA&amp;gt;           
##  6 AE                 United Arab Emi~ &amp;lt;NA&amp;gt;         NA           &amp;lt;NA&amp;gt;           
##  7 AE                 United Arab Emi~ &amp;lt;NA&amp;gt;         NA           &amp;lt;NA&amp;gt;           
##  8 AE                 United Arab Emi~ &amp;lt;NA&amp;gt;         NA           &amp;lt;NA&amp;gt;           
##  9 AE                 United Arab Emi~ &amp;lt;NA&amp;gt;         NA           &amp;lt;NA&amp;gt;           
## 10 AE                 United Arab Emi~ &amp;lt;NA&amp;gt;         NA           &amp;lt;NA&amp;gt;           
## # ... with 516,687 more rows, and 8 more variables: census_fips_code &amp;lt;lgl&amp;gt;,
## #   date &amp;lt;date&amp;gt;, retail_and_recreation_percent_change_from_baseline &amp;lt;dbl&amp;gt;,
## #   grocery_and_pharmacy_percent_change_from_baseline &amp;lt;dbl&amp;gt;,
## #   parks_percent_change_from_baseline &amp;lt;dbl&amp;gt;,
## #   transit_stations_percent_change_from_baseline &amp;lt;dbl&amp;gt;,
## #   workplaces_percent_change_from_baseline &amp;lt;dbl&amp;gt;,
## #   residential_percent_change_from_baseline &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Important is to take a look at the argument names, since they change in the &lt;code&gt;readr&lt;/code&gt; functions. For example, the well-known &lt;code&gt;header = TRUE&lt;/code&gt; argument of &lt;code&gt;read.csv()&lt;/code&gt; is in this case &lt;code&gt;col_names = TRUE&lt;/code&gt;. More details can be found in the &lt;a href=&#34;https://github.com/rstudio/cheatsheets/raw/master/data-import.pdf&#34;&gt;Cheat-Sheet&lt;/a&gt; of &lt;code&gt;readr&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;character-manipulations&#34; class=&#34;section level2&#34; number=&#34;4.2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.2&lt;/span&gt; Character manipulations&lt;/h2&gt;
&lt;p&gt;For working with strings we use the &lt;code&gt;stringr&lt;/code&gt; package, whose functions always start with &lt;code&gt;str_*&lt;/code&gt; followed by a verb and the first argument.&lt;/p&gt;
&lt;p&gt;Some of these functions are as follows:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Function&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;str_replace()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;replace patterns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;str_c()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;combine characters&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;str_detect()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;detect patterns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;str_extract()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;extract patterns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;str_sub()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;extract by position&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;str_length()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;length of string&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Regular expressions are often used for character patterns. For example, the regular expression &lt;code&gt;[aeiou]&lt;/code&gt; matches any single character that is a vowel. The use of square brackets &lt;code&gt;[]&lt;/code&gt; corresponds to character classes. For example, &lt;code&gt;[abc]&lt;/code&gt; corresponds to each letter regardless of its position. &lt;code&gt;[a-z]&lt;/code&gt;, &lt;code&gt;[A-Z]&lt;/code&gt; or &lt;code&gt;[0-9]&lt;/code&gt; each between a and z or 0 and 9. And finally, &lt;code&gt;[:punct:]&lt;/code&gt; punctuation, etc. With curly braces “{}” we can indicate the number of the previous element, &lt;code&gt;{2}&lt;/code&gt; would be twice, {1,2} between one and two, etc. Also with &lt;code&gt;$&lt;/code&gt; or &lt;code&gt;^&lt;/code&gt; we can indicate if the pattern starts at the beginning or ends at the end. More details and patterns can be found in the &lt;a href=&#34;https://github.com/rstudio/cheatsheets/raw/master/strings.pdf&#34;&gt;Cheat-Sheet&lt;/a&gt; of &lt;code&gt;stringr&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# replace &amp;#39;er&amp;#39; at the end with empty space

str_replace(month.name, &amp;quot;er$&amp;quot;, &amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;January&amp;quot;  &amp;quot;February&amp;quot; &amp;quot;March&amp;quot;    &amp;quot;April&amp;quot;    &amp;quot;May&amp;quot;      &amp;quot;June&amp;quot;    
##  [7] &amp;quot;July&amp;quot;     &amp;quot;August&amp;quot;   &amp;quot;Septemb&amp;quot;  &amp;quot;Octob&amp;quot;    &amp;quot;Novemb&amp;quot;   &amp;quot;Decemb&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_replace(month.name, &amp;quot;^Ma&amp;quot;, &amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;January&amp;quot;   &amp;quot;February&amp;quot;  &amp;quot;rch&amp;quot;       &amp;quot;April&amp;quot;     &amp;quot;y&amp;quot;         &amp;quot;June&amp;quot;     
##  [7] &amp;quot;July&amp;quot;      &amp;quot;August&amp;quot;    &amp;quot;September&amp;quot; &amp;quot;October&amp;quot;   &amp;quot;November&amp;quot;  &amp;quot;December&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# combine characters

a &amp;lt;- str_c(month.name, 1:12, sep = &amp;quot;_&amp;quot;)
a&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;January_1&amp;quot;   &amp;quot;February_2&amp;quot;  &amp;quot;March_3&amp;quot;     &amp;quot;April_4&amp;quot;     &amp;quot;May_5&amp;quot;      
##  [6] &amp;quot;June_6&amp;quot;      &amp;quot;July_7&amp;quot;      &amp;quot;August_8&amp;quot;    &amp;quot;September_9&amp;quot; &amp;quot;October_10&amp;quot; 
## [11] &amp;quot;November_11&amp;quot; &amp;quot;December_12&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# collapse combination

str_c(month.name, collapse = &amp;quot;, &amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;January, February, March, April, May, June, July, August, September, October, November, December&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# detect patterns

str_detect(a, &amp;quot;_[1-5]{1}&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract patterns

str_extract(a, &amp;quot;_[1-9]{1,2}&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;_1&amp;quot;  &amp;quot;_2&amp;quot;  &amp;quot;_3&amp;quot;  &amp;quot;_4&amp;quot;  &amp;quot;_5&amp;quot;  &amp;quot;_6&amp;quot;  &amp;quot;_7&amp;quot;  &amp;quot;_8&amp;quot;  &amp;quot;_9&amp;quot;  &amp;quot;_1&amp;quot;  &amp;quot;_11&amp;quot; &amp;quot;_12&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract the characters between position 1 and 2

str_sub(month.name, 1, 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Ja&amp;quot; &amp;quot;Fe&amp;quot; &amp;quot;Ma&amp;quot; &amp;quot;Ap&amp;quot; &amp;quot;Ma&amp;quot; &amp;quot;Ju&amp;quot; &amp;quot;Ju&amp;quot; &amp;quot;Au&amp;quot; &amp;quot;Se&amp;quot; &amp;quot;Oc&amp;quot; &amp;quot;No&amp;quot; &amp;quot;De&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# string length of each month

str_length(month.name)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 7 8 5 5 3 4 4 6 9 7 8 8&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the &amp;#39;.&amp;#39; represents the object passed by the pipe operator %&amp;gt;%
str_length(month.name) %&amp;gt;% 
   str_c(month.name, ., sep = &amp;quot;.&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;January.7&amp;quot;   &amp;quot;February.8&amp;quot;  &amp;quot;March.5&amp;quot;     &amp;quot;April.5&amp;quot;     &amp;quot;May.3&amp;quot;      
##  [6] &amp;quot;June.4&amp;quot;      &amp;quot;July.4&amp;quot;      &amp;quot;August.6&amp;quot;    &amp;quot;September.9&amp;quot; &amp;quot;October.7&amp;quot;  
## [11] &amp;quot;November.8&amp;quot;  &amp;quot;December.8&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A very useful function is &lt;code&gt;str_glue()&lt;/code&gt; to interpolate characters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;name &amp;lt;- c(&amp;quot;Juan&amp;quot;, &amp;quot;Michael&amp;quot;)
age &amp;lt;- c(50, 80) 
date_today &amp;lt;- Sys.Date()

str_glue(
  &amp;quot;My name is {name}, &amp;quot;,
  &amp;quot;I&amp;#39;am {age}, &amp;quot;,
  &amp;quot;and my birth year is {format(date_today-age*365, &amp;#39;%Y&amp;#39;)}.&amp;quot;
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## My name is Juan, I&amp;#39;am 50, and my birth year is 1971.
## My name is Michael, I&amp;#39;am 80, and my birth year is 1941.&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;management-of-dates-and-times&#34; class=&#34;section level2&#34; number=&#34;4.3&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.3&lt;/span&gt; Management of dates and times&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;lubridate&lt;/code&gt; package is very powerful in handling dates and times. It allows us to create R recognized objects with functions (like &lt;code&gt;ymd()&lt;/code&gt; or &lt;code&gt;ymd_hms()&lt;/code&gt;) and we can even make calculations.&lt;/p&gt;
&lt;p&gt;We only must know the following abbreviations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ymd&lt;/code&gt;: represents &lt;code&gt;y:year&lt;/code&gt;, &lt;code&gt;m: month&lt;/code&gt;, &lt;code&gt;d:day&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hms&lt;/code&gt;: represents &lt;code&gt;h:hour&lt;/code&gt;, &lt;code&gt;m:minutes&lt;/code&gt;, &lt;code&gt;s:seconds&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# load package
library(lubridate)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;lubridate&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:base&amp;#39;:
## 
##     date, intersect, setdiff, union&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# date vector
dat &amp;lt;- c(&amp;quot;1999/12/31&amp;quot;, &amp;quot;2000/01/07&amp;quot;, &amp;quot;2005/05/20&amp;quot;,&amp;quot;2010/03/25&amp;quot;)

# date-time vector
dat_time &amp;lt;- c(&amp;quot;1988-08-01 05:00&amp;quot;, &amp;quot;2000-02-01 22:00&amp;quot;)

# convert to date class
dat &amp;lt;- ymd(dat) 
dat&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;1999-12-31&amp;quot; &amp;quot;2000-01-07&amp;quot; &amp;quot;2005-05-20&amp;quot; &amp;quot;2010-03-25&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# other date formats
dmy(&amp;quot;05-02-2000&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2000-02-05&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ymd(&amp;quot;20000506&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2000-05-06&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# convert to POSIXct
dat_time &amp;lt;- ymd_hm(dat_time)
dat_time&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;1988-08-01 05:00:00 UTC&amp;quot; &amp;quot;2000-02-01 22:00:00 UTC&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# different date formats
dat_mix &amp;lt;- c(&amp;quot;1999/12/05&amp;quot;, &amp;quot;05-09-2008&amp;quot;, &amp;quot;2000/08/09&amp;quot;, &amp;quot;25-10-2019&amp;quot;)

# mixted formats with known convention found in ?strptime
parse_date_time(dat_mix, order = c(&amp;quot;%Y/%m/%d&amp;quot;, &amp;quot;%d-%m-%Y&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;1999-12-05 UTC&amp;quot; &amp;quot;2008-09-05 UTC&amp;quot; &amp;quot;2000-08-09 UTC&amp;quot; &amp;quot;2019-10-25 UTC&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;More useful functions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract the year
year(dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1999 2000 2005 2010&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the month
month(dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 12  1  5  3&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;month(dat, label = TRUE) # as label&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] dic ene may mar
## 12 Levels: ene &amp;lt; feb &amp;lt; mar &amp;lt; abr &amp;lt; may &amp;lt; jun &amp;lt; jul &amp;lt; ago &amp;lt; sep &amp;lt; ... &amp;lt; dic&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the day of the week
wday(dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 6 6 6 5&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;wday(dat, label = TRUE) # as label&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] vi\\. vi\\. vi\\. ju\\.
## Levels: do\\. &amp;lt; lu\\. &amp;lt; ma\\. &amp;lt; mi\\. &amp;lt; ju\\. &amp;lt; vi\\. &amp;lt; sá\\.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the hour
hour(dat_time)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  5 22&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# add 10 days
dat + days(10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2000-01-10&amp;quot; &amp;quot;2000-01-17&amp;quot; &amp;quot;2005-05-30&amp;quot; &amp;quot;2010-04-04&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# add 1 month
dat + months(1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2000-01-31&amp;quot; &amp;quot;2000-02-07&amp;quot; &amp;quot;2005-06-20&amp;quot; &amp;quot;2010-04-25&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, the &lt;code&gt;make_date()&lt;/code&gt; function is very useful to create dates from different date parts, such as the year, month, etc.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create date from its elements, here with year and month
make_date(2000, 5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2000-05-01&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create date with time
make_datetime(2005, 5, 23, 5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2005-05-23 05:00:00 UTC&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;More details can be found in the &lt;a href=&#34;https://github.com/rstudio/cheatsheets/raw/master/lubridate.pdf&#34;&gt;Cheat-Sheet&lt;/a&gt; of &lt;code&gt;lubridate&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;table-and-vector-manipulation&#34; class=&#34;section level2&#34; number=&#34;4.4&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.4&lt;/span&gt; Table and vector manipulation&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;dplyr&lt;/code&gt; and &lt;code&gt;tidyr&lt;/code&gt; packages provide us with a data manipulation grammar, a set of useful verbs to solve common problems. The most important functions are:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Function&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mutate()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;add new variables or modify existing ones&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;select()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;select variables&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;filter()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;filter&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;summarise()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;summarize/reduce&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;arrange()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;sort&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;group_by()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;group&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;rename()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;rename columns&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;In case you haven’t done it before, we import the mobility data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;google_mobility &amp;lt;- read_csv(&amp;quot;Global_Mobility_Report.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## -- Column specification --------------------------------------------------------
## cols(
##   country_region_code = col_character(),
##   country_region = col_character(),
##   sub_region_1 = col_character(),
##   sub_region_2 = col_logical(),
##   iso_3166_2_code = col_character(),
##   census_fips_code = col_logical(),
##   date = col_date(format = &amp;quot;&amp;quot;),
##   retail_and_recreation_percent_change_from_baseline = col_double(),
##   grocery_and_pharmacy_percent_change_from_baseline = col_double(),
##   parks_percent_change_from_baseline = col_double(),
##   transit_stations_percent_change_from_baseline = col_double(),
##   workplaces_percent_change_from_baseline = col_double(),
##   residential_percent_change_from_baseline = col_double()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: 597554 parsing failures.
##    row              col           expected         actual                         file
## 200119 sub_region_2     1/0/T/F/TRUE/FALSE Autauga County &amp;#39;Global_Mobility_Report.csv&amp;#39;
## 200119 census_fips_code 1/0/T/F/TRUE/FALSE 01001          &amp;#39;Global_Mobility_Report.csv&amp;#39;
## 200120 sub_region_2     1/0/T/F/TRUE/FALSE Autauga County &amp;#39;Global_Mobility_Report.csv&amp;#39;
## 200120 census_fips_code 1/0/T/F/TRUE/FALSE 01001          &amp;#39;Global_Mobility_Report.csv&amp;#39;
## 200121 sub_region_2     1/0/T/F/TRUE/FALSE Autauga County &amp;#39;Global_Mobility_Report.csv&amp;#39;
## ...... ................ .................. .............. ............................
## See problems(...) for more details.&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;select-and-rename&#34; class=&#34;section level3&#34; number=&#34;4.4.1&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.4.1&lt;/span&gt; Select and rename&lt;/h3&gt;
&lt;p&gt;We can select or remove columns with the &lt;code&gt;select()&lt;/code&gt; function, using the name or index of the column. To delete columns we make use of the negative sign. The &lt;code&gt;rename&lt;/code&gt; function helps in renaming columns with either the same name or their index.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;residential_mobility &amp;lt;- select(google_mobility, 
                               country_region_code:sub_region_1, 
                               date, 
                               residential_percent_change_from_baseline) %&amp;gt;% 
                        rename(resi = 5)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;filter-and-sort&#34; class=&#34;section level3&#34; number=&#34;4.4.2&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.4.2&lt;/span&gt; Filter and sort&lt;/h3&gt;
&lt;p&gt;To filter data, we use &lt;code&gt;filter()&lt;/code&gt; with logical operators (&lt;code&gt;|&lt;/code&gt;, &lt;code&gt;==&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;, etc) or functions that return a logical value (&lt;code&gt;str_detect()&lt;/code&gt;, &lt;code&gt;is.na()&lt;/code&gt; , etc.). The &lt;code&gt;arrange()&lt;/code&gt; function sorts from least to greatest for one or multiple variables (with the negative sign &lt;code&gt;-&lt;/code&gt; the order is reversed from greatest to least).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(residential_mobility, 
       country_region_code == &amp;quot;US&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 304,648 x 5
##    country_region_code country_region sub_region_1 date        resi
##    &amp;lt;chr&amp;gt;               &amp;lt;chr&amp;gt;          &amp;lt;chr&amp;gt;        &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt;
##  1 US                  United States  &amp;lt;NA&amp;gt;         2020-02-15    -1
##  2 US                  United States  &amp;lt;NA&amp;gt;         2020-02-16    -1
##  3 US                  United States  &amp;lt;NA&amp;gt;         2020-02-17     5
##  4 US                  United States  &amp;lt;NA&amp;gt;         2020-02-18     1
##  5 US                  United States  &amp;lt;NA&amp;gt;         2020-02-19     0
##  6 US                  United States  &amp;lt;NA&amp;gt;         2020-02-20     1
##  7 US                  United States  &amp;lt;NA&amp;gt;         2020-02-21     0
##  8 US                  United States  &amp;lt;NA&amp;gt;         2020-02-22    -1
##  9 US                  United States  &amp;lt;NA&amp;gt;         2020-02-23    -1
## 10 US                  United States  &amp;lt;NA&amp;gt;         2020-02-24     0
## # ... with 304,638 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(residential_mobility, 
       country_region_code == &amp;quot;US&amp;quot;, 
       sub_region_1 == &amp;quot;New York&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 7,068 x 5
##    country_region_code country_region sub_region_1 date        resi
##    &amp;lt;chr&amp;gt;               &amp;lt;chr&amp;gt;          &amp;lt;chr&amp;gt;        &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt;
##  1 US                  United States  New York     2020-02-15     0
##  2 US                  United States  New York     2020-02-16    -1
##  3 US                  United States  New York     2020-02-17     9
##  4 US                  United States  New York     2020-02-18     3
##  5 US                  United States  New York     2020-02-19     2
##  6 US                  United States  New York     2020-02-20     2
##  7 US                  United States  New York     2020-02-21     3
##  8 US                  United States  New York     2020-02-22    -1
##  9 US                  United States  New York     2020-02-23    -1
## 10 US                  United States  New York     2020-02-24     0
## # ... with 7,058 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(residential_mobility, 
       resi &amp;gt; 50) %&amp;gt;% 
          arrange(-resi)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 32 x 5
##    country_region_co~ country_region sub_region_1               date        resi
##    &amp;lt;chr&amp;gt;              &amp;lt;chr&amp;gt;          &amp;lt;chr&amp;gt;                      &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt;
##  1 KW                 Kuwait         Al Farwaniyah Governorate  2020-05-14    56
##  2 KW                 Kuwait         Al Farwaniyah Governorate  2020-05-21    55
##  3 SG                 Singapore      &amp;lt;NA&amp;gt;                       2020-05-01    55
##  4 KW                 Kuwait         Al Farwaniyah Governorate  2020-05-28    54
##  5 PE                 Peru           Metropolitan Municipality~ 2020-04-10    54
##  6 EC                 Ecuador        Pichincha                  2020-03-27    53
##  7 KW                 Kuwait         Al Farwaniyah Governorate  2020-05-11    53
##  8 KW                 Kuwait         Al Farwaniyah Governorate  2020-05-13    53
##  9 KW                 Kuwait         Al Farwaniyah Governorate  2020-05-20    53
## 10 SG                 Singapore      &amp;lt;NA&amp;gt;                       2020-04-10    53
## # ... with 22 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;group-and-summarize&#34; class=&#34;section level3&#34; number=&#34;4.4.3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.4.3&lt;/span&gt; Group and summarize&lt;/h3&gt;
&lt;p&gt;Where do we find greater variability between regions in each country on April 1, 2020?&lt;/p&gt;
&lt;p&gt;To answer this question, we first filter the data and then we group by the country column. When we use the &lt;code&gt;summarize()&lt;/code&gt; function after grouping, it allows us to summarize by these groups. Moreover, combining &lt;code&gt;group_by()&lt;/code&gt; with the &lt;code&gt;mutate()&lt;/code&gt; function modifies columns in each group separately. In &lt;code&gt;summarize()&lt;/code&gt; we calculate the maximum, minimum value and the difference between both extremes creating new columns.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;resi_variability &amp;lt;- residential_mobility %&amp;gt;% 
                        filter(date == ymd(&amp;quot;2020-04-01&amp;quot;),
                               !is.na(sub_region_1)) %&amp;gt;% 
                          group_by(country_region) %&amp;gt;% 
                           summarise(mx = max(resi, na.rm = TRUE), 
                                    min = min(resi, na.rm = TRUE),
                                    range = abs(mx)-abs(min))

arrange(resi_variability, -range)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 94 x 4
##    country_region    mx   min range
##    &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 Nigeria           43     6    37
##  2 United States     35     6    29
##  3 India             36    15    21
##  4 Malaysia          45    26    19
##  5 Philippines       40    21    19
##  6 Vietnam           28     9    19
##  7 Colombia          41    24    17
##  8 Ecuador           44    27    17
##  9 Argentina         35    19    16
## 10 Chile             30    14    16
## # ... with 84 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;join-tables&#34; class=&#34;section level3&#34; number=&#34;4.4.4&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.4.4&lt;/span&gt; Join tables&lt;/h3&gt;
&lt;p&gt;How can we filter the data to get a subset of Europe?&lt;/p&gt;
&lt;p&gt;To do this, we import a spatial dataset with the country code and a column of regions. Detailed explanations about the &lt;code&gt;sf&lt;/code&gt; (&lt;em&gt;simple feature&lt;/em&gt;) package, I’ll leave for another post.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rnaturalearth) # package of spatial vectorial data

# world limits
wld &amp;lt;- ne_countries(returnclass = &amp;quot;sf&amp;quot;)

# filter the countries with iso code and select the two columns of interest
wld &amp;lt;- filter(wld, !is.na(iso_a2)) %&amp;gt;% select(iso_a2, subregion)

# plot
plot(wld)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/index.en_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Other &lt;code&gt;dplyr&lt;/code&gt; functions allow us to join tables: &lt;code&gt;*_join ()&lt;/code&gt;. Depending on which table (left or right) you want to join, the functions change: &lt;code&gt;left_join()&lt;/code&gt;, &lt;code&gt;right_join()&lt;/code&gt; or even &lt;code&gt;full_join()&lt;/code&gt;. The &lt;code&gt;by&lt;/code&gt; argument is not necessary as long as both tables have a column in common. However, in this case the variable names are different, so we use the following way: &lt;code&gt;c(&#34;country_region_code&#34;=&#34;iso_a2&#34;)&lt;/code&gt;. The &lt;code&gt;forcats&lt;/code&gt; package of &lt;code&gt;tidyverse&lt;/code&gt; has many useful functions for handling categorical variables (&lt;code&gt;factors&lt;/code&gt;), variables that have a fixed and known set of possible values. All &lt;code&gt;forcats&lt;/code&gt; functions have the prefix &lt;code&gt;fct_*&lt;/code&gt;. For example, in this case we use &lt;code&gt;fct_reorder()&lt;/code&gt; to reorder the country labels in order of the maximum based on the residential mobility records. Finally, we create a new column &lt;code&gt;&#34;resi_real&#34;&lt;/code&gt; to change the reference value, the average or baseline, from 0 to 100.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;subset_europe &amp;lt;- filter(residential_mobility, 
                        is.na(sub_region_1),
                        !is.na(resi)) %&amp;gt;%
                 left_join(wld, by = c(&amp;quot;country_region_code&amp;quot;=&amp;quot;iso_a2&amp;quot;)) %&amp;gt;% 
                 filter(subregion %in% c(&amp;quot;Northern Europe&amp;quot;,
                                         &amp;quot;Southern Europe&amp;quot;,
                                          &amp;quot;Western Europe&amp;quot;,
                                          &amp;quot;Eastern Europe&amp;quot;)) %&amp;gt;%
                 mutate(resi_real = resi + 100,
                        region = fct_reorder(country_region, 
                                             resi, 
                                            .fun = &amp;quot;max&amp;quot;, 
                                            .desc = FALSE)) %&amp;gt;% 
                select(-geometry, -sub_region_1)

str(subset_europe)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## tibble [3,988 x 7] (S3: tbl_df/tbl/data.frame)
##  $ country_region_code: chr [1:3988] &amp;quot;AT&amp;quot; &amp;quot;AT&amp;quot; &amp;quot;AT&amp;quot; &amp;quot;AT&amp;quot; ...
##  $ country_region     : chr [1:3988] &amp;quot;Austria&amp;quot; &amp;quot;Austria&amp;quot; &amp;quot;Austria&amp;quot; &amp;quot;Austria&amp;quot; ...
##  $ date               : Date[1:3988], format: &amp;quot;2020-02-15&amp;quot; &amp;quot;2020-02-16&amp;quot; ...
##  $ resi               : num [1:3988] -2 -2 0 0 1 0 1 -2 0 -1 ...
##  $ subregion          : chr [1:3988] &amp;quot;Western Europe&amp;quot; &amp;quot;Western Europe&amp;quot; &amp;quot;Western Europe&amp;quot; &amp;quot;Western Europe&amp;quot; ...
##  $ resi_real          : num [1:3988] 98 98 100 100 101 100 101 98 100 99 ...
##  $ region             : Factor w/ 35 levels &amp;quot;Belarus&amp;quot;,&amp;quot;Ukraine&amp;quot;,..: 18 18 18 18 18 18 18 18 18 18 ...
##  - attr(*, &amp;quot;problems&amp;quot;)= tibble [597,554 x 5] (S3: tbl_df/tbl/data.frame)
##   ..$ row     : int [1:597554] 200119 200119 200120 200120 200121 200121 200122 200122 200123 200123 ...
##   ..$ col     : chr [1:597554] &amp;quot;sub_region_2&amp;quot; &amp;quot;census_fips_code&amp;quot; &amp;quot;sub_region_2&amp;quot; &amp;quot;census_fips_code&amp;quot; ...
##   ..$ expected: chr [1:597554] &amp;quot;1/0/T/F/TRUE/FALSE&amp;quot; &amp;quot;1/0/T/F/TRUE/FALSE&amp;quot; &amp;quot;1/0/T/F/TRUE/FALSE&amp;quot; &amp;quot;1/0/T/F/TRUE/FALSE&amp;quot; ...
##   ..$ actual  : chr [1:597554] &amp;quot;Autauga County&amp;quot; &amp;quot;01001&amp;quot; &amp;quot;Autauga County&amp;quot; &amp;quot;01001&amp;quot; ...
##   ..$ file    : chr [1:597554] &amp;quot;&amp;#39;Global_Mobility_Report.csv&amp;#39;&amp;quot; &amp;quot;&amp;#39;Global_Mobility_Report.csv&amp;#39;&amp;quot; &amp;quot;&amp;#39;Global_Mobility_Report.csv&amp;#39;&amp;quot; &amp;quot;&amp;#39;Global_Mobility_Report.csv&amp;#39;&amp;quot; ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;long-and-wide-tables&#34; class=&#34;section level3&#34; number=&#34;4.4.5&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.4.5&lt;/span&gt; Long and wide tables&lt;/h3&gt;
&lt;p&gt;Before we go to create graphics with &lt;code&gt;ggplot2&lt;/code&gt;, it is very common to modify the table between two main formats, long and wide. A table is tidy when 1) each variable is a column 2) each observation/case is a row and 3) each type of observational unit forms a table.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# subset
mobility_selection &amp;lt;- select(subset_europe, country_region_code, date:resi)
mobility_selection&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3,988 x 3
##    country_region_code date        resi
##    &amp;lt;chr&amp;gt;               &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt;
##  1 AT                  2020-02-15    -2
##  2 AT                  2020-02-16    -2
##  3 AT                  2020-02-17     0
##  4 AT                  2020-02-18     0
##  5 AT                  2020-02-19     1
##  6 AT                  2020-02-20     0
##  7 AT                  2020-02-21     1
##  8 AT                  2020-02-22    -2
##  9 AT                  2020-02-23     0
## 10 AT                  2020-02-24    -1
## # ... with 3,978 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# wide table
mobi_wide &amp;lt;- pivot_wider(mobility_selection, 
                         names_from = country_region_code,
                         values_from = resi)
mobi_wide&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 114 x 36
##    date          AT    BA    BE    BG    BY    CH    CZ    DE    DK    EE    ES
##    &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 2020-02-15    -2    -1    -1     0    -1    -1    -2    -1     0     0    -2
##  2 2020-02-16    -2    -1     1    -3     0    -1    -1     0     1     0    -2
##  3 2020-02-17     0    -1     0    -2     0     1     0     0     1     1    -1
##  4 2020-02-18     0    -1     0    -2     0     1     0     1     1     1     0
##  5 2020-02-19     1    -1     0    -1    -1     1     0     1     1     0    -1
##  6 2020-02-20     0    -1     0     0    -1     0     0     1     1     0    -1
##  7 2020-02-21     1    -2     0    -1    -1     1     0     2     1     1    -2
##  8 2020-02-22    -2    -1     0     0    -2    -2    -3     0     1     0    -2
##  9 2020-02-23     0    -1     0    -3    -1    -1     0     0     0    -2    -3
## 10 2020-02-24    -1    -1     4    -1     0     0     0     4     0    16     0
## # ... with 104 more rows, and 24 more variables: FI &amp;lt;dbl&amp;gt;, FR &amp;lt;dbl&amp;gt;, GB &amp;lt;dbl&amp;gt;,
## #   GR &amp;lt;dbl&amp;gt;, HR &amp;lt;dbl&amp;gt;, HU &amp;lt;dbl&amp;gt;, IE &amp;lt;dbl&amp;gt;, IT &amp;lt;dbl&amp;gt;, LT &amp;lt;dbl&amp;gt;, LU &amp;lt;dbl&amp;gt;,
## #   LV &amp;lt;dbl&amp;gt;, MD &amp;lt;dbl&amp;gt;, MK &amp;lt;dbl&amp;gt;, NL &amp;lt;dbl&amp;gt;, NO &amp;lt;dbl&amp;gt;, PL &amp;lt;dbl&amp;gt;, PT &amp;lt;dbl&amp;gt;,
## #   RO &amp;lt;dbl&amp;gt;, RS &amp;lt;dbl&amp;gt;, RU &amp;lt;dbl&amp;gt;, SE &amp;lt;dbl&amp;gt;, SI &amp;lt;dbl&amp;gt;, SK &amp;lt;dbl&amp;gt;, UA &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# back to long table
pivot_longer(mobi_wide,
             2:36,
             names_to = &amp;quot;country_code&amp;quot;,
             values_to = &amp;quot;resi&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3,990 x 3
##    date       country_code  resi
##    &amp;lt;date&amp;gt;     &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt;
##  1 2020-02-15 AT              -2
##  2 2020-02-15 BA              -1
##  3 2020-02-15 BE              -1
##  4 2020-02-15 BG               0
##  5 2020-02-15 BY              -1
##  6 2020-02-15 CH              -1
##  7 2020-02-15 CZ              -2
##  8 2020-02-15 DE              -1
##  9 2020-02-15 DK               0
## 10 2020-02-15 EE               0
## # ... with 3,980 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another group of functions you should take a look at are: &lt;code&gt;separate()&lt;/code&gt;, &lt;code&gt;case_when()&lt;/code&gt;, &lt;code&gt;complete()&lt;/code&gt;. More details can be found in the &lt;a href=&#34;https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf&#34;&gt;Cheat-Sheet&lt;/a&gt; of &lt;code&gt;dplyr&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;visualize-data&#34; class=&#34;section level2&#34; number=&#34;4.5&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.5&lt;/span&gt; Visualize data&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;ggplot2&lt;/code&gt; is a modern system for data visualization with a huge variety of options. Unlike the R Base graphic system, in &lt;code&gt;ggplot2&lt;/code&gt; a different grammar is used. The grammar of graphics (gg) consists of the sum of several independent layers or objects that are combined using &lt;code&gt;+&lt;/code&gt; to construct the final graph. &lt;code&gt;ggplot&lt;/code&gt; differentiates between data, what is displayed and how it is displayed.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;data&lt;/em&gt;: our dataset (&lt;code&gt;data.frame&lt;/code&gt; or &lt;code&gt;tibble&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;aesthetics&lt;/em&gt;: with the &lt;code&gt;aes()&lt;/code&gt; function we indicate the variables that correspond to the x, y, z, … axes, or when it is intended to apply graphic parameters (color, size, shape) according to a variable. It is possible to include &lt;code&gt;aes()&lt;/code&gt; in &lt;code&gt;ggplot()&lt;/code&gt; or in the corresponding function to a geometry &lt;code&gt;geom_ *&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;geometries&lt;/em&gt;: are &lt;code&gt;geom_ *&lt;/code&gt; objects that indicate the geometry to be used, (eg: &lt;code&gt;geom_point()&lt;/code&gt;, &lt;code&gt;geom_line()&lt;/code&gt;, &lt;code&gt;geom_boxplot()&lt;/code&gt;, etc.).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;scales&lt;/em&gt;: are objects of type &lt;code&gt;scales_ *&lt;/code&gt; (eg, &lt;code&gt;scale_x_continous()&lt;/code&gt;, &lt;code&gt;scale_colour_manual()&lt;/code&gt;) to manipulate axes, define colors, etc.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;statistics&lt;/em&gt;: are &lt;code&gt;stat_ *&lt;/code&gt; objects (eg, &lt;code&gt;stat_density()&lt;/code&gt;) that allow to apply statistical transformations.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;More details can be found in the &lt;a href=&#34;https://github.com/rstudio/cheatsheets/raw/master/data-visualization-2.1.pdf&#34;&gt;Cheat-Sheet&lt;/a&gt; of &lt;code&gt;ggplot2&lt;/code&gt;. &lt;code&gt;ggplot&lt;/code&gt; is constantly supplemented by extensions for geometries or other graphical options (see &lt;a href=&#34;https://exts.ggplot2.tidyverse.org/ggiraph.html&#34; class=&#34;uri&#34;&gt;https://exts.ggplot2.tidyverse.org/ggiraph.html&lt;/a&gt;), for graphical ideas have a look a the R Graph Gallery (&lt;a href=&#34;https://www.r-graph-gallery.com/&#34; class=&#34;uri&#34;&gt;https://www.r-graph-gallery.com/&lt;/a&gt;).&lt;/p&gt;
&lt;div id=&#34;line-and-scatter-plot&#34; class=&#34;section level3&#34; number=&#34;4.5.1&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.5.1&lt;/span&gt; Line and scatter plot&lt;/h3&gt;
&lt;p&gt;We create a subset of our mobility data for residences and parks, filtering the records for Italian regions. In addition, we divide the mobility values in percentage by 100 to obtain the fraction, since &lt;code&gt;ggplot2&lt;/code&gt; allows us to indicate the unit of percentage in the label argument (see last plot in this section).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create subset
it &amp;lt;- filter(google_mobility, 
             country_region == &amp;quot;Italy&amp;quot;, 
             is.na(sub_region_1)) %&amp;gt;% 
      mutate(resi = residential_percent_change_from_baseline/100,   
             parks = parks_percent_change_from_baseline/100)


# line plot
ggplot(it, 
       aes(date, resi)) + 
  geom_line()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/index.en_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;2100&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# scatter plot
ggplot(it, 
       aes(parks, resi)) + 
  geom_point() +
  geom_smooth(method = &amp;quot;lm&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/index.en_files/figure-html/unnamed-chunk-20-2.png&#34; width=&#34;2100&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To modify the axes, we use the different &lt;code&gt;scale_*&lt;/code&gt; functions that we must adapt to the scales of measurement (date, discrete, continuous, etc.). The &lt;code&gt;labs()&lt;/code&gt; function helps us define the axis, legend and plot titles. Finally, we add the style of the graph with &lt;code&gt;theme_light()&lt;/code&gt; (others are &lt;code&gt;theme_bw()&lt;/code&gt;, &lt;code&gt;theme_minimal()&lt;/code&gt;, etc.). We could also make changes to all graphic elements through &lt;code&gt;theme()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# time serie plot
ggplot(it, 
       aes(date, resi)) + 
  geom_line(colour = &amp;quot;#560A86&amp;quot;, size = 0.8) +
  scale_x_date(date_breaks = &amp;quot;10 days&amp;quot;, 
               date_labels = &amp;quot;%d %b&amp;quot;) +
  scale_y_continuous(breaks = seq(-0.1, 1, 0.1), 
                     labels = scales::percent) +
  labs(x = &amp;quot;&amp;quot;, 
       y = &amp;quot;Residential mobility&amp;quot;,
       title = &amp;quot;Mobility during COVID-19&amp;quot;) +
  theme_light()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/index.en_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;2100&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# scatter plot
ggplot(it, 
       aes(parks, resi)) + 
  geom_point(alpha = .4, size = 2) +
  geom_smooth(method = &amp;quot;lm&amp;quot;) +
  scale_x_continuous(breaks = seq(-1, 1.4, 0.2), 
                     labels = scales::percent) +
  scale_y_continuous(breaks = seq(-1, 1, 0.1), 
                     labels = scales::percent) +
  labs(x = &amp;quot;Park mobility&amp;quot;, 
       y = &amp;quot;Residential mobility&amp;quot;,
       title = &amp;quot;Mobility during COVID-19&amp;quot;) +
  theme_light()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/index.en_files/figure-html/unnamed-chunk-21-2.png&#34; width=&#34;2100&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;boxplot&#34; class=&#34;section level3&#34; number=&#34;4.5.2&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.5.2&lt;/span&gt; Boxplot&lt;/h3&gt;
&lt;p&gt;We can visualize different aspects of the mobility with other geometries. Here we will create boxplots for each European country representing the variability of mobility between and within countries during the COVID-19 pandemic.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# subset
subset_europe_reg &amp;lt;- filter(residential_mobility, 
                           !is.na(sub_region_1),
                           !is.na(resi)) %&amp;gt;%
                     left_join(wld, by = c(&amp;quot;country_region_code&amp;quot;=&amp;quot;iso_a2&amp;quot;)) %&amp;gt;% 
                     filter(subregion %in% c(&amp;quot;Northern Europe&amp;quot;,
                                         &amp;quot;Southern Europe&amp;quot;,
                                          &amp;quot;Western Europe&amp;quot;,
                                          &amp;quot;Eastern Europe&amp;quot;)) %&amp;gt;% 
                     mutate(resi = resi/100, 
                            country_region = fct_reorder(country_region, resi))

# boxplot
ggplot(subset_europe_reg, 
       aes(country_region, resi, fill = subregion)) + 
  geom_boxplot() +
  scale_y_continuous(breaks = seq(-0.1, 1, 0.1), labels = scales::percent) +
  scale_fill_brewer(palette = &amp;quot;Set1&amp;quot;) +
  coord_flip() +
   labs(x = &amp;quot;&amp;quot;, 
       y = &amp;quot;Residential mobility&amp;quot;,
       title = &amp;quot;Mobility during COVID-19&amp;quot;, 
       fill = &amp;quot;&amp;quot;) +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/index.en_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;2100&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;heatmap&#34; class=&#34;section level3&#34; number=&#34;4.5.3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.5.3&lt;/span&gt; Heatmap&lt;/h3&gt;
&lt;p&gt;To visualize the mobility trend of all European countries it is recommended to use a heatmap instead of a bundle of lines. Before building the graph, we will create a vector of Sundays for the x-axis labels in the observation period.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# sequence of dates
df &amp;lt;- data.frame(d = seq(ymd(&amp;quot;2020-02-15&amp;quot;), ymd(&amp;quot;2020-06-07&amp;quot;), &amp;quot;day&amp;quot;))

# filter on Sundays 
sundays &amp;lt;- df %&amp;gt;% 
            mutate(wd = wday(d, week_start = 1)) %&amp;gt;% 
             filter(wd == 7) %&amp;gt;% 
              pull(d)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To difference between European regions, we will use a color fill for the boxplots. We can set the color type with &lt;code&gt;scale_fill_*&lt;/code&gt;, in this case, from the viridis scheme. In addition, the &lt;code&gt;guides()&lt;/code&gt; function can modify the color bar of the legend. Finally, here we see the use of &lt;code&gt;theme()&lt;/code&gt; with additional changes to &lt;code&gt;theme_minimal()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# headmap
ggplot(subset_europe, 
       aes(date, region, fill = resi_real)) +
  geom_tile() +
  scale_x_date(breaks = sundays,
               date_labels = &amp;quot;%d %b&amp;quot;) +
  scale_fill_viridis_c(option = &amp;quot;A&amp;quot;, 
                       breaks = c(91, 146),
                       labels = c(&amp;quot;Less&amp;quot;, &amp;quot;More&amp;quot;), 
                       direction = -1) +
  theme_minimal() +
  theme(legend.position = &amp;quot;top&amp;quot;, 
        title = element_text(size = 14),
        panel.grid.major.x = element_line(colour = &amp;quot;white&amp;quot;, linetype = &amp;quot;dashed&amp;quot;),
        panel.grid.minor.x = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.ontop = TRUE,
        plot.margin = margin(r = 1, unit = &amp;quot;cm&amp;quot;)) +
  labs(y = &amp;quot;&amp;quot;, 
       x = &amp;quot;&amp;quot;, 
       fill = &amp;quot;&amp;quot;, 
       title = &amp;quot;Mobility trends for places of residence&amp;quot;,
       caption = &amp;quot;Data: google.com/covid19/mobility/&amp;quot;) +
  guides(fill = guide_colorbar(barwidth = 10, 
                               barheight = .5,
                               label.position = &amp;quot;top&amp;quot;, 
                               ticks = FALSE)) +
  coord_cartesian(expand = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/index.en_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;3675&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;apply-functions-on-vectors-or-lists&#34; class=&#34;section level2&#34; number=&#34;4.6&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.6&lt;/span&gt; Apply functions on vectors or lists&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;purrr&lt;/code&gt; package contains a set of advanced functional programming functions for working with functions and vectors. The known &lt;code&gt;lapply()&lt;/code&gt; family of R Base corresponds to the &lt;code&gt;map()&lt;/code&gt; functions in this package. One of the biggest advantages is being able to reduce the use of loops (&lt;code&gt;for&lt;/code&gt;, etc.).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# list of two vectors
vec_list &amp;lt;- list(x = 1:10, y = 50:70)

# calculate the average for each one
map(vec_list, mean)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $x
## [1] 5.5
## 
## $y
## [1] 60&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# change the output type map_* (dbl, chr, lgl, etc.)
map_dbl(vec_list, mean)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    x    y 
##  5.5 60.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, a more complex example. We calculate the correlation coefficient between residential and park mobility in all European countries. To get a tidy summary of a model or test we use the &lt;code&gt;tidy()&lt;/code&gt; function of the &lt;code&gt;broom&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(broom) # tidy outputs

# custom function
cor_test &amp;lt;- function(x, formula) { 
  
df &amp;lt;- cor.test(as.formula(formula), data = x) %&amp;gt;% tidy()

return(df)
  
}

# prepare the data
europe_reg &amp;lt;- filter(google_mobility, 
                           !is.na(sub_region_1),
                           !is.na(residential_percent_change_from_baseline)) %&amp;gt;%
                     left_join(wld, by = c(&amp;quot;country_region_code&amp;quot;=&amp;quot;iso_a2&amp;quot;)) %&amp;gt;% 
                     filter(subregion %in% c(&amp;quot;Northern Europe&amp;quot;,
                                         &amp;quot;Southern Europe&amp;quot;,
                                          &amp;quot;Western Europe&amp;quot;,
                                          &amp;quot;Eastern Europe&amp;quot;))

# apply the function to each country creating a list
cor_mobility &amp;lt;- europe_reg %&amp;gt;%
                 split(.$country_region_code) %&amp;gt;% 
                   map(cor_test, formula = &amp;quot;~ residential_percent_change_from_baseline + parks_percent_change_from_baseline&amp;quot;)  

cor_mobility[1:5]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $AT
## # A tibble: 1 x 8
##   estimate statistic  p.value parameter conf.low conf.high method    alternative
##      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;int&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;      
## 1   -0.360     -12.3 2.68e-32      1009   -0.413    -0.305 Pearson&amp;#39;~ two.sided  
## 
## $BE
## # A tibble: 1 x 8
##   estimate statistic  p.value parameter conf.low conf.high method    alternative
##      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;int&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;      
## 1   -0.312     -6.06  3.67e-9       340   -0.405    -0.213 Pearson&amp;#39;~ two.sided  
## 
## $BG
## # A tibble: 1 x 8
##   estimate statistic   p.value parameter conf.low conf.high method   alternative
##      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;int&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;      
## 1   -0.677     -37.8 1.47e-227      1694   -0.702    -0.650 Pearson~ two.sided  
## 
## $CH
## # A tibble: 1 x 8
##   estimate statistic p.value parameter conf.low conf.high method     alternative
##      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;     &amp;lt;int&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;      
## 1  -0.0786     -2.91 0.00370      1360   -0.131   -0.0256 Pearson&amp;#39;s~ two.sided  
## 
## $CZ
## # A tibble: 1 x 8
##   estimate statistic  p.value parameter conf.low conf.high method    alternative
##      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;int&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;      
## 1  -0.0837     -3.35 0.000824      1593   -0.132   -0.0347 Pearson&amp;#39;~ two.sided&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we’ve seen before, there are subfunctions of &lt;code&gt;map_*&lt;/code&gt; to get an object of another class instead of a list, here for a bind &lt;code&gt;data.frame&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor_mobility &amp;lt;- europe_reg %&amp;gt;%
                  split(.$country_region_code) %&amp;gt;% 
                     map_df(cor_test, 
                            formula = &amp;quot;~ residential_percent_change_from_baseline + parks_percent_change_from_baseline&amp;quot;, 
                            .id = &amp;quot;country_code&amp;quot;)

arrange(cor_mobility, estimate)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 27 x 9
##    country_code estimate statistic   p.value parameter conf.low conf.high method
##    &amp;lt;chr&amp;gt;           &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;int&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; 
##  1 IT             -0.831    -71.0  0              2250   -0.844    -0.818 Pears~
##  2 ES             -0.825    -65.4  0              2005   -0.839    -0.811 Pears~
##  3 PT             -0.729    -46.9  2.12e-321      1938   -0.749    -0.707 Pears~
##  4 FR             -0.698    -37.4  3.29e-216      1474   -0.723    -0.671 Pears~
##  5 GR             -0.692    -27.0  1.03e-114       796   -0.726    -0.654 Pears~
##  6 BG             -0.677    -37.8  1.47e-227      1694   -0.702    -0.650 Pears~
##  7 RO             -0.640    -56.0  0              4517   -0.657    -0.623 Pears~
##  8 SI             -0.627    -11.4  1.98e- 23       200   -0.704    -0.535 Pears~
##  9 HR             -0.579    -21.9  9.32e- 87       954   -0.620    -0.536 Pears~
## 10 LV             -0.544     -6.87 3.84e- 10       112   -0.662    -0.401 Pears~
## # ... with 17 more rows, and 1 more variable: alternative &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Other practical examples here in this &lt;a href=&#34;https://dominicroye.github.io/en/2019/import-excel-sheets-with-r/&#34;&gt;post&lt;/a&gt; or this &lt;a href=&#34;https://dominicroye.github.io/en/2019/tidy-correlation-tests-in-r/&#34;&gt;other&lt;/a&gt;. More details can be found in the &lt;a href=&#34;https://github.com/rstudio/cheatsheets/raw/master/purrr.pdf&#34;&gt;Cheat-Sheet&lt;/a&gt; of &lt;code&gt;purrr&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
      
            <category>introduction</category>
      
            <category>visualization</category>
      
            <category>manipulation</category>
      
            <category>data</category>
      
            <category>COVID-19</category>
      
      
            <category>tidyverse</category>
      
            <category>R</category>
      
            <category>R:elementary</category>
      
    </item>
    
    <item>
      <title>Visualize climate anomalies</title>
      <link>https://dominicroye.github.io/en/2020/visualize-climate-anomalies/</link>
      <pubDate>Sun, 29 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dominicroye.github.io/en/2020/visualize-climate-anomalies/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2020/visualize-climate-anomalies/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;When we visualize precipitation and temperature anomalies, we simply use time series as bar graph indicating negative and positive values in red and blue. However, in order to have a better overview we need both anomalies in a single graph. In this way we could more easly answer the question of whether a particular season or month was dry-warm or wet-cold, and even compare these anomalies in the context of previous years.&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Packages&lt;/h2&gt;
&lt;p&gt;In this post we will use the following packages:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;10%&#34; /&gt;
&lt;col width=&#34;89%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Package&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lubridate&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Easy manipulation of dates and times&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ggrepel&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Repel overlapping text labels in ggplot2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#we install the packages if necessary
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;ggrepel&amp;quot;)) install.packages(&amp;quot;ggrepel&amp;quot;)
if(!require(&amp;quot;lubridate&amp;quot;)) install.packages(&amp;quot;lubridate&amp;quot;)

#packages
library(tidyverse)
library(lubridate)
library(ggrepel)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;preparing-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Preparing the data&lt;/h2&gt;
&lt;p&gt;First we import the daily precipitation and temperature data from the selected weather station (&lt;a href=&#34;https://dominicroye.github.io/files/meteo_tenerife.csv&#34;&gt;download&lt;/a&gt;). We will use the data from Tenerife South (Spain) [1981-2020] accessible through &lt;a href=&#34;https://opendata.aemet.es/&#34;&gt;Open Data AEMET&lt;/a&gt;. In R there is a package called &lt;a href=&#34;https://vegmod.ctfc.cat/software/meteoland/&#34;&gt;&lt;code&gt;meteoland&lt;/code&gt;&lt;/a&gt; that facilitates the download with specific functions to access data from AEMET (Spanish State Meteorological Agency), Meteogalicia (Galician Meteorological Service) and Meteocat (Catalan Meteorological Service).&lt;/p&gt;
&lt;div id=&#34;step-1-import-the-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Step 1: import the data&lt;/h3&gt;
&lt;p&gt;We import the data in &lt;em&gt;csv&lt;/em&gt; format, the first column is the date, the second column the precipitation (pr) and the last column the average daily temperature (ta).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- read_csv(&amp;quot;meteo_tenerife.csv&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## -- Column specification --------------------------------------------------------
## cols(
##   date = col_date(format = &amp;quot;&amp;quot;),
##   pr = col_double(),
##   ta = col_double()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 14,303 x 3
##    date          pr    ta
##    &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 1981-01-02   0    17.6
##  2 1981-01-03   0    16.8
##  3 1981-01-04   0    17.4
##  4 1981-01-05   0    17.6
##  5 1981-01-06   0    17  
##  6 1981-01-07   0    17.6
##  7 1981-01-08   0    18.6
##  8 1981-01-09   0    19.8
##  9 1981-01-10   0    21.5
## 10 1981-01-11   3.8  17.6
## # ... with 14,293 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-2-preparing-the-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Step 2: preparing the data&lt;/h3&gt;
&lt;p&gt;In the second step we prepare the data to calculate the anomalies. To do this, we create three new columns: the month, the year, and the season of the year. Since our objective is to analyse winter anomalies, we cannot use the calendar year, because winter includes the month of December of one year and the months of January and February of the following. The custom function &lt;code&gt;meteo_yr()&lt;/code&gt; extracts the year from a date indicating the starting month. The concept is similar to the hydrological year in which it starts on October 1.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meteo_yr &amp;lt;- function(dates, start_month = NULL) {
  # convert to POSIXlt
  dates.posix &amp;lt;- as.POSIXlt(dates)
  # year offset
  offset &amp;lt;- ifelse(dates.posix$mon &amp;gt;= start_month - 1, 1, 0)
  # new year
  adj.year = dates.posix$year + 1900 + offset
  return(adj.year)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will use many functions of the package collection &lt;code&gt;tidyverse&lt;/code&gt; (&lt;a href=&#34;https://www.tidyverse.org/&#34; class=&#34;uri&#34;&gt;https://www.tidyverse.org/&lt;/a&gt;). The &lt;code&gt;mutate()&lt;/code&gt; function helps to add new columns or change existing ones. To define the seasons, we use the &lt;code&gt;case_when()&lt;/code&gt; function from the &lt;code&gt;dplyr&lt;/code&gt; package, which has many advantages compared to a chain of &lt;code&gt;ifelse()&lt;/code&gt;. In &lt;code&gt;case_when()&lt;/code&gt; we use two-side formulas, on the one hand the condition and on the other the action when that condition is met. A two-sided formula in R consists of the operator &lt;code&gt;~&lt;/code&gt;. The binary operator &lt;code&gt;%in%&lt;/code&gt; allows us to filter several values in a greater set.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- mutate(data, 
               winter_yr = meteo_yr(date, 12),
               month = month(date), 
               season = case_when(month %in% c(12,1:2) ~ &amp;quot;Winter&amp;quot;,
                                  month %in% 3:5 ~ &amp;quot;Spring&amp;quot;,
                                  month %in% 6:8 ~ &amp;quot;Summer&amp;quot;,
                                  month %in% 9:11 ~ &amp;quot;Autum&amp;quot;))

data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 14,303 x 6
##    date          pr    ta winter_yr month season
##    &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; 
##  1 1981-01-02   0    17.6      1981     1 Winter
##  2 1981-01-03   0    16.8      1981     1 Winter
##  3 1981-01-04   0    17.4      1981     1 Winter
##  4 1981-01-05   0    17.6      1981     1 Winter
##  5 1981-01-06   0    17        1981     1 Winter
##  6 1981-01-07   0    17.6      1981     1 Winter
##  7 1981-01-08   0    18.6      1981     1 Winter
##  8 1981-01-09   0    19.8      1981     1 Winter
##  9 1981-01-10   0    21.5      1981     1 Winter
## 10 1981-01-11   3.8  17.6      1981     1 Winter
## # ... with 14,293 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-3-estimate-winter-anomalies&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Step 3: estimate winter anomalies&lt;/h3&gt;
&lt;p&gt;In the next step we create a subset of the winter months. Then we group by the defined meteorological year and calculate the sum and average for precipitation and temperature, respectively. To facilitate the work, the &lt;code&gt;magrittr&lt;/code&gt; package introduces the operator called &lt;em&gt;pipe&lt;/em&gt; in the form &lt;code&gt;%&amp;gt;%&lt;/code&gt; with the aim of combining several functions without the need to assign the result to a new object. The &lt;em&gt;pipe&lt;/em&gt; operator passes the output of a function applied to the first argument of the next function. This way of combining functions allows you to chain several steps simultaneously. The &lt;code&gt;%&amp;gt;%&lt;/code&gt; must be understood and pronounced as &lt;em&gt;then&lt;/em&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_inv &amp;lt;- filter(data, 
                   season == &amp;quot;Winter&amp;quot;) %&amp;gt;% 
              group_by(winter_yr) %&amp;gt;%
                  summarise(pr = sum(pr, na.rm = TRUE),
                            ta = mean(ta, na.rm = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we only have to calculate the anomalies of precipitation and temperature. The columns &lt;code&gt;pr_mean&lt;/code&gt; and &lt;code&gt;ta_mean&lt;/code&gt; will contain the climate average, the reference for the anomalies with respect to the normal period 1981-2010. Therefore, we need to filter the values to the period before 2010, which we will do in the usual way of filtering vectors in R. Once we have the references we estimate the anomalies &lt;code&gt;pr_anom&lt;/code&gt; and &lt;code&gt;ta_anom&lt;/code&gt;. To facilitate the interpretation, in the case of precipitation we express the anomalies as percentage, with the average set at 0% instead of 100%.&lt;/p&gt;
&lt;p&gt;In addition, we add three required columns with information for the creation of the graph: 1) &lt;code&gt;labyr&lt;/code&gt; contains the year of each anomaly as long as it has been greater/less than -+10% or -+0.5ºC, respectively (this is for reducing the number of labels), 2) &lt;code&gt;symb_point&lt;/code&gt; is a dummy variable in order to be able to create different symbols between the cases of (1), and 3) &lt;code&gt;lab_font&lt;/code&gt; for highlighting in bold the year 2020.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_inv &amp;lt;-  mutate(data_inv, pr_mean = mean(pr[winter_yr &amp;lt;= 2010]), 
                              ta_mean = mean(ta[winter_yr &amp;lt;= 2010]),
                              pr_anom = (pr*100/pr_mean)-100, 
                              ta_anom = ta-ta_mean,
                              
                              labyr = case_when(pr_anom &amp;lt; -10 &amp;amp; ta_anom &amp;lt; -.5 ~ winter_yr,
                                                pr_anom &amp;lt; -10 &amp;amp; ta_anom &amp;gt; .5 ~ winter_yr,
                                                pr_anom &amp;gt; 10 &amp;amp; ta_anom &amp;lt; -.5 ~ winter_yr,
                                                pr_anom &amp;gt; 10 &amp;amp; ta_anom &amp;gt; .5 ~ winter_yr),
                              symb_point = ifelse(!is.na(labyr), &amp;quot;yes&amp;quot;, &amp;quot;no&amp;quot;),
                              lab_font = ifelse(labyr == 2020, &amp;quot;bold&amp;quot;, &amp;quot;plain&amp;quot;)
                    )&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-the-graph&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Creating the graph&lt;/h2&gt;
&lt;p&gt;We will build the chart adding layer by layer the distinctive elements: 1) the background with the different grids (Dry-Warm, Dry-Cold, etc.), 2) the points and labels, and 3) the style adjustments.&lt;/p&gt;
&lt;div id=&#34;part-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Part 1&lt;/h3&gt;
&lt;p&gt;The idea is that the points with dry-warm anomalies are located in quadrant I (top-right) and those with wet-cold in quadrant III (bottom-left). Therefore, we must invert the sign in the precipitation anomalies. Then we create a &lt;code&gt;data.frame&lt;/code&gt; with the label positions of the four quadrants. For the positions in &lt;em&gt;x&lt;/em&gt; and &lt;em&gt;y&lt;/em&gt; &lt;code&gt;Inf&lt;/code&gt; and &lt;code&gt;-Inf&lt;/code&gt; are used, which is equivalent to the maximum panel sides with respect to the data. However, it is necessary to adjust the position towards the extreme points within the panel with the known arguments of &lt;code&gt;ggplot2&lt;/code&gt;: &lt;em&gt;hjust&lt;/em&gt; and &lt;em&gt;vjust&lt;/em&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_inv_p &amp;lt;- mutate(data_inv, pr_anom = pr_anom * -1)

bglab &amp;lt;- data.frame(x = c(-Inf, Inf, -Inf, Inf), 
                    y = c(Inf, Inf, -Inf, -Inf),
                    hjust = c(1, 1, 0, 0), 
                    vjust = c(1, 0, 1, 0),
                    lab = c(&amp;quot;Wet-Warm&amp;quot;, &amp;quot;Dry-Warm&amp;quot;,
                              &amp;quot;Wet-Cold&amp;quot;, &amp;quot;Dry-Cold&amp;quot;))

  
bglab&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      x    y hjust vjust      lab
## 1 -Inf  Inf     1     1 Wet-Warm
## 2  Inf  Inf     1     0 Dry-Warm
## 3 -Inf -Inf     0     1 Wet-Cold
## 4  Inf -Inf     0     0 Dry-Cold&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;part-2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Part 2&lt;/h3&gt;
&lt;p&gt;In the second part we can start building the chart by adding all graphical elements. First we create the background with different colors of each quadrant. The function &lt;code&gt;annotate()&lt;/code&gt; allows adding geometry layers without the use of variables within &lt;code&gt;data.frames&lt;/code&gt;. With the &lt;code&gt;geom_hline()&lt;/code&gt; and &lt;code&gt;geom_vline()&lt;/code&gt; function we mark the quadrants horizontally and vertically using a dashed line. Finally, we draw the labels of each quadrant, using the function &lt;code&gt;geom_text()&lt;/code&gt;. When we use other data sources than the main one used in &lt;code&gt;ggplot()&lt;/code&gt;, we must indicate it with the argument &lt;code&gt;data&lt;/code&gt; in the corresponding geometry function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;g1 &amp;lt;- ggplot(data_inv_p, 
             aes(pr_anom, ta_anom)) +
         annotate(&amp;quot;rect&amp;quot;, xmin = -Inf, xmax = 0, ymin = 0, ymax = Inf, fill = &amp;quot;#fc9272&amp;quot;, alpha = .6) + #wet-warm
         annotate(&amp;quot;rect&amp;quot;, xmin = 0, xmax = Inf, ymin = 0, ymax = Inf, fill = &amp;quot;#cb181d&amp;quot;, alpha = .6) + #dry-warm
         annotate(&amp;quot;rect&amp;quot;, xmin = -Inf, xmax = 0, ymin = -Inf, ymax = 0, fill = &amp;quot;#2171b5&amp;quot;, alpha = .6) + #wet-cold
         annotate(&amp;quot;rect&amp;quot;, xmin = 0, xmax = Inf, ymin = -Inf, ymax = 0, fill = &amp;quot;#c6dbef&amp;quot;, alpha = .6) + #dry-cold
       geom_hline(yintercept = 0,
                  linetype = &amp;quot;dashed&amp;quot;) +
       geom_vline(xintercept = 0,
                  linetype = &amp;quot;dashed&amp;quot;) +
       geom_text(data = bglab, 
                     aes(x, y, label = lab, hjust = hjust, vjust = vjust),
                     fontface = &amp;quot;italic&amp;quot;, size = 5, 
                     angle = 90, colour = &amp;quot;white&amp;quot;)

g1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/visualize-climate-anomalies/index.en_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;3507&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;part-3&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Part 3&lt;/h3&gt;
&lt;p&gt;In the third part we simply add the points of the anomalies and the labels of the years. The &lt;code&gt;geom_text_repel()&lt;/code&gt; function is similar to the one known by default in &lt;code&gt;ggplot2&lt;/code&gt;, &lt;code&gt;geom_text()&lt;/code&gt;, but it repels overlapping text labels away from each other.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;g2 &amp;lt;- g1 + geom_point(aes(fill = symb_point, colour = symb_point),
                      size = 2.8, shape = 21, show.legend = FALSE) +
           geom_text_repel(aes(label = labyr, fontface = lab_font),
                           max.iter = 5000, 
                           size = 3.5) 
g2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 25 rows containing missing values (geom_text_repel).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/visualize-climate-anomalies/index.en_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;3507&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;part-4&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Part 4&lt;/h3&gt;
&lt;p&gt;In the last part we adjust, in addition to the general style, the axes, the color type and the (sub)title. Remember that we changed the sign on precipitation anomalies. Hence, we must use the arguments &lt;code&gt;breaks&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt; in the function &lt;code&gt;scale_x_continouous()&lt;/code&gt; to reverse the sign in the labels corresponding to the breaks.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;g3 &amp;lt;- g2 + scale_x_continuous(&amp;quot;Precipitation anomaly in %&amp;quot;,
                              breaks = seq(-100, 250, 10) * -1,
                              labels = seq(-100, 250, 10),
                              limits = c(min(data_inv_p$pr_anom), 100)) +
           scale_y_continuous(&amp;quot;Mean temperature anomaly in ºC&amp;quot;,
                              breaks = seq(-2, 2, 0.5)) +
           scale_fill_manual(values = c(&amp;quot;black&amp;quot;, &amp;quot;white&amp;quot;)) +
           scale_colour_manual(values = rev(c(&amp;quot;black&amp;quot;, &amp;quot;white&amp;quot;))) +
           labs(title = &amp;quot;Winter anomalies in Tenerife South&amp;quot;, 
                caption = &amp;quot;Data: AEMET\nNormal period 1981-2010&amp;quot;) +
           theme_bw()

g3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 25 rows containing missing values (geom_text_repel).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/visualize-climate-anomalies/index.en_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;3507&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
      
            <category>anomaly</category>
      
            <category>precipitation</category>
      
            <category>temperature</category>
      
            <category>climate</category>
      
            <category>points</category>
      
      
            <category>visualization</category>
      
            <category>R</category>
      
            <category>R:intermediate</category>
      
    </item>
    
    <item>
      <title>Geographic distance</title>
      <link>https://dominicroye.github.io/en/2020/geographic-distance/</link>
      <pubDate>Sun, 19 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dominicroye.github.io/en/2020/geographic-distance/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2020/geographic-distance/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;The first post of this year 2020, I will dedicate to a question that I was recently asked. The question was how to calculate the shortest distance between different points and how to know which is the closest point. When we work with spatial data in R, currently the easiest thing is to use the &lt;code&gt;sf&lt;/code&gt; package in combination with the &lt;code&gt;tidyverse&lt;/code&gt; collection of packages. We also use the &lt;code&gt;units&lt;/code&gt; package which is very useful for working with units of measurement.&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Packages&lt;/h2&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;12%&#34; /&gt;
&lt;col width=&#34;87%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Package&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Simple Feature: import, export and manipulate vector data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;units&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Support for measurement units in R vectors, matrices and arrays: propagation, conversion, derivation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;maps&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Draw geographical maps&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;rnaturalearth&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Hold and facilitate interaction with Natural Earth map data&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install the necessary packages
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;units&amp;quot;)) install.packages(&amp;quot;units&amp;quot;)
if(!require(&amp;quot;sf&amp;quot;)) install.packages(&amp;quot;sf&amp;quot;)
if(!require(&amp;quot;maps&amp;quot;)) install.packages(&amp;quot;maps&amp;quot;)
if(!require(&amp;quot;rnaturalearth&amp;quot;)) install.packages(&amp;quot;rnaturalearth&amp;quot;)

# load packages
library(maps)
library(sf) 
library(tidyverse)
library(units)
library(rnaturalearth)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;measurement-units&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Measurement units&lt;/h2&gt;
&lt;p&gt;The use of vectors and matrices with the &lt;code&gt;units&lt;/code&gt; class allows us to calculate and transform units of measurement.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# length
l &amp;lt;- set_units(1:10, m)
l&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Units: [m]
##  [1]  1  2  3  4  5  6  7  8  9 10&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# convert units
set_units(l, cm)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Units: [cm]
##  [1]  100  200  300  400  500  600  700  800  900 1000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# sum different units
set_units(l, cm) + l&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Units: [cm]
##  [1]  200  400  600  800 1000 1200 1400 1600 1800 2000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# area
a &amp;lt;- set_units(355, ha)
set_units(a, km2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 3.55 [km2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# velocity
vel &amp;lt;- set_units(seq(20, 50, 10), km/h)
set_units(vel, m/s)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Units: [m/s]
## [1]  5.555556  8.333333 11.111111 13.888889&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;capital-cities-of-the-world&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Capital cities of the world&lt;/h2&gt;
&lt;p&gt;We will use the capital cities of the whole world with the objective of calculating the distance to the nearest capital city and indicating the name/country.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# set of world cities with coordinates
head(world.cities) # from the maps package&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                 name country.etc   pop   lat  long capital
## 1 &amp;#39;Abasan al-Jadidah   Palestine  5629 31.31 34.34       0
## 2 &amp;#39;Abasan al-Kabirah   Palestine 18999 31.32 34.35       0
## 3       &amp;#39;Abdul Hakim    Pakistan 47788 30.55 72.11       0
## 4 &amp;#39;Abdullah-as-Salam      Kuwait 21817 29.36 47.98       0
## 5              &amp;#39;Abud   Palestine  2456 32.03 35.07       0
## 6            &amp;#39;Abwein   Palestine  3434 32.03 35.20       0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To convert points with longitude and latitude into a spatial object of class &lt;code&gt;sf&lt;/code&gt;, we use the function &lt;code&gt;st_as_sf()&lt;/code&gt;, indicating the coordinate columns and the coordinate reference system (WSG84, epsg: 4326).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# convert the points into an sf object with CRS WSG84
cities &amp;lt;- st_as_sf(world.cities, coords = c(&amp;quot;long&amp;quot;, &amp;quot;lat&amp;quot;), crs = 4326)
cities&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Simple feature collection with 43645 features and 4 fields
## Geometry type: POINT
## Dimension:     XY
## Bounding box:  xmin: -178.8 ymin: -54.79 xmax: 179.81 ymax: 78.93
## Geodetic CRS:  WGS 84
## First 10 features:
##                  name  country.etc   pop capital            geometry
## 1  &amp;#39;Abasan al-Jadidah    Palestine  5629       0 POINT (34.34 31.31)
## 2  &amp;#39;Abasan al-Kabirah    Palestine 18999       0 POINT (34.35 31.32)
## 3        &amp;#39;Abdul Hakim     Pakistan 47788       0 POINT (72.11 30.55)
## 4  &amp;#39;Abdullah-as-Salam       Kuwait 21817       0 POINT (47.98 29.36)
## 5               &amp;#39;Abud    Palestine  2456       0 POINT (35.07 32.03)
## 6             &amp;#39;Abwein    Palestine  3434       0  POINT (35.2 32.03)
## 7            &amp;#39;Adadlay      Somalia  9198       0  POINT (44.65 9.77)
## 8              &amp;#39;Adale      Somalia  5492       0   POINT (46.3 2.75)
## 9               &amp;#39;Afak         Iraq 22706       0 POINT (45.26 32.07)
## 10              &amp;#39;Afif Saudi Arabia 41731       0 POINT (42.93 23.92)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the next step, we filter by the capital cities encoded in the column &lt;em&gt;capital&lt;/em&gt; with 1. The advantage of the &lt;code&gt;sf&lt;/code&gt; package is the possibility of applying functions of the &lt;code&gt;tidyverse&lt;/code&gt; collection to manipulate the attributes. In addition, we add a column with new labels using the &lt;code&gt;str_c()&lt;/code&gt; function of the &lt;code&gt;stringr&lt;/code&gt; package, which is similar to that of &lt;em&gt;R Base&lt;/em&gt; &lt;code&gt;paste()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# filter the capital cities
capitals &amp;lt;- filter(cities, capital == 1)

# create a new label combining name and country
capitals &amp;lt;- mutate(capitals, city_country = str_c(name, &amp;quot; (&amp;quot;, country.etc, &amp;quot;)&amp;quot;))

capitals &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Simple feature collection with 230 features and 5 fields
## Geometry type: POINT
## Dimension:     XY
## Bounding box:  xmin: -176.13 ymin: -51.7 xmax: 179.2 ymax: 78.21
## Geodetic CRS:  WGS 84
## First 10 features:
##           name          country.etc     pop capital               geometry
## 1       &amp;#39;Amman               Jordan 1303197       1    POINT (35.93 31.95)
## 2    Abu Dhabi United Arab Emirates  619316       1    POINT (54.37 24.48)
## 3        Abuja              Nigeria  178462       1      POINT (7.17 9.18)
## 4        Accra                Ghana 2029143       1      POINT (-0.2 5.56)
## 5    Adamstown             Pitcairn      51       1  POINT (-130.1 -25.05)
## 6  Addis Abeba             Ethiopia 2823167       1     POINT (38.74 9.03)
## 7        Agana                 Guam    1041       1   POINT (144.75 13.47)
## 8      Algiers              Algeria 2029936       1     POINT (3.04 36.77)
## 9        Alofi                 Niue     627       1 POINT (-169.92 -19.05)
## 10   Amsterdam          Netherlands  744159       1     POINT (4.89 52.37)
##                        city_country
## 1                   &amp;#39;Amman (Jordan)
## 2  Abu Dhabi (United Arab Emirates)
## 3                   Abuja (Nigeria)
## 4                     Accra (Ghana)
## 5              Adamstown (Pitcairn)
## 6            Addis Abeba (Ethiopia)
## 7                      Agana (Guam)
## 8                 Algiers (Algeria)
## 9                      Alofi (Niue)
## 10          Amsterdam (Netherlands)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;calculate-distances&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Calculate distances&lt;/h2&gt;
&lt;p&gt;Geographical distance (Euclidean or greater circle) is calculated with the &lt;code&gt;st_distance()&lt;/code&gt; function, either between two points, between one point and others or between all points. In the latter case we obtain a symmetric matrix of distances (NxN), taken pairwise between the elements of the capital city set. In the diagonal we find the combinations between the same points giving all null values.&lt;/p&gt;
&lt;table&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;B&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;C&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;340&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;259&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;B&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;340&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;337&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;259&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;337&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;For instance, when we want to know the distance from Amsterdam to Abu Dhabi, Washington and Tokyo we pass two spatial objects.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# calculate distance
dist_amsterdam &amp;lt;- st_distance(slice(capitals, 10), 
                              slice(capitals, c(2, 220, 205)))

dist_amsterdam # distance in meters&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Units: [m]
##         [,1]    [,2]    [,3]
## [1,] 5167859 6203802 9316790&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The result is a matrix with a single row or column (depending on the order of the spatial objects) with a class of &lt;code&gt;units&lt;/code&gt;. Thus it is possible to convert easily to another unit of measure. If we want to obtain a vector without class &lt;code&gt;units&lt;/code&gt;, we only have to apply the function &lt;code&gt;as.vector()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# change from m to km
set_units(dist_amsterdam, &amp;quot;km&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Units: [km]
##          [,1]     [,2]    [,3]
## [1,] 5167.859 6203.802 9316.79&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# units class to vector
as.vector(dist_amsterdam)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 5167859 6203802 9316790&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the second step, we estimate the distance matrix between all the capital cities. It is important to convert the null values to &lt;code&gt;NA&lt;/code&gt; to subsequently obtain the correct matrix index.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# calculate distance
m_distance &amp;lt;- st_distance(capitals)

# matrix
dim(m_distance)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 230 230&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# change m to km
m_distance_km &amp;lt;- set_units(m_distance, km)

# replace the distance of 0 m with NA
m_distance_km[m_distance_km == set_units(0, km)] &amp;lt;- NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  
When the result is of the &lt;code&gt;units&lt;/code&gt; class, it is necessary to use the same class to be able to make logical queries. For example, &lt;code&gt;set_units(1, m) == set_units(1, m)&lt;/code&gt; vs. &lt;code&gt;set_units(1, m) == 1&lt;/code&gt;.

&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;To obtain the shortest distance, in addition to its position, we use the &lt;code&gt;apply ()&lt;/code&gt; function which in turn allows us to apply the function &lt;code&gt;which.min()&lt;/code&gt; and &lt;code&gt;min()&lt;/code&gt; on each row. It would also be possible to use the function on columns giving the same result. Finally, we add the results as new columns with the &lt;code&gt;mutate()&lt;/code&gt; function. The indices in &lt;em&gt;pos&lt;/em&gt; allow us to obtain the names of the nearest cities.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get the index (position) of the city and the distance
pos &amp;lt;- apply(m_distance_km, 1, which.min)
dist &amp;lt;- apply(m_distance_km, 1, min, na.rm = TRUE)

# add the distance and get the name of the city
capitals &amp;lt;- mutate(capitals, nearest_city =  city_country[pos], 
                             geometry_nearest = geometry[pos],
                             distance_city = dist)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;map-of-distances-to-the-next-capital-city&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Map of distances to the next capital city&lt;/h2&gt;
&lt;p&gt;Finally, we build a map representing the distance in proportional circles. To do this, we use the usual grammar of &lt;code&gt;ggplot()&lt;/code&gt; by adding the geometry &lt;code&gt;geom_sf()&lt;/code&gt;, first for the world map as background and then for the cities. In &lt;code&gt;aes()&lt;/code&gt; we indicate, with the argument &lt;code&gt;size = distance_city&lt;/code&gt;, the variable which we want to map proportionally. The &lt;code&gt;theme_void()&lt;/code&gt; function removes all style elements. In addition, we define with the function &lt;code&gt;coord_sf()&lt;/code&gt; a new projection indicating the &lt;em&gt;proj4&lt;/em&gt; format.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# world map
world &amp;lt;- ne_countries(scale = 10, returnclass = &amp;quot;sf&amp;quot;)

# map
ggplot(world) +
   geom_sf(fill = &amp;quot;black&amp;quot;, colour = &amp;quot;white&amp;quot;) +
   geom_sf(data = capitals, 
           aes(size = distance_city),
           alpha = 0.7,
           fill = &amp;quot;#bd0026&amp;quot;,
           shape = 21,
           show.legend = &amp;#39;point&amp;#39;) +
   coord_sf(crs = &amp;quot;+proj=robin +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs&amp;quot;) +
  labs(size = &amp;quot;Distance (km)&amp;quot;, title = &amp;quot;Distance to the next capital city&amp;quot;) +
  theme_void()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2020/geographic-distance/index.en_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
      
            <category>distance</category>
      
            <category>points</category>
      
            <category>cities</category>
      
      
            <category>spatial analysis</category>
      
            <category>R</category>
      
            <category>R:elementary</category>
      
            <category>gis</category>
      
    </item>
    
    <item>
      <title>Visualize urban growth</title>
      <link>https://dominicroye.github.io/en/2019/visualize-urban-growth/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://dominicroye.github.io/en/2019/visualize-urban-growth/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2019/visualize-urban-growth/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;The General Directorate for the Cadastre of Spain has spatial information of the all buildings except for the Basque Country and Navarra. This data set is part of the implementation of &lt;a href=&#34;https://inspire.ec.europa.eu/&#34;&gt;INSPIRE&lt;/a&gt;, the Space Information Infrastructure in Europe. More information can be found &lt;a href=&#34;http://www.catastro.meh.es/webinspire/index.html&#34;&gt;here&lt;/a&gt;. We will use the links (&lt;em&gt;urls&lt;/em&gt;) in &lt;em&gt;ATOM&lt;/em&gt; format, which is an RSS type for web feeds, allowing us to obtain the download link for each municipality.&lt;/p&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  
This blog post is a reduced version of the case study that you can find in our recent publication - &lt;a href=&#34;https://dominicroye.github.io/es/publication/manual_rgis_2019/&#34;&gt;Introduction to GIS with R&lt;/a&gt; - published by Dominic Royé and Roberto Serrano-Notivoli (in Spanish).

&lt;/div&gt;
&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Packages&lt;/h2&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;10%&#34; /&gt;
&lt;col width=&#34;89%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Package&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Simple Feature: import, export and manipulate vector data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;fs&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Provides a cross-platform, uniform interface to file system operations&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lubridate&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Easy manipulation of dates and times&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;feedeR&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Import feeds RSS or ATOM&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tmap&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Easy creation of thematic maps&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;classInt&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Create univariate class intervals&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sysfonts&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Loading system fonts and Google Fonts&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;showtext&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Using fonts more easily in R graphs&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install the packages if necessary
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;feedeR&amp;quot;)) install.packages(&amp;quot;feedeR&amp;quot;)
if(!require(&amp;quot;fs&amp;quot;)) install.packages(&amp;quot;fs&amp;quot;)
if(!require(&amp;quot;lubridate&amp;quot;)) install.packages(&amp;quot;lubridate&amp;quot;)
if(!require(&amp;quot;fs&amp;quot;)) install.packages(&amp;quot;fs&amp;quot;)
if(!require(&amp;quot;tmap&amp;quot;)) install.packages(&amp;quot;tmap&amp;quot;)
if(!require(&amp;quot;classInt&amp;quot;)) install.packages(&amp;quot;classInt&amp;quot;)
if(!require(&amp;quot;showtext&amp;quot;)) install.packages(&amp;quot;showtext&amp;quot;)
if(!require(&amp;quot;sysfonts&amp;quot;)) install.packages(&amp;quot;sysfonts&amp;quot;)
if(!require(&amp;quot;rvest&amp;quot;)) install.packages(&amp;quot;rvest&amp;quot;)

# load packages
library(feedeR)
library(sf) 
library(fs)
library(tidyverse)
library(lubridate)
library(classInt)
library(tmap)
library(rvest)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;download-links&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Download links&lt;/h2&gt;
&lt;p&gt;The first &lt;em&gt;url&lt;/em&gt; will give us access to a list of provinces, territorial headquarters (they do not always coincide with the oficial province), with new RSS links, which include the final download link for each municipality. In this case, we will download the buildings of Valencia. Cadastre data is updated every six months.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;url &amp;lt;- &amp;quot;http://www.catastro.minhap.es/INSPIRE/buildings/ES.SDGC.bu.atom.xml&amp;quot;

# import RSS feed with provincial links
prov_enlaces &amp;lt;- feed.extract(url)
str(prov_enlaces) # object is a list&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 4
##  $ title  : chr &amp;quot;Download service of Buildings. Territorial Office&amp;quot;
##  $ link   : chr &amp;quot;http://www.catastro.minhap.es/INSPIRE/buildings/ES.SDGC.BU.atom.xml&amp;quot;
##  $ updated: POSIXct[1:1], format: &amp;quot;2021-03-04&amp;quot;
##  $ items  : tibble[,5] [52 x 5] (S3: tbl_df/tbl/data.frame)
##   ..$ title      : chr [1:52] &amp;quot;Territorial office 02 Albacete&amp;quot; &amp;quot;Territorial office 03 Alicante&amp;quot; &amp;quot;Territorial office 04 Almería&amp;quot; &amp;quot;Territorial office 05 Avila&amp;quot; ...
##   ..$ date       : POSIXct[1:52], format: &amp;quot;2021-03-04&amp;quot; &amp;quot;2021-03-04&amp;quot; ...
##   ..$ link       : chr [1:52] &amp;quot;http://www.catastro.minhap.es/INSPIRE/buildings/02/ES.SDGC.bu.atom_02.xml&amp;quot; &amp;quot;http://www.catastro.minhap.es/INSPIRE/buildings/03/ES.SDGC.bu.atom_03.xml&amp;quot; &amp;quot;http://www.catastro.minhap.es/INSPIRE/buildings/04/ES.SDGC.bu.atom_04.xml&amp;quot; &amp;quot;http://www.catastro.minhap.es/INSPIRE/buildings/05/ES.SDGC.bu.atom_05.xml&amp;quot; ...
##   ..$ description: chr [1:52] &amp;quot;\n\n\t\t  &amp;quot; &amp;quot;\n\n\t\t  &amp;quot; &amp;quot;\n\n\t\t  &amp;quot; &amp;quot;\n\n\t\t  &amp;quot; ...
##   ..$ hash       : chr [1:52] &amp;quot;d21ebb7975e59937&amp;quot; &amp;quot;bdba5e149f09e9d8&amp;quot; &amp;quot;03bcbcc7c5be2e17&amp;quot; &amp;quot;8a154202dd778143&amp;quot; ...&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract the table with the links
prov_enlaces_tab &amp;lt;- as_tibble(prov_enlaces$items) %&amp;gt;% 
                       mutate(title = repair_encoding(title))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `html_encoding_repair()` was deprecated in rvest 1.0.0.
## Instead, re-load using the `encoding` argument of `read_html()`&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Best guess: UTF-8 (100% confident)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prov_enlaces_tab&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 52 x 5
##    title         date                link                    description hash   
##    &amp;lt;chr&amp;gt;         &amp;lt;dttm&amp;gt;              &amp;lt;chr&amp;gt;                   &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt;  
##  1 &amp;quot;Territorial~ 2021-03-04 00:00:00 http://www.catastro.mi~ &amp;quot;\n\n\t\t ~ d21ebb~
##  2 &amp;quot;Territorial~ 2021-03-04 00:00:00 http://www.catastro.mi~ &amp;quot;\n\n\t\t ~ bdba5e~
##  3 &amp;quot;Territorial~ 2021-03-04 00:00:00 http://www.catastro.mi~ &amp;quot;\n\n\t\t ~ 03bcbc~
##  4 &amp;quot;Territorial~ 2021-03-04 00:00:00 http://www.catastro.mi~ &amp;quot;\n\n\t\t ~ 8a1542~
##  5 &amp;quot;Territorial~ 2021-03-04 00:00:00 http://www.catastro.mi~ &amp;quot;\n\n\t\t ~ 7d3fd3~
##  6 &amp;quot;Territorial~ 2021-03-04 00:00:00 http://www.catastro.mi~ &amp;quot;\n\n\t\t ~ 9c0874~
##  7 &amp;quot;Territorial~ 2021-03-04 00:00:00 http://www.catastro.mi~ &amp;quot;\n\n\t\t ~ ff722b~
##  8 &amp;quot;Territorial~ 2021-03-04 00:00:00 http://www.catastro.mi~ &amp;quot;\n\n\t\t ~ b431aa~
##  9 &amp;quot;Territorial~ 2021-03-04 00:00:00 http://www.catastro.mi~ &amp;quot;\n\n\t\t ~ f79c65~
## 10 &amp;quot;Territorial~ 2021-03-04 00:00:00 http://www.catastro.mi~ &amp;quot;\n\n\t\t ~ d702a6~
## # ... with 42 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we access and download the data from Valencia. To filter the final download link we use the &lt;code&gt;filter()&lt;/code&gt; function of the &lt;code&gt;dplyr&lt;/code&gt; package, searching for the name of the territorial headquarter and then the name of the municipality in capital letters with the &lt;code&gt;str_detect()&lt;/code&gt; function of &lt;code&gt;stringr&lt;/code&gt;. The &lt;code&gt;pull()&lt;/code&gt; function allows us to extract a column from a &lt;code&gt;data.frame&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  
Currently the &lt;code&gt;feed.extract()&lt;/code&gt; function does not import correctly in the encoding UTF-8 under Windows. For this reason, in some cities a bad codification of special characters may appear “CÃ¡diz”. To solve this problem we apply the &lt;code&gt;repair_encoding()&lt;/code&gt; function of the &lt;code&gt;rvest&lt;/code&gt; package. Nevertheless, problems can arise that have to be corrected manually.

&lt;/div&gt;
&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# filter the province and get the RSS link
val_atom &amp;lt;- filter(prov_enlaces_tab, str_detect(title, &amp;quot;Valencia&amp;quot;)) %&amp;gt;% pull(link)

# import the RSS
val_enlaces &amp;lt;- feed.extract(val_atom)

# get the table with the download links
val_enlaces_tab &amp;lt;- val_enlaces$items
val_enlaces_tab &amp;lt;- mutate(val_enlaces_tab, title = repair_encoding(title),
                          link = repair_encoding(link)) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Best guess: UTF-8 (100% confident)
## Best guess: UTF-8 (100% confident)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#  filter the table with the name of the city
val_link &amp;lt;- filter(val_enlaces_tab, str_detect(title, &amp;quot;VALENCIA&amp;quot;)) %&amp;gt;% pull(link)
val_link&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;http://www.catastro.minhap.es/INSPIRE/Buildings/46/46900-VALENCIA/A.ES.SDGC.BU.46900.zip&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data-download&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data download&lt;/h2&gt;
&lt;p&gt;The download is done with the &lt;code&gt;download.file()&lt;/code&gt; function that only has two main arguments, the download link and the path with the file name. In this case, we use the &lt;code&gt;tempfile()&lt;/code&gt; function, which is useful for creating temporary files, that is, files that only exist in the memory for a certain time.
The file we download has the extension &lt;code&gt;*.zip&lt;/code&gt;, so we must unzip it with another function (&lt;code&gt;unzip()&lt;/code&gt;), which requires the name of the file and the name of the folder, where we want to unzip it. Finally, the &lt;code&gt;URLencode()&lt;/code&gt; function encodes an &lt;em&gt;URL&lt;/em&gt; address that contains special characters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create a temporary file
temp &amp;lt;- tempfile()

# download the data
download.file(URLencode(val_link), temp)

# unzip to a folder called buildings
unzip(temp, exdir = &amp;quot;buildings_valencia&amp;quot;) # change the name according to the city&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;import-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Import the data&lt;/h2&gt;
&lt;p&gt;To import the data we use the &lt;code&gt;dir_ls()&lt;/code&gt; function of the &lt;code&gt;fs&lt;/code&gt; package, which can obtain the files and folders of a specific path while filtering through a text pattern (&lt;em&gt;regexp &lt;/em&gt;: regular expression). We apply the &lt;code&gt;st_read()&lt;/code&gt; function of the &lt;code&gt;sf&lt;/code&gt; package to the &lt;em&gt;Geography Markup Language&lt;/em&gt; (GML) file.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get the path with the file
file_val &amp;lt;- dir_ls(&amp;quot;buildings_valencia&amp;quot;, regexp = &amp;quot;building.gml&amp;quot;) # change the folder if needed

# import the data
buildings_val &amp;lt;- st_read(file_val)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Reading layer `Building&amp;#39; from data source `D:\OneDriveUSC\OneDrive - Universidade de Santiago de Compostela\Documentos\GitHub\blogR_update\content\post\en\2019-11-01-visualize-urban-growth\buildings_valencia\A.ES.SDGC.BU.46900.building.gml&amp;#39; using driver `GML&amp;#39;
## Simple feature collection with 36279 features and 24 fields
## Geometry type: MULTIPOLYGON
## Dimension:     XY
## Bounding box:  xmin: 720608 ymin: 4351286 xmax: 734981.9 ymax: 4382906
## Projected CRS: ETRS89 / UTM zone 30N&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data-preparation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data preparation&lt;/h2&gt;
&lt;p&gt;We only have to convert the column of the construction year (beginning) into a &lt;code&gt;Date&lt;/code&gt; class. The date column contains some dates in &lt;code&gt;--01-01&lt;/code&gt; format, which does not correspond to any recognizable date. Therefore, we replace the first &lt;code&gt;-&lt;/code&gt; with &lt;code&gt;0000&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;buildings_val &amp;lt;- mutate(buildings_val, 
               beginning = str_replace(beginning, &amp;quot;^-&amp;quot;, &amp;quot;0000&amp;quot;) %&amp;gt;% 
                            ymd_hms() %&amp;gt;% as_date()
               )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: 5 failed to parse.&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;distribution-chart&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Distribution chart&lt;/h2&gt;
&lt;p&gt;Before creating the maps of the construction years, which will reflect urban growth, we will make a graph of distribution of the beginning variable. We can clearly identify periods of urban expansion. We will use the &lt;code&gt;ggplot2&lt;/code&gt; package with the geometry of &lt;code&gt;geom_density()&lt;/code&gt; for this purpose. The &lt;code&gt;font_add_google()&lt;/code&gt; function of the &lt;code&gt;sysfonts&lt;/code&gt; package allows us to download and include font families from Google.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#font download
sysfonts::font_add_google(&amp;quot;Montserrat&amp;quot;, &amp;quot;Montserrat&amp;quot;)

#use showtext for fonts
showtext::showtext_auto() &lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# limit the period after 1750
filter(buildings_val, beginning &amp;gt;= &amp;quot;1750-01-01&amp;quot;) %&amp;gt;%
 ggplot(aes(beginning)) + 
    geom_density(fill = &amp;quot;#2166ac&amp;quot;, alpha = 0.7) +
  scale_x_date(date_breaks = &amp;quot;20 year&amp;quot;, 
               date_labels = &amp;quot;%Y&amp;quot;) +
  theme_minimal(base_family = &amp;quot;Montserrat&amp;quot;) +
  labs(y = &amp;quot;&amp;quot;,x = &amp;quot;&amp;quot;, title = &amp;quot;Evolution of urban development&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-urban-growth/index.en_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;buffer-of-25-km-for-valencia&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Buffer of 2,5 km for Valencia&lt;/h2&gt;
&lt;p&gt;To visualize better the distribution of urban growth, we limit the map to a radius of 2.5 km from the city center. Therefore, we use the &lt;code&gt;geocode_OSM()&lt;/code&gt; function of the &lt;code&gt;tmaptools&lt;/code&gt; package to obtain the coordinates of Valencia in class &lt;code&gt;sf&lt;/code&gt;. Then we project the points to the system we use for the buildings (EPSG: 25830). The &lt;code&gt;st_crs()&lt;/code&gt; function returns the coordinate system of a spatial object &lt;code&gt;sf&lt;/code&gt;. Finally, we create with the function &lt;code&gt;st_buffer()&lt;/code&gt; a buffer with 2500 m and the intersection with our building data. It is also possible to create a buffer in the form of a rectangle indicating the style with the argument &lt;code&gt;endCapStyle =&#34; SQUARE &#34;&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get the coordinates of Valencia
ciudad_point &amp;lt;- tmaptools::geocode_OSM(&amp;quot;Valencia&amp;quot;, 
                                      as.sf = TRUE)

#  project the points
ciudad_point &amp;lt;- st_transform(ciudad_point, st_crs(buildings_val))

# create the buffer
point_bf &amp;lt;- st_buffer(ciudad_point, 2500) # radius of 2500 m


# get the intersection between the buffer and the building
buildings_val25 &amp;lt;- st_intersection(buildings_val, point_bf)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: attribute variables are assumed to be spatially constant throughout all
## geometries&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;prepare-data-for-mapping&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Prepare data for mapping&lt;/h2&gt;
&lt;p&gt;We categorize the year into 15 groups using quartiles. It is also possible to modify the number of classes or the applied method (eg jenks, fisher, etc), you can find more details in the help &lt;code&gt;?classIntervals&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# find 15 classes
br &amp;lt;- classIntervals(year(buildings_val25$beginning), 15, &amp;quot;quantile&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in classIntervals(year(buildings_val25$beginning), 15, &amp;quot;quantile&amp;quot;): var
## has missing values, omitted in finding classes&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create labels
lab &amp;lt;- names(print(br, under = &amp;quot;&amp;lt;&amp;quot;, over = &amp;quot;&amp;gt;&amp;quot;, cutlabels = FALSE))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## style: quantile
##      &amp;lt; 1890 1890 - 1912 1912 - 1925 1925 - 1930 1930 - 1940 1940 - 1950 
##         939        1361         957         595        1708        1055 
## 1950 - 1958 1958 - 1962 1962 - 1966 1966 - 1970 1970 - 1973 1973 - 1978 
##        1454        1029        1224        1160        1154        1191 
## 1978 - 1988 1988 - 1999      &amp;gt; 1999 
##        1148        1111        1207&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# categorize the year
buildings_val25 &amp;lt;- mutate(buildings_val25, 
                          yr_cl = cut(year(beginning), 
                                       br$brks, 
                                       labels = lab, 
                                       include.lowest = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;map-of-valencia&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Map of Valencia&lt;/h2&gt;
&lt;p&gt;For the mapping, we will use the &lt;code&gt;tmap&lt;/code&gt; package. It is an interesting alternative to &lt;code&gt;ggplot2&lt;/code&gt;. It is a package of functions specialized in creating thematic maps. The philosophy of the package follows the same as in &lt;code&gt;ggplot2&lt;/code&gt;, creating multiple layers with different functions, which always start with &lt;code&gt;tm_ *&lt;/code&gt;and combine with &lt;code&gt;+&lt;/code&gt;. Building a map with &lt;em&gt;tmap&lt;/em&gt; always starts with &lt;em&gt;tm_shape()&lt;/em&gt;, where the data, we want to draw, is defined. Then we add the corresponding geometry to the data type (&lt;code&gt;tm_polygon()&lt;/code&gt;, &lt;code&gt;tm_border()&lt;/code&gt;, &lt;code&gt;tm_dots()&lt;/code&gt; or even &lt;code&gt;tm_raster()&lt;/code&gt;). The &lt;code&gt;tm_layout()&lt;/code&gt; function help us to configure the map style.&lt;/p&gt;
&lt;p&gt;When we need more colors than the maximum allowed by &lt;code&gt;RColorBrewer&lt;/code&gt;, we can pass the colors to the &lt;code&gt;colorRampPalette()&lt;/code&gt; function. This function interpolates a set of given colors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# colours
col_spec &amp;lt;- RColorBrewer::brewer.pal(11, &amp;quot;Spectral&amp;quot;)

# colour ramp function
col_spec_fun &amp;lt;- colorRampPalette(col_spec)


# create the final map
tm_shape(buildings_val25) +
  tm_polygons(&amp;quot;yr_cl&amp;quot;, 
              border.col = &amp;quot;transparent&amp;quot;,
              palette = col_spec_fun(15), # adapt to the number of classes
              textNA = &amp;quot;Without data&amp;quot;,
              title = &amp;quot;&amp;quot;) +
 tm_layout(bg.color = &amp;quot;black&amp;quot;,
           outer.bg.color = &amp;quot;black&amp;quot;,
           legend.outside = TRUE,
           legend.text.color = &amp;quot;white&amp;quot;,
           legend.text.fontfamily = &amp;quot;Montserrat&amp;quot;, 
            panel.label.fontfamily = &amp;quot;Montserrat&amp;quot;,
            panel.label.color = &amp;quot;white&amp;quot;,
            panel.label.bg.color = &amp;quot;black&amp;quot;,
            panel.label.size = 5,
            panel.label.fontface = &amp;quot;bold&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-urban-growth/index.en_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can export our map using the function &lt;code&gt;tmap_save(&#34;name.png&#34;, dpi = 300)&lt;/code&gt;. I recommend using the &lt;code&gt;dpi = 300&lt;/code&gt; argument for a good image quality.&lt;/p&gt;
&lt;p&gt;An alternative way to the &lt;code&gt;tmap&lt;/code&gt; package is &lt;code&gt;ggplot2&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create the final map
ggplot(buildings_val25) +
     geom_sf(aes(fill = yr_cl), colour = &amp;quot;transparent&amp;quot;) +
  scale_fill_manual(values = col_spec_fun(15)) + # adapt to the number of classes
    labs(title = &amp;quot;VALÈNCIA&amp;quot;, fill = &amp;quot;&amp;quot;) +
  guides(fill = guide_legend(keywidth = .7, keyheight = 2.7)) +
theme_void(base_family = &amp;quot;Montserrat&amp;quot;) +
theme(panel.background = element_rect(fill = &amp;quot;black&amp;quot;),
      plot.background = element_rect(fill = &amp;quot;black&amp;quot;),
      legend.justification = .5,
      legend.text = element_text(colour = &amp;quot;white&amp;quot;, size = 12),
      plot.title = element_text(colour = &amp;quot;white&amp;quot;, hjust = .5, size = 60,
      margin = margin(t = 30)),
      plot.caption = element_text(colour = &amp;quot;white&amp;quot;,
      margin = margin(b = 20), hjust = .5, size = 16),
      plot.margin = margin(r = 40, l = 40))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-urban-growth/index.en_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;1536&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To export the result of ggplot we can use the function &lt;code&gt;ggsave(&#34;name.png&#34;)&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;dynamic-map-with-leaflet&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Dynamic map with leaflet&lt;/h2&gt;
&lt;p&gt;A very interesting advantage is the &lt;code&gt;tmap_leaflet()&lt;/code&gt; function of the &lt;code&gt;tmap&lt;/code&gt; package to easily pass a map created in the same frame to &lt;code&gt;leaflet&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# tmap object
m &amp;lt;-   tm_shape(buildings_val25) +
          tm_polygons(&amp;quot;yr_cl&amp;quot;, 
              border.col = &amp;quot;transparent&amp;quot;,
              palette = col_spec_fun(15), # adapt to the number of classes
              textNA = &amp;quot;Without data&amp;quot;,
              title = &amp;quot;&amp;quot;)


# dynamic map
tmap_leaflet(m)&lt;/code&gt;&lt;/pre&gt;
&lt;iframe src=&#34;https://dominicroye.github.io/files/urban_growth_leaflet.html&#34; width=&#34;672&#34; height=&#34;500px&#34;&gt;
&lt;/iframe&gt;
&lt;/div&gt;
</description>
      
            <category>urban growth</category>
      
            <category>city</category>
      
            <category>urban geography</category>
      
      
            <category>visualization</category>
      
            <category>R</category>
      
            <category>R:elementary</category>
      
            <category>gis</category>
      
    </item>
    
    <item>
      <title>Visualize monthly precipitation anomalies</title>
      <link>https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/</link>
      <pubDate>Sun, 07 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Normally when we visualize monthly precipitation anomalies, we simply use a bar graph indicating negative and positive values with red and blue. However, it does not explain the general context of these anomalies. For example, what was the highest or lowest anomaly in each month? In principle, we could use a &lt;em&gt;boxplot&lt;/em&gt; to visualize the distribution of the anomalies, but in this particular case they would not fit aesthetically, so we should look for an alternative. Here I present a very useful graphic form.&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Packages&lt;/h2&gt;
&lt;p&gt;In this post we will use the following packages:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;10%&#34; /&gt;
&lt;col width=&#34;89%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Package&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;readr&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Import data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ggthemes&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Themes for ggplot2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lubridate&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Easy manipulation of dates and times&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;cowplot&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Easy creation of multiple graphics with ggplot2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#we install the packages if necessary
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;ggthemes&amp;quot;)) install.packages(&amp;quot;broom&amp;quot;)
if(!require(&amp;quot;cowplot&amp;quot;)) install.packages(&amp;quot;cowplot&amp;quot;)
if(!require(&amp;quot;lubridate&amp;quot;)) install.packages(&amp;quot;lubridate&amp;quot;)

#packages
library(tidyverse) #include readr
library(ggthemes)
library(cowplot)
library(lubridate)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;preparing-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Preparing the data&lt;/h2&gt;
&lt;p&gt;First we import the daily precipitation of the selected weather station (&lt;a href=&#34;https://dominicroye.github.io/files/RR_STAID001394.txt&#34;&gt;download&lt;/a&gt;). We will use data from Santiago de Compostela (Spain) accessible through &lt;a href=&#34;https://eca.knmi.nl&#34;&gt;ECA&amp;amp;D&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;step-1-import-the-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Step 1: import the data&lt;/h3&gt;
&lt;p&gt;We not only import the data in &lt;em&gt;csv&lt;/em&gt; format, but we also make the first changes. We skip the first 21 rows that contain information about the weather station. In addition, we convert the date to the &lt;code&gt;date&lt;/code&gt; class and replace missing values (-9999) with &lt;code&gt;NA&lt;/code&gt;. The precipitation is given in 0.1 mm, therefore, we must divide the values by 10. Then we select the columns &lt;em&gt;DATE&lt;/em&gt; and &lt;em&gt;RR&lt;/em&gt;, and rename them.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- read_csv(&amp;quot;RR_STAID001394.txt&amp;quot;, skip = 21) %&amp;gt;%
             mutate(DATE = ymd(DATE), RR = ifelse(RR == -9999, NA, RR/10)) %&amp;gt;%
               select(DATE:RR) %&amp;gt;% 
             rename(date = DATE, pr = RR)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## -- Column specification --------------------------------------------------------
## cols(
##   STAID = col_double(),
##   SOUID = col_double(),
##   DATE = col_double(),
##   RR = col_double(),
##   Q_RR = col_double()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 27,606 x 2
##    date          pr
##    &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt;
##  1 1943-11-01   0.6
##  2 1943-11-02   0  
##  3 1943-11-03   0  
##  4 1943-11-04   0  
##  5 1943-11-05   0  
##  6 1943-11-06   0  
##  7 1943-11-07   0  
##  8 1943-11-08   0  
##  9 1943-11-09   0  
## 10 1943-11-10   0  
## # ... with 27,596 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-2-creating-monthly-values&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Step 2: creating monthly values&lt;/h3&gt;
&lt;p&gt;In the second step we calculate the monthly amounts of precipitation. To do this, a) we limit the period to the years after 1950, b) we add the month with its labels and the year as variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- mutate(data, mo = month(date, label = TRUE), yr = year(date)) %&amp;gt;%
            filter(date &amp;gt;= &amp;quot;1950-01-01&amp;quot;) %&amp;gt;%
                group_by(yr, mo) %&amp;gt;% 
                   summarise(prs = sum(pr, na.rm = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;yr&amp;#39;. You can override using the `.groups` argument.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 833 x 3
## # Groups:   yr [70]
##       yr mo      prs
##    &amp;lt;dbl&amp;gt; &amp;lt;ord&amp;gt; &amp;lt;dbl&amp;gt;
##  1  1950 Jan    55.6
##  2  1950 Feb   349. 
##  3  1950 Mar    85.8
##  4  1950 Apr    33.4
##  5  1950 May   272. 
##  6  1950 Jun   111. 
##  7  1950 Jul    35.4
##  8  1950 Aug    76.4
##  9  1950 Sep    85  
## 10  1950 Oct    53  
## # ... with 823 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-3-estimating-anomalies&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Step 3: estimating anomalies&lt;/h3&gt;
&lt;p&gt;Now we must estimate the normals of each month and join this table to our main data in order to calculate the monthly anomaly. We express the anomalies in percentage and subtract 100 to set the average to 0. In addition, we create a variable which indicates if the anomaly is negative or positive, and another with the date.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pr_ref &amp;lt;- filter(data, yr &amp;gt; 1981, yr &amp;lt;= 2010) %&amp;gt;%
                   group_by(mo) %&amp;gt;%
                      summarise(pr_ref = mean(prs))

data &amp;lt;- left_join(data, pr_ref, by = &amp;quot;mo&amp;quot;)

data &amp;lt;- mutate(data, 
               anom = (prs*100/pr_ref)-100, 
               date = str_c(yr, as.numeric(mo), 1, sep = &amp;quot;-&amp;quot;) %&amp;gt;% ymd(),
               sign= ifelse(anom &amp;gt; 0, &amp;quot;pos&amp;quot;, &amp;quot;neg&amp;quot;) %&amp;gt;% factor(c(&amp;quot;pos&amp;quot;, &amp;quot;neg&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can do a first test graph of anomalies (the classic one), for that we filter the year 2018. In this case we use a bar graph, remember that by default the function &lt;code&gt;geom_bar()&lt;/code&gt; applies the counting of the variable. However, in this case we know &lt;code&gt;y&lt;/code&gt;, hence we indicate with the argument &lt;code&gt;stat = &#34;identity&#34;&lt;/code&gt; that it should use the given value in &lt;code&gt;aes()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(data, yr == 2018) %&amp;gt;%
   ggplot(aes(date, anom, fill = sign)) + 
       geom_bar(stat = &amp;quot;identity&amp;quot;, show.legend = FALSE) + 
    scale_x_date(date_breaks = &amp;quot;month&amp;quot;, date_labels = &amp;quot;%b&amp;quot;) +
    scale_y_continuous(breaks = seq(-100, 100, 20)) +
    scale_fill_manual(values = c(&amp;quot;#99000d&amp;quot;, &amp;quot;#034e7b&amp;quot;)) +
         labs(y = &amp;quot;Precipitation anomaly (%)&amp;quot;, x = &amp;quot;&amp;quot;) +
          theme_hc()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-4-calculating-the-statistical-metrics&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Step 4: calculating the statistical metrics&lt;/h3&gt;
&lt;p&gt;In this last step we estimate the maximum, minimum value, the 25%/75% quantiles and the interquartile range per month of the entire time series.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_norm &amp;lt;-     group_by(data, mo) %&amp;gt;%
                     summarise(mx = max(anom),
                               min = min(anom),
                               q25 = quantile(anom, .25),
                               q75 = quantile(anom, .75),
                               iqr = q75-q25)
data_norm&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 12 x 6
##    mo       mx    min   q25   q75   iqr
##    &amp;lt;ord&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 Jan    193.  -89.6 -43.6 56.3   99.9
##  2 Feb    320.  -96.5 -51.2 77.7  129. 
##  3 Mar    381. -100   -40.6 88.2  129. 
##  4 Apr    198.  -93.6 -51.2 17.1   68.3
##  5 May    141.  -90.1 -45.2 17.0   62.2
##  6 Jun    419.  -99.3 -58.2 50.0  108. 
##  7 Jul    311.  -98.2 -77.3 27.1  104. 
##  8 Aug    264. -100   -68.2 39.8  108. 
##  9 Sep    241.  -99.2 -64.9 48.6  113. 
## 10 Oct    220.  -99.0 -54.5  4.69  59.2
## 11 Nov    137.  -98.8 -44.0 39.7   83.7
## 12 Dec    245.  -91.8 -49.8 36.0   85.8&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-the-graph&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Creating the graph&lt;/h2&gt;
&lt;p&gt;To create the anomaly graph with legend it is necessary to separate the main graph from the legends.&lt;/p&gt;
&lt;div id=&#34;part-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Part 1&lt;/h3&gt;
&lt;p&gt;In this first part we are adding layer by layer the different elements: 1) the range of anomalies maximum-minimum 2) the interquartile range and 3) the anomalies of the year 2018.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#range of anomalies maximum-minimum
g1.1 &amp;lt;- ggplot(data_norm)+
           geom_crossbar(aes(x = mo, y = 0, ymin = min, ymax = mx),
                        fatten = 0, fill = &amp;quot;grey90&amp;quot;, colour = &amp;quot;NA&amp;quot;)

g1.1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#adding interquartile range
g1.2 &amp;lt;- g1.1 + geom_crossbar(aes(x = mo, y = 0, ymin = q25, ymax = q75),
                              fatten = 0, fill = &amp;quot;grey70&amp;quot;)

g1.2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-9-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#adding anomalies of the year 2018 

g1.3 &amp;lt;- g1.2 + geom_crossbar(data = filter(data, yr == 2018),
                aes(x = mo, y = 0, ymin = 0, ymax = anom, fill = sign),
                fatten = 0, width = 0.7, alpha = .7, colour = &amp;quot;NA&amp;quot;,
                show.legend = FALSE)
g1.3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-9-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Finally we change some last style settings.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;g1 &amp;lt;- g1.3 + geom_hline(yintercept = 0)+
               scale_fill_manual(values=c(&amp;quot;#99000d&amp;quot;,&amp;quot;#034e7b&amp;quot;))+
               scale_y_continuous(&amp;quot;Precipitation anomaly (%)&amp;quot;,
                                   breaks = seq(-100, 500, 25),
                                   expand = c(0, 5))+
            labs(x = &amp;quot;&amp;quot;,
                 title = &amp;quot;Precipitation anomaly in Santiago de Compostela 2018&amp;quot;,
                 caption=&amp;quot;Dominic Royé (@dr_xeo) | Data: eca.knmi.nl&amp;quot;)+
            theme_hc()
g1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;part-2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Part 2&lt;/h3&gt;
&lt;p&gt;We still need a legend. First we create it for the normals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#legend data
legend &amp;lt;- filter(data_norm, mo == &amp;quot;Jan&amp;quot;)

legend_lab &amp;lt;- gather(legend, stat, y, mx:q75) %&amp;gt;%
                 mutate(stat = factor(stat, stat, c(&amp;quot;maximum&amp;quot;,
                                                   &amp;quot;minimum&amp;quot;,
                                                   &amp;quot;Quantile 25%&amp;quot;,
                                                   &amp;quot;Quantile 75%&amp;quot;)) %&amp;gt;%
                                            as.character())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: attributes are not identical across measure variables;
## they will be dropped&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#legend graph
g2 &amp;lt;- legend %&amp;gt;% ggplot()+
                  geom_crossbar(aes(x = mo, y = 0, ymin = min, ymax = mx),
                                fatten = 0, fill = &amp;quot;grey90&amp;quot;, colour = &amp;quot;NA&amp;quot;, width = 0.2) +
                  geom_crossbar(aes(x = mo, y = 0, ymin = q25, ymax = q75),
                                fatten = 0, fill = &amp;quot;grey70&amp;quot;, width = 0.2) +
                  geom_text(data = legend_lab, 
                            aes(x = mo, y = y+c(12,-8,-10,12), label = stat), 
                            fontface = &amp;quot;bold&amp;quot;, size = 2) +
                   annotate(&amp;quot;text&amp;quot;, x = 1.18, y = 40, 
                            label = &amp;quot;Period 1950-2018&amp;quot;, angle = 90, size = 3) +
              theme_void() + 
                theme(plot.margin = unit(c(0, 0, 0, 0), &amp;quot;cm&amp;quot;))

g2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Second, we create another legend for the current anomalies.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#legend data
legend2 &amp;lt;- filter(data, yr == 1950, mo %in% c(&amp;quot;Jan&amp;quot;,&amp;quot;Feb&amp;quot;)) %&amp;gt;% 
              ungroup() %&amp;gt;% 
            select(mo, anom, sign)

legend2[2,1] &amp;lt;- &amp;quot;Jan&amp;quot;

legend_lab2 &amp;lt;- data.frame(mo = rep(&amp;quot;Jan&amp;quot;, 3), 
                          anom= c(110, 3, -70), 
                          label = c(&amp;quot;Positive anomaly&amp;quot;, &amp;quot;Average&amp;quot;, &amp;quot;Negative anomaly&amp;quot;))

#legend graph
g3 &amp;lt;-  ggplot() + 
         geom_bar(data = legend2,
                aes(x = mo, y = anom, fill = sign),
                   alpha = .6, colour = &amp;quot;NA&amp;quot;, stat = &amp;quot;identity&amp;quot;, show.legend = FALSE, width = 0.2) +
         geom_segment(aes(x = .85, y = 0, xend = 1.15, yend = 0), linetype = &amp;quot;dashed&amp;quot;) +
         geom_text(data = legend_lab2, 
                   aes(x = mo, y = anom+c(10,5,-13), label = label), 
                   fontface = &amp;quot;bold&amp;quot;, size = 2) +
         annotate(&amp;quot;text&amp;quot;, x = 1.25, y = 20, 
                  label =&amp;quot;Reference 1971-2010&amp;quot;, angle = 90, size = 3) +
         scale_fill_manual(values = c(&amp;quot;#99000d&amp;quot;, &amp;quot;#034e7b&amp;quot;)) +
        theme_void() +
         theme(plot.margin = unit(c(0, 0, 0, 0), &amp;quot;cm&amp;quot;))

g3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;part-3&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Part 3&lt;/h3&gt;
&lt;p&gt;Finally, we only have to join the graph and the legends with the help of the &lt;code&gt;cowplot&lt;/code&gt; package. The main function of &lt;code&gt;cowplot&lt;/code&gt; is &lt;code&gt;plot_grid()&lt;/code&gt; which is used for combining different graphs. However, in this case it is necessary to use more flexible functions to create less common formats. The &lt;code&gt;ggdraw()&lt;/code&gt; function configures the basic layer of the graph, and the functions that are intended to operate on this layer start with &lt;code&gt;draw_*&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- ggdraw() +
       draw_plot(g1, x = 0, y = .3, width = 1, height = 0.6) +
       draw_plot(g2, x = 0, y = .15, width = .2, height = .15) +
       draw_plot(g3, x = 0.08, y = .15, width = .2, height = .15)

p&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;3729&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;save_plot(&amp;quot;pr_anomaly2016_scq.png&amp;quot;, p, dpi = 300, base_width = 12.43, base_height = 8.42)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;multiple-facets&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Multiple facets&lt;/h2&gt;
&lt;p&gt;In this section we will make the same graph as in the previous one, but for several years.&lt;/p&gt;
&lt;div id=&#34;part-1-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Part 1&lt;/h3&gt;
&lt;p&gt;First we need to filter again by set of years, in this case from 2016 to 2018, using the operator &lt;code&gt;%in%&lt;/code&gt;, we also add the function &lt;code&gt;facet_grid()&lt;/code&gt; to &lt;code&gt;ggplot&lt;/code&gt;, which allows us to plot the graph according to a variable. The formula used for the facet function is similar to the use in models: &lt;code&gt;variable_by_row ~ variable_by_column&lt;/code&gt;. When we do not have a variable in the column, we should use the &lt;code&gt;.&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#range of anomalies maximum-minimum
g1.1 &amp;lt;- ggplot(data_norm)+
           geom_crossbar(aes(x = mo, y = 0, ymin = min, ymax = mx),
                        fatten = 0, fill = &amp;quot;grey90&amp;quot;, colour = &amp;quot;NA&amp;quot;)

g1.1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#adding the interquartile range
g1.2 &amp;lt;- g1.1 + geom_crossbar(aes(x = mo, y = 0, ymin = q25, ymax = q75),
                              fatten = 0, fill = &amp;quot;grey70&amp;quot;)

g1.2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-14-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#adding the anomalies of the year 2016-2018

g1.3 &amp;lt;- g1.2 + geom_crossbar(data = filter(data, yr %in% 2016:2018),
                aes(x = mo, y = 0, ymin = 0, ymax = anom, fill = sign),
                fatten = 0, width = 0.7, alpha = .7, colour = &amp;quot;NA&amp;quot;,
                show.legend = FALSE) +
               facet_grid(yr ~ .)
g1.3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-14-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Finally we change some last style settings.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;g1 &amp;lt;- g1.3 + geom_hline(yintercept = 0)+
               scale_fill_manual(values=c(&amp;quot;#99000d&amp;quot;,&amp;quot;#034e7b&amp;quot;))+
               scale_y_continuous(&amp;quot;Anomalía de precipitación (%)&amp;quot;,
                                   breaks = seq(-100, 500, 50),
                                   expand = c(0, 5))+
            labs(x = &amp;quot;&amp;quot;,
                 title = &amp;quot;Anomalía de precipitación en Santiago de Compostela&amp;quot;,
                 caption=&amp;quot;Dominic Royé (@dr_xeo) | Datos: eca.knmi.nl&amp;quot;)+
            theme_hc()
g1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;3729&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We use the same legend created for the previous graph.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;part-2-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part 2&lt;/h2&gt;
&lt;p&gt;Finally, we join the graph and the legends with the help of the &lt;code&gt;cowplot&lt;/code&gt; package. The only thing we must adjust here are the arguments in the &lt;code&gt;draw_plot()&lt;/code&gt; function to correctly place the different parts.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- ggdraw() +
       draw_plot(g1, x = 0, y = .18, width = 1, height = 0.8) +
       draw_plot(g2, x = 0, y = .08, width = .2, height = .15) +
       draw_plot(g3, x = 0.08, y = .08, width = .2, height = .15)

p&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/visualize-monthly-precipitation-anomalies/index.en_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;3729&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;save_plot(&amp;quot;pr_anomaly20162018_scq.png&amp;quot;, p, dpi = 300, base_width = 12.43, base_height = 8.42)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
      
            <category>anomalies</category>
      
            <category>precipitation</category>
      
            <category>climate</category>
      
            <category>boxplot</category>
      
      
            <category>visualization</category>
      
            <category>R</category>
      
            <category>R:intermediate</category>
      
    </item>
    
    <item>
      <title>Tidy correlation tests in R</title>
      <link>https://dominicroye.github.io/en/2019/tidy-correlation-tests-in-r/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://dominicroye.github.io/en/2019/tidy-correlation-tests-in-r/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2019/tidy-correlation-tests-in-r/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;When we try to estimate the correlation coefficient between multiple variables, the task is more complicated in order to obtain a simple and tidy result. A simple solution is to use the &lt;code&gt;tidy()&lt;/code&gt; function from the &lt;em&gt;{broom}&lt;/em&gt; package. In this post we are going to estimate the correlation coefficients between the annual precipitation of several Spanish cities and climate teleconnections indices: &lt;a href=&#34;https://dominicroye.github.io/files/teleconnections_indices.zip&#34;&gt;download&lt;/a&gt;. The data of the teleconnections are preprocessed, but can be downloaded directly from &lt;a href=&#34;https://crudata.uea.ac.uk/cru/data/pci.htm&#34;&gt;crudata.uea.ac.uk&lt;/a&gt;. The daily precipitation data comes from &lt;a href=&#34;https://www.ecad.eu//dailydata/index.php&#34;&gt;ECA&amp;amp;D&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Packages&lt;/h2&gt;
&lt;p&gt;In this post we will use the following packages:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;10%&#34; /&gt;
&lt;col width=&#34;89%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Package&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;broom&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Convert results of statistical functions (lm, t.test, cor.test, etc.) into tidy tables&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;fs&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Provides a cross-platform, uniform interface to file system operations&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lubridate&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Easy manipulation of dates and times&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install the packages if necessary
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;broom&amp;quot;)) install.packages(&amp;quot;broom&amp;quot;)
if(!require(&amp;quot;fs&amp;quot;)) install.packages(&amp;quot;fs&amp;quot;)
if(!require(&amp;quot;lubridate&amp;quot;)) install.packages(&amp;quot;lubridate&amp;quot;)

#load packages
library(tidyverse)
library(broom)
library(fs)
library(lubridate)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;import-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Import data&lt;/h2&gt;
&lt;p&gt;First we have to import the daily precipitation of the selected weather stations.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Create a vector with all precipitation files using the function &lt;code&gt;dir_ls()&lt;/code&gt; of the &lt;em&gt;{fs}&lt;/em&gt; package.&lt;/li&gt;
&lt;li&gt;Import the data using the &lt;code&gt;map_df()&lt;/code&gt; function of the &lt;em&gt;{purrr}&lt;/em&gt; package that applies another function to a vector or list, and joins them together in a single &lt;em&gt;data.frame&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;Select the columns that interest us, b) Convert the date string into a date object using the &lt;code&gt;ymd()&lt;/code&gt; function of the &lt;em&gt;{lubridate}&lt;/em&gt; package, c) Create a new column &lt;em&gt;yr&lt;/em&gt; with the years, d) Divide the precipitation values by 10 and reclassify absent values -9999 by NA, e) Finally, reclassify the ID of each weather station creating a factor with new labels.&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;More details about the use of the &lt;code&gt;dir_ls()&lt;/code&gt; and &lt;code&gt;map_df()&lt;/code&gt; functions can be found in this previous &lt;a href=&#34;https://dominicroye.github.io/en/2019/import-excel-sheets-%20with-r%20/&#34;&gt;post&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#precipitation files
files &amp;lt;- dir_ls(regexp = &amp;quot;txt&amp;quot;)
files&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## RR_STAID001393.txt RR_STAID001394.txt RR_STAID002969.txt RR_STAID003946.txt 
## RR_STAID003969.txt&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#import all files and join them together
pr &amp;lt;- files %&amp;gt;% map_df(read_csv, skip = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## -- Column specification --------------------------------------------------------
## cols(
##   STAID = col_double(),
##   SOUID = col_double(),
##   DATE = col_double(),
##   RR = col_double(),
##   Q_RR = col_double()
## )
## 
## 
## -- Column specification --------------------------------------------------------
## cols(
##   STAID = col_double(),
##   SOUID = col_double(),
##   DATE = col_double(),
##   RR = col_double(),
##   Q_RR = col_double()
## )
## 
## 
## -- Column specification --------------------------------------------------------
## cols(
##   STAID = col_double(),
##   SOUID = col_double(),
##   DATE = col_double(),
##   RR = col_double(),
##   Q_RR = col_double()
## )
## 
## 
## -- Column specification --------------------------------------------------------
## cols(
##   STAID = col_double(),
##   SOUID = col_double(),
##   DATE = col_double(),
##   RR = col_double(),
##   Q_RR = col_double()
## )
## 
## 
## -- Column specification --------------------------------------------------------
## cols(
##   STAID = col_double(),
##   SOUID = col_double(),
##   DATE = col_double(),
##   RR = col_double(),
##   Q_RR = col_double()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pr&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 133,343 x 5
##    STAID SOUID     DATE    RR  Q_RR
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1  1393 20611 19470301     0     0
##  2  1393 20611 19470302     5     0
##  3  1393 20611 19470303     0     0
##  4  1393 20611 19470304    33     0
##  5  1393 20611 19470305    15     0
##  6  1393 20611 19470306     0     0
##  7  1393 20611 19470307    85     0
##  8  1393 20611 19470308     3     0
##  9  1393 20611 19470309     0     0
## 10  1393 20611 19470310     0     0
## # ... with 133,333 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#create levels for the factor 
id &amp;lt;- unique(pr$STAID)

#the corresponding labels
lab &amp;lt;- c(&amp;quot;Bilbao&amp;quot;, &amp;quot;Santiago&amp;quot;, &amp;quot;Barcelona&amp;quot;, &amp;quot;Madrid&amp;quot;, &amp;quot;Valencia&amp;quot;)

#first changes
pr &amp;lt;- select(pr, STAID, DATE, RR) %&amp;gt;% 
        mutate(DATE = ymd(DATE), 
               RR = ifelse(RR == -9999, NA, RR/10), 
               STAID = factor(STAID, id, lab), 
               yr = year(DATE)) 
pr&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 133,343 x 4
##    STAID  DATE          RR    yr
##    &amp;lt;fct&amp;gt;  &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 Bilbao 1947-03-01   0    1947
##  2 Bilbao 1947-03-02   0.5  1947
##  3 Bilbao 1947-03-03   0    1947
##  4 Bilbao 1947-03-04   3.3  1947
##  5 Bilbao 1947-03-05   1.5  1947
##  6 Bilbao 1947-03-06   0    1947
##  7 Bilbao 1947-03-07   8.5  1947
##  8 Bilbao 1947-03-08   0.3  1947
##  9 Bilbao 1947-03-09   0    1947
## 10 Bilbao 1947-03-10   0    1947
## # ... with 133,333 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We still need to filter and calculate the annual amount of precipitation. Actually, it is not correct to sum up precipitation without taking into account that there are missing values, but it should be enough for this practice. Then, we change the table format with the &lt;code&gt;spread()&lt;/code&gt; function, passing from a long to a wide table, that is, we want to obtain one column per weather station.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pr_yr &amp;lt;- filter(pr, DATE &amp;gt;= &amp;quot;1950-01-01&amp;quot;, DATE &amp;lt; &amp;quot;2018-01-01&amp;quot;) %&amp;gt;%
           group_by(STAID, yr)%&amp;gt;%
             summarise(pr = sum(RR, na.rm = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;STAID&amp;#39;. You can override using the `.groups` argument.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pr_yr&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 324 x 3
## # Groups:   STAID [5]
##    STAID     yr    pr
##    &amp;lt;fct&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 Bilbao  1950 1342 
##  2 Bilbao  1951 1306.
##  3 Bilbao  1952 1355.
##  4 Bilbao  1953 1372.
##  5 Bilbao  1954 1428.
##  6 Bilbao  1955 1062.
##  7 Bilbao  1956 1254.
##  8 Bilbao  1957  968.
##  9 Bilbao  1958 1272.
## 10 Bilbao  1959 1450.
## # ... with 314 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pr_yr &amp;lt;- spread(pr_yr, STAID, pr)
pr_yr&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 68 x 6
##       yr Bilbao Santiago Barcelona Madrid Valencia
##    &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
##  1  1950  1342     1800.      345     NA        NA
##  2  1951  1306.    2344.     1072.   798.       NA
##  3  1952  1355.    1973.      415.   524.       NA
##  4  1953  1372.     973.      683.   365.       NA
##  5  1954  1428.    1348.      581.   246.       NA
##  6  1955  1062.    1769.      530.   473.       NA
##  7  1956  1254.    1533.      695.   480.       NA
##  8  1957   968.    1599.      635.   424.       NA
##  9  1958  1272.    2658.      479.   482.       NA
## 10  1959  1450.    2847.     1006    665.       NA
## # ... with 58 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The next step is to import the climate teleconnection indices.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#teleconnections
telecon &amp;lt;- read_csv(&amp;quot;teleconnections_indices.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## -- Column specification --------------------------------------------------------
## cols(
##   yr = col_double(),
##   NAO = col_double(),
##   WeMO = col_double(),
##   EA = col_double(),
##   `POL-EUAS` = col_double(),
##   `EATL/WRUS` = col_double(),
##   MO = col_double(),
##   SCAND = col_double(),
##   AO = col_double()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;telecon&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 68 x 9
##       yr   NAO   WeMO     EA `POL-EUAS` `EATL/WRUS`    MO    SCAND        AO
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
##  1  1950  0.49  0.555 -0.332     0.0217     -0.0567 0.335  0.301   -0.199   
##  2  1951 -0.07  0.379 -0.372     0.402      -0.419  0.149 -0.00667 -0.365   
##  3  1952 -0.37  0.693 -0.688    -0.0117     -0.711  0.282  0.0642  -0.675   
##  4  1953  0.4  -0.213 -0.727    -0.0567     -0.0508 0.216  0.0233  -0.0164  
##  5  1954  0.51  1.20  -0.912     0.142      -0.318  0.386  0.458   -0.000583
##  6  1955 -0.64  0.138 -0.824    -0.0267      0.154  0.134  0.0392  -0.362   
##  7  1956  0.17  0.617 -1.29     -0.197       0.0617 0.256  0.302   -0.163   
##  8  1957 -0.02  0.321 -0.952    -0.638      -0.167  0.322 -0.134   -0.342   
##  9  1958  0.12  0.941 -0.243     0.138       0.661  0.296  0.279   -0.868   
## 10  1959  0.49 -0.055 -0.23     -0.0142      0.631  0.316  0.725   -0.0762  
## # ... with 58 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally we need to join both tables by year.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_all &amp;lt;- left_join(pr_yr, telecon, by = &amp;quot;yr&amp;quot;)
data_all&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 68 x 14
##       yr Bilbao Santiago Barcelona Madrid Valencia   NAO   WeMO     EA
##    &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
##  1  1950  1342     1800.      345     NA        NA  0.49  0.555 -0.332
##  2  1951  1306.    2344.     1072.   798.       NA -0.07  0.379 -0.372
##  3  1952  1355.    1973.      415.   524.       NA -0.37  0.693 -0.688
##  4  1953  1372.     973.      683.   365.       NA  0.4  -0.213 -0.727
##  5  1954  1428.    1348.      581.   246.       NA  0.51  1.20  -0.912
##  6  1955  1062.    1769.      530.   473.       NA -0.64  0.138 -0.824
##  7  1956  1254.    1533.      695.   480.       NA  0.17  0.617 -1.29 
##  8  1957   968.    1599.      635.   424.       NA -0.02  0.321 -0.952
##  9  1958  1272.    2658.      479.   482.       NA  0.12  0.941 -0.243
## 10  1959  1450.    2847.     1006    665.       NA  0.49 -0.055 -0.23 
## # ... with 58 more rows, and 5 more variables: POL-EUAS &amp;lt;dbl&amp;gt;, EATL/WRUS &amp;lt;dbl&amp;gt;,
## #   MO &amp;lt;dbl&amp;gt;, SCAND &amp;lt;dbl&amp;gt;, AO &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;correlation-test&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Correlation test&lt;/h2&gt;
&lt;p&gt;A correlation test between paired samples can be done with the &lt;code&gt;cor.test()&lt;/code&gt; function of R Base. In this case between the annual precipitation of Bilbao and the NAO index.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor_nao_bil &amp;lt;- cor.test(data_all$Bilbao, data_all$NAO,
                        method = &amp;quot;spearman&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in cor.test.default(data_all$Bilbao, data_all$NAO, method = &amp;quot;spearman&amp;quot;):
## Cannot compute exact p-value with ties&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor_nao_bil&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Spearman&amp;#39;s rank correlation rho
## 
## data:  data_all$Bilbao and data_all$NAO
## S = 44372, p-value = 0.2126
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##       rho 
## 0.1531149&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(cor_nao_bil)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 8
##  $ statistic  : Named num 44372
##   ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##  $ parameter  : NULL
##  $ p.value    : num 0.213
##  $ estimate   : Named num 0.153
##   ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##  $ null.value : Named num 0
##   ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##  $ alternative: chr &amp;quot;two.sided&amp;quot;
##  $ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##  $ data.name  : chr &amp;quot;data_all$Bilbao and data_all$NAO&amp;quot;
##  - attr(*, &amp;quot;class&amp;quot;)= chr &amp;quot;htest&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that the result is in an unmanageable and untidy format. It is a console summary of the correlation with all the statistical parameters necessary to get a conclusion about the relationship. The orginal structure is a list of vectors. However, the &lt;code&gt;tidy()&lt;/code&gt; function of the &lt;em&gt;{broom}&lt;/em&gt; package allows us to convert the result into a table format.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy(cor_nao_bil)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 5
##   estimate statistic p.value method                          alternative
##      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;                           &amp;lt;chr&amp;gt;      
## 1    0.153    44372.   0.213 Spearman&amp;#39;s rank correlation rho two.sided&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;apply-the-correlation-test-to-multiple-variables&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Apply the correlation test to multiple variables&lt;/h2&gt;
&lt;p&gt;The objective is to apply the correlation test to all weather stations and climate teleconnection indices.&lt;/p&gt;
&lt;p&gt;First, we must pass the table to the long format, that is, create a column/variable for the city and for the value of the corresponding precipitation. Then we repeat the same for the teleconnections indices.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- gather(data_all, city, pr, Bilbao:Valencia)%&amp;gt;%
                     gather(telecon, index, NAO:AO)
data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2,720 x 5
##       yr city      pr telecon index
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt;
##  1  1950 Bilbao 1342  NAO      0.49
##  2  1951 Bilbao 1306. NAO     -0.07
##  3  1952 Bilbao 1355. NAO     -0.37
##  4  1953 Bilbao 1372. NAO      0.4 
##  5  1954 Bilbao 1428. NAO      0.51
##  6  1955 Bilbao 1062. NAO     -0.64
##  7  1956 Bilbao 1254. NAO      0.17
##  8  1957 Bilbao  968. NAO     -0.02
##  9  1958 Bilbao 1272. NAO      0.12
## 10  1959 Bilbao 1450. NAO      0.49
## # ... with 2,710 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To apply the test to all cities, we need the corresponding groupings. Therefore, we use the &lt;code&gt;group_by()&lt;/code&gt; function for indicating the two groups: &lt;em&gt;city&lt;/em&gt; and &lt;em&gt;telecon&lt;/em&gt;. In addition, we apply the &lt;code&gt;nest()&lt;/code&gt; function of the &lt;em&gt;{tidyr}&lt;/em&gt; package (&lt;em&gt;{tidyverse}&lt;/em&gt; collection) with the aim of creating lists of tables nested per row. In other words, in each row of each city and teleconnection index we will have a new table that contains the year, the precipitation value and the value of each teleconection, correspondingly.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_nest &amp;lt;- group_by(data, city, telecon) %&amp;gt;% nest()
data_nest&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 40 x 3
## # Groups:   city, telecon [40]
##    city      telecon data             
##    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;   &amp;lt;list&amp;gt;           
##  1 Bilbao    NAO     &amp;lt;tibble [68 x 3]&amp;gt;
##  2 Santiago  NAO     &amp;lt;tibble [68 x 3]&amp;gt;
##  3 Barcelona NAO     &amp;lt;tibble [68 x 3]&amp;gt;
##  4 Madrid    NAO     &amp;lt;tibble [68 x 3]&amp;gt;
##  5 Valencia  NAO     &amp;lt;tibble [68 x 3]&amp;gt;
##  6 Bilbao    WeMO    &amp;lt;tibble [68 x 3]&amp;gt;
##  7 Santiago  WeMO    &amp;lt;tibble [68 x 3]&amp;gt;
##  8 Barcelona WeMO    &amp;lt;tibble [68 x 3]&amp;gt;
##  9 Madrid    WeMO    &amp;lt;tibble [68 x 3]&amp;gt;
## 10 Valencia  WeMO    &amp;lt;tibble [68 x 3]&amp;gt;
## # ... with 30 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(slice(data_nest, 1))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## grouped_df [40 x 3] (S3: grouped_df/tbl_df/tbl/data.frame)
##  $ city   : chr [1:40] &amp;quot;Barcelona&amp;quot; &amp;quot;Barcelona&amp;quot; &amp;quot;Barcelona&amp;quot; &amp;quot;Barcelona&amp;quot; ...
##  $ telecon: chr [1:40] &amp;quot;AO&amp;quot; &amp;quot;EA&amp;quot; &amp;quot;EATL/WRUS&amp;quot; &amp;quot;MO&amp;quot; ...
##  $ data   :List of 40
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] -0.199333 -0.364667 -0.674917 -0.016417 -0.000583 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] -0.333 -0.372 -0.688 -0.727 -0.912 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] -0.0567 -0.4192 -0.7108 -0.0508 -0.3175 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] 0.335 0.149 0.282 0.216 0.386 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] 0.49 -0.07 -0.37 0.4 0.51 -0.64 0.17 -0.02 0.12 0.49 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] 0.0217 0.4025 -0.0117 -0.0567 0.1425 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] 0.30083 -0.00667 0.06417 0.02333 0.4575 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] 0.555 0.379 0.693 -0.213 1.196 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1342 1306 1355 1372 1428 ...
##   .. ..$ index: num [1:68] -0.199333 -0.364667 -0.674917 -0.016417 -0.000583 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1342 1306 1355 1372 1428 ...
##   .. ..$ index: num [1:68] -0.333 -0.372 -0.688 -0.727 -0.912 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1342 1306 1355 1372 1428 ...
##   .. ..$ index: num [1:68] -0.0567 -0.4192 -0.7108 -0.0508 -0.3175 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1342 1306 1355 1372 1428 ...
##   .. ..$ index: num [1:68] 0.335 0.149 0.282 0.216 0.386 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1342 1306 1355 1372 1428 ...
##   .. ..$ index: num [1:68] 0.49 -0.07 -0.37 0.4 0.51 -0.64 0.17 -0.02 0.12 0.49 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1342 1306 1355 1372 1428 ...
##   .. ..$ index: num [1:68] 0.0217 0.4025 -0.0117 -0.0567 0.1425 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1342 1306 1355 1372 1428 ...
##   .. ..$ index: num [1:68] 0.30083 -0.00667 0.06417 0.02333 0.4575 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1342 1306 1355 1372 1428 ...
##   .. ..$ index: num [1:68] 0.555 0.379 0.693 -0.213 1.196 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA 798 524 365 246 ...
##   .. ..$ index: num [1:68] -0.199333 -0.364667 -0.674917 -0.016417 -0.000583 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA 798 524 365 246 ...
##   .. ..$ index: num [1:68] -0.333 -0.372 -0.688 -0.727 -0.912 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA 798 524 365 246 ...
##   .. ..$ index: num [1:68] -0.0567 -0.4192 -0.7108 -0.0508 -0.3175 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA 798 524 365 246 ...
##   .. ..$ index: num [1:68] 0.335 0.149 0.282 0.216 0.386 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA 798 524 365 246 ...
##   .. ..$ index: num [1:68] 0.49 -0.07 -0.37 0.4 0.51 -0.64 0.17 -0.02 0.12 0.49 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA 798 524 365 246 ...
##   .. ..$ index: num [1:68] 0.0217 0.4025 -0.0117 -0.0567 0.1425 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA 798 524 365 246 ...
##   .. ..$ index: num [1:68] 0.30083 -0.00667 0.06417 0.02333 0.4575 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA 798 524 365 246 ...
##   .. ..$ index: num [1:68] 0.555 0.379 0.693 -0.213 1.196 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1800 2344 1973 973 1348 ...
##   .. ..$ index: num [1:68] -0.199333 -0.364667 -0.674917 -0.016417 -0.000583 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1800 2344 1973 973 1348 ...
##   .. ..$ index: num [1:68] -0.333 -0.372 -0.688 -0.727 -0.912 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1800 2344 1973 973 1348 ...
##   .. ..$ index: num [1:68] -0.0567 -0.4192 -0.7108 -0.0508 -0.3175 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1800 2344 1973 973 1348 ...
##   .. ..$ index: num [1:68] 0.335 0.149 0.282 0.216 0.386 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1800 2344 1973 973 1348 ...
##   .. ..$ index: num [1:68] 0.49 -0.07 -0.37 0.4 0.51 -0.64 0.17 -0.02 0.12 0.49 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1800 2344 1973 973 1348 ...
##   .. ..$ index: num [1:68] 0.0217 0.4025 -0.0117 -0.0567 0.1425 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1800 2344 1973 973 1348 ...
##   .. ..$ index: num [1:68] 0.30083 -0.00667 0.06417 0.02333 0.4575 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1800 2344 1973 973 1348 ...
##   .. ..$ index: num [1:68] 0.555 0.379 0.693 -0.213 1.196 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA NA NA NA NA NA NA NA NA NA ...
##   .. ..$ index: num [1:68] -0.199333 -0.364667 -0.674917 -0.016417 -0.000583 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA NA NA NA NA NA NA NA NA NA ...
##   .. ..$ index: num [1:68] -0.333 -0.372 -0.688 -0.727 -0.912 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA NA NA NA NA NA NA NA NA NA ...
##   .. ..$ index: num [1:68] -0.0567 -0.4192 -0.7108 -0.0508 -0.3175 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA NA NA NA NA NA NA NA NA NA ...
##   .. ..$ index: num [1:68] 0.335 0.149 0.282 0.216 0.386 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA NA NA NA NA NA NA NA NA NA ...
##   .. ..$ index: num [1:68] 0.49 -0.07 -0.37 0.4 0.51 -0.64 0.17 -0.02 0.12 0.49 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA NA NA NA NA NA NA NA NA NA ...
##   .. ..$ index: num [1:68] 0.0217 0.4025 -0.0117 -0.0567 0.1425 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA NA NA NA NA NA NA NA NA NA ...
##   .. ..$ index: num [1:68] 0.30083 -0.00667 0.06417 0.02333 0.4575 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA NA NA NA NA NA NA NA NA NA ...
##   .. ..$ index: num [1:68] 0.555 0.379 0.693 -0.213 1.196 ...
##  - attr(*, &amp;quot;groups&amp;quot;)= tibble [40 x 3] (S3: tbl_df/tbl/data.frame)
##   ..$ city   : chr [1:40] &amp;quot;Barcelona&amp;quot; &amp;quot;Barcelona&amp;quot; &amp;quot;Barcelona&amp;quot; &amp;quot;Barcelona&amp;quot; ...
##   ..$ telecon: chr [1:40] &amp;quot;AO&amp;quot; &amp;quot;EA&amp;quot; &amp;quot;EATL/WRUS&amp;quot; &amp;quot;MO&amp;quot; ...
##   ..$ .rows  : list&amp;lt;int&amp;gt; [1:40] 
##   .. ..$ : int 1
##   .. ..$ : int 2
##   .. ..$ : int 3
##   .. ..$ : int 4
##   .. ..$ : int 5
##   .. ..$ : int 6
##   .. ..$ : int 7
##   .. ..$ : int 8
##   .. ..$ : int 9
##   .. ..$ : int 10
##   .. ..$ : int 11
##   .. ..$ : int 12
##   .. ..$ : int 13
##   .. ..$ : int 14
##   .. ..$ : int 15
##   .. ..$ : int 16
##   .. ..$ : int 17
##   .. ..$ : int 18
##   .. ..$ : int 19
##   .. ..$ : int 20
##   .. ..$ : int 21
##   .. ..$ : int 22
##   .. ..$ : int 23
##   .. ..$ : int 24
##   .. ..$ : int 25
##   .. ..$ : int 26
##   .. ..$ : int 27
##   .. ..$ : int 28
##   .. ..$ : int 29
##   .. ..$ : int 30
##   .. ..$ : int 31
##   .. ..$ : int 32
##   .. ..$ : int 33
##   .. ..$ : int 34
##   .. ..$ : int 35
##   .. ..$ : int 36
##   .. ..$ : int 37
##   .. ..$ : int 38
##   .. ..$ : int 39
##   .. ..$ : int 40
##   .. ..@ ptype: int(0) 
##   ..- attr(*, &amp;quot;.drop&amp;quot;)= logi TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The next step is to create a function, in which we define the correlation test and pass it to the clean format using the &lt;code&gt;tidy()&lt;/code&gt; function, which we apply to each groupings.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor_fun &amp;lt;- function(df) cor.test(df$pr, df$index, method = &amp;quot;spearman&amp;quot;) %&amp;gt;% tidy()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we only have to apply our function to the column that contains the tables for each combination between city and teleconnection. To do this, we use the &lt;code&gt;map()&lt;/code&gt; function that applies another function to a vector or list. What we do is create a new column that contains the result, a statistical summary table, for each combination.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_nest &amp;lt;- mutate(data_nest, model = map(data, cor_fun))
data_nest&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 40 x 4
## # Groups:   city, telecon [40]
##    city      telecon data              model           
##    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;   &amp;lt;list&amp;gt;            &amp;lt;list&amp;gt;          
##  1 Bilbao    NAO     &amp;lt;tibble [68 x 3]&amp;gt; &amp;lt;tibble [1 x 5]&amp;gt;
##  2 Santiago  NAO     &amp;lt;tibble [68 x 3]&amp;gt; &amp;lt;tibble [1 x 5]&amp;gt;
##  3 Barcelona NAO     &amp;lt;tibble [68 x 3]&amp;gt; &amp;lt;tibble [1 x 5]&amp;gt;
##  4 Madrid    NAO     &amp;lt;tibble [68 x 3]&amp;gt; &amp;lt;tibble [1 x 5]&amp;gt;
##  5 Valencia  NAO     &amp;lt;tibble [68 x 3]&amp;gt; &amp;lt;tibble [1 x 5]&amp;gt;
##  6 Bilbao    WeMO    &amp;lt;tibble [68 x 3]&amp;gt; &amp;lt;tibble [1 x 5]&amp;gt;
##  7 Santiago  WeMO    &amp;lt;tibble [68 x 3]&amp;gt; &amp;lt;tibble [1 x 5]&amp;gt;
##  8 Barcelona WeMO    &amp;lt;tibble [68 x 3]&amp;gt; &amp;lt;tibble [1 x 5]&amp;gt;
##  9 Madrid    WeMO    &amp;lt;tibble [68 x 3]&amp;gt; &amp;lt;tibble [1 x 5]&amp;gt;
## 10 Valencia  WeMO    &amp;lt;tibble [68 x 3]&amp;gt; &amp;lt;tibble [1 x 5]&amp;gt;
## # ... with 30 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(slice(data_nest, 1))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## grouped_df [40 x 4] (S3: grouped_df/tbl_df/tbl/data.frame)
##  $ city   : chr [1:40] &amp;quot;Barcelona&amp;quot; &amp;quot;Barcelona&amp;quot; &amp;quot;Barcelona&amp;quot; &amp;quot;Barcelona&amp;quot; ...
##  $ telecon: chr [1:40] &amp;quot;AO&amp;quot; &amp;quot;EA&amp;quot; &amp;quot;EATL/WRUS&amp;quot; &amp;quot;MO&amp;quot; ...
##  $ data   :List of 40
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] -0.199333 -0.364667 -0.674917 -0.016417 -0.000583 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] -0.333 -0.372 -0.688 -0.727 -0.912 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] -0.0567 -0.4192 -0.7108 -0.0508 -0.3175 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] 0.335 0.149 0.282 0.216 0.386 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] 0.49 -0.07 -0.37 0.4 0.51 -0.64 0.17 -0.02 0.12 0.49 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] 0.0217 0.4025 -0.0117 -0.0567 0.1425 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] 0.30083 -0.00667 0.06417 0.02333 0.4575 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 345 1072 415 683 581 ...
##   .. ..$ index: num [1:68] 0.555 0.379 0.693 -0.213 1.196 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1342 1306 1355 1372 1428 ...
##   .. ..$ index: num [1:68] -0.199333 -0.364667 -0.674917 -0.016417 -0.000583 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1342 1306 1355 1372 1428 ...
##   .. ..$ index: num [1:68] -0.333 -0.372 -0.688 -0.727 -0.912 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1342 1306 1355 1372 1428 ...
##   .. ..$ index: num [1:68] -0.0567 -0.4192 -0.7108 -0.0508 -0.3175 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1342 1306 1355 1372 1428 ...
##   .. ..$ index: num [1:68] 0.335 0.149 0.282 0.216 0.386 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1342 1306 1355 1372 1428 ...
##   .. ..$ index: num [1:68] 0.49 -0.07 -0.37 0.4 0.51 -0.64 0.17 -0.02 0.12 0.49 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1342 1306 1355 1372 1428 ...
##   .. ..$ index: num [1:68] 0.0217 0.4025 -0.0117 -0.0567 0.1425 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1342 1306 1355 1372 1428 ...
##   .. ..$ index: num [1:68] 0.30083 -0.00667 0.06417 0.02333 0.4575 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1342 1306 1355 1372 1428 ...
##   .. ..$ index: num [1:68] 0.555 0.379 0.693 -0.213 1.196 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA 798 524 365 246 ...
##   .. ..$ index: num [1:68] -0.199333 -0.364667 -0.674917 -0.016417 -0.000583 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA 798 524 365 246 ...
##   .. ..$ index: num [1:68] -0.333 -0.372 -0.688 -0.727 -0.912 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA 798 524 365 246 ...
##   .. ..$ index: num [1:68] -0.0567 -0.4192 -0.7108 -0.0508 -0.3175 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA 798 524 365 246 ...
##   .. ..$ index: num [1:68] 0.335 0.149 0.282 0.216 0.386 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA 798 524 365 246 ...
##   .. ..$ index: num [1:68] 0.49 -0.07 -0.37 0.4 0.51 -0.64 0.17 -0.02 0.12 0.49 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA 798 524 365 246 ...
##   .. ..$ index: num [1:68] 0.0217 0.4025 -0.0117 -0.0567 0.1425 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA 798 524 365 246 ...
##   .. ..$ index: num [1:68] 0.30083 -0.00667 0.06417 0.02333 0.4575 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA 798 524 365 246 ...
##   .. ..$ index: num [1:68] 0.555 0.379 0.693 -0.213 1.196 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1800 2344 1973 973 1348 ...
##   .. ..$ index: num [1:68] -0.199333 -0.364667 -0.674917 -0.016417 -0.000583 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1800 2344 1973 973 1348 ...
##   .. ..$ index: num [1:68] -0.333 -0.372 -0.688 -0.727 -0.912 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1800 2344 1973 973 1348 ...
##   .. ..$ index: num [1:68] -0.0567 -0.4192 -0.7108 -0.0508 -0.3175 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1800 2344 1973 973 1348 ...
##   .. ..$ index: num [1:68] 0.335 0.149 0.282 0.216 0.386 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1800 2344 1973 973 1348 ...
##   .. ..$ index: num [1:68] 0.49 -0.07 -0.37 0.4 0.51 -0.64 0.17 -0.02 0.12 0.49 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1800 2344 1973 973 1348 ...
##   .. ..$ index: num [1:68] 0.0217 0.4025 -0.0117 -0.0567 0.1425 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1800 2344 1973 973 1348 ...
##   .. ..$ index: num [1:68] 0.30083 -0.00667 0.06417 0.02333 0.4575 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] 1800 2344 1973 973 1348 ...
##   .. ..$ index: num [1:68] 0.555 0.379 0.693 -0.213 1.196 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA NA NA NA NA NA NA NA NA NA ...
##   .. ..$ index: num [1:68] -0.199333 -0.364667 -0.674917 -0.016417 -0.000583 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA NA NA NA NA NA NA NA NA NA ...
##   .. ..$ index: num [1:68] -0.333 -0.372 -0.688 -0.727 -0.912 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA NA NA NA NA NA NA NA NA NA ...
##   .. ..$ index: num [1:68] -0.0567 -0.4192 -0.7108 -0.0508 -0.3175 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA NA NA NA NA NA NA NA NA NA ...
##   .. ..$ index: num [1:68] 0.335 0.149 0.282 0.216 0.386 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA NA NA NA NA NA NA NA NA NA ...
##   .. ..$ index: num [1:68] 0.49 -0.07 -0.37 0.4 0.51 -0.64 0.17 -0.02 0.12 0.49 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA NA NA NA NA NA NA NA NA NA ...
##   .. ..$ index: num [1:68] 0.0217 0.4025 -0.0117 -0.0567 0.1425 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA NA NA NA NA NA NA NA NA NA ...
##   .. ..$ index: num [1:68] 0.30083 -0.00667 0.06417 0.02333 0.4575 ...
##   ..$ : tibble [68 x 3] (S3: tbl_df/tbl/data.frame)
##   .. ..$ yr   : num [1:68] 1950 1951 1952 1953 1954 ...
##   .. ..$ pr   : num [1:68] NA NA NA NA NA NA NA NA NA NA ...
##   .. ..$ index: num [1:68] 0.555 0.379 0.693 -0.213 1.196 ...
##  $ model  :List of 40
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num -0.00989
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 52912
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.936
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num -0.295
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 67832
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.0147
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num 0.161
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 43966
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.19
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num -0.255
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 65754
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.0361
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num -0.0203
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 53460
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.869
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num 0.178
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 43082
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.147
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num 0.161
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 43970
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.19
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num 0.0292
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 50862
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.813
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num -0.185
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 62070
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.131
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num -0.256
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 65825
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.0348
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num 0.0155
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 51584
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.9
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num -0.0457
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 54788
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.711
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num 0.153
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 44372
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.213
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num 0.147
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 44670
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.23
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num 0.357
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 33688
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.00296
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num 0.404
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 31242
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.000706
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num -0.313
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 65806
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.0102
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num -0.304
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 65369
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.0123
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num 0.0643
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 46893
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.605
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num -0.497
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 75028
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 2.42e-05
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num -0.291
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 64692
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.0169
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num 0.0835
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 45930
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.501
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num 0.306
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 34766
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.012
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num 0.109
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 44660
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.38
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num -0.443
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 75608
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.00018
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num -0.01
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 52919
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.935
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num 0.176
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 43170
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.151
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num -0.19
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 62364
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.12
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num -0.181
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 61902
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.139
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num 0.0504
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 49752
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.682
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num 0.44
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 29356
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.000203
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num 0.332
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 35014
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.00594
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num 0.211
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 19574
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.129
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num -0.0672
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 26472
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.632
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num 0.0542
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 23460
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.7
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num -0.0478
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 25990
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.733
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num -0.113
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 27600
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.422
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num 0.0971
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 22396
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.488
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num -0.0795
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 26776
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.57
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##   ..$ : tibble [1 x 5] (S3: tbl_df/tbl/data.frame)
##   .. ..$ estimate   : Named num -0.252
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;rho&amp;quot;
##   .. ..$ statistic  : Named num 31056
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr &amp;quot;S&amp;quot;
##   .. ..$ p.value    : num 0.0688
##   .. ..$ method     : chr &amp;quot;Spearman&amp;#39;s rank correlation rho&amp;quot;
##   .. ..$ alternative: chr &amp;quot;two.sided&amp;quot;
##  - attr(*, &amp;quot;groups&amp;quot;)= tibble [40 x 3] (S3: tbl_df/tbl/data.frame)
##   ..$ city   : chr [1:40] &amp;quot;Barcelona&amp;quot; &amp;quot;Barcelona&amp;quot; &amp;quot;Barcelona&amp;quot; &amp;quot;Barcelona&amp;quot; ...
##   ..$ telecon: chr [1:40] &amp;quot;AO&amp;quot; &amp;quot;EA&amp;quot; &amp;quot;EATL/WRUS&amp;quot; &amp;quot;MO&amp;quot; ...
##   ..$ .rows  : list&amp;lt;int&amp;gt; [1:40] 
##   .. ..$ : int 1
##   .. ..$ : int 2
##   .. ..$ : int 3
##   .. ..$ : int 4
##   .. ..$ : int 5
##   .. ..$ : int 6
##   .. ..$ : int 7
##   .. ..$ : int 8
##   .. ..$ : int 9
##   .. ..$ : int 10
##   .. ..$ : int 11
##   .. ..$ : int 12
##   .. ..$ : int 13
##   .. ..$ : int 14
##   .. ..$ : int 15
##   .. ..$ : int 16
##   .. ..$ : int 17
##   .. ..$ : int 18
##   .. ..$ : int 19
##   .. ..$ : int 20
##   .. ..$ : int 21
##   .. ..$ : int 22
##   .. ..$ : int 23
##   .. ..$ : int 24
##   .. ..$ : int 25
##   .. ..$ : int 26
##   .. ..$ : int 27
##   .. ..$ : int 28
##   .. ..$ : int 29
##   .. ..$ : int 30
##   .. ..$ : int 31
##   .. ..$ : int 32
##   .. ..$ : int 33
##   .. ..$ : int 34
##   .. ..$ : int 35
##   .. ..$ : int 36
##   .. ..$ : int 37
##   .. ..$ : int 38
##   .. ..$ : int 39
##   .. ..$ : int 40
##   .. ..@ ptype: int(0) 
##   ..- attr(*, &amp;quot;.drop&amp;quot;)= logi TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;How can we undo the list of tables in each row of our table?&lt;/p&gt;
&lt;p&gt;First we eliminate the column with the data and then simply we can apply the &lt;code&gt;unnest()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corr_pr &amp;lt;- select(data_nest, -data) %&amp;gt;% unnest()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `cols` is now required when using unnest().
## Please use `cols = c(model)`&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corr_pr&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 40 x 7
## # Groups:   city, telecon [40]
##    city     telecon estimate statistic p.value method                alternative
##    &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;                 &amp;lt;chr&amp;gt;      
##  1 Bilbao   NAO       0.153     44372. 2.13e-1 Spearman&amp;#39;s rank corr~ two.sided  
##  2 Santiago NAO      -0.181     61902. 1.39e-1 Spearman&amp;#39;s rank corr~ two.sided  
##  3 Barcelo~ NAO      -0.0203    53460. 8.69e-1 Spearman&amp;#39;s rank corr~ two.sided  
##  4 Madrid   NAO      -0.291     64692. 1.69e-2 Spearman&amp;#39;s rank corr~ two.sided  
##  5 Valencia NAO      -0.113     27600. 4.22e-1 Spearman&amp;#39;s rank corr~ two.sided  
##  6 Bilbao   WeMO      0.404     31242  7.06e-4 Spearman&amp;#39;s rank corr~ two.sided  
##  7 Santiago WeMO      0.332     35014  5.94e-3 Spearman&amp;#39;s rank corr~ two.sided  
##  8 Barcelo~ WeMO      0.0292    50862  8.13e-1 Spearman&amp;#39;s rank corr~ two.sided  
##  9 Madrid   WeMO      0.109     44660  3.80e-1 Spearman&amp;#39;s rank corr~ two.sided  
## 10 Valencia WeMO     -0.252     31056  6.88e-2 Spearman&amp;#39;s rank corr~ two.sided  
## # ... with 30 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The result is a table in which we can see the correlations and their statistical significance for each city and teleconnection index.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;heatmap-of-the-results&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Heatmap of the results&lt;/h2&gt;
&lt;p&gt;Finally, we make a heatmap of the obtained result. But, previously we create a column that indicates whether the correlation is significant with p-value less than 0.05.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corr_pr &amp;lt;- mutate(corr_pr, sig = ifelse(p.value &amp;lt;0.05, &amp;quot;Sig.&amp;quot;, &amp;quot;Non Sig.&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot()+
  geom_tile(data = corr_pr,
            aes(city, telecon, fill = estimate),
            size = 1,
            colour = &amp;quot;white&amp;quot;)+
  geom_tile(data = filter(corr_pr, sig == &amp;quot;Sig.&amp;quot;),
            aes(city, telecon),
            size = 1,
            colour = &amp;quot;black&amp;quot;,
            fill = &amp;quot;transparent&amp;quot;)+
  geom_text(data = corr_pr,
            aes(city, telecon, label = round(estimate, 2),
            fontface = ifelse(sig == &amp;quot;Sig.&amp;quot;, &amp;quot;bold&amp;quot;, &amp;quot;plain&amp;quot;)))+
  scale_fill_gradient2(breaks = seq(-1, 1, 0.2))+
  labs(x = &amp;quot;&amp;quot;, y = &amp;quot;&amp;quot;, fill = &amp;quot;&amp;quot;, p.value = &amp;quot;&amp;quot;)+
  theme_minimal()+
  theme(panel.grid.major = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.ticks = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/tidy-correlation-tests-in-r/index.en_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;2100&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
      
            <category>correlation</category>
      
            <category>variables</category>
      
            <category>tidy</category>
      
            <category>tests</category>
      
      
            <category>statistics</category>
      
            <category>R</category>
      
            <category>R:advanced</category>
      
    </item>
    
    <item>
      <title>Import Excel sheets with R</title>
      <link>https://dominicroye.github.io/en/2019/import-excel-sheets-with-r/</link>
      <pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://dominicroye.github.io/en/2019/import-excel-sheets-with-r/</guid>
      <description>


&lt;p&gt;We usually work with different data sources, and sometimes we can find tables distributed over several Excel sheets. In this post we are going to import the average daily temperature of Madrid and Berlin which is found in two Excel files with sheets for each year between 2000 and 2005: &lt;a href=&#34;https://dominicroye.github.io/files/Data_Excel.zip&#34;&gt;download&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Packages&lt;/h2&gt;
&lt;p&gt;In this post we will use the following packages:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Packages&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, purrr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;fs&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Provides a cross-platform, uniform interface to file system operations&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;readxl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Import Excel files&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install the packages if necessary
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;fs&amp;quot;)) install.packages(&amp;quot;fs&amp;quot;)
if(!require(&amp;quot;readxl&amp;quot;)) install.packages(&amp;quot;readxl&amp;quot;)


#load packages
library(tidyverse)
library(fs)
library(readxl)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By default, the &lt;code&gt;read_excel()&lt;/code&gt; function imports the first sheet. To import a different sheet it is necessary to indicate the number or name with the argument &lt;em&gt;sheet&lt;/em&gt; (second argument).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#import first sheet
read_excel(&amp;quot;madrid_temp.xlsx&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 366 x 3
##    date                   ta    yr
##    &amp;lt;dttm&amp;gt;              &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 2000-01-01 00:00:00   5.4  2000
##  2 2000-01-02 00:00:00   5    2000
##  3 2000-01-03 00:00:00   3.5  2000
##  4 2000-01-04 00:00:00   4.3  2000
##  5 2000-01-05 00:00:00   0.6  2000
##  6 2000-01-06 00:00:00   3.8  2000
##  7 2000-01-07 00:00:00   6.2  2000
##  8 2000-01-08 00:00:00   5.4  2000
##  9 2000-01-09 00:00:00   5.5  2000
## 10 2000-01-10 00:00:00   4.8  2000
## # ... with 356 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#import third sheet
read_excel(&amp;quot;madrid_temp.xlsx&amp;quot;, 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 365 x 3
##    date                   ta    yr
##    &amp;lt;dttm&amp;gt;              &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 2002-01-01 00:00:00   8.7  2002
##  2 2002-01-02 00:00:00   7.4  2002
##  3 2002-01-03 00:00:00   8.5  2002
##  4 2002-01-04 00:00:00   9.2  2002
##  5 2002-01-05 00:00:00   9.3  2002
##  6 2002-01-06 00:00:00   7.3  2002
##  7 2002-01-07 00:00:00   5.4  2002
##  8 2002-01-08 00:00:00   5.6  2002
##  9 2002-01-09 00:00:00   6.8  2002
## 10 2002-01-10 00:00:00   6.1  2002
## # ... with 355 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;excel_sheets()&lt;/code&gt; function can extract the names of the sheets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;path &amp;lt;- &amp;quot;madrid_temp.xlsx&amp;quot;

path %&amp;gt;%
  excel_sheets()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2000&amp;quot; &amp;quot;2001&amp;quot; &amp;quot;2002&amp;quot; &amp;quot;2003&amp;quot; &amp;quot;2004&amp;quot; &amp;quot;2005&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The results are the sheet names and we find the years from 2000 to 2005. The most important function to read multiple sheets is &lt;code&gt;map()&lt;/code&gt; of the &lt;em&gt;{purrr}&lt;/em&gt; package, which is part of the &lt;em&gt;{tidyverse]&lt;/em&gt; collection. &lt;code&gt;map()&lt;/code&gt; allows you to apply a function to each element of a vector or list.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;path &amp;lt;- &amp;quot;madrid_temp.xlsx&amp;quot;

mad &amp;lt;- path %&amp;gt;%
        excel_sheets() %&amp;gt;%
        set_names() %&amp;gt;%
       map(read_excel,
           path = path)
        
str(mad)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 6
##  $ 2000:Classes &amp;#39;tbl_df&amp;#39;, &amp;#39;tbl&amp;#39; and &amp;#39;data.frame&amp;#39;:    366 obs. of  3 variables:
##   ..$ date: POSIXct[1:366], format: &amp;quot;2000-01-01&amp;quot; ...
##   ..$ ta  : num [1:366] 5.4 5 3.5 4.3 0.6 3.8 6.2 5.4 5.5 4.8 ...
##   ..$ yr  : num [1:366] 2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...
##  $ 2001:Classes &amp;#39;tbl_df&amp;#39;, &amp;#39;tbl&amp;#39; and &amp;#39;data.frame&amp;#39;:    365 obs. of  3 variables:
##   ..$ date: POSIXct[1:365], format: &amp;quot;2001-01-01&amp;quot; ...
##   ..$ ta  : num [1:365] 8.2 8.8 7.5 9.2 10 9 5.5 4.6 3 7.9 ...
##   ..$ yr  : num [1:365] 2001 2001 2001 2001 2001 ...
##  $ 2002:Classes &amp;#39;tbl_df&amp;#39;, &amp;#39;tbl&amp;#39; and &amp;#39;data.frame&amp;#39;:    365 obs. of  3 variables:
##   ..$ date: POSIXct[1:365], format: &amp;quot;2002-01-01&amp;quot; ...
##   ..$ ta  : num [1:365] 8.7 7.4 8.5 9.2 9.3 7.3 5.4 5.6 6.8 6.1 ...
##   ..$ yr  : num [1:365] 2002 2002 2002 2002 2002 ...
##  $ 2003:Classes &amp;#39;tbl_df&amp;#39;, &amp;#39;tbl&amp;#39; and &amp;#39;data.frame&amp;#39;:    365 obs. of  3 variables:
##   ..$ date: POSIXct[1:365], format: &amp;quot;2003-01-01&amp;quot; ...
##   ..$ ta  : num [1:365] 9.4 10.8 9.7 9.2 6.3 6.6 3.8 6.4 4.3 3.4 ...
##   ..$ yr  : num [1:365] 2003 2003 2003 2003 2003 ...
##  $ 2004:Classes &amp;#39;tbl_df&amp;#39;, &amp;#39;tbl&amp;#39; and &amp;#39;data.frame&amp;#39;:    366 obs. of  3 variables:
##   ..$ date: POSIXct[1:366], format: &amp;quot;2004-01-01&amp;quot; ...
##   ..$ ta  : num [1:366] 6.6 5.9 7.8 8.1 6.4 5.7 5.2 6.9 11.8 12.2 ...
##   ..$ yr  : num [1:366] 2004 2004 2004 2004 2004 ...
##  $ 2005:Classes &amp;#39;tbl_df&amp;#39;, &amp;#39;tbl&amp;#39; and &amp;#39;data.frame&amp;#39;:    365 obs. of  3 variables:
##   ..$ date: POSIXct[1:365], format: &amp;quot;2005-01-01&amp;quot; ...
##   ..$ ta  : num [1:365] 7.1 7.8 6.4 5.6 4.4 6.8 7.4 6 5.2 4.2 ...
##   ..$ yr  : num [1:365] 2005 2005 2005 2005 2005 ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The result is a named list with the name of each sheet that contains the data.frame. Since it is the same table in all sheets, we could use the function &lt;code&gt;bind_rows()&lt;/code&gt;, however, there is a variant of &lt;code&gt;map()&lt;/code&gt; that directly joins all the tables by row: &lt;code&gt;map_df()&lt;/code&gt;. If it were necessary to join by column, &lt;code&gt;map_dfc()&lt;/code&gt; could be used.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;path &amp;lt;- &amp;quot;madrid_temp.xlsx&amp;quot;

mad &amp;lt;- path %&amp;gt;%
        excel_sheets() %&amp;gt;%
        set_names() %&amp;gt;%
       map_df(read_excel,
           path = path)

mad&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2,192 x 3
##    date                   ta    yr
##    &amp;lt;dttm&amp;gt;              &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 2000-01-01 00:00:00   5.4  2000
##  2 2000-01-02 00:00:00   5    2000
##  3 2000-01-03 00:00:00   3.5  2000
##  4 2000-01-04 00:00:00   4.3  2000
##  5 2000-01-05 00:00:00   0.6  2000
##  6 2000-01-06 00:00:00   3.8  2000
##  7 2000-01-07 00:00:00   6.2  2000
##  8 2000-01-08 00:00:00   5.4  2000
##  9 2000-01-09 00:00:00   5.5  2000
## 10 2000-01-10 00:00:00   4.8  2000
## # ... with 2,182 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In our case we have a column in each sheet (year, but also the date) that differentiates each table. If it were not the case, we should use the name of the sheets as a new column when joining all of them. In &lt;code&gt;bind_rows()&lt;/code&gt; it can be done with the &lt;em&gt;.id&lt;/em&gt; argument by assigning a name for the column. The same works for &lt;code&gt;map_df()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;path &amp;lt;- &amp;quot;madrid_temp.xlsx&amp;quot;

mad &amp;lt;- path %&amp;gt;%
        excel_sheets() %&amp;gt;%
        set_names() %&amp;gt;%
       map_df(read_excel,
           path = path,
           .id = &amp;quot;yr2&amp;quot;)

str(mad)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Classes &amp;#39;tbl_df&amp;#39;, &amp;#39;tbl&amp;#39; and &amp;#39;data.frame&amp;#39;:    2192 obs. of  4 variables:
##  $ yr2 : chr  &amp;quot;2000&amp;quot; &amp;quot;2000&amp;quot; &amp;quot;2000&amp;quot; &amp;quot;2000&amp;quot; ...
##  $ date: POSIXct, format: &amp;quot;2000-01-01&amp;quot; &amp;quot;2000-01-02&amp;quot; ...
##  $ ta  : num  5.4 5 3.5 4.3 0.6 3.8 6.2 5.4 5.5 4.8 ...
##  $ yr  : num  2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But how do we import multiple Excel files?&lt;/p&gt;
&lt;p&gt;To do this, first we must know the &lt;code&gt;dir_ls()&lt;/code&gt; function from the &lt;a href=&#34;https://github.com/r-lib/fs&#34;&gt;&lt;em&gt;{fs}&lt;/em&gt;&lt;/a&gt; package. Indeed, there is the &lt;code&gt;dir()&lt;/code&gt; function of &lt;em&gt;R Base&lt;/em&gt;, but the advantages of the recent package are several, especially the compatibility with the &lt;em&gt;{tidyverse}&lt;/em&gt; collection.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dir_ls()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## berlin_temp.xlsx featured.png     index.en.html    index.en.Rmd     
## madrid_temp.xlsx&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#we can filter the files that we want
dir_ls(regexp = &amp;quot;xlsx&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## berlin_temp.xlsx madrid_temp.xlsx&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We import the two Excel files.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#without joining
dir_ls(regexp = &amp;quot;xlsx&amp;quot;) %&amp;gt;%
  map(read_excel)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $berlin_temp.xlsx
## # A tibble: 366 x 3
##    date                   ta    yr
##    &amp;lt;dttm&amp;gt;              &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 2000-01-01 00:00:00   1.2  2000
##  2 2000-01-02 00:00:00   3.6  2000
##  3 2000-01-03 00:00:00   5.7  2000
##  4 2000-01-04 00:00:00   5.1  2000
##  5 2000-01-05 00:00:00   2.2  2000
##  6 2000-01-06 00:00:00   1.8  2000
##  7 2000-01-07 00:00:00   4.2  2000
##  8 2000-01-08 00:00:00   4.2  2000
##  9 2000-01-09 00:00:00   4.2  2000
## 10 2000-01-10 00:00:00   1.7  2000
## # ... with 356 more rows
## 
## $madrid_temp.xlsx
## # A tibble: 366 x 3
##    date                   ta    yr
##    &amp;lt;dttm&amp;gt;              &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 2000-01-01 00:00:00   5.4  2000
##  2 2000-01-02 00:00:00   5    2000
##  3 2000-01-03 00:00:00   3.5  2000
##  4 2000-01-04 00:00:00   4.3  2000
##  5 2000-01-05 00:00:00   0.6  2000
##  6 2000-01-06 00:00:00   3.8  2000
##  7 2000-01-07 00:00:00   6.2  2000
##  8 2000-01-08 00:00:00   5.4  2000
##  9 2000-01-09 00:00:00   5.5  2000
## 10 2000-01-10 00:00:00   4.8  2000
## # ... with 356 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#joining with a new id column
dir_ls(regexp = &amp;quot;xlsx&amp;quot;) %&amp;gt;%
  map_df(read_excel, .id = &amp;quot;city&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 732 x 4
##    city             date                   ta    yr
##    &amp;lt;chr&amp;gt;            &amp;lt;dttm&amp;gt;              &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 berlin_temp.xlsx 2000-01-01 00:00:00   1.2  2000
##  2 berlin_temp.xlsx 2000-01-02 00:00:00   3.6  2000
##  3 berlin_temp.xlsx 2000-01-03 00:00:00   5.7  2000
##  4 berlin_temp.xlsx 2000-01-04 00:00:00   5.1  2000
##  5 berlin_temp.xlsx 2000-01-05 00:00:00   2.2  2000
##  6 berlin_temp.xlsx 2000-01-06 00:00:00   1.8  2000
##  7 berlin_temp.xlsx 2000-01-07 00:00:00   4.2  2000
##  8 berlin_temp.xlsx 2000-01-08 00:00:00   4.2  2000
##  9 berlin_temp.xlsx 2000-01-09 00:00:00   4.2  2000
## 10 berlin_temp.xlsx 2000-01-10 00:00:00   1.7  2000
## # ... with 722 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, in this case we only import the first sheet of each Excel file. To solve this problem, we must create our own function. In this function we do what we previously did individually.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;read_multiple_excel &amp;lt;- function(path) {
  path %&amp;gt;%
    excel_sheets() %&amp;gt;% 
    set_names() %&amp;gt;% 
  map_df(read_excel, path = path)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We apply our created function to import multiple sheets of several Excel files.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#separately
data &amp;lt;- dir_ls(regexp = &amp;quot;xlsx&amp;quot;) %&amp;gt;% 
           map(read_multiple_excel)

str(data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 2
##  $ berlin_temp.xlsx:Classes &amp;#39;tbl_df&amp;#39;, &amp;#39;tbl&amp;#39; and &amp;#39;data.frame&amp;#39;:    2192 obs. of  3 variables:
##   ..$ date: POSIXct[1:2192], format: &amp;quot;2000-01-01&amp;quot; ...
##   ..$ ta  : num [1:2192] 1.2 3.6 5.7 5.1 2.2 1.8 4.2 4.2 4.2 1.7 ...
##   ..$ yr  : num [1:2192] 2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...
##  $ madrid_temp.xlsx:Classes &amp;#39;tbl_df&amp;#39;, &amp;#39;tbl&amp;#39; and &amp;#39;data.frame&amp;#39;:    2192 obs. of  3 variables:
##   ..$ date: POSIXct[1:2192], format: &amp;quot;2000-01-01&amp;quot; ...
##   ..$ ta  : num [1:2192] 5.4 5 3.5 4.3 0.6 3.8 6.2 5.4 5.5 4.8 ...
##   ..$ yr  : num [1:2192] 2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#joining all data.frames
data_df &amp;lt;- dir_ls(regexp = &amp;quot;xlsx&amp;quot;) %&amp;gt;% 
           map_df(read_multiple_excel,
                  .id = &amp;quot;city&amp;quot;)

str(data_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Classes &amp;#39;tbl_df&amp;#39;, &amp;#39;tbl&amp;#39; and &amp;#39;data.frame&amp;#39;:    4384 obs. of  4 variables:
##  $ city: chr  &amp;quot;berlin_temp.xlsx&amp;quot; &amp;quot;berlin_temp.xlsx&amp;quot; &amp;quot;berlin_temp.xlsx&amp;quot; &amp;quot;berlin_temp.xlsx&amp;quot; ...
##  $ date: POSIXct, format: &amp;quot;2000-01-01&amp;quot; &amp;quot;2000-01-02&amp;quot; ...
##  $ ta  : num  1.2 3.6 5.7 5.1 2.2 1.8 4.2 4.2 4.2 1.7 ...
##  $ yr  : num  2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
      
            <category>excel</category>
      
            <category>sheets</category>
      
            <category>import</category>
      
      
            <category>management</category>
      
            <category>R</category>
      
            <category>R:intermediate</category>
      
    </item>
    
    <item>
      <title>Calculating the distance to the sea in R</title>
      <link>https://dominicroye.github.io/en/2019/calculating-the-distance-to-the-sea-in-r/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://dominicroye.github.io/en/2019/calculating-the-distance-to-the-sea-in-r/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2019/calculating-the-distance-to-the-sea-in-r/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;The distance to the sea is a fundamental variable in geography, especially relevant when it comes to modeling. For example, in interpolations of air temperature, the distance to the sea is usually used as a predictor variable, since there is a casual relationship between the two that explains the spatial variation. How can we estimate the (shortest) distance to the coast in R?&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Packages&lt;/h2&gt;
&lt;p&gt;In this post we will use the following libraries:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;15%&#34; /&gt;
&lt;col width=&#34;84%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Library&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tidyverse&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collection of packages (visualization, manipulation): ggplot2, dplyr, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Simple Feature: import, export and manipulate vector data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;raster&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Import, export and manipulate raster&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;rnaturalearth&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Set of vector maps ‘natural earth’&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;RColorBrewer&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Color palettes&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install the libraries if necessary
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;sf&amp;quot;)) install.packages(&amp;quot;sf&amp;quot;)
if(!require(&amp;quot;raster&amp;quot;)) install.packages(&amp;quot;raster&amp;quot;)
if(!require(&amp;quot;rnaturalearth&amp;quot;)) install.packages(&amp;quot;rnaturalearth&amp;quot;)

#packages
library(rnaturalearth)
library(sf)
library(raster)
library(tidyverse)
library(RColorBrewer)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-coast-of-iceland-as-an-example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The coast of Iceland as an example&lt;/h2&gt;
&lt;p&gt;Our example in this post will be Iceland, and, as it is an island territory it will facilitate the tutorial showing the process in a simple manner. The &lt;em&gt;rnaturalearth&lt;/em&gt; package allows you to import the boundaries of countries (with different administrative levels) from around the world. The data comes from the platform &lt;a href=&#34;http://www.naturalearthdata.com/&#34;&gt;naturalearthdata.com&lt;/a&gt;. I recommend exploring the package, more info &lt;a href=&#34;https://github.com/ropensci/rnaturalearth&#34;&gt;here&lt;/a&gt;. The &lt;code&gt;ne_countries( )&lt;/code&gt; function imports the country boundaries. In this case we indicate with the argument &lt;em&gt;scale&lt;/em&gt; the resolution (10, 50 or 110m), with &lt;em&gt;country&lt;/em&gt; we indicate the specific country of interest and with &lt;em&gt;returnclass&lt;/em&gt; we determine which class we want (&lt;em&gt;sf&lt;/em&gt; or &lt;em&gt;sp&lt;/em&gt;), in our case &lt;em&gt;sf&lt;/em&gt; (simple feature).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;world &amp;lt;- ne_countries(scale = 50) #world map with 50m resolution

plot(world) #sp class by default&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/calculating-the-distance-to-the-sea-in-r/index.en_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#import the limits of Iceland
iceland &amp;lt;- ne_countries(scale = 10, country = &amp;quot;Iceland&amp;quot;, returnclass = &amp;quot;sf&amp;quot;)

#info of our spatial vector object
iceland&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Simple feature collection with 1 feature and 94 fields
## Geometry type: MULTIPOLYGON
## Dimension:     XY
## Bounding box:  xmin: -24.53991 ymin: 63.39671 xmax: -13.50292 ymax: 66.56415
## CRS:           +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0
##          featurecla scalerank labelrank sovereignt sov_a3 adm0_dif level
## 188 Admin-0 country         0         3    Iceland    ISL        0     2
##                  type   admin adm0_a3 geou_dif geounit gu_a3 su_dif subunit
## 188 Sovereign country Iceland     ISL        0 Iceland   ISL      0 Iceland
##     su_a3 brk_diff    name name_long brk_a3 brk_name brk_group  abbrev postal
## 188   ISL        0 Iceland   Iceland    ISL  Iceland      &amp;lt;NA&amp;gt; Iceland     IS
##               formal_en formal_fr name_ciawf note_adm0 note_brk name_sort
## 188 Republic of Iceland      &amp;lt;NA&amp;gt;    Iceland      &amp;lt;NA&amp;gt;     &amp;lt;NA&amp;gt;   Iceland
##     name_alt mapcolor7 mapcolor8 mapcolor9 mapcolor13 pop_est pop_rank
## 188     &amp;lt;NA&amp;gt;         1         4         4          9  339747       10
##     gdp_md_est pop_year lastcensus gdp_year                    economy
## 188      16150     2017         NA     2016 2. Developed region: nonG7
##               income_grp wikipedia fips_10_ iso_a2 iso_a3 iso_a3_eh iso_n3
## 188 1. High income: OECD        NA       IC     IS    ISL       ISL    352
##     un_a3 wb_a2 wb_a3   woe_id woe_id_eh                   woe_note adm0_a3_is
## 188   352    IS   ISL 23424845  23424845 Exact WOE match as country        ISL
##     adm0_a3_us adm0_a3_un adm0_a3_wb continent region_un       subregion
## 188        ISL         NA         NA    Europe    Europe Northern Europe
##                 region_wb name_len long_len abbrev_len tiny homepart min_zoom
## 188 Europe &amp;amp; Central Asia        7        7          7   NA        1        0
##     min_label max_label      ne_id wikidataid name_ar name_bn name_de name_en
## 188         2         7 1159320917       Q189    &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;  Island Iceland
##      name_es name_fr name_el name_hi name_hu  name_id name_it name_ja name_ko
## 188 Islandia Islande    &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;  Izland Islandia Islanda    &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;
##     name_nl  name_pl  name_pt name_ru name_sv name_tr name_vi name_zh
## 188 IJsland Islandia Islândia    &amp;lt;NA&amp;gt;  Island Izlanda Iceland    &amp;lt;NA&amp;gt;
##                           geometry
## 188 MULTIPOLYGON (((-14.56363 6...&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#here Iceland
plot(iceland)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/calculating-the-distance-to-the-sea-in-r/index.en_files/figure-html/unnamed-chunk-3-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;By default, the &lt;code&gt;plot( )&lt;/code&gt; function with the class &lt;em&gt;sf&lt;/em&gt; creates as many facets of the map as there are variables in it. To limit this behavior we can use either a variable name &lt;code&gt;plot(iceland[&#34;admin&#34;])&lt;/code&gt; or the limit argument &lt;code&gt;plot(iceland, max.plot = 1)&lt;/code&gt;. With the argument &lt;em&gt;max.plot = 1&lt;/em&gt; the function uses the first available variable of the map.&lt;/p&gt;
&lt;p&gt;In addition, we see in the information of the object &lt;em&gt;sf&lt;/em&gt; that the projection is WGS84 with decimal degrees (EPSG code: 4326). For the calculation of distances it is more convenient to use meters instead of degrees. Because of this, the first thing we do is to transform the map of Iceland to UTM Zone 27 (EPSG code: 3055). More information about EPSG and projections &lt;a href=&#34;http://spatialreference.org/ref/epsg/wgs-84/&#34;&gt;here&lt;/a&gt;. For that purpose, we use the &lt;code&gt;st_transform( )&lt;/code&gt; function. We simply indicate the map and the EPSG code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#transform to UTM
iceland &amp;lt;- st_transform(iceland, 3055)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;create-a-fishnet-of-points&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Create a fishnet of points&lt;/h2&gt;
&lt;p&gt;We still need the points where we want to know the distance. In our case it will be a regular fishnet of points in Iceland with a resolution of 5km. We do this with the function &lt;code&gt;st_make_grid( )&lt;/code&gt;, indicating the resolution in the unit of the coordinate system (meters in our case) with the argument &lt;em&gt;cellsize&lt;/em&gt;, and what geometry we would like to create &lt;em&gt;what&lt;/em&gt; (polygons, centers or corners).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#create the fishnet
grid &amp;lt;- st_make_grid(iceland, cellsize = 5000, what = &amp;quot;centers&amp;quot;)

#our fishnet with the extension of Iceland
plot(grid)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/calculating-the-distance-to-the-sea-in-r/index.en_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#only extract the points in the limits of Iceland
grid &amp;lt;- st_intersection(grid, iceland)   

#our fishnet now
plot(grid)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/calculating-the-distance-to-the-sea-in-r/index.en_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;calculating-the-distance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Calculating the distance&lt;/h2&gt;
&lt;p&gt;To estimate the distance we use the &lt;code&gt;st_distance( )&lt;/code&gt; function that returns a vector of distances for all our points in the fishnet. But first it is necessary to transform the map of Iceland from a polygon shape (MULTIPOLYGON) to a line (MULTILINESTRING). More details with &lt;code&gt;?st_cast&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#transform Iceland from polygon shape to line
iceland &amp;lt;- st_cast(iceland, &amp;quot;MULTILINESTRING&amp;quot;)

#calculation of the distance between the coast and our points
dist &amp;lt;- st_distance(iceland, grid)

#distance with unit in meters
head(dist[1,])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Units: [m]
## [1]  790.7906 1151.4360 1270.7603 3128.9057 2428.5677 4197.7472&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;plotting-the-calculated-distance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plotting the calculated distance&lt;/h2&gt;
&lt;p&gt;Once obtained the distance for our points, we can combine them with the coordinates and plot them in &lt;em&gt;ggplot2&lt;/em&gt;. For this, we create a &lt;em&gt;data.frame&lt;/em&gt;. The object &lt;em&gt;dist&lt;/em&gt; is a matrix of one column, so we have to convert it to a vector with the function &lt;code&gt;as.vector( )&lt;/code&gt;. In addition, we divide by 1000 to convert the distance in meters to km. The &lt;code&gt;st_coordinates( )&lt;/code&gt; function extracts the coordinates of our points. For the final visualization we use a vector of colors with the RdGy palette (more &lt;a href=&#34;http://colorbrewer2.org&#34;&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#create a data.frame with the distance and the coordinates of the points
df &amp;lt;- data.frame(dist = as.vector(dist)/1000,
                    st_coordinates(grid))

#structure
str(df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;data.frame&amp;#39;:    4104 obs. of  3 variables:
##  $ dist: num  0.791 1.151 1.271 3.129 2.429 ...
##  $ X   : num  608796 613796 583796 588796 593796 ...
##  $ Y   : num  7033371 7033371 7038371 7038371 7038371 ...&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#colors 
col_dist &amp;lt;- brewer.pal(11, &amp;quot;RdGy&amp;quot;)


ggplot(df, aes(X, Y, fill = dist))+ #variables
         geom_tile()+ #geometry
           scale_fill_gradientn(colours = rev(col_dist))+ #colors for plotting the distance
             labs(fill = &amp;quot;Distance (km)&amp;quot;)+ #legend name
             theme_void()+ #map theme
              theme(legend.position = &amp;quot;bottom&amp;quot;) #legend position&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/calculating-the-distance-to-the-sea-in-r/index.en_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;export-the-distance-as-a-raster&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Export the distance as a raster&lt;/h2&gt;
&lt;p&gt;To be able to export the estimated distance to the sea of Iceland, we need to use the &lt;code&gt;rasterize( )&lt;/code&gt; function of the library &lt;em&gt;raster&lt;/em&gt;.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;First, it is necessary to create an empty raster. In this raster we have to indicate the resolution, in our case it is of 5000m, the projection and the extension of the raster.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;p&gt;We can extract the projection from the information of the map of Iceland.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The extension can be extracted from our &lt;em&gt;grid&lt;/em&gt; points with the function &lt;code&gt;extent( )&lt;/code&gt;. However, this last function needs the class &lt;em&gt;sp&lt;/em&gt;, so we pass the object &lt;em&gt;grid&lt;/em&gt; in &lt;em&gt;sf&lt;/em&gt; format, only for this time, to the class &lt;em&gt;sp&lt;/em&gt; using the function &lt;code&gt;as( )&lt;/code&gt; and the argument “Spatial”.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In addition to the above, the &lt;em&gt;data.frame&lt;/em&gt; &lt;strong&gt;df&lt;/strong&gt;, that we created earlier, has to be converted into the &lt;em&gt;sf&lt;/em&gt; class. Therefore, we apply the function &lt;code&gt;st_as_sf( )&lt;/code&gt; with the argument &lt;em&gt;coords&lt;/em&gt; indicating the names of the coordinates. Additionally, we also define the coordinate system that we know.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#get the extension
ext &amp;lt;- extent(as(grid, &amp;quot;Spatial&amp;quot;))

#extent object
ext&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class      : Extent 
## xmin       : 338795.6 
## xmax       : 848795.6 
## ymin       : 7033371 
## ymax       : 7383371&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#raster destination
r &amp;lt;- raster(resolution = 5000, ext = ext, crs = &amp;quot;+proj=utm +zone=27 +ellps=intl +towgs84=-73,47,-83,0,0,0,0 +units=m +no_defs&amp;quot;)

#convert the points to a spatial object class sf
dist_sf &amp;lt;- st_as_sf(df, coords = c(&amp;quot;X&amp;quot;, &amp;quot;Y&amp;quot;)) %&amp;gt;%
                      st_set_crs(3055)

#create the distance raster
dist_raster &amp;lt;- rasterize(dist_sf, r, &amp;quot;dist&amp;quot;, fun = mean)

#raster
dist_raster&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class      : RasterLayer 
## dimensions : 70, 102, 7140  (nrow, ncol, ncell)
## resolution : 5000, 5000  (x, y)
## extent     : 338795.6, 848795.6, 7033371, 7383371  (xmin, xmax, ymin, ymax)
## crs        : +proj=utm +zone=27 +ellps=intl +units=m +no_defs 
## source     : memory
## names      : layer 
## values     : 0.006124901, 115.1712  (min, max)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#plot the raster
plot(dist_raster)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/calculating-the-distance-to-the-sea-in-r/index.en_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#export the raster
writeRaster(dist_raster, file = &amp;quot;dist_islandia.tif&amp;quot;, format = &amp;quot;GTiff&amp;quot;, overwrite = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;rasterize( )&lt;/code&gt; function is designed to create rasters from an irregular grid. In case we have a regular grid, like this one, we can use an easier alternative way. The &lt;code&gt;rasterFromXYZ( )&lt;/code&gt; function converts a &lt;em&gt;data.frame&lt;/em&gt; with longitude, latitude and the variable &lt;em&gt;Z&lt;/em&gt; into a raster object. It is important that the order should be longitude, latitude, variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r &amp;lt;- rasterFromXYZ(df[, c(2:3, 1)], crs = &amp;quot;+proj=utm +zone=27 +ellps=intl +towgs84=-73,47,-83,0,0,0,0 +units=m +no_defs&amp;quot;)

plot(r)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2019/calculating-the-distance-to-the-sea-in-r/index.en_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;With the calculation of distance we can create art, as seen in the header of this post, which includes a world map only with the distance to the sea of all continents. A different perspective to our world (&lt;a href=&#34;https://www.geografiainfinita.com/2017/06/una-radiografia-del-mundo-a-traves-de-la-distancia-al-mar/&#34;&gt;here more (spanish)&lt;/a&gt;) .&lt;/p&gt;
&lt;/div&gt;
</description>
      
            <category>distance</category>
      
            <category>raster</category>
      
            <category>estimation</category>
      
            <category>variable</category>
      
      
            <category>gis</category>
      
            <category>R</category>
      
            <category>R:elementary</category>
      
    </item>
    
    <item>
      <title>How to create &#39;Warming Stripes&#39; in R</title>
      <link>https://dominicroye.github.io/en/2018/how-to-create-warming-stripes-in-r/</link>
      <pubDate>Wed, 05 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dominicroye.github.io/en/2018/how-to-create-warming-stripes-in-r/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2018/how-to-create-warming-stripes-in-r/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This year, the so-called &lt;em&gt;warming stripes&lt;/em&gt;, which were created by the scientist &lt;a href=&#34;https://twitter.com/ed_hawkins?lang=es&#34;&gt;Ed Hawkins&lt;/a&gt; of the University of Reading, became very famous all over the world. These graphs represent and communicate climate change in a very illustrative and effective way.&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Visualising global temperature change since records began in 1850. Versions for USA, central England &amp;amp; Toronto available too: &lt;a href=&#34;https://t.co/H5Hv9YgZ7v&#34;&gt;https://t.co/H5Hv9YgZ7v&lt;/a&gt; &lt;a href=&#34;https://t.co/YMzdySrr3A&#34;&gt;pic.twitter.com/YMzdySrr3A&lt;/a&gt;&lt;/p&gt;&amp;mdash; Ed Hawkins (@ed_hawkins) &lt;a href=&#34;https://twitter.com/ed_hawkins/status/999242147135188993?ref_src=twsrc%5Etfw&#34;&gt;May 23, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/p&gt;
&lt;p&gt;From his idea, I created strips for examples of Spain, like the next one in Madrid.&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;es&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://twitter.com/hashtag/Temperatura?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Temperatura&lt;/a&gt; anual en &lt;a href=&#34;https://twitter.com/hashtag/MadridRetiro?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#MadridRetiro&lt;/a&gt; desde 1920 a 2017.  &lt;a href=&#34;https://twitter.com/hashtag/CambioClimatico?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#CambioClimatico&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/dataviz?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#dataviz&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/ggplot2?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#ggplot2&lt;/a&gt; (idea de &lt;a href=&#34;https://twitter.com/ed_hawkins?ref_src=twsrc%5Etfw&#34;&gt;@ed_hawkins&lt;/a&gt; 🙏) &lt;a href=&#34;https://twitter.com/Divulgameteo?ref_src=twsrc%5Etfw&#34;&gt;@Divulgameteo&lt;/a&gt; &lt;a href=&#34;https://twitter.com/edupenabad?ref_src=twsrc%5Etfw&#34;&gt;@edupenabad&lt;/a&gt; &lt;a href=&#34;https://twitter.com/climayagua?ref_src=twsrc%5Etfw&#34;&gt;@climayagua&lt;/a&gt; &lt;a href=&#34;https://twitter.com/ClimaGroupUB?ref_src=twsrc%5Etfw&#34;&gt;@ClimaGroupUB&lt;/a&gt; &lt;a href=&#34;https://twitter.com/4gotas_com?ref_src=twsrc%5Etfw&#34;&gt;@4gotas_com&lt;/a&gt; &lt;a href=&#34;https://t.co/wmLb5uczpT&#34;&gt;pic.twitter.com/wmLb5uczpT&lt;/a&gt;&lt;/p&gt;&amp;mdash; Dominic Royé (@dr_xeo) &lt;a href=&#34;https://twitter.com/dr_xeo/status/1002954473927561217?ref_src=twsrc%5Etfw&#34;&gt;June 2, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/p&gt;
&lt;p&gt;In this post I will show how you can create these strips in R with the library &lt;em&gt;ggplot2&lt;/em&gt;. Although I must say that there are many ways in R that can lead us to the same result or to a similar one, even within &lt;em&gt;ggplot2&lt;/em&gt;.&lt;/p&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;In this case we will use the annual temperatures of Lisbon
&lt;a href=&#34;https://data.giss.nasa.gov/gistemp/stdata/&#34;&gt;GISS Surface Temperature Analysis&lt;/a&gt;, homogenized time series, comprising the period from 1880 to 2018. Monthly temperatures or other time series could also be used. The file can be downloaded &lt;a href=&#34;https://dominicroye.github.io/files/temp_lisboa.csv&#34;&gt;here&lt;/a&gt;. First, we should, as long as we have not done it, install the collection of &lt;em&gt;tidyverse&lt;/em&gt; libraries that also include &lt;em&gt;ggplot2&lt;/em&gt;. In addition, we will need the library &lt;em&gt;lubridate&lt;/em&gt; for the treatment of dates. Then, we import the data of Lisbon in csv format.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install the lubridate and tidyverse libraries
if(!require(&amp;quot;lubridate&amp;quot;)) install.packages(&amp;quot;lubridate&amp;quot;)
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)

#packages
library(tidyverse)
library(lubridate)
library(RColorBrewer)

#import the annual temperatures
temp_lisboa &amp;lt;- read_csv(&amp;quot;temp_lisboa.csv&amp;quot;)

str(temp_lisboa)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## spec_tbl_df [139 x 18] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
##  $ YEAR  : num [1:139] 1880 1881 1882 1883 1884 ...
##  $ JAN   : num [1:139] 9.17 11.37 10.07 10.86 11.16 ...
##  $ FEB   : num [1:139] 12 11.8 11.9 11.5 10.6 ...
##  $ MAR   : num [1:139] 13.6 14.1 13.5 10.5 12.4 ...
##  $ APR   : num [1:139] 13.1 14.4 14 13.8 12.2 ...
##  $ MAY   : num [1:139] 15.7 17.3 15.6 14.6 16.4 ...
##  $ JUN   : num [1:139] 17 19.2 17.9 17.2 19.1 ...
##  $ JUL   : num [1:139] 19.1 21.8 20.3 19.5 21.4 ...
##  $ AUG   : num [1:139] 20.6 23.5 21 21.6 22.4 ...
##  $ SEP   : num [1:139] 20.7 20 18 18.8 19.5 ...
##  $ OCT   : num [1:139] 17.9 16.3 16.4 15.8 16.4 ...
##  $ NOV   : num [1:139] 12.5 14.7 13.7 13.5 12.5 ...
##  $ DEC   : num [1:139] 11.07 9.97 10.66 9.46 10.25 ...
##  $ D-J-F : num [1:139] 10.7 11.4 10.6 11 10.4 ...
##  $ M-A-M : num [1:139] 14.1 15.2 14.3 12.9 13.6 ...
##  $ J-J-A : num [1:139] 18.9 21.5 19.7 19.4 20.9 ...
##  $ S-O-N : num [1:139] 17 17 16 16 16.1 ...
##  $ metANN: num [1:139] 15.2 16.3 15.2 14.8 15.3 ...
##  - attr(*, &amp;quot;spec&amp;quot;)=
##   .. cols(
##   ..   YEAR = col_double(),
##   ..   JAN = col_double(),
##   ..   FEB = col_double(),
##   ..   MAR = col_double(),
##   ..   APR = col_double(),
##   ..   MAY = col_double(),
##   ..   JUN = col_double(),
##   ..   JUL = col_double(),
##   ..   AUG = col_double(),
##   ..   SEP = col_double(),
##   ..   OCT = col_double(),
##   ..   NOV = col_double(),
##   ..   DEC = col_double(),
##   ..   `D-J-F` = col_double(),
##   ..   `M-A-M` = col_double(),
##   ..   `J-J-A` = col_double(),
##   ..   `S-O-N` = col_double(),
##   ..   metANN = col_double()
##   .. )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see in the columns that we have monthly and seasonal values, and the annual temperature value. But before proceeding to visualize the annual temperature, we must replace the missing values &lt;em&gt;999.9&lt;/em&gt; with &lt;code&gt;NA&lt;/code&gt;, using the &lt;code&gt;ifelse( )&lt;/code&gt; function that evaluates a condition and perform the given argument corresponding to true and false.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#select only the annual temperature and year column
temp_lisboa_yr &amp;lt;- select(temp_lisboa, YEAR, metANN)

#rename the temperature column
temp_lisboa_yr &amp;lt;- rename(temp_lisboa_yr, ta = metANN)

#missing values 999.9
summary(temp_lisboa_yr) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       YEAR            ta        
##  Min.   :1880   Min.   : 14.53  
##  1st Qu.:1914   1st Qu.: 15.65  
##  Median :1949   Median : 16.11  
##  Mean   :1949   Mean   : 37.38  
##  3rd Qu.:1984   3rd Qu.: 16.70  
##  Max.   :2018   Max.   :999.90&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;temp_lisboa_yr &amp;lt;- mutate(temp_lisboa_yr, ta = ifelse(ta == 999.9, NA, ta))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When we use the year as a variable, we do not usually convert it into a date object, however it is advisable. This allows us to use the date functions of the library &lt;em&gt;lubridate&lt;/em&gt; and the support functions inside of &lt;em&gt;ggplot2&lt;/em&gt;. The &lt;code&gt;str_c( )&lt;/code&gt; function of the library &lt;em&gt;stringr&lt;/em&gt;, part of the collection of &lt;em&gt;tidyverse&lt;/em&gt;, is similar to &lt;code&gt;paste( )&lt;/code&gt; of R Base that allows us to combine characters by specifying a separator (sep = “-”). The &lt;code&gt;ymd( )&lt;/code&gt; (year month day) function of the &lt;em&gt;lubridate&lt;/em&gt; library converts a date character into a &lt;em&gt;Date&lt;/em&gt; object. It is possible to combine several functions
using the &lt;em&gt;pipe operator&lt;/em&gt; &lt;code&gt;%&amp;gt;%&lt;/code&gt; that helps to chain without assigning the result to a new object. Its use is very extended especially with the library &lt;em&gt;tidyverse&lt;/em&gt;. If you want to know more about its use, &lt;a href=&#34;https://www.datacamp.com/community/tutorials/pipe-r-tutorial&#34;&gt;here&lt;/a&gt; you have a tutorial.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;temp_lisboa_yr &amp;lt;- mutate(temp_lisboa_yr, date = str_c(YEAR, &amp;quot;01-01&amp;quot;, sep = &amp;quot;-&amp;quot;) %&amp;gt;% ymd())&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-the-strips&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Creating the strips&lt;/h2&gt;
&lt;p&gt;First, we create the style of the graph, specifying all the arguments of the theme we want to adjust. We start with the default style of &lt;code&gt;theme_minimal( )&lt;/code&gt;. In addition, we assign
the colors from &lt;em&gt;RColorBrewer&lt;/em&gt; to an object &lt;em&gt;col_srip&lt;/em&gt;. More information about the colors used &lt;a href=&#34;http://colorbrewer2.org&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;theme_strip &amp;lt;- theme_minimal()+
                 theme(axis.text.y = element_blank(),
                       axis.line.y = element_blank(),
                       axis.title = element_blank(),
                       panel.grid.major = element_blank(),
                       legend.title = element_blank(),
                       axis.text.x = element_text(vjust = 3),
                       panel.grid.minor = element_blank(),
                        plot.title = element_text(size = 14, face = &amp;quot;bold&amp;quot;)
                       )


col_strip &amp;lt;- brewer.pal(11, &amp;quot;RdBu&amp;quot;)

brewer.pal.info&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          maxcolors category colorblind
## BrBG            11      div       TRUE
## PiYG            11      div       TRUE
## PRGn            11      div       TRUE
## PuOr            11      div       TRUE
## RdBu            11      div       TRUE
## RdGy            11      div      FALSE
## RdYlBu          11      div       TRUE
## RdYlGn          11      div      FALSE
## Spectral        11      div      FALSE
## Accent           8     qual      FALSE
## Dark2            8     qual       TRUE
## Paired          12     qual       TRUE
## Pastel1          9     qual      FALSE
## Pastel2          8     qual      FALSE
## Set1             9     qual      FALSE
## Set2             8     qual       TRUE
## Set3            12     qual      FALSE
## Blues            9      seq       TRUE
## BuGn             9      seq       TRUE
## BuPu             9      seq       TRUE
## GnBu             9      seq       TRUE
## Greens           9      seq       TRUE
## Greys            9      seq       TRUE
## Oranges          9      seq       TRUE
## OrRd             9      seq       TRUE
## PuBu             9      seq       TRUE
## PuBuGn           9      seq       TRUE
## PuRd             9      seq       TRUE
## Purples          9      seq       TRUE
## RdPu             9      seq       TRUE
## Reds             9      seq       TRUE
## YlGn             9      seq       TRUE
## YlGnBu           9      seq       TRUE
## YlOrBr           9      seq       TRUE
## YlOrRd           9      seq       TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the final graphic we use the geometry &lt;code&gt;geom_tile( )&lt;/code&gt;. Since the data does not have a specific value for the Y axis, we need a &lt;em&gt;dummy&lt;/em&gt; value, here I used 1. Also, I adjust the width of the color bar in the legend.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;     ggplot(temp_lisboa_yr,
             aes(x = date, y = 1, fill = ta))+
        geom_tile()+
           scale_x_date(date_breaks = &amp;quot;6 years&amp;quot;,
                     date_labels = &amp;quot;%Y&amp;quot;,
                     expand = c(0, 0))+
           scale_y_continuous(expand = c(0, 0))+
           scale_fill_gradientn(colors = rev(col_strip))+
             guides(fill = guide_colorbar(barwidth = 1))+
            labs(title = &amp;quot;LISBOA 1880-2018&amp;quot;,
                caption = &amp;quot;Datos: GISS Surface Temperature Analysis&amp;quot;)+
              theme_strip&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2018/how-to-create-warming-stripes-in-r/index.en_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In case we want to get only the strips, we can use &lt;code&gt;theme_void( )&lt;/code&gt; and the argument &lt;em&gt;show.legend = FALSE&lt;/em&gt; in &lt;code&gt;geom_tile( )&lt;/code&gt; to remove all style elements. We can also change the color for the &lt;code&gt;NA&lt;/code&gt; values, including the argument &lt;em&gt;na.value = “gray70”&lt;/em&gt; in the &lt;code&gt;scale_fill_gradientn( )&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;     ggplot(temp_lisboa_yr,
             aes(x = date, y = 1, fill = ta))+
        geom_tile(show.legend = FALSE)+
           scale_x_date(date_breaks = &amp;quot;6 years&amp;quot;,
                     date_labels = &amp;quot;%Y&amp;quot;,
                     expand = c(0, 0))+
           scale_y_discrete(expand = c(0, 0))+
           scale_fill_gradientn(colors = rev(col_strip))+
             theme_void()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2018/how-to-create-warming-stripes-in-r/index.en_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
      
            <category>ggplot2</category>
      
            <category>warming stripes</category>
      
            <category>global warming</category>
      
            <category>visualization</category>
      
      
            <category>datavis</category>
      
            <category>R</category>
      
            <category>R:elementary</category>
      
    </item>
    
    <item>
      <title>Accessing OpenStreetMap data with R</title>
      <link>https://dominicroye.github.io/en/2018/accessing-openstreetmap-data-with-r/</link>
      <pubDate>Sat, 03 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dominicroye.github.io/en/2018/accessing-openstreetmap-data-with-r/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2018/accessing-openstreetmap-data-with-r/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;the-database-of-open-street-maps&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The database of Open Street Maps&lt;/h2&gt;
&lt;p&gt;Recently I created a map of the distribution of gas stations and electric charging stations in Europe.&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Population density through the number of gas stations in Europe. &lt;a href=&#34;https://twitter.com/hashtag/dataviz?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#dataviz&lt;/a&gt; &lt;a href=&#34;https://twitter.com/AGE_Oficial?ref_src=twsrc%5Etfw&#34;&gt;@AGE_Oficial&lt;/a&gt; &lt;a href=&#34;https://twitter.com/mipazos?ref_src=twsrc%5Etfw&#34;&gt;@mipazos&lt;/a&gt; &lt;a href=&#34;https://twitter.com/simongerman600?ref_src=twsrc%5Etfw&#34;&gt;@simongerman600&lt;/a&gt; &lt;a href=&#34;https://twitter.com/openstreetmap?ref_src=twsrc%5Etfw&#34;&gt;@openstreetmap&lt;/a&gt; &lt;a href=&#34;https://t.co/eIUx2yn7ej&#34;&gt;pic.twitter.com/eIUx2yn7ej&lt;/a&gt;&lt;/p&gt;&amp;mdash; Dominic Royé (@dr_xeo) &lt;a href=&#34;https://twitter.com/dr_xeo/status/967811548646379521?ref_src=twsrc%5Etfw&#34;&gt;February 25, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/p&gt;
&lt;p&gt;How can you obtain this data?&lt;/p&gt;
&lt;p&gt;Well, in this case I used points of interest (POIs) from the database of &lt;em&gt;Open Street Maps&lt;/em&gt; (OSM). Obviously OSM not only contains streets and highways, but also information that can be useful when we use a map such as locations of hospitals or gas stations. To avoid downloading the entire OSM and extracting the required information, you can use an &lt;em&gt;overpass API&lt;/em&gt;, which allows us to query the OSM database with our own criteria.&lt;/p&gt;
&lt;p&gt;An easy way to access an &lt;em&gt;overpass API&lt;/em&gt; is through &lt;a href=&#34;http://overpass-turbo.eu&#34;&gt;overpass-turbo.eu&lt;/a&gt;, which even includes a wizard to build a query and display the results on a interactive map. A detailed explanation of the previous web can be found &lt;a href=&#34;https://wiki.openstreetmap.org/wiki/ES:Overpass_turbo&#34;&gt;here&lt;/a&gt;.
However, we have at our disposal a package &lt;em&gt;osmdata&lt;/em&gt; that allows us to create and make queries directly from the R environment. Nevertheless, the use of the &lt;em&gt;overpass-turbo.eu&lt;/em&gt; can be useful when we are not sure what we are looking for or when we have some difficulty in building the query.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;accessing-the-overpass-api-from-r&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Accessing the overpass API from R&lt;/h2&gt;
&lt;p&gt;The first step is to install several packages, in case they are not installed. In almost all my scripts I use &lt;a href=&#34;https://www.tidyverse.org/&#34;&gt;&lt;em&gt;tidyverse&lt;/em&gt;&lt;/a&gt; which is a fundamental collection of different packages, including &lt;em&gt;dplyr&lt;/em&gt; (data manipulation), &lt;em&gt;ggplot2&lt;/em&gt; (visualization), etc. The &lt;a href=&#34;https://r-spatial.github.io/sf/articles/sf1.html&#34;&gt;&lt;em&gt;sf&lt;/em&gt;&lt;/a&gt; package is the new standard for working with spatial data and is compatible with &lt;em&gt;ggplot2&lt;/em&gt; and &lt;em&gt;dplyr&lt;/em&gt;. Finally, &lt;a href=&#34;http://stat405.had.co.nz/ggmap.pdf&#34;&gt;&lt;em&gt;ggmap&lt;/em&gt;&lt;/a&gt; makes it easier for us to create maps.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install the osmdata, sf, tidyverse and ggmap package
if(!require(&amp;quot;osmdata&amp;quot;)) install.packages(&amp;quot;osmdata&amp;quot;)
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;sf&amp;quot;)) install.packages(&amp;quot;sf&amp;quot;)
if(!require(&amp;quot;ggmap&amp;quot;)) install.packages(&amp;quot;ggmap&amp;quot;)

#load packages
library(tidyverse)
library(osmdata)
library(sf)
library(ggmap)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;build-a-query&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Build a query&lt;/h2&gt;
&lt;p&gt;Before creating a query, we need to know what we can filter. The &lt;code&gt;available_features( )&lt;/code&gt; function returns a list of available OSM features that have different tags. More details are available in the OSM &lt;em&gt;wiki&lt;/em&gt; &lt;a href=&#34;https://wiki.openstreetmap.org/wiki/Map_Features&#34;&gt;here&lt;/a&gt;.
For example, the feature &lt;em&gt;shop&lt;/em&gt; contains several tags among others &lt;em&gt;supermarket&lt;/em&gt;, &lt;em&gt;fishing&lt;/em&gt;, &lt;em&gt;books&lt;/em&gt;, etc.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#the first five features
head(available_features())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;4wd_only&amp;quot;  &amp;quot;abandoned&amp;quot; &amp;quot;abutters&amp;quot;  &amp;quot;access&amp;quot;    &amp;quot;addr&amp;quot;      &amp;quot;addr:city&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#amenities
head(available_tags(&amp;quot;amenity&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;animal_boarding&amp;quot; &amp;quot;animal_breeding&amp;quot; &amp;quot;animal_shelter&amp;quot;  &amp;quot;arts_centre&amp;quot;    
## [5] &amp;quot;atm&amp;quot;             &amp;quot;baby_hatch&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#shops
head(available_tags(&amp;quot;shop&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;agrarian&amp;quot;  &amp;quot;alcohol&amp;quot;   &amp;quot;anime&amp;quot;     &amp;quot;antiques&amp;quot;  &amp;quot;appliance&amp;quot; &amp;quot;art&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;the-first-query-where-are-cinemas-in-madrid&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The first query: Where are cinemas in Madrid?&lt;/h3&gt;
&lt;p&gt;To build the query, we use the &lt;em&gt;pipe operator&lt;/em&gt; &lt;code&gt;%&amp;gt;%&lt;/code&gt;, which helps to chain several functions without assigning the result to a new object. Its use is very extended especially within the &lt;em&gt;tidyverse&lt;/em&gt; package collection. If you want to know more about its use, you can find &lt;a href=&#34;https://www.datacamp.com/community/tutorials/pipe-r-tutorial&#34;&gt;here&lt;/a&gt; a tutorial.&lt;/p&gt;
&lt;p&gt;In the first part of the query we need to indicate the place where we want to extract the information. The &lt;code&gt;getbb( )&lt;/code&gt; function creates a boundering box for a given place, looking for the name. The main function is &lt;code&gt;opq( )&lt;/code&gt; which build the final query. We add our filter criteria with the &lt;code&gt;add_osm_feature( )&lt;/code&gt; function. In this first query we will look for cinemas in Madrid. That’s why we use as key &lt;em&gt;amenity&lt;/em&gt; and &lt;em&gt;cinema&lt;/em&gt; as tag. There are several formats to obtain the resulting spatial data of the query. The &lt;code&gt;osmdata_*( )&lt;/code&gt; function sends the query to the server and, depending on the suffix * sf/sp/xml, returns a &lt;em&gt;simple feature&lt;/em&gt;, &lt;em&gt;spatial&lt;/em&gt; or &lt;em&gt;XML&lt;/em&gt; format.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#building the query
q &amp;lt;- getbb(&amp;quot;Madrid&amp;quot;) %&amp;gt;%
      opq() %&amp;gt;%
       add_osm_feature(&amp;quot;amenity&amp;quot;, &amp;quot;cinema&amp;quot;)

str(q) #query structure&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 4
##  $ bbox    : chr &amp;quot;40.3119774,-3.8889539,40.6437293,-3.5179163&amp;quot;
##  $ prefix  : chr &amp;quot;[out:xml][timeout:25];\n(\n&amp;quot;
##  $ suffix  : chr &amp;quot;);\n(._;&amp;gt;;);\nout body;&amp;quot;
##  $ features: chr &amp;quot; [\&amp;quot;amenity\&amp;quot;=\&amp;quot;cinema\&amp;quot;]&amp;quot;
##  - attr(*, &amp;quot;class&amp;quot;)= chr [1:2] &amp;quot;list&amp;quot; &amp;quot;overpass_query&amp;quot;
##  - attr(*, &amp;quot;nodes_only&amp;quot;)= logi FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cinema &amp;lt;- osmdata_sf(q)
cinema&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Object of class &amp;#39;osmdata&amp;#39; with:
##                  $bbox : 40.3119774,-3.8889539,40.6437293,-3.5179163
##         $overpass_call : The call submitted to the overpass API
##                  $meta : metadata including timestamp and version numbers
##            $osm_points : &amp;#39;sf&amp;#39; Simple Features Collection with 197 points
##             $osm_lines : NULL
##          $osm_polygons : &amp;#39;sf&amp;#39; Simple Features Collection with 11 polygons
##        $osm_multilines : NULL
##     $osm_multipolygons : NULL&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that the result is a list of different spatial objects. In our case, we are only interested in &lt;em&gt;osm_points&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;How can we visulise these points?&lt;/p&gt;
&lt;p&gt;The advantage of &lt;em&gt;sf&lt;/em&gt; objects is that for &lt;em&gt;ggplot2&lt;/em&gt; already exists a geometry function &lt;code&gt;geom_sf( )&lt;/code&gt;. Furthermore, we can include a background map using &lt;em&gt;ggmap&lt;/em&gt;. The &lt;code&gt;get_map( )&lt;/code&gt; function downloads the map for a given place. Alternatively, it can be an address, latitude/longitude or a bounding box. The &lt;em&gt;maptype&lt;/em&gt; argument allows us to indicate the style or type of map. You can find more details in the help of the &lt;code&gt;?get_map&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;When we build a graph with &lt;em&gt;ggplot&lt;/em&gt; we usually start with &lt;code&gt;ggplot( )&lt;/code&gt;. In this case, we start with &lt;code&gt;ggmap( )&lt;/code&gt; that includes the object with our background map. Then we add with &lt;code&gt;geom_sf( )&lt;/code&gt; the points of the cinemas in Madrid. It is important to indicate with the argument &lt;em&gt;inherit.aes = FALSE&lt;/em&gt; that it has to use the &lt;em&gt;aesthetic mappings&lt;/em&gt; of the spatial object &lt;em&gt;osm_points&lt;/em&gt;. In addition, we change the color, fill, transparency (&lt;em&gt;alpha&lt;/em&gt;), type and size of the circles.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#our background map
mad_map &amp;lt;- get_map(getbb(&amp;quot;Madrid&amp;quot;), maptype = &amp;quot;toner-background&amp;quot;)

#final map
ggmap(mad_map)+
  geom_sf(data = cinema$osm_points,
          inherit.aes = FALSE,
          colour = &amp;quot;#238443&amp;quot;,
          fill = &amp;quot;#004529&amp;quot;,
          alpha = .5,
          size = 4,
          shape = 21)+
  labs(x = &amp;quot;&amp;quot;, y = &amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2018/accessing-openstreetmap-data-with-r/index.en_files/figure-html/fig.width==5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;where-can-we-find-mercadona-supermarkets&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Where can we find Mercadona supermarkets?&lt;/h3&gt;
&lt;p&gt;Instead of obtaining a bounding box with the function &lt;em&gt;getbb( )&lt;/em&gt; we can build our own box. To do this, we create a vector of four elements, the order has to be West/South/East/North. In the query we use two features: &lt;em&gt;name&lt;/em&gt; and &lt;em&gt;shop&lt;/em&gt; to filter supermarkets that are of this particular brand. Depending on the area or volume of the query, it is necessary to extend the waiting time. By default, the limit is set at 25 seconds (&lt;em&gt;timeout&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;The map, we create in this case, consists only of the supermarket points. Therefore, we use the usual grammar by adding the geometry &lt;code&gt;geom_sf( )&lt;/code&gt;. The &lt;code&gt;theme_void( )&lt;/code&gt; function removes everything except for the points.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#bounding box for the Iberian Peninsula
m &amp;lt;- c(-10, 30, 5, 46)

#building the query
q &amp;lt;- m %&amp;gt;% 
      opq (timeout = 25*100) %&amp;gt;%
         add_osm_feature(&amp;quot;name&amp;quot;, &amp;quot;Mercadona&amp;quot;) %&amp;gt;%
         add_osm_feature(&amp;quot;shop&amp;quot;, &amp;quot;supermarket&amp;quot;)

#query
mercadona &amp;lt;- osmdata_sf(q)

#final map
ggplot(mercadona$osm_points)+
  geom_sf(colour = &amp;quot;#08519c&amp;quot;,
          fill = &amp;quot;#08306b&amp;quot;,
          alpha = .5,
          size = 1,
          shape = 21)+
  theme_void()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2018/accessing-openstreetmap-data-with-r/index.en_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
      
            <category>database</category>
      
            <category>overpass API</category>
      
            <category>OSM</category>
      
            <category>Point of interest</category>
      
      
            <category>visualization</category>
      
            <category>R:elementary</category>
      
            <category>R</category>
      
            <category>mapping</category>
      
    </item>
    
    <item>
      <title>Access to climate reanalysis data from R</title>
      <link>https://dominicroye.github.io/en/2018/access-to-climate-reanalysis-data-from-r/</link>
      <pubDate>Sat, 15 Sep 2018 10:59:44 +0100</pubDate>
      
      <guid>https://dominicroye.github.io/en/2018/access-to-climate-reanalysis-data-from-r/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;1&lt;/span&gt; Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ncep&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2&lt;/span&gt; NCEP&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#packages&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.1&lt;/span&gt; Packages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-download&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.2&lt;/span&gt; Data download&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#monthly-average&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.3&lt;/span&gt; Monthly average&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#visualization&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.4&lt;/span&gt; Visualization&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#era-interim&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3&lt;/span&gt; ERA-Interim&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#installation&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.1&lt;/span&gt; Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#connection-and-download-with-the-ecmwf-api&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.2&lt;/span&gt; Connection and download with the ECMWF API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#processing-ncdf&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.3&lt;/span&gt; Processing ncdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#update-for-accessing-era-5&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4&lt;/span&gt; Update for accessing ERA-5&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;A friend advised me to introduce R levels as categories. An idea that I now add to each blog post. There are three levels: elementary, intermediate, and advanced. I hope it will help the reader and the R user.&lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Introduction&lt;/h1&gt;
&lt;p&gt;In this post, I will show how we can download and work directly with data from climatic reanalysis in R. These kind of datasets are a combination of forcast models and data assimilation systems, which allows us to create corrected global grids of recent history of the atmosphere, land surface, and oceans. The two most used reanalyses are &lt;a href=&#34;https://climatedataguide.ucar.edu/climate-data/ncep-reanalysis-r2&#34;&gt;NCEP-DO&lt;/a&gt; (Reanalysis II) from the &lt;em&gt;NOAA/OAR/ESRL&lt;/em&gt;, an improved version of &lt;em&gt;NCEP-NCAR&lt;/em&gt; (Reanalysis I), and &lt;em&gt;ERA-Interim&lt;/em&gt; from the &lt;a href=&#34;https://www.ecmwf.int/en/research/climate-reanalysis&#34;&gt;&lt;em&gt;ECMWF&lt;/em&gt;&lt;/a&gt;. Since &lt;em&gt;NCEP-DO&lt;/em&gt; is the first generation, it is recommended to use third-generation climate reanalysis, especially &lt;em&gt;ERA-Interim&lt;/em&gt;. An overview of the current atmospheric reanalysis can be found &lt;a href=&#34;https://reanalyses.org/index.php/atmosphere/overview-current-atmospheric-reanalyses&#34;&gt;here&lt;/a&gt;. First, let’s see how to access the &lt;em&gt;NCEP&lt;/em&gt; data through an R library on &lt;em&gt;CRAN&lt;/em&gt; that facilitates the download and handling of the data. Then we will do the same with the &lt;em&gt;ERA-Interim&lt;/em&gt;, however, to access this last reanalysis dataset it is necessary to use &lt;em&gt;python&lt;/em&gt; and the corresponding API of the &lt;em&gt;ECMWF&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ncep&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; NCEP&lt;/h1&gt;
&lt;p&gt;To access the &lt;em&gt;NCEP&lt;/em&gt; reanalysis it is required to install the corresponding package &lt;em&gt;RNCEP&lt;/em&gt;. The main function is &lt;code&gt;NCEP.gather( )&lt;/code&gt;. The resolution of the &lt;em&gt;NCEP&lt;/em&gt; reanalysis is 2.5º X 2.5º.&lt;/p&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.1&lt;/span&gt; Packages&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install the RNCEP, lubridate and tidyverse packages
if(!require(&amp;quot;RNCEP&amp;quot;)) install.packages(&amp;quot;RNCEP&amp;quot;)
if(!require(&amp;quot;lubridate&amp;quot;)) install.packages(&amp;quot;lubridate&amp;quot;)
if(!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)
if(!require(&amp;quot;sf&amp;quot;)) install.packages(&amp;quot;sf&amp;quot;)

#load the packages
library(RNCEP)
library(lubridate) #date and time manipulation
library(tidyverse) #data manipulation and visualization
library(RColorBrewer) #color schemes
library(sf) #to import a spatial object and to work with geom_sf in ggplot2&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data-download&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.2&lt;/span&gt; Data download&lt;/h2&gt;
&lt;p&gt;We will download the air temperature of the 850haPa pressure level for the year 2016. The variables and pressure levels can be found in the details of the function &lt;code&gt;?NCEP.gather&lt;/code&gt;. The &lt;em&gt;reanalysis2&lt;/em&gt; argument allows us to download both version I and version II, being by default &lt;em&gt;FALSE&lt;/em&gt;, that is, we access reanalysis I. In all the requests we will obtain data of every 6 hours (00:00, 06:00, 12:00 and 18:00). This supposes a total of 1464 values for the year 2016.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#define the necessary arguments
month_range &amp;lt;- c(1,12)     #period of months
year_range &amp;lt;- c(2016,2016) #period of years

lat_range &amp;lt;- c(30,60)      #latitude range
lon_range &amp;lt;- c(-30,50)     #longitude range
 

data &amp;lt;- NCEP.gather(&amp;quot;air&amp;quot;,    #name of the variable
                    850, #pressure level 850hPa
                    month_range,year_range,
                    lat_range,lon_range,
                    return.units = TRUE,
                    reanalysis2=TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] Units of variable &amp;#39;air&amp;#39; are degK
## [1] Units of variable &amp;#39;air&amp;#39; are degK&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#dimensions                    
dim(data) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]   13   33 1464&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#we find lon, lat and time with dimnames()
#date and time
date_time &amp;lt;- dimnames(data)[[3]]
date_time &amp;lt;- ymd_h(date_time)
head(date_time)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2016-01-01 00:00:00 UTC&amp;quot; &amp;quot;2016-01-01 06:00:00 UTC&amp;quot;
## [3] &amp;quot;2016-01-01 12:00:00 UTC&amp;quot; &amp;quot;2016-01-01 18:00:00 UTC&amp;quot;
## [5] &amp;quot;2016-01-02 00:00:00 UTC&amp;quot; &amp;quot;2016-01-02 06:00:00 UTC&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#longitude and latitude
lat &amp;lt;- dimnames(data)[[1]]
lon &amp;lt;- dimnames(data)[[2]]
head(lon);head(lat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;-30&amp;quot;   &amp;quot;-27.5&amp;quot; &amp;quot;-25&amp;quot;   &amp;quot;-22.5&amp;quot; &amp;quot;-20&amp;quot;   &amp;quot;-17.5&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;60&amp;quot;   &amp;quot;57.5&amp;quot; &amp;quot;55&amp;quot;   &amp;quot;52.5&amp;quot; &amp;quot;50&amp;quot;   &amp;quot;47.5&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;monthly-average&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.3&lt;/span&gt; Monthly average&lt;/h2&gt;
&lt;p&gt;We see that the downloaded data is an &lt;em&gt;array&lt;/em&gt; of three dimensions with [lat, lon, time]. As above mentioned, we extracted latitude, longitude and time. The temperature is given in Kelvin. The objective in the next section will be to show two maps comparing January and July.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#create our grouping variable
group &amp;lt;- month(date_time) 

#estimate the average temperature by month 
data_month &amp;lt;- aperm(
  apply(
    data, #our data
    c(1,2), #apply to each time series 1:row, 2:column a the mean( ) function
    by, #group by
    group, #months
    function(x)ifelse(all(is.na(x)),NA,mean(x))),
  c(2,3,1)) #reorder to get an array like the original

dim(data_month) #850haPa temperature per month January to December&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 13 33 12&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;visualization&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.4&lt;/span&gt; Visualization&lt;/h2&gt;
&lt;p&gt;Once we got here, we can visualize the 850hPa temperature of January and July with &lt;em&gt;ggplot2&lt;/em&gt;. In this example, I use &lt;code&gt;geom_sf( )&lt;/code&gt; from the library &lt;a href=&#34;https://github.com/r-spatial/sf&#34;&gt;&lt;em&gt;sf&lt;/em&gt;&lt;/a&gt;, which makes the work easier to visualize spatial objects in &lt;em&gt;ggplot&lt;/em&gt; (in the near future I will make a post about &lt;em&gt;sf&lt;/em&gt; and &lt;em&gt;ggplot&lt;/em&gt;). In the dimension of latitude and longitude we saw that it only indicates a value for each row and column. But we need the coordinates of all the cells in the matrix. To create all combinations between two variables we can use the &lt;code&gt;expand.grid( )&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#first we create all the combinations of lon-lat
lonlat &amp;lt;- expand.grid(lon=lon,lat=lat)

#as lonlat was a row/column name, it is character, that&amp;#39;s why we convert it into numeric
lonlat &amp;lt;- apply(lonlat,2,as.numeric)

#lon and lat are not in the order as we expect
#row=lon; column=lat
data_month &amp;lt;- aperm(data_month,c(2,1,3))

#subtract 273.15K to convert K to ºC.
df &amp;lt;- data.frame(lonlat,
                 Ta01=as.vector(data_month[,,1])-273.15,
                 Ta07=as.vector(data_month[,,7])-273.15)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before we can make the map with &lt;em&gt;ggplot2&lt;/em&gt;, we have to adapt the table. The shapefile with the countries limits can be downloaded &lt;a href=&#34;https://dominicroye.github.io/files/CNTR_RG_03M_2014.zip&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#convert the wide table into a long one
df &amp;lt;- gather(df,month,Ta,Ta01:Ta07)%&amp;gt;%
             mutate(month=factor(month,unique(month),c(&amp;quot;Jan&amp;quot;,&amp;quot;Jul&amp;quot;)))

#import the countries limits
limit &amp;lt;- st_read(&amp;quot;CNTR_RG_03M_2014.shp&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Reading layer `CNTR_RG_03M_2014&amp;#39; from data source `C:\Users\xeo19\Documents\GitHub\blogR_update\content\post\en\2018-09-15-access-to-climate-reanalysis-data-from-r\CNTR_RG_03M_2014.shp&amp;#39; using driver `ESRI Shapefile&amp;#39;
## Simple feature collection with 256 features and 3 fields
## geometry type:  MULTIPOLYGON
## dimension:      XY
## bbox:           xmin: -180 ymin: -90 xmax: 180 ymax: 83.66068
## epsg (SRID):    NA
## proj4string:    +proj=longlat +ellps=GRS80 +no_defs&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#color scheme
colbr &amp;lt;- brewer.pal(11,&amp;quot;RdBu&amp;quot;)

ggplot(df)+
      geom_tile(aes(lon,lat,fill=Ta))+ #temperature data
      geom_sf(data=limit,fill=NA,size=.5)+ #limits 
        scale_fill_gradientn(colours=rev(colbr))+
          coord_sf(ylim=c(30,60),xlim=c(-30,50))+
          scale_x_continuous(breaks=seq(-30,50,10),expand=c(0,0))+
          scale_y_continuous(breaks=seq(30,60,5),expand=c(0,0))+
          labs(x=&amp;quot;&amp;quot;,y=&amp;quot;&amp;quot;,fill=&amp;quot;Ta 850hPa (ºC)&amp;quot;)+
           facet_grid(month~.)+ #plot panels by month
             theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/post/en/2018-09-15-access-to-climate-reanalysis-data-from-r/index.en_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;era-interim&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; ERA-Interim&lt;/h1&gt;
&lt;p&gt;The &lt;em&gt;ECMWF&lt;/em&gt; offers access to its public databases from a &lt;a href=&#34;https://confluence.ecmwf.int//display/WEBAPI/Access+ECMWF+Public+Datasets&#34;&gt;&lt;em&gt;pyhton-API&lt;/em&gt;&lt;/a&gt;. It is required to be registered on the &lt;em&gt;ECMWF&lt;/em&gt; website. You can register &lt;a href=&#34;https://apps.ecmwf.int/registration/&#34;&gt;here&lt;/a&gt;. When dealing with another programming language, in R we have to use an interface between both which allows the library &lt;a href=&#34;https://github.com/rstudio/reticulate&#34;&gt;&lt;em&gt;reticulate&lt;/em&gt;&lt;/a&gt;. We must also have installed a pyhton distribution (version 2.x or 3.x). In the case of Windows we can use &lt;a href=&#34;https://www.anaconda.com/download/&#34;&gt;anaconda&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  
Recently a new package called &lt;code&gt;ecmwfr&lt;/code&gt; has been published that facilitates accessing the Copernicus and ECMWF APIs. The major advantage is that it is not necessary to install &lt;code&gt;python&lt;/code&gt;. More details &lt;a href=&#34;https://github.com/khufkens/ecmwfr&#34;&gt;here&lt;/a&gt;.

&lt;/div&gt;
&lt;/p&gt;
&lt;div id=&#34;installation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.1&lt;/span&gt; Installation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if(!require(&amp;quot;reticulate&amp;quot;)) install.packages(&amp;quot;reticulate&amp;quot;)
if(!require(&amp;quot;ncdf4&amp;quot;)) install.packages(&amp;quot;ncdf4&amp;quot;) #to manage netCDF format

#load packages
library(reticulate)
library(ncdf4)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once we have installed &lt;em&gt;anaconda&lt;/em&gt; and the package &lt;em&gt;reticulate&lt;/em&gt;, we can install the library &lt;em&gt;python ecmwfapi&lt;/em&gt;. We can carry out the installation, or through the Windows CMD using the command &lt;em&gt;conda install -c conda-forge ecmwf-api-client&lt;/em&gt;, or with the R function &lt;code&gt;py_install( )&lt;/code&gt; from the &lt;em&gt;reticulate&lt;/em&gt; package. The same function allows us to install any &lt;em&gt;python&lt;/em&gt; library from R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install the python ECMWF API
py_install(&amp;quot;ecmwf-api-client&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;connection-and-download-with-the-ecmwf-api&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.2&lt;/span&gt; Connection and download with the ECMWF API&lt;/h2&gt;
&lt;p&gt;In order to access the API, it is required to create a file with the user’s information.&lt;/p&gt;
&lt;p&gt;The “.ecmwfapirc” file must contain the following information:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
    &amp;quot;url&amp;quot;   : &amp;quot;https://api.ecmwf.int/v1&amp;quot;,
    &amp;quot;key&amp;quot;   : &amp;quot;XXXXXXXXXXXXXXXXXXXXXX&amp;quot;,
    &amp;quot;email&amp;quot; : &amp;quot;john.smith@example.com&amp;quot;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The key can be obtained with the user account &lt;a href=&#34;https://api.ecmwf.int/v1/key/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The file can be created with the Windows notebook.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;We create a document “ecmwfapirc.txt”.&lt;/li&gt;
&lt;li&gt;Rename this file to “.ecmwfapirc.”&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The last point disappears automatically. Then we save this file in “C:/USERNAME/.ecmwfapirc” or “C:/USERNAME/Documents/.ecmwfapirc”.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#import the python library ecmwfapi
ecmwf &amp;lt;- import(&amp;#39;ecmwfapi&amp;#39;)

#for this step there must exist the file .ecmwfapirc
server = ecmwf$ECMWFDataServer() #start the connection&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One we get here, how do we create a query? The easiest thing is to go to the website of &lt;a href=&#34;http://apps.ecmwf.int/datasets/data/interim-full-daily/levtype=sfc/&#34;&gt;&lt;em&gt;ECMWF&lt;/em&gt;&lt;/a&gt;, where we choose the database, in this case &lt;em&gt;ERA-Interim&lt;/em&gt; surface, to create a script with all the necessary data. More details about the syntax can be found &lt;a href=&#34;https://confluence.ecmwf.int/display/WEBAPI/Brief+request+syntax&#34;&gt;here&lt;/a&gt;. When we proceed on the website, we only have to click on “View MARS Request”. This step takes us to the script in &lt;em&gt;python&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/img/erainterim1.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/img/erainterim2.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;With the syntax of the script from the &lt;em&gt;MARS Request&lt;/em&gt;, we can create the query in R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#we create the query
query &amp;lt;-r_to_py(list(
  class=&amp;#39;ei&amp;#39;,
  dataset= &amp;quot;interim&amp;quot;, #dataset
  date= &amp;quot;2017-01-01/to/2017-12-31&amp;quot;, #time period
  expver= &amp;quot;1&amp;quot;,
  grid= &amp;quot;0.125/0.125&amp;quot;, #resolution
  levtype=&amp;quot;sfc&amp;quot;,
  param= &amp;quot;167.128&amp;quot;, # air temperature (2m)
  area=&amp;quot;45/-10/30/5&amp;quot;, #N/W/S/E
  step= &amp;quot;0&amp;quot;,
  stream=&amp;quot;oper&amp;quot;,
  time=&amp;quot;00:00:00/06:00:00/12:00:00/18:00:00&amp;quot;, #hours
  type=&amp;quot;an&amp;quot;,
  format= &amp;quot;netcdf&amp;quot;, #format
  target=&amp;#39;ta2017.nc&amp;#39; #file name
))

#query to get the ncdf
server$retrieve(query)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The result is a netCDF file that we can process with the library &lt;em&gt;ncdf4&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;processing-ncdf&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.3&lt;/span&gt; Processing ncdf&lt;/h2&gt;
&lt;p&gt;In the next section, the objective will be the extraction of a time serie from the closest coordinate to a given one. We will use the coordinates of Madrid (40.418889, -3.691944).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#load packages
library(sf)
library(ncdf4)
library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#open the connection with the ncdf file
nc &amp;lt;- nc_open(&amp;quot;ta2017.nc&amp;quot;)

#extract lon and lat
lat &amp;lt;- ncvar_get(nc,&amp;#39;latitude&amp;#39;)
lon &amp;lt;- ncvar_get(nc,&amp;#39;longitude&amp;#39;)
dim(lat);dim(lon)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 121&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 121&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#extract the time
t &amp;lt;- ncvar_get(nc, &amp;quot;time&amp;quot;)

#time unit: hours since 1900-01-01
ncatt_get(nc,&amp;#39;time&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $units
## [1] &amp;quot;hours since 1900-01-01 00:00:00.0&amp;quot;
## 
## $long_name
## [1] &amp;quot;time&amp;quot;
## 
## $calendar
## [1] &amp;quot;gregorian&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#convert the hours into date + hour
#as_datetime() function of the lubridate package needs seconds
timestamp &amp;lt;- as_datetime(c(t*60*60),origin=&amp;quot;1900-01-01&amp;quot;)

#import the data
data &amp;lt;- ncvar_get(nc,&amp;quot;t2m&amp;quot;)

#close the conection with the ncdf file
nc_close(nc)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this next section we use the &lt;em&gt;sf&lt;/em&gt; package, which is replacing the well known &lt;em&gt;sp&lt;/em&gt; and &lt;em&gt;rgdal&lt;/em&gt; packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#create all the combinations of lon-lat
lonlat &amp;lt;- expand.grid(lon=lon,lat=lat)

#we must convert the coordinates in a spatial object sf
#we also indicate the coordinate system in EPSG code
coord &amp;lt;- st_as_sf(lonlat,coords=c(&amp;quot;lon&amp;quot;,&amp;quot;lat&amp;quot;))%&amp;gt;%
                    st_set_crs(4326)

#we do the same with our coordinate of Madrid
psj &amp;lt;- st_point(c(-3.691944,40.418889))%&amp;gt;%
                   st_sfc()%&amp;gt;%
                     st_set_crs(4326)

#plot all points
plot(st_geometry(coord))
plot(psj,add=TRUE,pch = 3, col = &amp;#39;red&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/post/en/2018-09-15-access-to-climate-reanalysis-data-from-r/index.en_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the next steps we calculate the distance of our reference point to all the grid points. Then we look for the one with less distance.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#add the distance to the points
coord &amp;lt;- mutate(coord,dist=st_distance(coord,psj))

#create a distance matrix with the same dimensions as our data
dist_mat &amp;lt;- matrix(coord$dist,dim(data)[-3])

#the arrayInd function is useful to obtain the row and column indexes
mat_index &amp;lt;- as.vector(arrayInd(which.min(dist_mat), dim(dist_mat)))

#we extract the time serie and change the unit from K to ºC
#we convert the time in date + hour
df &amp;lt;- data.frame(ta=data[mat_index[1],mat_index[2],],time=timestamp)%&amp;gt;%
        mutate(ta=ta-273.15,time=ymd_hms(time))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we visualize our time series.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(df,
       aes(time,ta))+
    geom_line()+
    labs(y=&amp;quot;Temperature (ºC)&amp;quot;,
             x=&amp;quot;&amp;quot;)+
    theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/post/en/2018-09-15-access-to-climate-reanalysis-data-from-r/index.en_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;update-for-accessing-era-5&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;4&lt;/span&gt; Update for accessing ERA-5&lt;/h1&gt;
&lt;p&gt;Recently the new reanalysis ERA-5 with &lt;a href=&#34;https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=overview&#34;&gt;single level&lt;/a&gt; or &lt;a href=&#34;https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-pressure-levels?tab=overview&#34;&gt;pressure level&lt;/a&gt; was made available to users. It is the fifth generation of the European Center for Medium-Range Weather Forecasts (ECMWF) and accessible through a new Copernicus API. The ERA-5 reanalysis has a temporary coverage from 1950 to the present at a horizontal resolution of 30km worldwide, with 137 levels from the surface to a height of 80km. An important difference with respect to the previous ERA-Interim is the temporal resolution with hourly data.&lt;/p&gt;
&lt;p&gt;The access changes to the Climate Data Store (CDS) infrastructure with its own API. It is possible to download directly from the web or using the Python API in a similar way to the one already presented in this post. However, there are slight differences which I will explain below.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;It is necessary to have a Copernicus CDS account &lt;a href=&#34;https://cds.climate.copernicus.eu/user/register&#34;&gt;link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Again, you need a account key &lt;a href=&#34;https://cds.climate.copernicus.eu/api-how-to&#34;&gt;link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;There are changes in the Python library and in some arguments of the query.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#load libraries 
library(sf)
library(ncdf4)
library(tidyverse)
library(reticulate)

#install the CDS API
conda_install(&amp;quot;r-reticulate&amp;quot;,&amp;quot;cdsapi&amp;quot;, pip=TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To be able to access the API, a requirement is to create a file with the user’s information.&lt;/p&gt;
&lt;p&gt;The “.cdsapirc” file must contain the following information:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
url: https://cds.climate.copernicus.eu/api/v2
key: {uid}:{api-key}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The key can be obtained with the user account in the &lt;em&gt;User profile&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The file can be created in the same way as it has been explained for ERA-Interim.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#import python CDS-API
cdsapi &amp;lt;- import(&amp;#39;cdsapi&amp;#39;)

#for this step there must exist the file .cdsapirc
server = cdsapi$Client() #start the connection&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the syntax of the script from the &lt;em&gt;Show API request&lt;/em&gt; &lt;a href=&#34;https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=overview&#34;&gt;single level&lt;/a&gt;, we can create the query in R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#we create the query
query &amp;lt;- r_to_py(list(
    variable= &amp;quot;2m_temperature&amp;quot;,
    product_type= &amp;quot;reanalysis&amp;quot;,
    year= &amp;quot;2018&amp;quot;,
    month= &amp;quot;07&amp;quot;, #formato: &amp;quot;01&amp;quot;,&amp;quot;01&amp;quot;, etc.
    day= str_pad(1:31,2,&amp;quot;left&amp;quot;,&amp;quot;0&amp;quot;),   
    time= str_c(0:23,&amp;quot;00&amp;quot;,sep=&amp;quot;:&amp;quot;)%&amp;gt;%str_pad(5,&amp;quot;left&amp;quot;,&amp;quot;0&amp;quot;),
    format= &amp;quot;netcdf&amp;quot;,
    area = &amp;quot;45/-20/35/5&amp;quot; # North, West, South, East
  ))

#query to get the ncdf
server$retrieve(&amp;quot;reanalysis-era5-single-levels&amp;quot;,
                  query,
                 &amp;quot;era5_ta_2018.nc&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is possible that the first time an error message is received, given that the required terms and conditions have not yet been accepted. Simply, the indicated link should be followed.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Error in py_call_impl(callable, dots$args, dots$keywords) : 
  Exception: Client has not agreed to the required terms and conditions.. To access this resource, you first need to accept the termsof &amp;#39;Licence to Use Copernicus Products&amp;#39; at https://cds.climate.copernicus.eu/cdsapp/#!/terms/licence-to-use-copernicus-products&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From here we can follow the same steps as with ERA-Interim.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#open the connection with the file
nc &amp;lt;- nc_open(&amp;quot;era5_ta_2018.nc&amp;quot;)

#extract lon, lat
lat &amp;lt;- ncvar_get(nc,&amp;#39;latitude&amp;#39;)
lon &amp;lt;- ncvar_get(nc,&amp;#39;longitude&amp;#39;)
dim(lat);dim(lon)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 41&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 101&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#extract time
t &amp;lt;- ncvar_get(nc, &amp;quot;time&amp;quot;)

#time unit: hours from 1900-01-01
ncatt_get(nc,&amp;#39;time&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $units
## [1] &amp;quot;hours since 1900-01-01 00:00:00.0&amp;quot;
## 
## $long_name
## [1] &amp;quot;time&amp;quot;
## 
## $calendar
## [1] &amp;quot;gregorian&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#we convert the hours into date+time 
#as_datetime from lubridate needs seconds
timestamp &amp;lt;- as_datetime(c(t*60*60),origin=&amp;quot;1900-01-01&amp;quot;)

#temperatures in K from july 2018
head(timestamp)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2018-07-01 00:00:00 UTC&amp;quot; &amp;quot;2018-07-01 01:00:00 UTC&amp;quot;
## [3] &amp;quot;2018-07-01 02:00:00 UTC&amp;quot; &amp;quot;2018-07-01 03:00:00 UTC&amp;quot;
## [5] &amp;quot;2018-07-01 04:00:00 UTC&amp;quot; &amp;quot;2018-07-01 05:00:00 UTC&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#import temperature data
data &amp;lt;- ncvar_get(nc,&amp;quot;t2m&amp;quot;)

#plot 2018-07-01
filled.contour(data[,,1])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/post/en/2018-09-15-access-to-climate-reanalysis-data-from-r/index.en_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#time serie plot for a pixel
plot(data.frame(date=timestamp,
                ta=data[1,5,]),
     type=&amp;quot;l&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/post/en/2018-09-15-access-to-climate-reanalysis-data-from-r/index.en_files/figure-html/unnamed-chunk-18-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#close the conection with the ncdf file
nc_close(nc)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
      
            <category>reanalisis</category>
      
            <category>interim</category>
      
            <category>NCEP/NCAR</category>
      
            <category>era</category>
      
            <category>download</category>
      
            <category>ncdf</category>
      
            <category>access</category>
      
            <category>api</category>
      
            <category>python</category>
      
            <category>ECMWF</category>
      
      
            <category>R</category>
      
            <category>R:intermediate</category>
      
    </item>
    
    <item>
      <title>the pie chart</title>
      <link>https://dominicroye.github.io/en/2018/the-pie-chart/</link>
      <pubDate>Wed, 22 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dominicroye.github.io/en/2018/the-pie-chart/</guid>
      <description>
&lt;script src=&#34;https://dominicroye.github.io/en/2018/the-pie-chart/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Welcome to my blog! I am Dominic Royé, researcher and lecturer of physical geography at the University of Santiago de Compostela. One of my passions is R programming to visualize and analyze any type of data. Hence, my idea of this blog has its origin in my datavis publications I have been cooking in the last year on Twitter on different topics describing the world. In addition, I would like to take advantage of the blog and publish short introductions and explanation on data visualization, management and manipulation in R. I hope you like it. Any suggestion or ideas are welcomed.&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;background&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;I have always wanted to write about the use of the pie chart. The pie chart is widely used in research, teaching, journalism or technical reports. I do not know if it is due to Excel, but even worse than the pie chart itself, is its 3D version (the same for the bar chart). About the 3D versions, I only want to say that they are not recommended, since in these cases the third dimension does not contain any information and therefore it does not help to correctly read the information of the graphic. Regarding the pie chart, among many experts its use is not advised. But why?&lt;/p&gt;
&lt;p&gt;Already in a study conducted by Simkin (1987) they found that the interpretation and processing of angles is more difficult than that of linear forms. Mostly it is easier to read a bar chart than a pie chart. A problem that becomes very visible when we have; 1) too many categories 2) few differences between categories 3) a misuse of colors as legend or 4) comparisons between various pie charts.&lt;/p&gt;
&lt;p&gt;In general, to decide what possible graphic representations exist for our data, I recommend using the website &lt;a href=&#34;https://www.data-to-viz.com&#34;&gt;www.data-to-viz.com&lt;/a&gt; or the &lt;em&gt;Financial Times Visual Vocabulary&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/ft-interactive/chart-doctor/tree/master/visual-vocabulary&#34;&gt;&lt;img src=&#34;https://dominicroye.github.io/img/poster_piepost.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Well, now what alternative ways can we use in R?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;alternatives-to-the-pie-chart&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Alternatives to the pie chart&lt;/h2&gt;
&lt;p&gt;The dataset we will use about the vaccination status of &lt;strong&gt;measles&lt;/strong&gt; correspond to June 2018 in Europe and come from the &lt;a href=&#34;https://ecdc.europa.eu/en/surveillance-atlas-infectious-diseases&#34;&gt;ECDC&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#packages
library(tidyverse)
library(scales)
library(RColorBrewer)

#data
measles &amp;lt;- data.frame(
          vacc_status=c(&amp;quot;Unvaccinated&amp;quot;,&amp;quot;1 Dose&amp;quot;,
                        &amp;quot;&amp;gt;= 2 Dose&amp;quot;,&amp;quot;Unkown Dose&amp;quot;,&amp;quot;Unkown&amp;quot;),
          prop=c(0.75,0.091,0.05,0.012,0.096)
          )

#we order from the highest to the lowest and fix it with a factor

measles &amp;lt;- arrange(measles,
                   desc(prop))%&amp;gt;%
              mutate(vacc_status=factor(vacc_status,vacc_status))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;vacc_status&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;prop&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Unvaccinated&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.750&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Unkown&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.096&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;1 Dose&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.091&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt;= 2 Dose&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.050&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Unkown Dose&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.012&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;bar-plot-or-similar&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Bar plot or similar&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(measles,aes(vacc_status,prop))+
            geom_bar(stat=&amp;quot;identity&amp;quot;)+
             scale_y_continuous(breaks=seq(0,1,.1),
                                labels=percent,    #convert to %
                                limits=c(0,1))+
            labs(x=&amp;quot;&amp;quot;,y=&amp;quot;&amp;quot;)+
            theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2018/the-pie-chart/index.en_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(measles,aes(x=vacc_status,prop,ymin=0,ymax=prop))+
            geom_pointrange()+
             scale_y_continuous(breaks=seq(0,1,.1),
                                labels=percent,    #convert to %
                                limits=c(0,1))+
            labs(x=&amp;quot;&amp;quot;,y=&amp;quot;&amp;quot;)+
            theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2018/the-pie-chart/index.en_files/figure-html/unnamed-chunk-3-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#custom themes definitions
theme_singlebar &amp;lt;- theme_bw()+
  theme(
    legend.position = &amp;quot;bottom&amp;quot;,
    axis.title = element_blank(),
    axis.ticks.y = element_blank(),
    axis.text.y = element_blank(),
    panel.border = element_blank(),
    panel.grid=element_blank(),
    plot.title=element_text(size=14, face=&amp;quot;bold&amp;quot;)
  )

#plot
mutate(measles,
       vacc_status=factor(vacc_status,               #we change the order of the categories
                          rev(levels(vacc_status))))%&amp;gt;%
ggplot(aes(1,prop,fill=vacc_status))+  #we put 1 in x to create a single bar
         geom_bar(stat=&amp;quot;identity&amp;quot;)+
          scale_y_continuous(breaks=seq(0,1,.1),
                             labels=percent,
                             limits=c(0,1),
                             expand=c(.01,.01))+
          scale_x_continuous(expand=c(0,0))+
              scale_fill_brewer(&amp;quot;&amp;quot;,palette=&amp;quot;Set1&amp;quot;)+
                coord_flip()+
                  theme_singlebar&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2018/the-pie-chart/index.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#we expand our data with numbers from Italy
measles2 &amp;lt;- mutate(measles,
                  italy=c(0.826,0.081,0.053,0.013,0.027),
                  vacc_status=factor(vacc_status,rev(levels(vacc_status))))%&amp;gt;%
                rename(europe=&amp;quot;prop&amp;quot;)%&amp;gt;%
                gather(region,prop,europe:italy)

#plot
ggplot(measles2,aes(region,prop,fill=vacc_status))+
            geom_bar(stat=&amp;quot;identity&amp;quot;,position=&amp;quot;stack&amp;quot;)+ #stack bar
             scale_y_continuous(breaks=seq(0,1,.1),
                                labels=percent,    #convert to %
                                limits=c(0,1),
                                expand=c(0,0))+
            scale_fill_brewer(palette = &amp;quot;Set1&amp;quot;)+
            labs(x=&amp;quot;&amp;quot;,y=&amp;quot;&amp;quot;,fill=&amp;quot;Vaccination Status&amp;quot;)+
            theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2018/the-pie-chart/index.en_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;waffle-plot&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Waffle plot&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#package
library(waffle)

#the waffle function uses a vector with names
val_measles &amp;lt;- round(measles$prop*100)
names(val_measles) &amp;lt;- measles$vacc_status

#plot
waffle(val_measles, #data
        colors=brewer.pal(5,&amp;quot;Set1&amp;quot;), #colors
        rows=5) #row number &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2018/the-pie-chart/index.en_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The Waffle chart seems very interesting to me when we want to show a proportion of an individual category.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#data
medida &amp;lt;- c(41,59) #data from the OECD 2015
names(medida) &amp;lt;- c(&amp;quot;Estudios Superiores&amp;quot;,&amp;quot;Otros estudios&amp;quot;)

#plot
waffle(medida,
       colors=c(&amp;quot;#377eb8&amp;quot;,&amp;quot;#bdbdbd&amp;quot;),
       rows=5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2018/the-pie-chart/index.en_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;treemap&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Treemap&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#package
library(treemap)

#plot
treemap(measles,
index=&amp;quot;vacc_status&amp;quot;, #variable with categories
vSize=&amp;quot;prop&amp;quot;,        #values
type=&amp;quot;index&amp;quot;,        #style more in ?treemap
title=&amp;quot;&amp;quot;,            
palette = brewer.pal(5,&amp;quot;Set1&amp;quot;) #colors
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominicroye.github.io/en/2018/the-pie-chart/index.en_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Personally, I think that all types of graphic representations have their advantages and disadvantages. However, we currently have a huge variety of alternatives to avoid using the pie chart. If you still want to make a pie chart, which I would not rule out either, I recommend following certain rules, which you can find very well summarized in a recent &lt;a href=&#34;https://academy.datawrapper.de/article/127-what-to-consider-when-creating-a-pie-chart&#34;&gt;post&lt;/a&gt; by &lt;a href=&#34;https://twitter.com/lisacrost&#34;&gt;Lisa Charlotte Rost&lt;/a&gt;. For example, you should order from the highest to the lowest unless there is a natural order or use a maximum of five categories. Finally, I leave you a link to a &lt;a href=&#34;https://policyviz.com/2018/08/07/dataviz-cheatsheet/&#34;&gt;cheat sheet&lt;/a&gt; from &lt;em&gt;policyviz&lt;/em&gt; with basic rules of data visualization. A good reference on graphics using different programs from Excel to R can be found in the book &lt;em&gt;Creating More Effective Graphs&lt;/em&gt; (Robbins 2013).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
      
            <category>pie chart</category>
      
            <category>data</category>
      
            <category>circular</category>
      
            <category>proportions</category>
      
            <category>first post</category>
      
            <category>treemap</category>
      
            <category>waffle</category>
      
            <category>bar</category>
      
      
            <category>datavis</category>
      
            <category>R</category>
      
            <category>R:elementary</category>
      
    </item>
    
  </channel>
</rss>